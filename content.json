{"meta":{"title":"Sakura        Momoko","subtitle":null,"description":null,"author":"dummerfu","url":"https://dummerfu.top"},"pages":[{"title":"About Me","date":"2020-11-11T22:14:36.000Z","updated":"2022-09-20T15:19:19.431Z","comments":true,"path":"about/index.html","permalink":"https://dummerfu.top/about/index.html","excerpt":"","text":"个人信息： dummerfu XDU智能科学与技术专业本科生 别骂了别骂了 主流都会一点，又都不能应付面试的样子简称半吊子 Github 博客历史 φ(*￣0￣)高中由于打oi就在wordpress莫名奇妙搭了一个博客，但是由于访问太慢就放弃了 之后大学打ACM就在博客园一直写啦，想看之前的博客可以点这里几乎都是刷题文章看到别人的博客美化感觉很nb，就自己也搭了一个。这个博客最开始还是Sakura主题，但是标签外挂很难搞就换成butterfly了又折腾了好久","keywords":"关于"},{"title":"朋友圈","date":"2022-09-20T15:19:19.431Z","updated":"2022-09-20T15:19:19.431Z","comments":false,"path":"circle/index.html","permalink":"https://dummerfu.top/circle/index.html","excerpt":"","text":"与主机通讯中…… var fdataUser = { apiurl: 'https://hexo-circle-of-friends-ten.vercel.app/' }"},{"title":"client","date":"2018-12-20T23:13:35.000Z","updated":"2022-09-20T15:19:19.431Z","comments":false,"path":"client/index.html","permalink":"https://dummerfu.top/client/index.html","excerpt":"","text":"直接下载 or 扫码下载：","keywords":"Android客户端"},{"title":"留言板","date":"2018-12-20T23:13:48.000Z","updated":"2022-09-20T15:19:19.431Z","comments":true,"path":"comment/index.html","permalink":"https://dummerfu.top/comment/index.html","excerpt":"","text":"念两句诗 叙别梦、扬州一觉。 【宋代】吴文英《夜游宫·人去西楼雁杳》","keywords":"留言板"},{"title":"donate","date":"2018-12-20T23:13:05.000Z","updated":"2022-09-20T15:19:19.431Z","comments":false,"path":"donate/index.html","permalink":"https://dummerfu.top/donate/index.html","excerpt":"","text":"","keywords":"谢谢饲主了喵~"},{"title":"lab","date":"2019-01-05T21:47:59.000Z","updated":"2022-09-20T15:19:19.431Z","comments":false,"path":"lab/index.html","permalink":"https://dummerfu.top/lab/index.html","excerpt":"","text":"sakura主题balabala","keywords":"Lab实验室"},{"title":"友人帐","date":"2018-12-19T23:11:06.000Z","updated":"2022-09-20T15:19:19.431Z","comments":true,"path":"links/index.html","permalink":"https://dummerfu.top/links/index.html","excerpt":"","text":"欢迎交换友链 ꉂ(ˊᗜˋ)交换友链的话，先加博主是礼仪哦 😀友链格式我的友链信息- name: 必选 link: 必选 avatar: 必选 descr: 可选 siteshot: 可选- name: dummerfu link: https://dummerfu.top/ avatar: https://cdn.jsdelivr.net/gh/dummerchen/cdn@master/img/custom/avatar.jpg descr: 一个兴趣使然的programmer siteshot: https://cdn.jsdelivr.net/gh/dummerchen/My_Image_Bed03@image_bed_001/img/20210728175020.png","keywords":"友链"},{"title":"music","date":"2018-12-20T23:14:28.000Z","updated":"2022-09-20T15:19:19.431Z","comments":false,"path":"music/index.html","permalink":"https://dummerfu.top/music/index.html","excerpt":"","text":"","keywords":"喜欢的音乐"},{"title":"rss","date":"2018-12-20T23:09:03.000Z","updated":"2022-09-20T15:19:19.431Z","comments":true,"path":"rss/index.html","permalink":"https://dummerfu.top/rss/index.html","excerpt":"","text":""},{"title":"说说","date":"2022-09-20T15:19:19.431Z","updated":"2022-09-20T15:19:19.431Z","comments":false,"path":"shuoshuo/index.html","permalink":"https://dummerfu.top/shuoshuo/index.html","excerpt":"","text":""},{"title":"tags","date":"2021-01-12T22:14:16.000Z","updated":"2022-09-20T15:19:19.431Z","comments":true,"path":"tags/index.html","permalink":"https://dummerfu.top/tags/index.html","excerpt":"","text":""},{"title":"video","date":"2018-12-20T23:14:38.000Z","updated":"2022-09-20T15:19:19.431Z","comments":false,"path":"video/index.html","permalink":"https://dummerfu.top/video/index.html","excerpt":"","text":"var videos = [ { img: 'https://lain.bgm.tv/pic/cover/l/0e/1e/218971_2y351.jpg', title: '朝花夕誓——于离别之朝束起约定之花', status: '已追完', progress: 100, jp: 'さよならの朝に約束の花をかざろう', time: '放送时间: 2018-02-24 SUN.', desc: ' 住在远离尘嚣的土地，一边将每天的事情编织成名为希比欧的布，一边静静生活的伊欧夫人民。在15岁左右外表就停止成长，拥有数百年寿命的他们，被称为“离别的一族”，并被视为活着的传说。没有双亲的伊欧夫少女玛奇亚，过着被伙伴包围的平稳日子，却总感觉“孤身一人”。他们的这种日常，一瞬间就崩溃消失。追求伊欧夫的长寿之血，梅萨蒂军乘坐着名为雷纳特的古代兽发动了进攻。在绝望与混乱之中，伊欧夫的第一美女蕾莉亚被梅萨蒂带走，而玛奇亚暗恋的少年克里姆也失踪了。玛奇亚虽然总算逃脱了，却失去了伙伴和归去之地……。' }, { img : 'https://lain.bgm.tv/pic/cover/l/0e/1e/218971_2y351.jpg', title: '朝花夕誓——于离别之朝束起约定之花', status: '已追完', progress: 100, jp: 'さよならの朝に約束の花をかざろう', time: '2018-02-24 SUN.', desc: ' 住在远离尘嚣的土地，一边将每天的事情编织成名为希比欧的布，一边静静生活的伊欧夫人民。在15岁左右外表就停止成长，拥有数百年寿命的他们，被称为“离别的一族”，并被视为活着的传说。没有双亲的伊欧夫少女玛奇亚，过着被伙伴包围的平稳日子，却总感觉“孤身一人”。他们的这种日常，一瞬间就崩溃消失。追求伊欧夫的长寿之血，梅萨蒂军乘坐着名为雷纳特的古代兽发动了进攻。在绝望与混乱之中，伊欧夫的第一美女蕾莉亚被梅萨蒂带走，而玛奇亚暗恋的少年克里姆也失踪了。玛奇亚虽然总算逃脱了，却失去了伙伴和归去之地……。' } ] .should-ellipsis{overflow:hidden;text-overflow:ellipsis;white-space:nowrap;width:95%;}.should-ellipsis-full{overflow:hidden;text-overflow:ellipsis;white-space:nowrap;width:100%;}.should-ellipsis i{position:absolute;right:24px;}.grey-text{color:#9e9e9e !important}.grey-text.text-darken-4{color:#212121 !important}html{line-height:1.15;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}body{margin:0}img{border-style:none}progress{display:inline-block;vertical-align:baseline}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}html{-webkit-box-sizing:border-box;box-sizing:border-box}*,*:before,*:after{-webkit-box-sizing:inherit;box-sizing:inherit}ul:not(.browser-default){padding-left:0;list-style-type:none}ul:not(.browser-default)>li{list-style-type:none}.card{-webkit-box-shadow:0 2px 2px 0 rgba(0,0,0,0.14),0 3px 1px -2px rgba(0,0,0,0.12),0 1px 5px 0 rgba(0,0,0,0.2);box-shadow:0 2px 2px 0 rgba(0,0,0,0.14),0 3px 1px -2px rgba(0,0,0,0.12),0 1px 5px 0 rgba(0,0,0,0.2)}.hoverable{-webkit-transition:-webkit-box-shadow .25s;transition:-webkit-box-shadow .25s;transition:box-shadow .25s;transition:box-shadow .25s,-webkit-box-shadow .25s}.hoverable:hover{-webkit-box-shadow:0 8px 17px 0 rgba(0,0,0,0.2),0 6px 20px 0 rgba(0,0,0,0.19);box-shadow:0 8px 17px 0 rgba(0,0,0,0.2),0 6px 20px 0 rgba(0,0,0,0.19)}i{line-height:inherit}i.right{float:right;margin-left:15px}.bangumi .right{float:right !important}.material-icons{text-rendering:optimizeLegibility;-webkit-font-feature-settings:'liga';-moz-font-feature-settings:'liga';font-feature-settings:'liga'}.row{margin-left:auto;margin-right:auto;margin-bottom:20px}.row:after{content:\"\";display:table;clear:both}.row .col{float:left;-webkit-box-sizing:border-box;box-sizing:border-box;padding:0 .75rem;min-height:1px}.row .col.s12{width:100%;margin-left:auto;left:auto;right:auto}@media only screen and (min-width:601px){.row .col.m6{width:50%;margin-left:auto;left:auto;right:auto}}html{line-height:1.5;font-family:-apple-system,BlinkMacSystemFont,\"Segoe UI\",Roboto,Oxygen-Sans,Ubuntu,Cantarell,\"Helvetica Neue\",sans-serif;font-weight:normal;color:rgba(0,0,0,0.87)}@media only screen and (min-width:0){html{font-size:14px}}@media only screen and (min-width:992px){html{font-size:14.5px}}@media only screen and (min-width:1200px){html{font-size:15px}}.card{position:relative;margin:.5rem 0 1rem 0;background-color:#fff;-webkit-transition:-webkit-box-shadow .25s;transition:-webkit-box-shadow .25s;transition:box-shadow .25s;transition:box-shadow .25s,-webkit-box-shadow .25s;border-radius:2px}.card .card-title{font-size:24px;font-weight:300}.card .card-title.activator{cursor:pointer}.card .card-image{position:relative}.card .card-image img{display:block;border-radius:2px 2px 0 0;position:relative;left:0;right:0;top:0;bottom:0;width:100%}.card .card-content{padding:24px;border-radius:0 0 2px 2px}.card .card-content p{margin:0}.card .card-content .card-title{display:block;line-height:32px;margin-bottom:8px}.card .card-content .card-title i{line-height:32px}.card .card-reveal{padding:24px;position:absolute;background-color:#fff;width:100%;overflow-y:auto;left:0;top:100%;height:100%;z-index:3;display:none}.card .card-reveal .card-title{cursor:pointer;display:block}.waves-effect{position:relative;cursor:pointer;display:inline-block;overflow:hidden;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;-webkit-tap-highlight-color:transparent;vertical-align:middle;z-index:1;-webkit-transition:.3s ease-out;transition:.3s ease-out}.waves-effect img{position:relative;z-index:-1}.waves-block{display:block}::-webkit-input-placeholder{color:#d1d1d1}::-moz-placeholder{color:#d1d1d1}:-ms-input-placeholder{color:#d1d1d1}::-ms-input-placeholder{color:#d1d1d1}[type=\"radio\"]:not(:checked){position:absolute;opacity:0;pointer-events:none}[type=\"radio\"]:not(:checked)+span{position:relative;padding-left:35px;cursor:pointer;display:inline-block;height:25px;line-height:25px;font-size:1rem;-webkit-transition:.28s ease;transition:.28s ease;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}[type=\"radio\"]:not(:checked)+span:before,[type=\"radio\"]:not(:checked)+span:after{border-radius:50%}[type=\"radio\"]:not(:checked)+span:before,[type=\"radio\"]:not(:checked)+span:after{border:2px solid #5a5a5a}[type=\"radio\"]:not(:checked)+span:after{-webkit-transform:scale(0);transform:scale(0)}[type=\"checkbox\"]:not(:checked){position:absolute;opacity:0;pointer-events:none}[type=\"checkbox\"]:not(:checked):disabled+span:not(.lever):before{border:none;background-color:rgba(0,0,0,0.42)}[type=\"checkbox\"].filled-in:not(:checked)+span:not(.lever):before{width:0;height:0;border:3px solid transparent;left:6px;top:10px;-webkit-transform:rotateZ(37deg);transform:rotateZ(37deg);-webkit-transform-origin:100% 100%;transform-origin:100% 100%}[type=\"checkbox\"].filled-in:not(:checked)+span:not(.lever):after{height:20px;width:20px;background-color:transparent;border:2px solid #5a5a5a;top:0px;z-index:0}input[type=checkbox]:not(:disabled) ~ .lever:active:before,input[type=checkbox]:not(:disabled).tabbed:focus ~ .lever::before{-webkit-transform:scale(2.4);transform:scale(2.4);background-color:rgba(0,0,0,0.08)}input[type=range].focused:focus:not(.active)::-webkit-slider-thumb{-webkit-box-shadow:0 0 0 10px rgba(38,166,154,0.26);box-shadow:0 0 0 10px rgba(38,166,154,0.26)}input[type=range].focused:focus:not(.active)::-moz-range-thumb{box-shadow:0 0 0 10px rgba(38,166,154,0.26)}input[type=range].focused:focus:not(.active)::-ms-thumb{box-shadow:0 0 0 10px rgba(38,166,154,0.26)} 番组计划 这里将是永远的回忆 window.onload = function(){ videos.forEach(function(video, i){ $('#rootRow').append(` ${video.title} ${video.jp} ${video.status} ${video.title} ${video.jp} 放送时间: ${video.time} ${video.desc} ${video.status} `) }) }","keywords":"B站"}],"posts":[{"title":"【论文复现】Restormer","slug":"Restormer","date":"2022-07-30T00:00:00.000Z","updated":"2022-07-30T00:00:00.000Z","comments":true,"path":"p/49081.html","link":"","permalink":"https://dummerfu.top/p/49081.html","excerpt":"","text":"摘要因为transformer太大了，本文就设计了一个新的方式计算transformer，和新的transformer block使其复杂度降低成$O(C^2WH)$的同时刷新了sota。 方法网络结构 创新点主集中在transformer block： GDFN(gate de-conv feedforward network)： 这部分由gate(gelu)+dwconv+1x1 conv组成，这个门似乎是灵光一闪出来的，凑创新点。 MDTA(muti-head de-conv transpose attention)： 这个论文里面说的很nb，仔细看就发现他是相当于把矩阵转置然后再乘，原本的$HW^2$就变成了$C^2$，个人感觉这个东西挺好想的，但是为什么没人做呢。 进化学习前面说其他transformer用了patch对图片空间性不好，对于图像重建不友好等等，我还以为他把patch去掉了，结果只是越往后patch size越大来搞，唬人。 这个idea和fine tune很像，首先训练2x放大，再训练4x放大，这样训练出的网络会更好。可以借鉴一下思想。 消融实验就说一下比较关注的GDFN和MDTA，其他的像progressive learning和加深网络什么的我觉得没有什么好讲的。 如下图： 可以发现MTA+GFN是不如MTA+FN的但是MTA+DFN却有很大增长，同样MDTA+FN比MTA+FN也有很大增长，相比之下gelu的效果就没有那么明显，说明这个dwconv非常重要(或者是加了一层conv效果显著?这个应该也有个对比实验)，这可以思考借鉴一下。 后记 GDTA：dwconv的效果比门gelu提升更明显，更有借鉴意义？。 MDTA：文章明明强调了attention的优化，但是对比实验里面却没有着重对比速度，flops之类的，只有摘要旁边的那个图，就很迷惑。 progressive learning可以记一笔。","categories":[{"name":"论文","slug":"论文","permalink":"https://dummerfu.top/categories/%E8%AE%BA%E6%96%87/"}],"tags":[{"name":"论文","slug":"论文","permalink":"https://dummerfu.top/tags/%E8%AE%BA%E6%96%87/"}],"keywords":[{"name":"论文","slug":"论文","permalink":"https://dummerfu.top/categories/%E8%AE%BA%E6%96%87/"}]},{"title":"【论文复现】SwinIR","slug":"swinIR","date":"2022-07-30T00:00:00.000Z","updated":"2022-07-30T00:00:00.000Z","comments":true,"path":"p/3640.html","link":"","permalink":"https://dummerfu.top/p/3640.html","excerpt":"","text":"前言好久没更博客了，这次就爆肝两篇。 摘要原来的图像重建都很少基于transformer如IPT和VSR-transformer但是这两个都是patch-wise对图像重建不是很合适，这篇文章借鉴了swin transformer的架构并且参数量更少，还能提点也不是patch-wise（但是看后面也没有着重强调这一点）。 方法网络架构网络包括浅层特征提取+深层特征提取+图像重建模块，如下图： 对于不同的任务，图像重建模块不同，但是浅层和深层模块都一样： 浅层模块就是一个3X3卷积，深层模块是k个有shortcut 的swin transformer的堆叠，最后也是加一个3X3卷积层。 但是对于任务不同，图像重建模块是不同的： 图像超分：因为最后要上采样，所以要加一层sub pixel。 图像去噪，jpeg去伪影：就是单纯的一层卷积层（也没有说是什么卷积层）。 文章还解释了一下几个创新点： 为什么要在外层加入short cut：因为深层特征提取会忽视低频特征，留下高频特征，用shortcut可以最后加入低频特征。 为什么内层RSTB也要有short cut：shortcut能聚合不同层次的特征 因为short cut nb 为什么RSTB里面需要一层卷积层：transformer可以看作空间变换的一个特例，但是卷积具有空间滤波不变性能增加平移方差。（不是很懂这个理论） loss同样，对于不同任务的loss也不同： 图像超分：经典的和轻量级的图像超分直接用L1 pixel loss，现实图像超分使用pixel loss+gan loss+percep loss 图像去噪：使用charbonnier loss 消融实验具体实验结果图如下： 3X3卷积的通道数：与PSNR呈正比，论文取180。 RSTB数量：与PSNR成正比，论文取6层 STL数量：与PSNR成正比，论文取6层。 RSTB中的卷积层：在有short cut的条件下尝试了1x1，3x3和三个3x3，发现一个3x3效果最好，因为1x1没有提取到图像邻近信息，文章没有说为什么3个3x3效果会变差。 RSTB中的short cut：去掉short cut 下降了0.16db。 后记读完这篇论文，感觉只有trick 又多了一个，这篇似乎只验证了short cut的可行性，平均比sota高0.3%。 ensemble-strategy这个分为epoch ensemble strategy和self ensemble strategy： epoch ensemble strategy：取两次不同的epoch对同一张图片进行测试对结果求平均。 self ensemble strategy：对一张图片进行水平反转+垂直反转+原图+水平垂直翻转，测试后再转回去取平均。 卷积的空间平移方差增大感觉是翻译问题，我找了半天最接近的应该是translation equalvariance？ ，意思是平移卷积和卷积平移的结果不变，公式上来表示就是：$f(g(x))=g(f(x))$，这是cnn的一个现验条件之一（另一个现验条件是cnn卷积时相邻信息相关性强）","categories":[{"name":"论文","slug":"论文","permalink":"https://dummerfu.top/categories/%E8%AE%BA%E6%96%87/"}],"tags":[{"name":"论文","slug":"论文","permalink":"https://dummerfu.top/tags/%E8%AE%BA%E6%96%87/"}],"keywords":[{"name":"论文","slug":"论文","permalink":"https://dummerfu.top/categories/%E8%AE%BA%E6%96%87/"}]},{"title":"图像理解与计算机视觉笔记","slug":"图像理解与计算机视觉笔记","date":"2022-06-18T00:00:00.000Z","updated":"2022-06-18T00:00:00.000Z","comments":true,"path":"p/63048.html","link":"","permalink":"https://dummerfu.top/p/63048.html","excerpt":"","text":"一、图像信号分析基础灰度与灰度级每个像素的取值为灰度，所有灰度的种类成为灰度级。通常有2、8、256、65536灰度级。 色彩包括亮度、色调、饱和度。 邻域与邻接 四邻域：上下左右，四个像素相邻。 八邻域：上下左右，斜边八像素相邻。 D邻域：只有斜边的四个像素相邻。 m-连接：两个像素的四邻域没有相交且是D邻域或八邻域连接则为m连接（就是只有斜着的两个像素） 边缘线对于不同的联通方式会有不同的边缘线，比如四联通和八联通就不一样。求的都是最长的边缘线。 对于一个边缘线可以用链码来描述，按逆时针方向分别标注为0~7，七个方向。对链码进行差分则得到的是方向的相对位置，所以对平移、旋转变换很鲁棒。注意，差分是当前点减去前一个点。 卷积运算这里都默认是Same，所以要在外面填充0，然后需要注意的是模板要旋转180度。 二、图像增强与恢复直方图均衡化通过修改像素种类的分布，使图片对比度增加，注意映射函数是向上取整。 图像平滑空域平滑 平滑模板 多帧图片求平均 频域平滑 低通滤波 高通滤波 中值滤波个人觉得这应该算是空域平滑的平滑模板类里面。 也就是分不同的平滑模板，但是只是求中值而不是平均值。 图像锐化感觉和求边缘很相似，都是求梯度这种，也是拉普拉斯算子之类的。拉普拉斯模板就是拉普拉斯算子求出来后再加原图片，所以中间都会比拉普拉斯算子多1。 图像复原类似图像超分，先对图像进行退化再学习一个函数对图像进行复原，如果无约束就是一个梯度下降，有约束加一个拉格朗日算子。 图像退化分为: 简单退化：直接图像加噪声 通用退化：退化函数+噪声 变形退化：也是退化函数+噪声 频域退化：频域退化函数+频域噪声 现在gan都是用类通用退化，用不同的退化函数多次退化但是不加噪声，因为退化函数本身就会携带噪声进去，比如jpeg压缩会带有伪影。使用多次退化函数也能让模型学习的函数不是简单的逆函数。 三、图像边缘检测图像边缘是一个区域的终结到另一个区域的开始，是图像局部特征不连续的表现，由导数可以很明显的判断。 一阶导数不同方法就是计算水平梯度和垂直梯度的区别。 正交梯度： 对图片分别求水平梯度和垂直梯度，然后按不同的梯度幅值规则，合称为梯度图像，然后设定阈值对图片进行分割。 robert算子： 对斜方向计算梯度，剩下步骤与正交梯度相同。但是对噪声更敏感 W_h= \\left[ \\begin{matrix} -1&0& 0\\\\ 0&1&0\\\\ 0&0&0 \\end{matrix} \\right] \\quad W_v= \\left[ \\begin{matrix} 0&-1& 0\\\\ 1&0&0\\\\ 0&0&0 \\end{matrix} \\right] prewitt算子：使用了平均，能减少噪声的影响，但是会使边缘也更模糊 W_h=\\frac{1}{3} \\left[ \\begin{matrix} -1&0&1\\\\ -1&0&1\\\\ -1&0&1 \\end{matrix} \\right] \\quad W_v=\\frac{1}{3}\\left[ \\begin{matrix} -1&-1&-1\\\\ 0&0&0\\\\ 1&1&1 \\end{matrix} \\right] sobel算子：使用加权平均，比prewitt边缘更清晰 W_h=\\frac{1}{4} \\left[ \\begin{matrix} -1&0&1\\\\ -2&0&2\\\\ -1&0&1 \\end{matrix} \\right] \\quad W_v=\\frac{1}{4}\\left[ \\begin{matrix} -1&-2&-1\\\\ 0&0&0\\\\ 1&2&1 \\end{matrix} \\right] 二阶导数 拉普拉斯算子：对独立点和线效果很好，但是对噪声不耐受，所以一般先平滑处理，有四近邻模板，八近邻模板等。 W_4=\\left[ \\begin{matrix} 0&-1&0\\\\ -1&4&-1\\\\ 0&-1&0 \\end{matrix} \\right] LoG算子(高斯拉普拉斯算子)：实际上就是先高斯滤波平滑处理后再使用拉普拉斯算子。 canny算子： 先高斯模糊，再计算梯度，采用非极大值抑制删掉不需要的梯度（将当前像素点与其梯度方向的像素点梯度对比，最大才保留），然后用双阈值法连接边缘（阈值高部分轮廓丢失，阈值低有假边缘，消失轮廓就用低阈值的边缘填充更有效） ​ 拉普拉斯算子增强了图像中的灰度不连续边缘，而减弱了对应图像中灰度值缓慢变化区域的对比度，将这样的结果叠加到原始图像上就能得到锐化后的图像。 霍夫变换挺麻烦的，基本上就是将点通过映射到极坐标系确定线。广义霍夫变换还能检测物体位置（利用模板边缘和目标图片）。 四、图像分割基于阈值分割都是比较针对于单一目标，对于多目标难以奏效。 直方图均值法： 对于双峰直方图，选取峰值间的最低点作为分割阈值，对于多峰灰度直方图，分别选取峰值最低点作为分割阈值。 最佳阈值法： 类似最小错误率的贝叶斯决策，通过求两个分布的交点来求出阈值。 均值迭代法： 初始选取双峰的最低点作为分割阈值，然后每次选择两个区域的均值再求平均得到新的阈值，直至阈值不再改变。 类间方差法（OTSU）阈值分割： 和LDA类似，要求类间方差大，类内方差小，遍历一个阈值T，分别计算两个区域的均值，然后在计算类间加权方差，求出最大方差对应的T。 基于区域的分割 区域生长法： 遍历每一个像素与其邻域，如果规定的距离小于规定的阈值则合并，否则不合并。 对于不同规定的距离，分为不同的生长法：简单生长法（当前点与邻域像素值求abs），质心生长法（当前点与邻域区域平均值求abs），混合生长法（两个区域间的平均值求abs） 分裂合并法： ​ 利用均方差MSE，可计算区域间和区域内的loss，当一个区域间的loss大于阈值，则说明该区域不是一类，分割为4个区域，当区域间的loss小于阈值，说明区域相似，合并为一个区域。 ​ 初始将图片分割为四个区域，然后遍历四个区域进行分裂合并（分裂和合并是互不影响的）。并且不同规定的最小分裂块对结果也不同。 分水岭分割就是用洪水填充得到最后的边界，边界像素宽度必定是为1。计算简单但是容易过度分割，产生细小的区域。 五、形态学数字图像处理 腐蚀： 给定一个模板B，遍历原图A每一个像素，与模板B匹配，当B中的全部1都在A中也为1则新像素为1。与卷积相同，新图大小会改变，所以一般在外围填充0，二值图表现为图像变暗，小白点消失。 膨胀： 给定一个模板B，遍历原图A每一个像素，与模板B匹配，当B中存在1在A中也为1则新像素为1。与腐蚀相同，新图大小会改变，所以一般在外围填充0，二值图表现为图像变亮，小黑点消失。 开操作： 先对原图进行腐蚀，再膨胀的操作称为开操作，能够去掉噪声，二值图中表现为小白点消失，暗效果不变化。 $A\\circ B=(A\\ominus B)\\oplus B$。 闭操作： 先对原图进行膨胀再腐蚀的操作称为闭操作，能够去掉细小空洞，填补断裂，二值图中表现为小黑点消失，亮效果不变化。 $A\\bullet B=(A\\oplus B)\\ominus B$ 击中击不中变换：寻找形状的位置，B为需要找的形状，则$A*B=(A\\ominus B)\\and(A^C\\ominus B^C) $，注意这里$B^C$是对一个任意大于B的窗口求补集。 应用： 边界提取：A与AB腐蚀相减，$A-A\\ominus B$。 区域填充：A的补中所有区域像素分别与B膨胀得到的结果。 细化：用于提取骨架特征，使用八个方向的模板B分别对A求击中击不中变换求补集再与A求交集。 $A\\otimes B=A\\and (A*B)^C \\quad B={B0,B1…B7} $","categories":[{"name":"随笔","slug":"随笔","permalink":"https://dummerfu.top/categories/%E9%9A%8F%E7%AC%94/"}],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://dummerfu.top/tags/%E9%9A%8F%E7%AC%94/"}],"keywords":[{"name":"随笔","slug":"随笔","permalink":"https://dummerfu.top/categories/%E9%9A%8F%E7%AC%94/"}]},{"title":"代码审计工具","slug":"代码审计工具","date":"2022-05-20T00:00:00.000Z","updated":"2022-05-20T00:00:00.000Z","comments":true,"path":"p/42559.html","link":"","permalink":"https://dummerfu.top/p/42559.html","excerpt":"","text":"前言​ 上次抠图比赛失利，最后发现是网络最后一层操作花费太多时间，直接改成插值就能到70fps（还是python运行的!!，onnx只会更快）。上次面试也问到项目代码量是多少，我发现需要一些代码审计工具来统计分析程序的效率等功能 代码量统计​ 这个很简单，pycharm里安装插件Statistic就行了，注意可以在设置里exclude 不需要统计的文件，前几次统计会有点慢，后面就快了。 代码运行时间统计查看文件代码运行时间Pycharm 专业版有一个profile功能在Run/profile xxx.py，能查看该文件下运行的，最后会生成一个statistic和一个可视化的graph。这个分析的最小单位是函数 查看每行代码运行时间​ profile最小单位是函数，有时候挺鸡肋的，想到vsdebug模式下能直接看到每行代码运行的时间，pycharm能不能有这个功能呢？找了半天发现似乎只有line_profile是最满足需求的包(参考这篇blog 使用首先简单安装一下 pip install line_profiler 有实例化line_profile类进行使用的，但是更多使用@profile装饰器会更方便（无需导入包，运行时会自动实例化）。 @profile(func=None, stream=None, precision=1, backend=’psutil’) stream表示将分析结果输出的文件，默认为命令行；precision表示分析结果中数字小数点保留位数。 # 在需要查看时间的函数上使用装饰器，比如我想要查看网络哪层更耗时class SRResNet(nn.Module): def __init__(self,in_channels,n_block,scale_factor,hidden_channels): super(SRResNet, self).__init__() self.num_blocks=n_block self.conv1=nn.Conv2d(in_channels,hidden_channels,kernel_size=(9,9),stride=(1,1),padding=4) self.ac1=nn.PReLU(num_parameters=1,init=0.25) self.blocks=nn.Sequential(*[Block(in_channels=hidden_channels,hidden=hidden_channels) for i in range(self.num_blocks)]) self.conv2=nn.Conv2d(hidden_channels,hidden_channels,kernel_size=3,stride=1,padding=1) self.bn=nn.BatchNorm2d(hidden_channels) self.pixel_shuffle=nn.Sequential(*[SubPixelShuffleConvBlock(in_channels=hidden_channels) for i in range(scale_factor//2)]) self.conv3=nn.Conv2d(hidden_channels,3,kernel_size=(9,9),stride=1,padding=4) def init_weights(self): for m in self.modules(): if isinstance(m,nn.Conv2d): n=m.kernel_size[0]*m.kernel_size[1]*m.out_channels m.weight.data.normal_(0,math.sqrt(2./n)) if m.bias!=None: m.bias.data.zero_() @profile def forward(self,x): out1=self.conv1(x) # B,64,w,h out1=self.ac1(out1) out2=self.blocks(out1) # B,64,w,h out3=self.conv2(out2) # B,64,w,h out3=self.bn(out3) out4=out1+out3 out5=self.pixel_shuffle(out4) # B,64,w*4,h*4 out6=self.conv3(out5) # B,3,w*4,h*4 return out6 查看参数： $ kernprof --helpusage: kernprof [-h] [-V] [-l] [-b] [-o OUTFILE] [-s SETUP] [-v] [-u UNIT] [-z] script ...Run and profile a python script.positional arguments: script The python script file to run args Optional script argumentsoptional arguments: -h, --help show this help message and exit -V, --version show program&#x27;s version number and exit -l, --line-by-line Use the line-by-line profiler instead of cProfile. Implies --builtin. -b, --builtin Put &#x27;profile&#x27; in the builtins. Use &#x27;profile.enable()&#x27;/&#x27;.disable()&#x27;, &#x27;@profile&#x27; to decorate functions, or &#x27;with profile:&#x27; to profile a section of code. -o OUTFILE, --outfile OUTFILE Save stats to &lt;outfile&gt; (default: &#x27;scriptname.lprof&#x27; with --line-by-line, &#x27;scriptname.prof&#x27; without) -s SETUP, --setup SETUP Code to execute before the code to profile -v, --view View the results of the profile in addition to saving it -u UNIT, --unit UNIT Output unit (in seconds) in which the timing info is displayed (default: 1e-6) -z, --skip-zero Hide functions which have not been called 通常都是下面的参数运行 kernprof -l -v -z -u 1e-3 xxx.py 结果： Wrote profile results to eval.py.lprofTimer unit: 0.001 sTotal time: 89.0344 sFile: E:\\XXX\\SRResNet.pyFunction: forward at line 30Line # Hits Time Per Hit % Time Line Contents============================================================== 30 @profile 31 def forward(self,x): 32 2 296.9 148.5 0.3 out1=self.conv1(x) # B,64,w,h 33 2 47.0 23.5 0.1 out1=self.ac1(out1) 34 2 11893.6 5946.8 13.4 out2=self.blocks(out1) # B,64,w,h 35 2 240.6 120.3 0.3 out3=self.conv2(out2) # B,64,w,h 36 2 57.4 28.7 0.1 out3=self.bn(out3) 37 2 34.9 17.4 0.0 out4=out1+out3 38 2 9280.0 4640.0 10.4 out5=self.pixel_shuffle(out4) # B,64,w*4,h*4 39 2 67184.0 33592.0 75.5 out6=self.conv3(out5) # B,3,w*4,h*4 40 2 0.0 0.0 0.0 return out6 名称 意义 Timer unit 计时器单位，微秒 Total time 测试代码总运行时间 File 测试代码文件名 Hits 每行代码运行次数 Time 每行代码运行时间 Per Hit 每行代码运行一次的时间 % Time 每行代码运行时间的百分比 Line Contents 每行代码内容 通常看Time，%Time就好了，觉得命令麻烦的可以加alias 读取lprof 文件进入当前目录后，在命令行中使用 python -m line_profiler xxxx.lprof (x.lprof是自己的文件名) 但是正常调试运行时会报错没有这个属性，我们需要把profile属性定义一下，让他正常运行时不用删更方便： # 加在需要运行的程序最上方，本质是不使用kernprof时profile装饰器调用原本函数import builtinsif &#x27;builtins&#x27; not in dir() or not hasattr(builtins, &#x27;profile&#x27;): def profile(func): def inner(*args, **kwargs): return func(*args, **kwargs) return inner builtins.__dict__[&#x27;profile&#x27;] = profile 代码运行内存统计也是模仿上面那位大神开发出的包： pip install memory_profiler# 加速memory profilerpip install psutil 也是同样加@profile装饰器（方便二者能同时用，而不冲突） 运行方式: python -m memory_profiler test.py 运行结果： Filename: E:\\paper解读\\Gan\\2016.09_SRGAN\\codes\\model\\SRResNet.pyLine # Mem usage Increment Occurrences Line Contents============================================================= 30 505.516 MiB -60.969 MiB 2 @profile 31 def forward(self,x): 32 547.445 MiB -349.020 MiB 2 out1=self.conv1(x) # B,64,w,h 33 547.488 MiB -432.805 MiB 2 out1=self.ac1(out1) 34 585.656 MiB -356.387 MiB 2 out2=self.blocks(out1) # B,64,w,h 35 623.355 MiB -357.324 MiB 2 out3=self.conv2(out2) # B,64,w,h 36 623.355 MiB -432.723 MiB 2 out3=self.bn(out3) 37 661.055 MiB -357.324 MiB 2 out4=out1+out3 38 606.195 MiB -110.090 MiB 2 out5=self.pixel_shuffle(out4) # B,64,w*4,h*4 39 640.629 MiB 65.297 MiB 2 out6=self.conv3(out5) # B,3,w*4,h*4 40 640.645 MiB -3.902 MiB 2 return out6 个人感觉没有line_profile常用，更详细方法可参考这篇。 最后加一点代码检查：在code选项中inspect code可以看到自己哪些有warning，还可以防一手内存泄漏。","categories":[{"name":"随笔","slug":"随笔","permalink":"https://dummerfu.top/categories/%E9%9A%8F%E7%AC%94/"}],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://dummerfu.top/tags/%E9%9A%8F%E7%AC%94/"}],"keywords":[{"name":"随笔","slug":"随笔","permalink":"https://dummerfu.top/categories/%E9%9A%8F%E7%AC%94/"}]},{"title":"【论文复现】卷积网络可视化Grad-cam和Guide backpropagation","slug":"【论文复现】Grad-cam","date":"2022-05-16T00:00:00.000Z","updated":"2022-05-16T00:00:00.000Z","comments":true,"path":"p/44311.html","link":"","permalink":"https://dummerfu.top/p/44311.html","excerpt":"","text":"Grad cam参考我导的讲解 论文小结总的公式如下：对于某一类C，比如Cat有 Mat_{grad-cam}^c=Relu(\\sum_k \\alpha^c_kA^k)其中: A代表某个特征层，在论文中一般指的是最后一个卷积层输出的特征层 K代表特征层A中第k个通道(channel) c代表类别c $A^k$代表特征层A中通道k的数据 $\\alpha^c_k$ 代表$A^k$对应的权重 最后输出的是一个特征层宽高的矩阵。 计算权重 \\alpha^c_k= \\frac{1}{Z}\\sum_i\\sum_j \\frac{\\partial y^c}{\\partial A^k}后面那一项其实是第c类对权重的梯度，可以通过反向传播得到，本质就是对反向传播的矩阵进行一个求平均操作，输出K维的向量作为权重。 根据上式计算Mat转换为图片这时已经得到了0~1的灰度图mask，如果想放大则直接使用插值得到结果图 cv2.resize(mat,targetsize) 转rgb热力图灰度图只能显示提取到的特征，不能很好显示注意力的位置，可以修改为热力图来显示。 # 将灰度转热力三通道heat_map=cv2.applyColorMap(mask,colormap=colormap)heat_map=heat_map/255.image=image+heat_mapimage=image/np.max(image) 代码class GradCam: def __init__(self,model_name:list,target_size=None): self.fh=[] self.bh=[] self.target_size=target_size for i in model_name: i.register_forward_hook(self.forward_hook) i.register_backward_hook(self.backward_hook) def forward_hook(self,module,input,output): self.fh.append(output.cpu().detach().numpy()) def backward_hook(self,module, grad_in, grad_out): self.bh = [grad_out[0].cpu().detach().numpy()] + self.bh def get_rgb_image(self,image,mask,colormap: int = cv2.COLORMAP_JET,rgb_or_bgr=False,use_heatmap=True): if use_heatmap==True: mask = np.uint8(mask * 255) heat_map=cv2.applyColorMap(mask,colormap=colormap) if rgb_or_bgr==True: heat_map=cv2.cvtColor(heat_map,cv2.COLOR_BGR2RGB) heat_map=heat_map/255. image=image+heat_map image=image/np.max(image) else: mask=np.expand_dims(mask,axis=2) image=image*mask return image def cal_cam(self,image,colormap: int = cv2.COLORMAP_JET,rgb_or_bgr=False,use_heatmap=True): &#x27;&#x27;&#x27; 获得各层的 mask和image :param image: 输入的图片 0~1格式 :param colormap: 热力图colormap格式 :param rgb_or_bgr: 输入图片是否为rgb格式HWC :param use_heatmap: 输出热力图或蒙版图 :return: images,masks &#x27;&#x27;&#x27; self.Image=[] self.masks=[] for a, a_ in zip(self.fh, self.bh): # 1,C,W,H -&gt; CWH a=np.squeeze(a) a_=np.squeeze(a_) # C,1,1 alpha = np.mean(a_, axis=(1,2),keepdims=True) # CWH-&gt; WH mat = np.sum(alpha*a,axis=0) # relu mat[mat&lt;0]=0 # 转换到0-1 mat=(mat-np.min(mat))/(np.max(mat)+1e-7) if self.target_size!=None: # targetsize W,H mask=cv2.resize(mat,self.target_size) else: mask=mat image=self.get_rgb_image(image,mask,colormap=colormap,rgb_or_bgr=False,use_heatmap=use_heatmap) self.masks.append(mask) self.Image.append(image) return self.Image,self.masks# 使用方式cam=GradCam(feature_name,target_size)images,_=cam.cal_cam(raw_image/255.)cv2.imshow(images[0])cv2.waitKey()cv2.destroyAllWindows() Guide backpropagation论文小结​ 总的来说就是根据正反向传播通过relu激活函数的特性进行一个可视化：正向传播中被成功激活的才认为是有效信息，反向传播也同理，所以我们通过正向传播获得激活参数的位置，与反向传播权重进行relu后相乘获得新的反向传播权重权重并回传。 ​ 注意这个是要走一遍所有反向传播过程，只是在relu层进行重新回传梯度这个操作，所以最后输出是第一个网络层的梯度(这里需要设置图片允许求梯度，否则第一个会是None），维度与输入图片相同，梯度的输出含义则是图片的边缘信息。 论文里实现部分讲的很难理解，我是根据代码进一步理解的。 我尝试了直接输出第一个网络层（上图）的梯度与GBP（下图）进行对比，只筛选被激活部分还是挺能说明一些东西的。 代码代码实现时有几点要注意的顺便总结一下： permute，transpose，view： view：将图片全部展开为一维，然后按照给定的维度进行拼接，会改变原始的矩阵信息。 transpose和permute，不会改变原始矩阵信息，用法也相同，只是一个是numpy一个是tensor。 比如permute(2,1,0)，代表原本第2个维到到第一个位置，第1个元素到第二个位置第0维到第三个位置。 直接输出的图片太暗： 通过debug可以发现最后输出并不是0~1，所以我们需要把他进行一个0~1的转换，然后由于我们只关心高频边缘信息，所以把0~1直接的全部置0，只保留原始为1的数。这里转换还要注意一点，为了增强对比度，我们将均值设置在0.5左右，标准差设置在0.1，上图为min-max归一化，中图为mean-std归一化，下图在中图基础上还设置了方差和均值。 由于会改变反向传播的梯度，不能在训练的时候用也不能和grad-cam同时用（这里的同时是指只进行一次前后向传播） 输出gbp.image不存在：需要给前向传播的那张图片设置允许求梯度requiregrad() class GuideBackPropagation: def __init__(self,model_name:list): self.fh=[] self.model=model # 所有relu层都注册 for name, module in model.features.named_children(): if isinstance(module, nn.ReLU): module.register_forward_hook(self.forward_hook) module.register_backward_hook(self.backward_hook) # 第一个卷积层位置 for i in model_name: i.register_backward_hook(self.first_backward_hook) def normalize(self,I): # 归一化梯度map，先归一化到 mean=0 std=1 norm = (I - I.mean()) / I.std() # 把 std 重置为 0.1，让梯度map中的数值尽可能接近 0 norm = norm * 0.1 # 均值加 0.5，保证大部分的梯度值为正 norm = norm + 0.5 # 把 0，1 以外的梯度值分别设置为 0 和 1 norm = norm.clip(0, 1) return norm def forward_hook(self,module,input,output): self.fh.append(output.cpu().detach().numpy()) def first_backward_hook(self,module,grad_in,grad_out): # 获取第一个卷积层反向传播的权重 # BCHW-&gt; CHW -&gt;h,w,c self.image=grad_in[0].cpu().detach()[0] self.image=self.image.permute(1,2,0).numpy() self.image=self.normalize(self.image) pass def backward_hook(self,module, grad_in, grad_out): a=self.fh.pop() a[a&gt;0]=1 # 反向传播 relu new_grad=torch.clamp(grad_out[0],min=0.0) # rule 是返回一个参数,返回修改后的梯度 return (new_grad*a,)# 使用gbp=GuideBackPropagation(feature_name)res=model(image.require_grad_())res[0,0].backward()image=gbp.image","categories":[{"name":"论文","slug":"论文","permalink":"https://dummerfu.top/categories/%E8%AE%BA%E6%96%87/"}],"tags":[{"name":"论文","slug":"论文","permalink":"https://dummerfu.top/tags/%E8%AE%BA%E6%96%87/"}],"keywords":[{"name":"论文","slug":"论文","permalink":"https://dummerfu.top/categories/%E8%AE%BA%E6%96%87/"}]},{"title":"【杂谈】 西电保研二三事","slug":"保研后的感想","date":"2022-05-16T00:00:00.000Z","updated":"2022-05-16T00:00:00.000Z","comments":true,"path":"p/37004.html","link":"","permalink":"https://dummerfu.top/p/37004.html","excerpt":"","text":"闲话​ 细心的同学肯定会发现，我已经鸽了近4个月。这四个月我都在忙保研，最终结果在9.20号终于出来了，不负众望。但是中间的种种吐槽，我觉得还是值得记录下来，毕竟人生就这么一次大四。 ​ 首当其冲是西电人工智能院出名单这么晚！！！直接一锤子定死，24号考研预报名，20号才出名额这不是搞吗。学院不给你时间能够提要求修改名单什么的，我只能说很绝。也杜绝了边缘人保外校的希望（没错就是我）。 ​ 然后就是名额数量问题，我终于知道保研名额是出了名额后再算比例的意思了。他是全院一起排名至少今年2022年人工智能院是这样的 然后取一个名次比如95，然后前面95人有36人智科专业，39人智能专业，最低分92.23。最后再折算比例：智科18%（200人），智能24%（159人）。虽然专业间的有几门课不同，大众角度来看还是比较公平的，最后只有边缘躺平人受伤的世界达成了。而且这名额是计算突出特长竞赛的！！所以实际上名额更少。 ​ 最后就是图灵班问题，总共似乎是50个人，保了20个（包括5个突出特长），最低分91.63。因为是第一年，可以理解学院偏爱了，但是可惜了我的室友等边缘人。 虽然我也是边缘人 室友预测打脸环节这里仅仅是给网友一个忠告不要太乐观，没有吐槽室友的想法，我是怀着悲痛的心情记录下这些文字，对他们的遭遇我只感到十分的惋惜。 室友A加分15.5，裸分84.9，室友B加分9，裸分87.6，室友C Run出国。他们担心联系不上导师都提前了5个月联系到了导师，下面为室友的语录。 保研前4个月5.20，A猜测最高综合加分不会超过25，预计能到91.5~92，从往年来看，最低分为91还没有增加政治几门课，而且竞赛加分不限（今年开始学科竞赛等加分限制数量了）预测今年肯定会更低。 保研前1个月8.20，B问导师自己分数怎么样，导师劝导他做好考研的准备以防万一。室友A本来说帮老师写论文但似乎和npy过的很开心，玩了一个暑假。 保研前15天9.5，我们开学了，回到学校可以看到室友B在准备考研，我也在稍微准备，问室友A的想法，他说不缺这几天，名单出来后再准备也不迟 我深以为然，也松懈了。 9.14日左右，名单第一版出来，发现综合分数按专业最高分折算，包括突出特长！也就是38分！我们三心凉了一截，A还在安慰说肯定加错了，不可能有38，并且应该按专业分开算最高分折算比例，我又开始准备考研了。 好在当天就说名单出了明显问题，A，B肯定是分数出现错误，我不以为然。 9.15，A猜测正确，名单确定出错了，并且按专业最高折算，我们三分别是36，39，41。A觉得自己很危险但又没那么危险，毕竟觉得保研率不可能会低于20%，而且听说别的学校都多了很多名额。室友B觉得自己应该还行，就和D打起了游戏。我虽然感觉应该没问题但还是不放心。 9.17 ，A从导师那得到消息名额只有39个！B也去找导师确认，结果B的导师把B卖了，直接拿聊天截图去问A导师，A导师说没有这回事。虽然我也找了我导师确认，但是无奈他很自闭，不管这些东西 9.19 ，名单正式出来，智科36，智能39。班群可想而知炸了，边缘人全在喷教务处，我们也很伤心。本来还说保研了我请吃饭，看来要等到12月了。 小插曲9.4 室友C的托福因为疫情又推延到了10.17。他已经从去年12月等了快一年了。 9.10~9.18 室友A在室友C劝说下玩起了宝可梦，回忆童年。但我感觉他并没有乐在其中，只是在缓解焦虑。 9.10~9.18 室友C上大师失败，并且每天的目标都是昨天的分数，疯狂反复横跳。 后记​ 大学四年过的真的很快，我有时会想，如果我没有跟从室友一起一个人做事 会不会是截然不同的一条道路。。从大一什么都感兴趣到大四不那么想看论文，我能感觉到我的学习力越来越低，越来越躺平了。看到我高中同学有些能去清北深，我有点后悔，不禁反问起自己是不是大二再努力点我也有机会呢？混的不好同学聚会很尴尬 ​ 现在比别人多了95天的时间是应该好好利用起来了。","categories":[{"name":"论文","slug":"论文","permalink":"https://dummerfu.top/categories/%E8%AE%BA%E6%96%87/"}],"tags":[{"name":"论文","slug":"论文","permalink":"https://dummerfu.top/tags/%E8%AE%BA%E6%96%87/"}],"keywords":[{"name":"论文","slug":"论文","permalink":"https://dummerfu.top/categories/%E8%AE%BA%E6%96%87/"}]},{"title":"【论文复现】SRGan","slug":"SRGan","date":"2022-05-08T00:00:00.000Z","updated":"2022-05-08T00:00:00.000Z","comments":true,"path":"p/39020.html","link":"","permalink":"https://dummerfu.top/p/39020.html","excerpt":"","text":"前言似乎是第一篇用Gan做超分？挺有借鉴意义的，原文为Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial 摘要简单来说就是用MSE做loss容易丢失高频信息，他们提出用内容损失更好就是特征图的MSE，并且提出MOS作为评价指标自己定的一个评分标准，用来吹水，然后使用Gan来训练能够避免高频信息丢失，MOS更好确实人眼效果更好。 网络SRResNet就是一个ResNet堆叠然后使用2个pixel shuffler层放大了4倍。 看到网上有些人把BN换成了IN，PRelu换成了LeakyRelu，其实是个trick，IN在gan里面表现更好。 SRGan使用有预训练的SRResNet作为生成器，训练一个新卷积网络作为判别器。 训练先单独使用MSE loss训练SRResNet，有一定效果后作为生成器的预训练权重，然后训练gan，有些细节： Adam beta0 使用0.9 影响不大 lr 训练到一半时降一半 个人因为没有训练那么多epoch就没有降 lr 使用ImageNet参数normalize，hr归一到-1~1。 方便统一数量级 MSE loss 除一个常数，也是方便统一数量级但是新的pytorch mse默认求平均，本身就很小感觉不用除 但是统一数量级很值得借鉴 生成器的loss为内容损失+1e-4 判别器交叉熵损失 文章还说一个图片拆成16个96X96，但我只是随机crop了96X96，然后flip，多次训练。 代码最后附上我实现的代码，见Github，参考了这篇 blog，数据集使用的是coco2014的val 4w张图片，验证集是bsd100。个人亲测训练集太小（使用bsd500 train）效果不好 也有可能是我数据增强写的不好？。","categories":[{"name":"论文","slug":"论文","permalink":"https://dummerfu.top/categories/%E8%AE%BA%E6%96%87/"}],"tags":[{"name":"论文","slug":"论文","permalink":"https://dummerfu.top/tags/%E8%AE%BA%E6%96%87/"}],"keywords":[{"name":"论文","slug":"论文","permalink":"https://dummerfu.top/categories/%E8%AE%BA%E6%96%87/"}]},{"title":"记一次使用VB操作excel","slug":"记一次使用VB操作excel","date":"2022-04-27T00:00:00.000Z","updated":"2022-04-27T00:00:00.000Z","comments":true,"path":"p/35344.html","link":"","permalink":"https://dummerfu.top/p/35344.html","excerpt":"","text":"记一次使用VB操作excel代码感觉没什么特殊的，if for都差不多，上手很快。但是表格的active不是很好控制，不能使用变量来指定挺麻烦的。 总之就是水一篇博客，顺便把代码存一下我妈年终还要用 就是实现一个把总表按表头grouby 然后放入新表对应名字的sheet中。就是不知道为什么xp上跑不了？？现在才知道测试环境和应用环境差距真的大。 Sub create_sheet()&#x27; 批量新建多个sheet表，新建一个cresheet的宏Application.ScreenUpdating = FalseDim name As Stringname = &quot;注射剂二楼&quot;Set st = Worksheets(name) &#x27; 表初始值，定位源数据表，更改成需要拆分表的名称Workbooks.AddFor i = 2 To st.UsedRange.Rows.Count On Error Resume Next &#x27; 若表名不存在，忽略代码引起的运行错误 nn = st.Cells(i, &quot;A&quot;).Value If nn &lt;&gt; &quot;&quot; Then If Worksheets(st.Cells(i, &quot;A&quot;).Value) Is Nothing Then &#x27;判断是否存在对应的工作表 Worksheets.Add after:=Worksheets(Worksheets.Count) &#x27;永远将新表加入到最后一个工作表之后 ActiveSheet.name = nn &#x27;新的工作表为当前活动的工作，将工作表的名称更改为神山表中对应单元格的名字。 st.Range(&quot;A1&quot;).Resize(1, 6).Copy ActiveSheet.Range(&quot;A1&quot;) &#x27;resize 后面的6代表需要复制的行数，即表头有多少行 End If Set rng = Worksheets(nn).Range(&quot;A100000&quot;).End(xlUp).Offset(1, 0) st.Cells(i, &quot;A&quot;).Resize(1, 6).Copy rng End IfNextApplication.DisplayAlerts = False &#x27;取消确定弹窗Sheets(1).DeleteActiveWorkbook.SaveAs ThisWorkbook.Path &amp; &quot;./&quot; &amp; nameApplication.ScreenUpdating = TrueEnd Sub","categories":[{"name":"技术","slug":"技术","permalink":"https://dummerfu.top/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://dummerfu.top/tags/%E9%9A%8F%E7%AC%94/"}],"keywords":[{"name":"技术","slug":"技术","permalink":"https://dummerfu.top/categories/%E6%8A%80%E6%9C%AF/"}]},{"title":"c++ onnxruntime部署避坑记录","slug":"c++使用onnxruntime部署onnx文件","date":"2022-03-28T00:00:00.000Z","updated":"2022-04-20T00:00:00.000Z","comments":true,"path":"p/10043.html","link":"","permalink":"https://dummerfu.top/p/10043.html","excerpt":"","text":"前言​ 我一直都知道我学的c++和工程c++不一样，所以知道这篇文章之前我连库都不知道如何安装，毕竟刷算法题不需要也不能用额外的库。我也花了很大精力从舒适区走出来，终于成功c++部署modnet|RVM上线，我感觉收获了很多。对比之下用python真简单 ​ 注意，本文章并不是教程，更多是避坑记录，面向已经阅读过网上多数教程后需要debug的群体。 #无特殊说明默认是在cpu i5上的结果，否则以特殊说明的型号为准win 10x64 cpu i5vs2019opencv 4.5.5onnx 1.9.1 由于比赛原因，我近一个月后这篇文章才发布。 环境安装VisualStudio 2019​ 有人肯定会说为什么不用vscode啊巴拉巴拉。一个主打轻量级去做这种项目免不了安装很多插件这么多插件哪天一个不支持了就gg。所以还是vs更方便，当然各有各的喜好。 ​ vs正常安装下载，然后把 xx\\VisualStudio\\VC\\Tools\\MSVC\\14.29.30133\\bin\\Hostx64\\x64路径放到环境变量即可。 这里大概说一下bin，include，lib文件夹的作用，后面安装库文件的时候就会明白很多，而不是一头雾水： include：.h结尾，主要是函数声明，可以放入子文件夹当然如果这样引用也需要带文件夹。如果运行程序include报错多半是找不到这个路径。 bin：.dll结尾，动态链接文件。 lib：.lib结尾，静态链接文件。 c++编译过程图可以参考这篇 opencv​ 这个网上有很多，都是安装后把有include的路径加入环境变量，链接库加入链接什么的。但是根据上面的理解，我们可以发现vs已经链接了xx\\VisualStudio\\VC\\Tools\\MSVC\\14.29.30133\\include、xx\\VisualStudio\\VC\\Tools\\MSVC\\14.29.30133\\lib\\x64。我们可以把编译好的opencv里的\\include\\opencv，lib\\xxx，bin\\xxx放入vs的对应文件夹即可。同理，其他库比如gflags也是一样，编译好丢进去就行了就是怕冲突不好删除，就不用每次一个库占一个文件夹还要添加环境变量。 ​ 不过这样做就需要项目部署时把依赖重新全部丢进去。 onnxruntime​ 为避免踩坑可以看这篇csdn博客，我最开始还以为像其他库一样需要编译，结果直接可以用vs自带的包管理软件nuget直接下载。编译报一堆错误弄半天，吐血 去下载安装包https://www.nuget.org/ (建议不要下载最新)。然后打开vs2019，工具-&gt;NuGet程序包管理器-&gt;程序包管理控制平台： Install-Package microsoft.ml.onnxruntime.1.xx.x -Source your nupkg dir python 导出onnxpip install onnxpip install onnxmltool 这个具体如何从pth导出onnx还是要参考官网给的例子，网络不同细节也不同。 ModNet onnxruntimeC++部署读取图像并预处理​ 输入网络肯定是要预处理的图像，用image watch可以边调试边查看图片，同时我发现比较小的matting网络normalized可能效果会更差，因为相当于就是一个floor full，normalized后颜色更不好区分了,这个需要自己微调。image watch真好用 vector&lt;cv::Mat&gt; HumanSeg::preprocess(cv::Mat &amp;image) &#123; image_h = image.rows; image_w = image.cols; int rw, rh; /* if (image_w &gt; image_h) &#123; rh = 512; rw = (image_w*1.0 / image_h) *refsize; &#125; else &#123; rw = 512; rh = (image_h *1.0/ image_w) * refsize; &#125; rh -= rh % 32; rw -= rw % 32; */ // 图像还是出bug了，有时间能改就改 rh = rw = refsize; cv::Mat resized_image,resized_image_float,normalized_image; cv::cvtColor(image, image, cv::ColorConversionCodes::COLOR_BGR2RGB); cv::resize(image, resized_image, cv::Size(rw,rh),0,0,cv::INTER_AREA); //41ms resized_image.convertTo(resized_image_float, CV_32F,1.0/255); //14 ms normalized_image = normalize(resized_image_float); // 16ms input_node_dims = &#123; 1,3,rh,rw &#125;; return &#123; resized_image,normalized_image &#125;;&#125; onnx网络运行并输出 首先要将hwc格式转为bchw格式才能输入网络(blob函数) 输出的是float数组指针类型，需要按对应点转换为矩阵这个我也不怎么明白怎么方便转换。 转换之后要转换为uint8类才能参与后面的运算。 cv::Mat blob = cv::dnn::blobFromImage(normalized_image, 1, cv::Size((512),(512)), cv::Scalar(0, 0, 0), false, true); // create input tensor auto memory_info = Ort::MemoryInfo::CreateCpu(OrtArenaAllocator, OrtMemTypeDefault); input_tensors.emplace_back(Ort::Value::CreateTensor&lt;float&gt;(memory_info, blob.ptr&lt;float&gt;(), blob.total(), input_node_dims.data(), input_node_dims.size())); // 798ms std::vector&lt;Ort::Value&gt; output_tensors = session.Run( Ort::RunOptions&#123; nullptr &#125;, input_node_names.data(), input_tensors.data(), input_node_names.size(), out_node_names.data(), out_node_names.size() ); // h,w,3 float* floatarr = output_tensors[0].GetTensorMutableData&lt;float&gt;(); cv::Mat mask, mask_1f; mask_1f = cv::Mat1f(input_node_dims[2],input_node_dims[3], floatarr); mask_1f *= 255; mask_1f.convertTo(mask, CV_8U); resize并添加alpha通道要注意，网上最常见的用split然后push_back alpha通道 再merge的方法但这是有弊端的，因为输出的是四通道图片，opencv::imwrite和视频流都无法输出。 cv::cvtcolor的bgra2bgr参数 是直接丢去alpha通道，而不是智能转换。 cv::Mat add_alpha(cv::Mat src,cv::Mat alpha) vector&lt;cv::Mat&gt; srcChannels; cv::split(src, srcChannels); dstChannels.push_back(srcChannels[0]); dstChannels.push_back(srcChannels[1]); dstChannels.push_back(srcChannels[2]); //添加透明度通道 dstChannels.push_back(alpha); //合并通道 cv::merge(dstChannels, dst);return dst 如果用矩阵乘法转三通道也是可以的。 raw_image.convertTo(fimg,CV_32FC1);cv::Mat rest =cv::Scalar(1.)-pmat;std::vector&lt;cv::Mat1f&gt; channels;cv::split(fimg,channels);// 都是255就是黑色背景，这个参数是绿色背景cv::Mat mbmat = channels[0].mul(pmat) + rest.mul(cv::Scalar(153.));cv::Mat mgmat = channels[1].mul(pmat) + rest.mul(cv::Scalar(255.));cv::Mat mrmat = channels[2].mul(pmat) + rest.mul(cv::Scalar(120.));vector&lt;cv::Mat&gt; merge_channel_mats;merge_channel_mats.push_back(mbmat);merge_channel_mats.push_back(mgmat);merge_channel_mats.push_back(mrmat); 用位与运算是可以的，如果边缘非常模糊还可以通过调节阈值来选择mask来除去。位运算这个思路很巧妙： cv::threshold(mask, mask_thresh, 250, 255, cv::THRESH_TOZERO);cv::bitwise_and(src, src, dst, alpha);cv::resize(pre_image, without_bg, cv::Size(image_w, image_h), 0, 0, cv::INTER_AREA);// 123ms 注意先后顺序，如果后resize则运算量会小一点，同时锯齿现象也会小取决于插值方法。 完整代码感兴趣可以去我的github仓库看 onnx加速Fp32转Fp16众所周知，Fp16会更快，训练的时候用混合精度训练也会更快 但是注意自己的精度是否支持，有的显卡是不支持fp16或int8的，通常来说fp32转fp16各方面效率都会快两倍,但是只支持gpu，cup可能效果还会差。 多线程运行我一直都在找onnxruntime的多线程，发现真的只有那一个参数有明显改变。其他参数我试过没有用，估计默认的就是开了。 // 就这一个有用session_options.SetIntraOpNumThreads(num_threads);//这个开了和没开一样 //session_options.SetInterOpNumThreads(num_threads);// 如果开parallel会变慢//session_options.SetExecutionMode(ExecutionMode::ORT_PARALLEL); 果然最后还是和别人一样没有复现出来ModNet(700ms)，论文夹带私货太严重了。 Robust Video Matting​ 这篇论文比modnet友好很多，没有藏着掖着，该开源的都开源了，但是能看的c++部署还是一如既往的少只有这一个issuse。而lite.ai.toolkit又”高度”耦合化，单独使用还挺麻烦的，所以我就借鉴了一下代码，然后自己写的个cpp。部署后用cpu i5跑FP32是300ms/frame的样子。更换好点的cpu可以到13fps openvino 部署​ 看网上都说这个框架比onnx还能加速，但是用python实测发现IR效果和直接用pth权重推理速度相同，猜测是没有起到加速作用，就没有使用c++部署。 onnxruntime c++部署同见github 优化&amp;&amp;总结rvm原始代码是将图像缩放到0~1即不做任何处理直接输入，输出也是直接通过alpha进行合成，下面我将图像进行其他简单的预处理： coco数据集常数进行normalization：预处理后的边缘会变的很明显，噪声很多，效果也变差很多（出现多余的目标）。 缩放到[-1,1]：效果比上一个的稍好，但是人物边缘会更模糊但是检测的精度有时会更高。 对alpha通过阈值筛选，减少边缘模糊： ​ 将阈值设为0.32左右可以有效减少边缘模糊(不同数据集上要自己进行微调) 修改输出节点仅为pha： ​ 因为应用中不需要fgr等，源码不仅仅输出alpha，还输出了fgr，r1o等层，我们更改输出仅为alpha，代码量减少。 实践证明fp32和fp16在仅在cpu上运行是没有优化的推理时间相同。 也尝试了使用Int8量化，但是网络结构包含大量四则运算，故需要频繁quant和dequant，并没有起到优化作用速度反而下降了两倍。参考到这篇文章也是没有量化成功，可见并非所有网络都能量化成功和达到理想的效果。 onnxfp32转int8比pth的fp32转int8更方便，用pth先转int8比较麻烦，还要改网络等，onnx只需要一行代码，所以个人建议先转fp32 onnx再转int8更简单（虽然不知道原理）而且用onnx的int8速度只会下降一点。","categories":[{"name":"技术","slug":"技术","permalink":"https://dummerfu.top/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"c++,机器学习","slug":"c-机器学习","permalink":"https://dummerfu.top/tags/c-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"keywords":[{"name":"技术","slug":"技术","permalink":"https://dummerfu.top/categories/%E6%8A%80%E6%9C%AF/"}]},{"title":"放下鼠标，更高效的工作","slug":"放下鼠标更高效工作","date":"2022-03-15T00:00:00.000Z","updated":"2022-04-20T00:00:00.000Z","comments":true,"path":"p/11693.html","link":"","permalink":"https://dummerfu.top/p/11693.html","excerpt":"","text":"前言​ 你是否曾想过像黑客一样只用键盘操控电脑？实际上是为了防止鼠标手？😀，这篇文章就是介绍几个好用的插件让你实现”鼠标自由”。 ​ 个人亲测用了近一个月还是比较方便的。 浏览器脱离鼠标这里就要靠vimium这款神器插件下载时可以选择vimium C，这个有更多功能，熟练应用它后操作浏览器就像hacker操作vim一样，而且操作也很简单。最大的优点就是看小说很方便 但是功能太多也有不好的地方，容易误触比如i，而且随着浏览器的升级，有些按钮不再自带herf属性比如简书的评论区翻页，f检测不到也是个问题，我想这也是作者不怎么更新的理由吧。但是不影响装逼 下面我分享我的快捷键设置： # 网页内操作# 刷新页面ctrl runmap runmap R# 关闭就手动关闭，i容易误触unmap i# 文本框选择模式用就行了unmap giunmap guunmap gUunmap [[unmap ]]unmap Pmap p openCopiedUrlInNewTabmap I zoomInmap O zoomOutmap lh LinkHints.activateHovermap f LinkHints.activateOpenInNewTabmap F LinkHints.activate# 搜索框选项unmap gnunmap geunmap gEunmap bunmap Bunmap Tunmap munmap Nmap m performBackwardsFindmap v enterVisualMode# 标签页设置unmap tunmap g0unmap g$unmap xunmap Xunmap Wunmap ytunmap &lt;&lt;unmap &gt;&gt;unmap gtunmap gT 把大部分不常用的功能关掉可以有效减少误触的概率。 但是这里有几点新手比较难用： 焦点选择： 比如知乎你打开了评论区，但是评论区是一个新窗口用，此时焦点还是在原来窗口，这个时候用鼠标重新选择焦点就显得很憨。可以使用lh我设置的快捷键，默认是没有这个的，模拟鼠标点击获取焦点。 文字选择： 某 时候发现文章有些生词看不懂，想用鼠标复制会显得很憨。如果是超链接可以使用yv进入文字模式直接copy 如果是普通文字可以使用/搜索然后回车用n|m上下选择关键字，然后用v进入visual mod进行选择文字，alt+方向键进行拓展选择。不得不说这个还是挺麻烦的 桌面脱离鼠标当然，只有浏览器脱离鼠标还是不够的，如果用鼠标打开浏览器那岂能前功尽弃。 我们可以使用wox这款软件，它综合和优化了everything的功能，alt+space可以让你随时能够搜索和打开想要的软件，根本不需要鼠标进行操作。 如果要在文件夹里操作本人亲测HuntAndPeck软件并不像vimium那么好用，文本选项并不能很好的找到，而且快捷键也容易冲突，不如用bash。 任务栏脱离鼠标有人说，我想要聊天怎么办？不还是要鼠标来点击任务栏里的任务吗。对于这一点倒不必担心，windows已经为我们准备好了快捷键win+b对任务栏进行选择，左右键可以移动焦点，Enter选择打开应用。","categories":[{"name":"随笔","slug":"随笔","permalink":"https://dummerfu.top/categories/%E9%9A%8F%E7%AC%94/"}],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://dummerfu.top/tags/%E9%9A%8F%E7%AC%94/"}],"keywords":[{"name":"随笔","slug":"随笔","permalink":"https://dummerfu.top/categories/%E9%9A%8F%E7%AC%94/"}]},{"title":"百面机器学习","slug":"百面机器学习","date":"2022-02-17T00:00:00.000Z","updated":"2022-03-05T00:00:00.000Z","comments":true,"path":"p/44332.html","link":"","permalink":"https://dummerfu.top/p/44332.html","excerpt":"","text":"前言虽然是临时抱佛脚，但是这些面试题对我这种小白来说还是学到很多。后面没有星星的问题并不是原书上的，因为面试也常顺便就归类了。 特征工程为什么需要对数值类型的特征做归一化？$\\bigstar$归一化分为min-max和z-score归一化，前者只需要min和max即可归一，后者还需要均值和方差。效果也不一定会更好，但是通常z-score效果会更好一点 因为计算均值和方差更麻烦，对于需要梯度下降的算法如svm，线性回归，逻辑回归，神经网路等，在相同的学习率下，归一化能明显降低算法收敛速度。但决策树不适用 怎样处理类别型特征？$\\bigstar\\bigstar$类别型特征分为两类：可比较和不可比较。 对于可比较类别型特征映射为0，1，2这种当然是没有问题。因为也保留了可比较这种特征 但是对于不可比较特征如男女，应该使用不可比较映射如onehot或二进制编码现在二进制编码不常用等。 对于onehot，如果特征过多会很冗余浪费空间可以用向量的稀疏表示节省空间。如[0,0,0,5,0,0,0,0,1]=&gt;(10,[3,9],[5,1])，代表第3和9位上有个5和1 什么是组合特征？如何处理高维组合特征？$\\bigstar\\bigstar$组合特征简单理解就是多个类别型特征对应一个label就是常见的excel文件。 我们通常处理都说分别使用onehot然后再拼接。比如： 有m个用户，n个物品，label为是否点击，拼接后对应的就是m+n+2维onehot向量（label看情况拼接） 但是对于互联网来说m和n太大了，尽管向量稀疏表示可以节省空间但是网络的训练参数确不能节省（m*n)。这个时候就需要矩阵分解了，将m*n分解乘m*k+k*n，k&lt;&lt;m,n。训练参数也大大减少 矩阵分解具体可以看这篇知乎 怎样有效地找到组合特征?$\\bigstar\\bigstar$可以通过决策树帮助来寻找。 比如通过上面的决策树可以筛选出如下四个特征： 年龄&lt;=35”且“性别=女”。 年龄&lt;=35”且“物品类别=护肤”。 用户类型=付费”且“物品类型=食品”。 用户类型=付费”且“年龄&lt;=40”。 那么下面这条信息可以被视为[1，1，0，0] ：满足一二条不满足三四条 是否点击 年龄 性别 用户类型 物品类型 1 28 女 免费 护肤 有哪些文本表示模型？它们各有什么优缺点？$\\bigstar\\bigstar$词袋模型​ 将整段文本以词为单位切分开[i,am,food]， 然后每篇文章可以表示成一个长向量[[a,b,c],[aa,bb,cc],[aaa,bbb,ccc]]，向量中的每一维代表一个单词，而该维对应的权重则反映了这个词在原文章中的重要程度。 ​ 可以看出权重计算极其关键，那如何计算权重呢？常用的是TF-IDF来计算文本的权重：TF-IDF=TF*IDF TF为单词t在所有文章里的频率，IDF=$log \\frac{文章总数}{包含单词t的文章总数+1}$。实际应用时可能不会直接按单词直接分割文本，而是可以word stemming（提取词干）和n-gram（提取短语）结合处理文本后再进行分割计算权重。 主题模型LDA（隐迪利克雷模型）通过对所有文章训练然后将所有文章分为k个主题，每个主题n个关键词（k，n为参数） 深度学习模型和词嵌入模型通过各种玄学的网络结构（如transformer）将文本映射为一系列向量，由于深度网络很大，能更深层的提取语义特征。 词嵌入模型作用也是和神经网络相同将词映射为向量最常用的就是谷歌提出的word2vec（本质也是个小型神经网路） Word2Vec是如何工作的？它和LDA有什么区别与联系？$\\bigstar\\bigstar\\bigstar$word2vec是将一个词映射为一个向量，属于文本表示模型中的词嵌入模型 本质是一个神经网络，分为CBOW（根据前后预测中间的概率）和Skip-gram（通过中间预测前后的概率）两种实现方式，如上图 主题模型是一种基于概率图模型的生成式模型，其似然函数可以写成若干条件概率连乘的形式，其中包括需要推测的隐含变 量（即主题）；而词嵌入模型一般表达为神经网络的形式，似然函数定义在网络的输出之上，需要通过学习网络的权重以得 到单词的稠密向量表示。 在图像分类任务中，训练数据不足会带来什么问题？如何缓解数据量不足带来的问题？$\\bigstar\\bigstar$数据不足代表现验信息较少会导致训练集上效果可能还不错，测试集上蒙蔽（鲁棒性不强，过拟合)。 向增加模型泛化能力着手： 可以减少非线性层，增加惩罚项，调节dropout超参数等。 向增加现验信息着手，在保证特定信息条件下对数据进行扩充（Data Agumentation）： 形态变换上可以：旋转，伸缩，裁剪（mask），平移，填充，目标检测还可以重叠mosaic|mix up 颜色饱和度等方面：噪声扰动，对颜色进行pca聚类得到三个主成分向量再在rgb添加主成分增量（可以参考Alex net） 图像空间上可以：在特征空间上进行变换如通用的SMOTE（Synthetic Minority Over-sampling Technique）算法。 增加样本上还可以使用Gan。 模型评估准确率的局限性精确率准确率召回率f1score就不再说了，值得一提的是可以找更好的评估指标，比如平均绝对百分比误差（Mean Absolute Percent Error，MAPE），它比RMSE的鲁棒性更好。 降维如何定义主成分？从这种定义出发，如何设计目标函数使得降维达到提取主成分的目的？针对这个目标函数，如何对PCA问题进行求解 $\\bigstar \\bigstar$主成分从数学上来说是降维后特征向量对应的特征值最大的为候选，但具体为哪些要通过人为设置的阈值来决定。降维的目的是我们想降维后的样本距离间尽可能大，投影尽可能分开并且样本离超平面尽可能近(回归的角度)。虽然有两个目标但是最后推导出的目标函数是相同的，下面以样本间距离尽可能大来推导： 首先我们需要将样本进行中心化，即$\\sum_{i=1}^m X_i=0$，这样样本方差可以表示为$W^TXX^TW$，而且$W^TW=I$: \\begin{cases} min_w -tr(W^TXX^TW) \\\\ s.t. W^TW=I \\end{cases}对于具有类别标签的数据，应当如何设计目标函数使得降维的过程中不损失类别信息？在这种目标下，应当如何进行求解？（手推LDA）$\\bigstar \\bigstar$​ 又pca我们知道，它不管类别标签，在对于有标签情况下根本无法使用。而我们可以从pca中受到启发，目标为类内距离尽可能小，类间距离尽可能大，下面用两类标签情况来演示（fisher 线性判别分析）多类则叫LDA ​ 我们还是需要求解个超平面（二维是直线）W，满足上述条件： 假设低维类均值为$\\bar\\mu_i$,方差为$\\bar\\Sigma_i$，特征值为$y_i$，高维空间均值方差为$\\mu_i,\\Sigma_i$，特征值为x_i。目标函数为$max J_w=\\frac{(\\bar\\mu_1-\\bar\\mu_2)^2}{\\bar\\Sigma_1^2+\\bar\\Sigma_2^2}$ 投影后的类间距离可以表示为: \\bar\\mu_1-\\bar\\mu_2=\\frac{1}{n}\\sum_{i=1}^ny_{1i}-\\frac{1}{m}\\sum_{i=1}^my_{2i}=\\frac{1}{n}\\sum W^Tx_1-\\frac{1}{m}\\sum W^Tx_2=W^T(\\mu_1-\\mu_2)我们知道协方差矩阵可以写为: \\bar\\Sigma_i^2=\\sum_{j=1}^m(y_{2j}-\\bar\\mu_{1i})^2=W^T\\sum(x_{2j}-\\mu_1)^T(x_{2j}-\\mu_1)W=W^T\\Sigma_iW故$L(w,\\lambda)=W^T(\\mu_1-\\mu_2)(\\mu_1-\\mu_2)^TW+\\lambda(W^T(\\Sigma_1+\\Sigma_2) W-c)$ $\\frac{\\partial L}{\\partial w}=(\\mu_1-\\mu_2)(\\mu_1-\\mu_2)^TW+\\lambda(\\Sigma_1+\\Sigma_2) W=0$ 故$W=\\frac{1}{\\lambda}(\\Sigma_1+\\Sigma_2)^{-1}(\\mu_1-\\mu_2)R=(\\Sigma_1+\\Sigma_2)^{-1}(\\mu_1-\\mu_2)$ LDA和PCA作为经典的降维算法，如何从应用的角度分析其原理的异同？从数学推导的角度，两种降维算法在目标函数上有何区别与联系？​ 从应用角度来说，无监督使用PCA，因为PCA不涉及到类间距离，只人为类内距离越大隐含的信息越多，留下的主成分认为是最佳描述整体的特征（用于除去冗余信息如噪音）。而LDA需要标签来区别类间的距离，留下的主成分认为是每个类别的最佳描述特征。 ​ 从上面来看，LDA具有很大的优势，但由于涉及到不同领域（有监督和无监督）所整体来看还是各有千秋。 从算法流程来看，目标函数在一维下是相同的，且两者最后都是计算特征向量，非常相似，所以算法本质是相同的。 除了pca传统的的特征降维方法有哪些，特征选择方法有哪些LDA(linear discriminat analysis)，MDS(muti dimension scaling)，LLE(local linear embeding)。 特征选择有过滤式选择，包裹式选择和嵌入式选择。 过滤式选择是先人为选择好特征子集再训练，模型与特征选择无关。 包裹式选择是选择与模型匹配的最好特征，即每次随机选择特征给模型进行训练，最后效果肯定比过滤式选择好，但是更耗费时间。 嵌入式选择是在训练的时候删去某个特征，然后对比效果，简单来说就是增加L1正则化，正则化项中有一项为0就是代表删去了特征。L1正则化比L2正则化稀疏解更多，即w中0更多。由下图可知： L1的等值线与误差等值线交点更多在坐标轴上，L2则是在象限中。 什么是流型学习，ISOmap和LLE的原理流型是指局部具有欧式空间同胚的空间，流型学习是指低维欧式空间嵌入到高维仍具有欧式空间的特性，通过计算高维空间的距离并利用流型空间的特性可以局部映射到低维空间，然后再把局部映射关系推广到全局。因为具有距离不变性，常常用来数据可视化。比如已知n个城市飞机飞行的距离（高维空间的距离），我们可以用ISOmap将城市映射到二维空间并可视化。 ISOmap(isometric map)等度量映射：实际上是将MDS在应用方向的另一个名称，算法本质就是MDS。具体步骤：已知高维空间坐标，计算高维空间两两距离，然后使用MDS映射到低维空间得到低维空间的坐标。 由于ISOmap只能离线处理(每次需要等数据输入完后再计算，且不能用于预测)，实际使用并不是很方便，比较流行的方法： 通过n个点高维坐标输入，低维坐标作为输出训练一个回归器，当第n+1个点输入时使用回归器预测n+1点低维的坐标。 但是仍不能很好解决问题。 LLE(Local linear embedding)局部线性嵌入：与保持空间距离不变不同LLE旨在保持空间的线性性：假设高维空间的n节点可以用k近邻个节点线性表示，那么我们希望低维空间的n节点仍然有这个性质(组合系数w不变)。 即先后优化两个Loss： L_w=argmin_w \\sum_{i=1}^{n} ||x_i-\\sum_{j=1}^K w^Tx_j||^2 \\\\ L_y'=argmin_y \\sum_{i=1}^n ||y_i-\\sum_{j=1}^K w^Ty_j||2第一个目标函数求出组合系数w第二个目标函数求出低维坐标y。 无监督学习K均值算法的优缺点是什么？如何对其进行调优？$\\bigstar \\bigstar\\bigstar$优点： 算法足够高效，复杂度低。 局部最优常常也能满足需求。 缺点： 离群值处理不太行。 对于数据分布不均匀处理不当。 不太适用离散分布。 初始点选择很重要。 K值选择也很重要。 调优： 适用中位数代替平均数（k-media）和对数据进行预处理，能很好减少离群点的影响 多次尝试初始值可以缓解初始值的影响或适用Kmeans++来弥补。 可以通过手肘法或Gap Statistic方法选择K值。 通过核函数映射到高维（核kmeans）达到更准确的聚类结果 高斯混合模型的核心思想是什么？它是如何迭代计算的$\\bigstar\\bigstar$高斯混合模型和核心是假设数据是高斯分布生成出来的，但我们不知道均值方差和权重，故先假设已知再通过EM算法求出最合适（似然函数变化稳定）的均值方差和权重。 以聚类问题为例，假设没有外部标签数据，如何评估两个聚类算法的优劣？$\\bigstar\\bigstar\\bigstar$SVM推导SVM我们需要一个超平面将两类点分隔开，且不同类别的点到直线距离都尽可能大。$max {min J(w)=\\frac{|w^Tx+b|}{||w||}}$ 设标签类别为$y_i$，由于对于正类$y_i&gt;0$且$w^Tx+b&gt;=1$对于负类$y_i&lt;0$, $w^Tx+b&lt;=-1$:故点到直线距离可去掉绝对值统一为$y_i*(w^Tx+b)$。 对于$|w^Tx+b|=1$这两条线，我们称为支持向量，如果点线性可分（下面讨论线性可分支持向量机），则上述目标函数可转换为两个支持向量距离最长即： max J_w=\\frac{1}{||w||}\\frac{(w^Tx+b-1)-(w^Tx+b+1)}{||w||}=\\frac{2}{||w||^2}=min J_w=\\frac{||w||^2}{2}约束条件为：w,x为列向量 y_i*(w^Tx+b)>=1拉格朗日函数： L(w,b,a)=\\frac{||w||^2}{2}-\\sum a_i(y_i(w^Tx_i+b)-1) \\quad a_i>=0此方程组的限制条件（又称KKT条件）为： \\begin{cases} \\frac{\\partial L}{\\partial w,b}=0 \\\\ y_i(w^Tx_i+b)-1>=0 \\\\ a_i>=0 \\\\ a_i*(y_i(w^Tx_i+b)-1)=0 \\end{cases}其中$a_i$为KKT乘数，如何判断KKT乘数的符号也有讲究：对于min问题，乘数项应该异号对于max问题，乘数项应该同号。 KKT条件实际上并不是条件，而是前提，存在不等式方程组求解时，如果可以求解则必须满足KKT条件，此时通过求解的拉格朗日方程组也叫KKT方程组。自己理解，不一定对 对上式求偏导： \\begin{cases} \\frac{\\partial L}{\\partial w}=w-\\sum a_iy_ix_i=0 \\\\ \\frac{\\partial L}{\\partial b}=\\sum a_iy_i=0 \\\\ \\end{cases}带入拉格朗日方程： \\begin{aligned} min L&=\\frac{1}{2}\\sum_{i=1}^m a_ia_jy_iy_jx_i^Tx_j-\\sum_{i=1}^ma_iy_iw^Tx_i-\\sum_{i=1}^ma_iy_ib+\\sum_{i=1}^m a_i \\\\ &=\\frac{1}{2}\\sum_{i=1}^m a_ia_jy_iy_jx_i^Tx_j-\\sum_{i=1}^ma_iy_i\\sum_{j=1}^ma_jy_jx_j^T x_i-\\sum_{i=1}^ma_iy_ib+\\sum_{i=1}^m a_i \\\\ &=-\\frac{1}{2}\\sum_{i=1}^ma_ia_jy_iy_jx_i^Tx_j+\\sum_{i=1}^ma_i \\end{aligned}其实这里已经可以求解出具体的w和b了。但是不同方法结果不同，我这里采用SMO方法求解(具体SMO还是得看书，比较麻烦）。 选取$ai,a_j$,其余$a_k$看成常数，$a_iy_i+a_jy_j=\\sum{k\\neq i,j}^ma_ky_k$ 用$ai$表示$a_j$，对消去$a_j$的L求导可求出$a{i}$。 关于b，我们可以通过支持向量的约束来求解$ys(\\sum{i\\in S}a_iy_ix_i^Tx_s+b)=1$ 但每一个支持向量的点都能求出一个b，这里直接暴力去平均即可得到$b=\\frac{1}{|S|}\\sum{i \\in S} (y_s-\\sum{i\\in S}a_iy_ix_i^Tx_s)$ 在空间上线性可分的两类点，分别向SVM分类的超平面上做投影，这些点在超平面上的投影仍然是线性可分的吗？ $\\bigstar \\bigstar\\bigstar$结论：对于任意线性可分的两组点，它们在SVM分类的超平面上的投影都是线性不可分的。 该问题可以通过凸优化理论中的超平面分离定理（Separating Hyperplane Theorem，SHT）更加轻巧地解决。该定理描述的是，对于不相交的两个凸集，存在一个超平面，将两个凸集分离。对于二维的情况，两个凸集间距离最短两点连线的中垂线就是一个将它们分离的超平面。 通过以上定理，我们可以将两组点先各自求凸包，可以发现分割两个凸包的超平面就是SVM所得出的支持向量（二维情况下就是两个凸包距离最小点的中垂线）。 遂有图3.12三种情况，对于任意一种情况，其投影都线性不可分。（在二维情况上就是两个点集投影在支持向量上，然后再用一条线将他们分开，显然不可能） Logistic 回归逻辑回归相比于线性回归，有何异同？$\\bigstar \\bigstar$​ 在此之前我们要知道广义的线性回归：满足$y=g(w^Tx+b)$，其中g为可微函数。 由于人们在考虑回归时也想用回归来进行分类任务，灵机一动想到阶跃函数，但是阶跃函数不可微，遂使用对数几率函数(Logistic Function)$y=\\frac{1}{1+e^{-z}}$函数来代替，这个函数是Sigmod函数的一种只要是S形状的都是sigmod函数。 ​ 我们将logistic function代替广义回归式中的g并做变换则有： ln(\\frac{y}{1-y})=w^Tx+b若将y视为x为正例的可能性，1-y则是x为反例的可能性，他们比值就是几率反映了相对可能性，这就是对数几率回归(logistic regression)的由来。 然而逻辑回归的最优化函数与线性回归截然不同： 通过上述有$p(y=k|x)=e^{w^x+b}$，要求分类错误最小则最大化对数似然函数，估计w和b： max L(w,b)=max \\sum_{i=1}^{n}ln(y_ip(y=1|x)+(1-y_i)p(y=0|x)) \\\\ =max \\sum_{i=1}^n ln(e^{w^Tx+b}y_i+(1-y_i)) -ln(1+e^{w^Tx+b}) \\leftrightarrow min \\sum_{i=1}^{n}-y_i*(w^Tx+b)+ln(1+e^{w^T+b})则也是最小化$-L(w,b)$即等价于最小化CrossEntryloss 总结以下，逻辑回归与线性回归相比： 一个用于分类，一个用于回归，使用方向完全不同。 线性回归是求解均方差最小，而logistic regression是求解最大似然函数。 但他们求解方法都可以使用梯度下降法求解。 逻辑回归为什么不使用MSE作为loss假设这是一个二分类，预测类别为0，实际类别为1。显然这个分类器完全错误，但是MSE loss仅仅为1！！！。对比交叉熵： Entry loss=-1*log(0)\\rightarrow\\infin其次，MSE会出现梯度消失现： L_w=\\sum (y_i-h(s_i))^2 \\quad s=w^Tx+b \\quad h=\\frac{1}{1+e^{-s}} \\\\ L_w'=-2\\sum_{i=1}^m (y_i-h(s_i))h(s_i)(1-h(s_i))*x_i当$h(s_i)$为1或0时$L_w’\\rightarrow0$，出现梯度消失。 更重要的是，它不是一个非凸函数，要知道梯度下降需要如果优化非凸函数并不能找到全局最优虽然一般也找不到： \\begin{aligned} L_w''&=-2\\sum_{i=1}^m [-h(s_i)+h^2(s_i)+(y-h(s_i)(1-2h(s_i))] (h(s_i)-h^2(s_i))x_i\\\\ &=-2\\sum_{i=1}^m[y-2yh(s_i)-2h(s_i)+3h^2(s_i)](h-h^2(s_i))x_i^2 \\end{aligned}当$h(s_i)\\in (0,1)，y=0$时，$L’’$由$3h(s_i)^2-2h(s_i)$决定，这个在$h\\in (0,1)$有正有负，所以$L_w$非凸。 当使用逻辑回归处理多标签的分类问题时，有哪些常见做法，分别应用于哪些场景，它们之间又有怎样的关系？$\\bigstar \\bigstar \\bigstar$对于每类只有一个标签的多分类，我们假设每类都符合几何分布： h_{\\theta}(x)=\\left[ \\begin{matrix} p(y=1|x;\\theta)\\\\ \\vdots \\\\ p(y=n|x;\\theta) \\\\ \\end{matrix}\\right] =\\frac{1}{\\sum_{j=1}^{k}e^{\\theta_j^Tx}}\\left[ \\begin{matrix} e^{\\theta_1^Tx} \\\\ \\vdots \\\\ e^{\\theta_n^Tx} \\\\ \\end{matrix}\\right]一般来说，多项逻辑回归具有参数冗余的特点，即将同时加减一个向量后预测结果不变。特别地，当类别数为2时。 h_{\\theta}(x) =\\frac{1}{e^{\\theta_1^Tx}+e^{\\theta_2^Tx}}\\left[ \\begin{matrix} e^{\\theta_1^Tx} \\\\ e^{\\theta_2^Tx} \\\\ \\end{matrix}\\right]令所有参数减去$\\theta_1$，则有 h_{\\theta}(x) =\\frac{1}{1+e^{(\\theta_2-\\theta_1)^Tx}}\\left[ \\begin{matrix} 1 \\\\ e^{(\\theta_2-\\theta_1)^Tx} \\\\ \\end{matrix}\\right]整理后发现与逻辑回归相同。因此，多标签分类逻辑回归实际上是二分类的一种拓展。而多元逻辑回归式子又叫softmax函数。 决策树决策树有哪些常用的启发函数？$\\bigstar \\bigstar$ IDF3(Iterater dichotomister 3) 最大信息增益： 数据集D的经验熵：$H(D)=-\\sum_{i=1}^SP(w_i|t)*log_2P(w_i|t)$ 对于特征A经验条件熵$H(D|A)=\\sum_i^n \\frac{|D_i|}{|D|}H(D_i)$ 判定停止条件为：$max {g(D)}=H(D)-H(D|A)$ C4.5 最大信息增益比： 判断停止条件为$g_r(D)=\\frac{g(D)}{H_A(D)}$ 其中取值熵：$HA(D)=\\sum{i=1}^{n}\\frac{|D_i|}{|D|}log_2\\frac{|D_i|}{|D|}$ CART(Classification And Regression Tree) 最大基尼系数： $G(D)=\\sum{i=1}^{n}p(x_i)(1-p{xi})=1-\\sum{i=1}^{n}p(xi)^2=1-\\sum{i=1}^n(\\frac{|C_k|}{|D|})^2$ k为所有特征种类如年龄性别等 代表从数据集D中随机抽取两个样本，其类别标记不一致的概率。因此G(D)越小，则数据集D的纯度越高。 特征A的基尼系数$G(D|A)=\\sum_{i=1}^n\\frac{|D_i|}{|D|}G(D_i)$，n为特征A的种类如年龄中的老少等。 划分点就是最小特征基尼系数。 首先，ID3是采用信息增益作为评价标准，会倾向于取值较多的特征。因为，信息增益反映的是给定条件以后不确定性减少的程度，特征取值越多就意味着确定性更高，也就是条件熵越小，信息增益越大。这导致泛化能力很弱。因此，C4.5实际上是对ID3进行优化，通过引入信息增益比，一定程度上对取值比较多的特征进行惩罚，避免ID3出现过拟合的特性，提升决策树的泛化能力。 其次，从样本类型的角度，ID3只能处理离散型变量（对于长度这种就不能了），而C4.5和CART都可以处理连续型变量。C4.5处理连续型变量时，通过对数据排序之后找到数值不同的点，根据切分点把连续属性转换为布尔型，从而将连续型变量转换多个取值区间的离散型变量。而对于CART，由于其构建时每次都会对特征进行二值划分，因此可以很好地适用于连续性变量。 从应用角度，ID3和C4.5只能用于分类任务，而CART可以用于回归任务（回归树使用最小平方误差准则）。 此外，从实现细节、优化过程等角度：ID3对样本特征缺失值比较敏感，而C4.5和CART可以对缺失值进行不同方式的处理；ID3和C4.5可以在每个结点上产生出多叉分支，且每个特征在层级之间不会复用，而CART每个结点只会产生两个分支，因此最后会形成一颗二叉树，且每个特征可以被重复使用；ID3和C4.5通过剪枝来权衡树的准确性与泛化能力，而CART直接利用全部数据发现所有可能的树结构进行对比。 如何对决策树进行剪枝？ $\\bigstar \\bigstar \\bigstar$预剪枝(pre-pruning)： 做数据集划分，每次生成分支的时候通过验证集算损失，损失最小时则停止。 设置固定深度，到达深度时停止增长。 设置熵变化量阈值，熵变化量小于阈值时停止 信息增益显著性分析，如果当前增益不显著则停止划分。通常使用卡方检验。 后剪枝(post-pruning): 基于最小分类错误(Reduced Error Pruning，REP)：如果去掉该枝干错误率减小则剪枝。 最小长度准则：对决策树编码，剪枝得到编码最短的决策树（不是很明白） 基于代价和复杂性综合考虑(Cost Complexity Pruning，CCP)：如果去掉该枝干，综合错误率和复杂性综合考虑是否剪枝。 设在t处剪枝的误差为：$\\alpha=\\frac{R(t)-R(Tt)}{|L(t)|-1}$ L(t)代表以t节点为根的叶子数总数,R(t)代表t 优化算法监督学习的损失函数 $\\bigstar$最基础的肯定是0-1 loss，预测正确为0，错误为1，但是它不平滑不可导，就有了hinge loss替代它： hingeloss= max(0,1-f*y)同样，预测正确时损失为0，预测错误是hinge loss 是0-1 loss的凸上界。但是显然，某一点仍然不可导不能用梯度下降法进行优化。 0-1 loss 另一个替代就是logsitic loss： logistic loss=log_2(1+e^{-fy})它处处可导，但是在预测正确时仍有损失，还有一种就是交叉熵损失： Entry loss= -log_2(\\frac{1+fy}{2})四种函数图像如下所示","categories":[{"name":"面试","slug":"面试","permalink":"https://dummerfu.top/categories/%E9%9D%A2%E8%AF%95/"}],"tags":[{"name":"面试","slug":"面试","permalink":"https://dummerfu.top/tags/%E9%9D%A2%E8%AF%95/"}],"keywords":[{"name":"面试","slug":"面试","permalink":"https://dummerfu.top/categories/%E9%9D%A2%E8%AF%95/"}]},{"title":"最巧妙的算法之一--快速傅里叶变换","slug":"FFT","date":"2021-12-01T00:00:00.000Z","updated":"2021-12-01T00:00:00.000Z","comments":true,"path":"p/33310.html","link":"","permalink":"https://dummerfu.top/p/33310.html","excerpt":"","text":"引子​ 数字信号处理FFT讲的和什么一样，完全听不懂还好这个有翻译的3Blue1Brown讲解FFT，不然就gg了，由于视频讲的太妙了，让我不总结一下不行。 Step 1​ 如果让你求两个多项式相乘后的多项式即求$C(x):C(x)=A(x)*B(x)$，你会想到什么方法？On的暴力？没错，但是我们能否改进呢： 引理1： 最少已知一个多项式的m+1个点，则可以唯一确定这个多项式（m为多项式的阶数，下面假设$n=2^{\\lceil{log(m+1)}\\rceil}$​​​​） 由于多项式可写成矩阵相乘的形式，则可通过范德蒙行列式和克莱默法得到上述结论。 Step 2现在问题则变成了： ​ 已知两个n阶多项式的n+1个点，求这两个多项式的乘积后的多项式 现在暴力则变成了O(n)，对吗？但是还有些问题，比如如何找这n+1个点及已知n+1个点如何转换为多项式。后者我们先按下不表，先解决找点的问题。 如果随便找n+1个点，每个点x计算y(x)也是O(n)总复杂度还是O(n^2)没有变，我们需要更高效的找点算法： 假设函数$y=x^2+1$，如果让你找8个点是不是会倾向于找对称点呢？比如寻找$[(1,2),(2,5),…(4,17)]$这样你就知道了$[(-1,2),..(-4,17)]$寻找8个点就变成了找4个点的问题，规模小了一半！类比于奇函数也有这种性质。 我们知道任何函数都可以表示偶函数和奇函数的和，多项式也不例外。 假设有多项式: P(x) =1+2x^2+3x^3+4x^4+5x^5+6x^6可以变形为： P(x) =(1+2x^2+4x^4+6x^6)+x(3x^2+5x^4)=P_e(t)+xP_o(t)为方便理解，我变量替换了一下，t=x^2，可以看出这里$P_e$和$P_t$​​都是偶函数，由于： P(x)=P_e(t)+xP_o(t)\\\\ P(-x)=P_e(t)-xP_o(t)故满足上述条件，此变换可以将寻找的点数减半。我们只需求出$P_e(t)$和$P_o(t)$两个多项式即可。 看到这里，显然可以发现这是一个递归过程，因为$P_e(t)$和$P_o(t)$明显可以在像$P(x)$一样拆分。 P_e(t)=1+2t+4t^2+6t^3=P_e^{\\prime}(t^\\prime)+tP_o^{\\prime}(t^\\prime)但是遗憾的是$t^\\prime$​​ 在实数域取负值，也就是说无法利用O(1)对称，似乎陷入了瓶颈？接着往下看，这就是FFT的由来。 FFT​ 我们现在需要的是寻找一个$x_1、x_2$有$x_1^2=-x_2^2$，显然实数域不存在，故拓展到负数域，由于可以随便取初始点，方便起见令$t^n=1$，由欧拉公式可知，这样寻找的n个点则是在负数域单位圆周上等间隔分布即第k个点$w_k=e^{\\frac{2\\pi}{n}*k}$​​，这样无论递归到何时，t都存在对称点的情况，同时推导P(x)的公式也需要跟着改变： 由于 P(x):[x_0,x_1,...,x_{n-1}]\\leftrightarrow [w^0,w^1,...,w^{n-1}] \\\\ P_e(x):[x_0,x_2,...,x_{n-2}]\\leftrightarrow[w^0,w^2,w^4,...,w^{n-2}]\\\\ P_o(x):[x_1,x_3,...,x_{n-1}]\\leftrightarrow[w^1,w^3,w^5,...,w^{n-1}]\\\\根据第i个点$w^i$求函数值如下： P(w^i)=P_e(w^{2i})+w^iP_o(w^{2i}) \\\\ P(-w^i)=P(w^{i+n/2})=P_e(w^{2i})-w^iP_o(w^{2i}) \\quad i \\in [0,n/2-1]\\\\FFT代码void FFT(vector&lt;complexx&gt; &amp;A, int tempn,int flag)&#123; // flag作用后面会解释 if (tempn == 1) return; int M = tempn/2; vector&lt;complexx&gt; A0, A1; for (int i = 0; i &lt;= tempn; i+=2) &#123; A0.push_back(A[i]); A1.push_back(A[i+1]); &#125; FFT(A0, M,flag); FFT(A1, M,flag); auto W = complexx(cos(1.0 * Pi / M),flag*sin(1.0 * Pi / M)); auto w = complexx(1.0, 0.0); for (int i = 0; i &lt; M; ++i) &#123; A[i] = A0[i] + w * A1[i]; A[i + M] = A0[i] - w * A1[i]; w= w*W; &#125; A0.clear(); A1.clear();&#125; IFFT现在还剩最后一个问题，如何将已知的函数值转换回对应的多项式系数呢？ 已知多项式可以被以下矩阵乘法表示 \\left[ \\begin{matrix} p(w^0) \\\\ p(w^1) \\\\ p(w^2) \\\\ \\vdots \\\\ p(w^{n-1}) \\\\ \\end{matrix} \\right] = \\left[ \\begin{matrix} 1 & 1 & 1 & 1 & 1 \\\\ 1 & w& w^2 & w^3 &w^{n-1} \\\\ 1 & w^2& w^4 & \\dots &w^{2(n-1)} \\\\ \\vdots & \\vdots & \\vdots &\\ddots &\\vdots \\\\ 1 & w^{n-1} & w^{2(n-1)} & \\dots &w^{(n-1)(n-1)}\\\\ \\end{matrix} \\right] \\left[ \\begin{matrix} p_0 \\\\ p_1 \\\\ p_2 \\\\ \\vdots \\\\ p_{n-1} \\\\ \\end{matrix} \\right]则取逆变换有： \\left[ \\begin{matrix} p_0 \\\\ p_1 \\\\ p_2 \\\\ \\vdots \\\\ p_{n-1} \\\\ \\end{matrix} \\right] = \\left[ \\begin{matrix} 1 & 1 & 1 & 1 & 1 \\\\ 1 & w& w^2 & w^3 &w^{n-1} \\\\ 1 & w^2& w^4 & \\dots &w^{2(n-1)} \\\\ \\vdots &\\vdots & \\vdots & \\ddots & \\vdots \\\\ 1 & w^{n-1} & w^{2(n-1)} & \\dots &w^{(n-1)(n-1)}\\\\ \\end{matrix} \\right] ^{-1} \\left[ \\begin{matrix} p(w^0) \\\\ p(w^1) \\\\ p(w^2) \\\\ \\vdots \\\\ p(w^{n-1}) \\\\ \\end{matrix} \\right]由范德蒙行列式的特性求逆可转换为以下形式： \\left[ \\begin{matrix} p_0 \\\\ p_1 \\\\ p_2 \\\\ \\vdots \\\\ p_{n-1} \\\\ \\end{matrix} \\right] = \\frac{1}{n} \\left[ \\begin{matrix} 1 & 1 & 1 & 1 & 1 \\\\ 1 & w^{-1} & w^{-2} & w^{-3} &w^{-(n-1)} \\\\ 1 & w^{-2}& w^{-4} & \\dots & w^{-2(n-1)} \\\\ \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\ 1 & w^{-(n-1)} & w^{-2(n-1)} & \\dots &w^{-(n-1)(n-1)}\\\\ \\end{matrix} \\right] \\left[ \\begin{matrix} p(w^0) \\\\ p(w^1) \\\\ p(w^2) \\\\ \\vdots \\\\ p(w^{n-1}) \\\\ \\end{matrix} \\right]可见IFFT与FFT变动并不大，代码甚至只需要修改W的正负（flag的作用），然后最后除n即可 参考","categories":[{"name":"随笔","slug":"随笔","permalink":"https://dummerfu.top/categories/%E9%9A%8F%E7%AC%94/"}],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://dummerfu.top/tags/%E9%9A%8F%E7%AC%94/"}],"keywords":[{"name":"随笔","slug":"随笔","permalink":"https://dummerfu.top/categories/%E9%9A%8F%E7%AC%94/"}]},{"title":"算法设计技巧与分析笔记","slug":"算法设计技巧与分析","date":"2021-11-25T00:00:00.000Z","updated":"2021-12-07T00:00:00.000Z","comments":true,"path":"p/26814.html","link":"","permalink":"https://dummerfu.top/p/26814.html","excerpt":"","text":"前言​ 本来是觉得可以不用复习的angry bird还没写完呢，但是老师说全是大题还是有点慌 毕竟我不记得英文名啊，只写过代码 小小的按目录考点顺序总结一下。书在这里下载 ​ 代码都是伪代码大概，还有些自己yy的抓题。 复杂度这一部分单独提前提出来复习一下，不然后面算法要分析复杂度又提一遍。 O：最坏复杂度 $\\Omega$：理想情况下最好的时间复杂度​ $\\Theta$：平均复杂度 ​ 通常解题说的O是渐进时间复杂度，因为我们只关心最坏的时间复杂度能不能过这一题，而不是$ \\Omega $，且因为最好情况没有实际意义。而$\\Theta$、可能是因为打出来太麻烦导致人们不是很常用（其实我们平常口胡的复杂度含义更多是$\\Theta$​），而且人们更喜欢一个确定的值故O更为常用 个人理解。 使用什么算法大概可以用以下依据判断: 每个阶段只有一个状态-&gt;递推；每个阶段的最优状态都是由上一个阶段的最优状态得到的-&gt;贪心；每个阶段的最优状态是由之前所有阶段的状态的组合得到的-&gt;搜索；每个阶段的最优状态可以从之前某个阶段的某个或某些状态直接得到而不管之前这个状态是如何得到的-&gt;动态规划。 重要推论在推导复杂度或比较次数的时候会遇到很多形如下面的式子： f(n) \\begin{cases} d & \\quad n=1\\\\ af(n/c)+bn &\\quad n\\geq2 \\end{cases}上述递推式的解为 f(n)= \\begin{cases} bnlog_cn+dn & \\quad a=c \\\\ (d+\\frac{bc}{a-c})n^{log_c a}-\\frac{bc}{a-c}n &\\quad a\\neq c \\end{cases}通常情况下c=a=2，所以通常复杂度是$bnlog_2n+dn$​ 更通常情况： f(n) \\begin{cases} d & \\quad n=1\\\\ af(n/c)+bn^x &\\quad n\\geq2 \\end{cases}的解是： f(n)= \\begin{cases} \\Theta(n^x) \\\\ \\Theta(n^xlog~n) \\\\ \\Theta(n^{log_ca}) \\\\ \\end{cases} =\\begin{cases} bn^x & \\quad ac^x \\\\ \\end{cases}O还是$\\Theta$我也有点不确定 上面通解看似难实际上 就是比较递归部分和非递归部分的复杂度递归部分$O(n^{log_ca})$，非递归部分$bn^x$， 二分搜索(binary find)没啥，最大比较次数$\\lfloor{log n}\\rfloor+1$​​​，因为一颗二叉树最大高度是$\\lfloor log n\\rfloor$​​ // a递增l=1,r=n;while l&lt;=r mid=(l+r)/2; if a[mid]==x return mid; else if a[mid]&lt;x l=mid+1; else r=mid-1; 容易被误导的例子同时寻找数组中最大和最小的数。很容易被误导为二分，但是仔细一下发现必须遍历一遍所以复杂度不可能是O(log)而应是O(n)的 find(l,r) if r-l==1 // 用if可以实现只比较1次 return min(a[l],a[r]),max(a[l],a[r]) mid=(l+r)/2 x1,y1=find(l,mid) x2,y2=find(mid+1,r) x=min(x1,x2) y=max(y1,y2) return x,y 递推式是： f(n)= \\begin{cases} 1 &\\quad n=2 \\\\ 2*f(n/2)+2 & \\quad n>2 \\\\ \\end{cases}算出比较次数为n/2+n-2 合并有序的两个列表(merge)太简单，单独出大题不太可能。比较次数在$min(n_1，n_2) 到 n_1+n_2-1$​​​​​之间 // a[p,q] a[q+1,r]有序,从小到大合并x=p,y=q+1while x&lt;=q &amp;&amp; y&lt;=r if a[x]&lt;a[y] b[k]=a[x]; x++ else b[k]=a[y]; y++; k++;if x==q+1 for i=y;i&lt;=r;i++,k++ b[k]=a[i]else for i=x;i&lt;=q;i++,k++ b[k]=a[i] 选择排序(selection sort)依次选出第k小，$O(n^2)$ for i=1;i&lt;=n;i++; temp=i; for j=i+1;j&lt;n;j++; if a[j]&lt;a[temp] temp=j swap(a[i],a[temp]) 算法比较次数为$\\sum_1^{n-1}n-i=\\frac{n(n-1)}{2}$，因为每次循环都会赋值三次，故赋值次数为0~3(n-1)​ 插入排序(insertion sort)从已经排好序的序列中寻找小于当前值的进行插入 for i=2;i&lt;=n;i++ x=a[i] j=i-1 while j&gt;0 &amp;&amp; a[j]&gt;x; a[j+1]=a[j] j--; a[j+1]=x; 最大比较次数：$\\sum_{i=2}^n i-1=\\frac{n(n-1)}{2}$，最小比较次数：n-1，元素赋值次数：比较次数+n-1​​ 自底向上的排序(bottom up)其实就是一个递归，只有两个元素的时候回溯(见下面的merge sort)，合并就是上面的merge t=1while t&lt;n s=t,t=2*s,i=0; while i+t&lt;=n // 分别对应p,q,r // 每次合并[p,q],[q+1,r] merge(i+1,i+s,i+t); i+=t if i+s&lt;n merge(i+1,i+s,n); 有观察结论：每次比较次数在$\\frac{n}{2^j}2^{j-1}$​​​~$\\frac{n}{2^j}(2^j-1)$​​​，级数求和可知最少比较次数为$\\frac{nlog_2n}{2}$​​​最大比较次数为$nlog n-n+1$​​​。 算法分析外层循环为$\\lfloor log (n-1)\\rfloor+1$​​​，现先假设n为二的幂，这样if语句不会被执行，外层循环log n次，里层的while执行为n/t次(注意t=2*s把t重新赋值了涉及到循环次数问题)，每次复杂度为O(merge): 当merge总是最小比较次数时： f(t)=\\frac{n}{t}*min(s,t-s-1+1)=n/t*s \\\\ \\begin{aligned} f(n)&=\\sum_{t=1}^{n-1} f(t)\\\\ ~~~~&=\\sum_{i=1}^{k} \\frac{n}{2^i}*\\frac{2^{i}}{2} \\\\ ~~~~&= \\frac{n}{2}logn \\end{aligned}当merge部分总是最大比较次数时： f(t)=\\frac{n}{t}*(s+t-s-1+1-1)=n/t*(t-1) \\\\ \\begin{aligned} f(n)&=\\sum_{t=1}^{n-1} f(t) \\\\ &=\\sum_{i=1}^{k} \\frac{n}{2^i}*(2^{i}-1) \\\\ &= nlogn-n\\sum_{i=1}^k 2^{-i} \\\\ &= nlogn-n(1-\\frac{1}{n}) \\\\ &= nlogn-n+1 \\\\ \\end{aligned}基数排序(radix sort)这个伪代码比较好写 L=&#123;a0,a1,...an&#125; for i in 1~k L0~L9=empty while L!=empty: a=L.font; L.pop; if j=a的第i位数字 Lj.push a L=L0 for i in 1~9 L.push Liprint L 生成排列方法1似乎和书上的有些不同 如果有1~n-1的排列，则将n插入到每个排列的每个位置则可以得到1~n的排列。故从1开始到n+1结束（边界记得模拟一下） for i=1;i&lt;=n;i++ p[i]=i;perm(1)perm m: if m==n print p[1~n] else for(int i=m;i&lt;=n;i++) swap(p[m],p[i]); perm(m+1) swap(p[m],p[i]); 方法2​ 排列就是n个数的自由组合，每一次选择一个数到下一个状态，知道每个数都选择完毕即可。 for(int i=1;i&lt;=n;i++) use[i]=0;perm(1)perm m: if m==n+1 print use[1~n]; for(int i=1;i&lt;=n;i++) if use[i]==1 continue; use[i]=m; perm(m+1); use[i]=0 复杂度是n*n! 算法分析自己的yy每太看懂书上递推的写法，自己yy的感觉没问题 f(m)= \\begin{cases} n & m=n+1\\\\ (n-m+1)f(m+1) & 1=2\\\\ \\end{cases}最后计算得比较次数为$nlogn/2$~$nlogn-n+1$之间，时间复杂度为$\\Theta (nlogn)$，空间复杂度为$\\Theta(n)$​ 快速排序个人觉得未增强的快排和merge sort差不多，就是合并的算法不一样罢了。 split 算法选择一个初始区间，在for之后在区间内得到一个位置i，位置小于i的全部不大于a[l]，位置大于i的全部不小于a[l]。 并不保证前半部分和后半部分有序！！ split(l,r): // x=a[l] pos=l for (i=l+1;i&lt;=r;i++) if a[i]&lt;=x pos++ if i!=pos swap(a[i],a[pos]) swap(a[l],a[pos]) return a,pos 每次固定比较n-1次但可能不交换，故复杂度为O(n) 快排因为根据split算法，已经将序列分为两个有序的部分，现在只需要执行分治的基本思想即可： sort(a,l,r) w=split(l,r) sort(a,l,w-1) sort(a,w+1,n) 算法分析假设需求是从小到大排序。 最坏情况可见快排的分治不像buttomup sort那样非常稳定（永远都是分一半），所以最坏的情况是每次w=l+1，即序列每次都被分为sort(a,l,l)，sort(a,l+1,n)，这样则需要递归调用n次，而split比较次数是稳定的(n-1)，故最坏情况复杂度为: $\\sum_{i=1}^{n} i-1=\\frac{n(n-1)}{2}=O(n^2)$ 平均情况考虑数字都是随机排列且没有重复。则每个数字被split后w位置随机：设f(m)代表区间长度为m时的快排比较次数 f(n)= \\begin{cases} 0 & \\quad n=1 \\\\ n-1+\\frac{1}{n}\\sum_{w=1}^{w=n} f(w-1)+f(n-w) & \\quad n>1 \\end{cases} \\begin{aligned} f(n)&=n-1+\\frac{1}{n}\\sum_{w=1}^{w=n} f(w-1)+f(m-w) \\\\ &=n-1+\\frac{2}{n}\\sum_{w=1}^{n}f(w-1) \\\\ \\end{aligned}变形则有： \\begin{cases} n*f(n)&=n*(n-1)+2\\sum_{w=1}^{n}f(w-1) \\\\ (n-1)*f(n-1)&=(n-1)*(n-2)+2\\sum_{w=1}^{n-1}f(w-1) \\\\ \\end{cases} \\rightarrow \\\\ \\frac{f(n)}{n+1}=\\frac{2(n-1)}{n(n+1)}+\\frac{f(n-1)}{n}令$D(n)=\\frac{f(n)}{n+1}$，D(1)=0： \\begin{aligned} D(n)&=\\sum_{i=1}^{n} \\frac{2(i-1)}{i*(i+1)} \\\\ &=\\sum_{i=1}^{n} \\frac{4}{i+1}-\\frac{2}{i} \\\\ &=\\frac{4}{n+1}-4+\\sum_{i=1}^{n} \\frac{2}{i} \\\\ &=\\frac{4}{n+1}-4+2\\gamma+2ln(n) \\\\ &=2log(n)+\\Theta(1) \\\\ &\\approx 1.44log (n) \\end{aligned}所以$f(n)=\\Theta(nlog(n))$​ 排序算法总结 算法名称 平均比较次数 最好比较次数 最坏比较次数 是否稳定 选择排序 $\\frac{n*(n-1)}{2}$ $\\frac{n(n-1)}{2}$ $\\frac{n(n-1)}{2}$ 否 插入排序 $n^2$ $n-1$ $\\frac{n*(n-1)}{2}$ 是 冒泡排序 $n^2$​ $\\frac{n(n-1)}{2}$​​ $\\frac{n(n-1)}{2}$ 是 radix sort $nd$ $nd$ $nd$ 是 bottomup sort $nlog_2n$ $\\frac{nlog_2n}{2}$ $nlog_2n-n+1$ 是 merge sort $nlog_2n$ $\\frac{nlog_2n}{2}$ $nlog_2n-n+1$ 是 quick sort $nlog_2n$ $nlogn$ $n^2$ 否 寻找第k小元素伪代码select(A,l,r,k)&#123; p=r-l+1; if p&lt;44 // c sort(A) return A[k] q=p/5 将A分为五组 将q组中的元素单独排序找出中项并得到中项集合M。 mm=select(M,1,q,(q+1)/2) // f(n/5) // n A1=&#123;a|a&lt;mm&#125; A2=&#123;a|a=mm&#125; A3=&#123;a|a&gt;mm&#125; // f(0.7n) case: |A1|&gt;=k return select(A1,1,|A1|,k); |A2|+|A1|&gt;=k // 一定在A2里面 return mm; |A1|+|A2|&lt;k // 一定在A3里面 return select(A3,1,|A3|,k);&#125; 复杂度分析由上伪代码可见，关键是0.7n是如何计算出来的。只考虑第一和第三种情况，不考虑之间返回mm，只考虑最坏情况: 显然该两种情况是对称的，故可以只计算A1或A3的规模，严格小于可以转换为n-A3’其中A3’为大于等于mm的数 故有： |A1||A3|\\leq n-\\frac{3}{2} \\lfloor{n/5}\\rfloor \\leq n-\\frac{3(n-4)}{2*5}=0.7n+1.2想办法去掉1.2的常数 假设$0.7n+1.2 \\leq \\lfloor{0.75n}\\rfloor$ 当然这里0.75是可以随便设置的 0.7n+1.2 \\leq 0.75*n-1=> \\quad n>=44当然，不等式放缩可以有别的方式，所以常数可能不一样 f(n)= \\begin{cases} c1 \\quad & n= C \\end{cases}最长公子序列问题(LCS)感觉dp的都不是很侧重讲啊。 伪代码for int i=1;i&lt;=n;i++ l[i,1]=0;for(int i=1;i&lt;=m;i++) l[1,j]=0;for(int i=1;i&lt;=n;i++) for(int j=1;j&lt;=m;j++) if a[i]==b[j] l[i][j]=l[i-1][j-1]+1; else l[i][j]=max(l[i-1][j],l[i][j-1]); 背包问题for int i=1;i&lt;=n;i++ for(int j=0;j&lt;=m;j++) f[i,j]=0 for(int i=1;i&lt;=n;i++) for(int j=0;j&lt;=m;j++) fp[i][j]=f[i-1][j] if j&gt;=s[i] f[i][j]=max(f[i][j],f[i-1][j-s[i]]+v[i]) 图论两两间最短路dijstrafor(int i=1;i&lt;=n;i++) dis[i]=inf while(!q.empty()) temp=q.front() q.pop() for(i in temp的边) if i not in q if dis[i]&gt;dis[temp]+length[i][temp] dis[i]=dis[temp]+length[i][temp] q.push(i) krusal将边从小到大排序得到Etot=0for(e in E)&#123; if find(e.l)!=find(e.r) tot++ fa[e.l]=find(e.r) if tot&gt;=n-1 break&#125; primT=&#123;&#125;,x=&#123;1&#125;,y=V-&#123;1&#125;while(y!=&#123;&#125;) (x,y)为最小权重边,x属于X，y属于Y X=X+&#123;y&#125; Y=Y-&#123;y&#125; T=T+(x,y) 三着色问题|八皇后问题这两个本质都是染色问题，所以在一起分析。 伪代码\\\\递归回溯for i=1;i&lt;=n;i++ c[i]=0;color(k): for i in color c[k]=i // check为 O(n) if check(c)全部着色且不冲突 return and print c； else if check(c)不冲突 // 部分着色 color(k+1)； return \\\\ 迭代回溯for i in n: c[i]=0while(k&gt;=1) while(c[k]&lt;color) c[k]++ if check 全部着色且不冲突 print c return else if check部分着色且不冲突 k++ end while c[k]=0 k--end while 复杂度分析 f(k)= \\begin{cases} n \\quad & k=1 \\\\ 3*f(k-1) & k>=2\\\\ \\end{cases}搜索剪枝他不香吗 网络流(了解步骤即可)FF如果流量是无理数，可能找不到解，如果流量收敛可能不是最优解 for 边u,v 属于E f(u,v)=0 while G中有一条增广路径 p delta=p的瓶颈流量 for p中每条边u,v f(u,v)=f(u,v)+delta 更新剩余图G 最短路径长度增广(Minimum path length augmentation)初始化剩余图R&lt;-G，层次图L while t在L中 while L中存在s到t的路径 对每个路径分别求出瓶颈容量d 该路径增值d 更新L end while 用剩余图更新Lend while 匈牙利伪代码初始化匹配M=&#123;0&#125;while G中存在自由节点x，y： 设r为一个自由节点，从r开始搜索生成一个路径交替树T。 if T是一条匈牙利树 G-=t if T中找到一条增广路m M+=m","categories":[{"name":"随笔","slug":"随笔","permalink":"https://dummerfu.top/categories/%E9%9A%8F%E7%AC%94/"}],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://dummerfu.top/tags/%E9%9A%8F%E7%AC%94/"}],"keywords":[{"name":"随笔","slug":"随笔","permalink":"https://dummerfu.top/categories/%E9%9A%8F%E7%AC%94/"}]},{"title":"Unity 基本属性（占坑）","slug":"Unity","date":"2021-11-15T00:00:00.000Z","updated":"2021-11-20T00:00:00.000Z","comments":true,"path":"p/61367.html","link":"","permalink":"https://dummerfu.top/p/61367.html","excerpt":"","text":"Unity坐标系参考 暂停|等待操作","categories":[{"name":"随笔","slug":"随笔","permalink":"https://dummerfu.top/categories/%E9%9A%8F%E7%AC%94/"}],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://dummerfu.top/tags/%E9%9A%8F%E7%AC%94/"}],"keywords":[{"name":"随笔","slug":"随笔","permalink":"https://dummerfu.top/categories/%E9%9A%8F%E7%AC%94/"}]},{"title":"Mosaic And Mixup 实现源码分析","slug":"Mosaic and Mixup实现","date":"2021-09-25T00:00:00.000Z","updated":"2021-09-25T00:00:00.000Z","comments":true,"path":"p/45458.html","link":"","permalink":"https://dummerfu.top/p/45458.html","excerpt":"","text":"前言​ 看了yolox后发现数据增强是真的nb，但是自己想如何实现的时候就感觉不太行了（不能简洁的实现）。又一想，数据增强这种trick肯定会用到其他网络的dataloader里面啊，所以仔细研究了一下代码复现一下。 ​ 最后附上我自己封装的mosaic和mixup，不自己封装到时候现copy别人的都不知bug在哪 虽然核心与原论文差不多 Mosaic源码分析下面根据yolox源码进行分析： yolox想法是先生成一个Dataset类，然后根据这个类可以进行iterater，故写了一个pull_item函数。 基于以上，然后可以定义到MosaicDetection类 class MosaicDetection(Dataset): &quot;&quot;&quot;Detection dataset wrapper that performs mixup for normal dataset.&quot;&quot;&quot; def __init__( self, dataset, img_size, mosaic=True, preproc=None, degrees=10.0, translate=0.1, mosaic_scale=(0.5, 1.5), mixup_scale=(0.5, 1.5), shear=2.0, perspective=0.0, enable_mixup=True, mosaic_prob=1.0, mixup_prob=1.0, *args ): super().__init__(img_size, mosaic=mosaic) self._dataset = dataset self.preproc = preproc self.degrees = degrees self.translate = translate self.scale = mosaic_scale self.shear = shear self.perspective = perspective self.mixup_scale = mixup_scale self.enable_mosaic = mosaic self.enable_mixup = enable_mixup self.mosaic_prob = mosaic_prob self.mixup_prob = mixup_prob self.local_rank = get_local_rank() 参数含义就不讲了，关键是self._dataset这个字段，可以看出Mosaic是在原先的Dataset基础上实现的。 也就是说需要的只是重写getitem和len，下面开始讲解getitem 第一部分 图片拼接def __getitem__(self, idx): if self.enable_mosaic and random.random() &lt; self.mosaic_prob: mosaic_labels = [] input_dim = self._dataset.input_dim input_h, input_w = input_dim[0], input_dim[1] # yc, xc = s, s # mosaic center x, y # 画布大小为input_h,input_w # 拼接公共点位置 yc = int(random.uniform(0.5 * input_h, 1.5 * input_h)) xc = int(random.uniform(0.5 * input_w, 1.5 * input_w)) # 3 additional image indices indices = [idx] + [random.randint(0, len(self._dataset) - 1) for _ in range(3)] for i_mosaic, index in enumerate(indices): img, _labels, _, img_id = self._dataset.pull_item(index) # 得到的第一张图片的原始大小 h0, w0 = img.shape[:2] scale = min(1. * input_h / h0, 1. * input_w / w0) # 放大到input size img = cv2.resize( img, (int(w0 * scale), int(h0 * scale)), interpolation=cv2.INTER_LINEAR ) # generate output mosaic image (h, w, c) = img.shape[:3] # 生成一个新的画布，颜色是114 if i_mosaic == 0: mosaic_img = np.full((input_h * 2, input_w * 2, c), 114, dtype=np.uint8) # suffix l means large image, while s means small image in mosaic aug. # 根据图片的先后顺序分别放入左上、右上、左下、右下四个方向。 # 函数返回的是基于画布的新坐标 和 原图像的坐标（要注意由于0.5-1.5倍，原图像可能会超出画布范围 (l_x1, l_y1, l_x2, l_y2), (s_x1, s_y1, s_x2, s_y2) = get_mosaic_coordinate( mosaic_img, i_mosaic, xc, yc, w, h, input_h, input_w ) # 赋值到画布 mosaic_img[l_y1:l_y2, l_x1:l_x2] = img[s_y1:s_y2, s_x1:s_x2] plt.imshow(mosaic_img) plt.show() # 坐标偏移量 padw, padh = l_x1 - s_x1, l_y1 - s_y1 labels = _labels.copy() # Normalized xywh to pixel xyxy format # 个人觉得这个注释意思有问题（可能我理解错了？下面细说 # 这是转换到新坐标轴的坐标 if _labels.size &gt; 0: # 左上角坐标 labels[:, 0] = scale * _labels[:, 0] + padw labels[:, 1] = scale * _labels[:, 1] + padh # 右下 labels[:, 2] = scale * _labels[:, 2] + padw labels[:, 3] = scale * _labels[:, 3] + padh mosaic_labels.append(labels) plt.imshow(mosaic_img) plt.show() ​ 大概思路是先随机得到四张图片，然后创建一个大小为网络输入两倍的input，随机（0.5-1.5 scale）生成一个mosaic center（简单理解就是四张图片的公共点）。之后按照顺序拼接到左上、右上、左下、右下四个部分。 ​ 当一张图片放入画布时，得到x，y的原偏移量（padw，padh），然后计算偏移后的bbox位置。 ​ 有个问题是新bbox的坐标，注释写的是xywh转x1 y1 x2 y2，但是个人实现的时候发现输入是bbox的x1y1x2y2转换能正确框出，有无评论区大佬说明一下。 第二部分：图像旋转与剪切 if len(mosaic_labels): # 将bbox超出画布部分变为画布边缘 mosaic_labels = np.concatenate(mosaic_labels, 0) np.clip(mosaic_labels[:, 0], 0, 2 * input_w, out=mosaic_labels[:, 0]) np.clip(mosaic_labels[:, 1], 0, 2 * input_h, out=mosaic_labels[:, 1]) np.clip(mosaic_labels[:, 2], 0, 2 * input_w, out=mosaic_labels[:, 2]) np.clip(mosaic_labels[:, 3], 0, 2 * input_h, out=mosaic_labels[:, 3])# 顺时针旋转degree°，输出新的图像和新的bbox坐标 mosaic_img, mosaic_labels = random_perspective( mosaic_img, mosaic_labels, degrees=self.degrees, translate=self.translate, scale=self.scale, shear=self.shear, perspective=self.perspective, border=[-input_h // 2, -input_w // 2], ) # border to remove ​ 这一部分就比较简单了，先是用clip函数处理好画布，然后旋转一个角度，旋转后bbox坐标变化其实可以不用关心，因为角度很小物体几乎超不出bbox的范围。细究旋转代码可以自己去看看我不想看了，最后还裁剪成了input size，所以这个最后输出还是input size而不是2*input size Mix up论文mosaic后半部分还增加了mixup（可选，但默认使用 # ----------------------------------------------------------------- # CopyPaste: https://arxiv.org/abs/2012.07177 # ----------------------------------------------------------------- if ( self.enable_mixup and not len(mosaic_labels) == 0 and random.random() &lt; self.mixup_prob # 如果mosaic_prob=0.5 mixup_prob=0.5这里0.5*0.5是0.25的概率mixup了 ): mosaic_img, mosaic_labels = self.mixup(mosaic_img, mosaic_labels, self.input_dim) # 这里还增加了其他的预处理 mix_img, padded_labels = self.preproc(mosaic_img, mosaic_labels, self.input_dim) img_info = (mix_img.shape[1], mix_img.shape[0]) # ----------------------------------------------------------------- # img_info and img_id are not used for training. # They are also hard to be specified on a mosaic image. # ----------------------------------------------------------------- return mix_img, padded_labels, img_info, img_id else: # 这个else是和mosaic的if对应的，不mosaic则默认只有预处理 self._dataset._input_dim = self.input_dim img, label, img_info, img_id = self._dataset.pull_item(idx) img, label = self.preproc(img, label, self.input_dim) return img, label, img_info, img_id # mixup函数 def mixup(self, origin_img, origin_labels, input_dim): jit_factor = random.uniform(*self.mixup_scale) # 图像是否翻转 FLIP = random.uniform(0, 1) &gt; 0.5 cp_labels = [] # 保证不是背景 load_anno函数不涉及图像读取会更快（coco类 while len(cp_labels) == 0: cp_index = random.randint(0, self.__len__() - 1) cp_labels = self._dataset.load_anno(cp_index) # 确定不是背景后再载入img img, cp_labels, _, _ = self._dataset.pull_item(cp_index) # 创建画布 if len(img.shape) == 3: cp_img = np.ones((input_dim[0], input_dim[1], 3), dtype=np.uint8) * 114 else: cp_img = np.ones(input_dim, dtype=np.uint8) * 114 # 计算scale cp_scale_ratio = min(input_dim[0] / img.shape[0], input_dim[1] / img.shape[1]) # resize resized_img = cv2.resize( img, (int(img.shape[1] * cp_scale_ratio), int(img.shape[0] * cp_scale_ratio)), interpolation=cv2.INTER_LINEAR, ) # 放入画布 cp_img[ : int(img.shape[0] * cp_scale_ratio), : int(img.shape[1] * cp_scale_ratio) ] = resized_img # 画布放大jit factor倍 cp_img = cv2.resize( cp_img, (int(cp_img.shape[1] * jit_factor), int(cp_img.shape[0] * jit_factor)), ) cp_scale_ratio *= jit_factor if FLIP: cp_img = cp_img[:, ::-1, :] # 以上创建好了一个可以mix up的图像 # 下面开始mix up # 创建的画布向输入的图像上面叠加 origin_h, origin_w = cp_img.shape[:2] target_h, target_w = origin_img.shape[:2] # 取最大面积然后全部padding 0 padded_img = np.zeros( (max(origin_h, target_h), max(origin_w, target_w), 3), dtype=np.uint8 ) # 放入新画布（也只有新画布 padded_img[:origin_h, :origin_w] = cp_img # 随机偏移量 x_offset, y_offset = 0, 0 if padded_img.shape[0] &gt; target_h: y_offset = random.randint(0, padded_img.shape[0] - target_h - 1) if padded_img.shape[1] &gt; target_w: x_offset = random.randint(0, padded_img.shape[1] - target_w - 1) # 裁剪画布 padded_cropped_img = padded_img[ y_offset: y_offset + target_h, x_offset: x_offset + target_w ] # 调整scale后画布中图像的bbox坐标 cp_bboxes_origin_np = adjust_box_anns( cp_labels[:, :4].copy(), cp_scale_ratio, 0, 0, origin_w, origin_h ) # 是否镜像翻转 if FLIP: cp_bboxes_origin_np[:, 0::2] = ( origin_w - cp_bboxes_origin_np[:, 0::2][:, ::-1] ) # 调整裁剪后bbox坐标（以裁剪左上角为新的原点 cp_bboxes_transformed_np = cp_bboxes_origin_np.copy() cp_bboxes_transformed_np[:, 0::2] = np.clip( cp_bboxes_transformed_np[:, 0::2] - x_offset, 0, target_w ) cp_bboxes_transformed_np[:, 1::2] = np.clip( cp_bboxes_transformed_np[:, 1::2] - y_offset, 0, target_h ) # 通过五个条件判断offset是否合理，下面细说 keep_list = box_candidates(cp_bboxes_origin_np.T, cp_bboxes_transformed_np.T, 5) # 满足条件则合并label和image if keep_list.sum() &gt;= 1.0: cls_labels = cp_labels[keep_list, 4:5].copy() box_labels = cp_bboxes_transformed_np[keep_list] labels = np.hstack((box_labels, cls_labels)) origin_labels = np.vstack((origin_labels, labels)) origin_img = origin_img.astype(np.float32) origin_img = 0.5 * origin_img + 0.5 * padded_cropped_img.astype(np.float32) return origin_img.astype(np.uint8), origin_labels 总体来说比较好理解，因为坐标变换方法和mosaic相同，而最头疼的就是坐标变换了。 首先随机出一个非背景图像（必定有bbox的图像），然后缩放到input size，再放入input size（比如650*640）大小的画布。然后画布整体放大到jit facotr倍，在原图和新图中寻找最大的画布，在大画布中随机出裁剪偏移量，裁剪，检查没问题后mix up即可。 大致流程如下（省略了寻找最大的画布过程）： 下面讲检查函数box_candidates： def box_candidates(box1, box2, wh_thr=2, ar_thr=20, area_thr=0.2): # box1(4,n), box2(4,n) # Compute candidate boxes which include follwing 5 things: # box1 before augment, box2 after augment, wh_thr (pixels), aspect_ratio_thr, area_ratio w1, h1 = box1[2] - box1[0], box1[3] - box1[1] w2, h2 = box2[2] - box2[0], box2[3] - box2[1] ar = np.maximum(w2 / (h2 + 1e-16), h2 / (w2 + 1e-16)) # aspect ratio return ( (w2 &gt; wh_thr) &amp; (h2 &gt; wh_thr) &amp; (w2 * h2 / (w1 * h1 + 1e-16) &gt; area_thr) &amp; (ar &lt; ar_thr) ) # candidates 就是将偏移后的box和偏移前的box进行比较，四项指标分别是偏移后的box宽度，高度，面积，box长宽比 注释里写的五个实现只有四个 最终结果，中间的那两个是mix up 自用代码因为yolox等里面肯定是用了各种东西对dataloader加速比如pycoco类封装（这个包不是很懂）、preload等，一时半会也看不完。只好剥离了，loader的效率估计不会那么高 以后变成大牛了再加吧 # -*- coding:utf-8 -*-# @Author : Dummerfu# @Contact : https://github.com/dummerchen # @Time : 2021/9/25 14:06import mathfrom draw_box_utli import draw_boxfrom torch.utils.data import Datasetfrom VocDataset import VocDataSetimport matplotlib as mplimport randomimport cv2import numpy as npfrom matplotlib import pyplot as pltmpl.rcParams[&#x27;font.sans-serif&#x27;] = &#x27;SimHei&#x27;mpl.rcParams[&#x27;axes.unicode_minus&#x27;] = Falsedef get_mosaic_coordinate(mosaic_image, mosaic_index, xc, yc, w, h, input_h, input_w): # TODO update doc # index0 to top left part of image if mosaic_index == 0: x1, y1, x2, y2 = max(xc - w, 0), max(yc - h, 0), xc, yc small_coord = w - (x2 - x1), h - (y2 - y1), w, h # index1 to top right part of image elif mosaic_index == 1: x1, y1, x2, y2 = xc, max(yc - h, 0), min(xc + w, input_w * 2), yc small_coord = 0, h - (y2 - y1), min(w, x2 - x1), h # index2 to bottom left part of image elif mosaic_index == 2: x1, y1, x2, y2 = max(xc - w, 0), yc, xc, min(input_h * 2, yc + h) small_coord = w - (x2 - x1), 0, w, min(y2 - y1, h) # index2 to bottom right part of image elif mosaic_index == 3: x1, y1, x2, y2 = xc, yc, min(xc + w, input_w * 2), min(input_h * 2, yc + h) # noqa small_coord = 0, 0, min(w, x2 - x1), min(y2 - y1, h) return (x1, y1, x2, y2), small_coorddef random_perspective( img, targets=(), degrees=10, translate=0.1, scale=0.1, shear=10, perspective=0.0, border=(0, 0),): # targets = [cls, xyxy] height = img.shape[0] + border[0] * 2 # shape(h,w,c) width = img.shape[1] + border[1] * 2 # Center C = np.eye(3) C[0, 2] = -img.shape[1] / 2 # x translation (pixels) C[1, 2] = -img.shape[0] / 2 # y translation (pixels) # Rotation and Scale R = np.eye(3) a = random.uniform(-degrees, degrees) # a += random.choice([-180, -90, 0, 90]) # add 90deg rotations to small rotations s = random.uniform(scale[0], scale[1]) # s = 2 ** random.uniform(-scale, scale) R[:2] = cv2.getRotationMatrix2D(angle=a, center=(0, 0), scale=s) # Shear S = np.eye(3) S[0, 1] = math.tan(random.uniform(-shear, shear) * math.pi / 180) # x shear (deg) S[1, 0] = math.tan(random.uniform(-shear, shear) * math.pi / 180) # y shear (deg) # Translation T = np.eye(3) T[0, 2] = ( random.uniform(0.5 - translate, 0.5 + translate) * width ) # x translation (pixels) T[1, 2] = ( random.uniform(0.5 - translate, 0.5 + translate) * height ) # y translation (pixels) # Combined rotation matrix M = T @ S @ R @ C # order of operations (right to left) is IMPORTANT ########################### # For Aug out of Mosaic # s = 1. # M = np.eye(3) ########################### if (border[0] != 0) or (border[1] != 0) or (M != np.eye(3)).any(): # image changed if perspective: img = cv2.warpPerspective( img, M, dsize=(width, height), borderValue=(114, 114, 114) ) else: # affine img = cv2.warpAffine( img, M[:2], dsize=(width, height), borderValue=(114, 114, 114) ) # Transform label coordinates n = len(targets) if n: # warp points xy = np.ones((n * 4, 3)) xy[:, :2] = targets[:, [0, 1, 2, 3, 0, 3, 2, 1]].reshape( n * 4, 2 ) # x1y1, x2y2, x1y2, x2y1 xy = xy @ M.T # transform if perspective: xy = (xy[:, :2] / xy[:, 2:3]).reshape(n, 8) # rescale else: # affine xy = xy[:, :2].reshape(n, 8) # create new boxes x = xy[:, [0, 2, 4, 6]] y = xy[:, [1, 3, 5, 7]] xy = np.concatenate((x.min(1), y.min(1), x.max(1), y.max(1))).reshape(4, n).T # clip boxes xy[:, [0, 2]] = xy[:, [0, 2]].clip(0, width) xy[:, [1, 3]] = xy[:, [1, 3]].clip(0, height) # filter candidates i = box_candidates(box1=targets[:, :4].T * s, box2=xy.T) targets = targets[i] targets[:, :4] = xy[i] return img, targetsdef box_candidates(box1, box2, wh_thr=2, ar_thr=20, area_thr=0.2): # box1(4,n), box2(4,n) # Compute candidate boxes which include follwing 5 things: # box1 before augment, box2 after augment, wh_thr (pixels), aspect_ratio_thr, area_ratio w1, h1 = box1[2] - box1[0], box1[3] - box1[1] w2, h2 = box2[2] - box2[0], box2[3] - box2[1] ar = np.maximum(w2 / (h2 + 1e-16), h2 / (w2 + 1e-16)) # aspect ratio return ( (w2 &gt; wh_thr) &amp; (h2 &gt; wh_thr) &amp; (w2 * h2 / (w1 * h1 + 1e-16) &gt; area_thr) &amp; (ar &lt; ar_thr) ) # candidatesdef adjust_box_anns(bbox, scale_ratio, padw, padh, w_max, h_max): bbox[:, 0::2] = np.clip(bbox[:, 0::2] * scale_ratio + padw, 0, w_max) bbox[:, 1::2] = np.clip(bbox[:, 1::2] * scale_ratio + padh, 0, h_max) return bboxclass MasaicDataset(Dataset): def __init__( self, dataset, input_size=(640,640),mosaic=True, preproc=None, degrees=10.0, translate=0.1, mosaic_scale=(0.5, 1.5), mixup_scale=(0.5, 1.5), shear=2.0, perspective=0.0, enable_mixup=True, mosaic_prob=1.0, mixup_prob=1.0, *args ): &quot;&quot;&quot; Args: dataset(Dataset) : Pytorch dataset object. img_size (tuple): mosaic (bool): enable mosaic augmentation or not. preproc (func): degrees (float): translate (float): mosaic_scale (tuple): mixup_scale (tuple): shear (float): perspective (float): enable_mixup (bool): *args(tuple) : Additional arguments for mixup random sampler. &quot;&quot;&quot; self._dataset = dataset self.input_dim=input_size self.preproc = preproc self.degrees = degrees self.translate = translate self.scale = mosaic_scale self.shear = shear self.perspective = perspective self.mixup_scale = mixup_scale self.enable_mosaic = mosaic self.enable_mixup = enable_mixup self.mosaic_prob = mosaic_prob self.mixup_prob = mixup_prob def __len__(self): return len(self._dataset) def __getitem__(self, idx): if self.enable_mosaic and random.random() &lt; self.mosaic_prob: mosaic_labels = [] input_h, input_w = self.input_dim[0], self.input_dim[1] # input_h,input_w=2600,4624 # yc, xc = s, s # mosaic center x, y # 画布大小为input_h,input_w # yc = int(random.uniform(0.5 * input_h, 1.5 * input_h)) # xc = int(random.uniform(0.5 * input_w, 1.5 * input_w)) yc=640 xc=640 # 3 additional image indices indices = [idx] + [random.randint(0, len(self._dataset) - 1) for _ in range(3)] for i_mosaic, index in enumerate(indices): img, target = self._dataset.pull_item(index) _labels=target[&#x27;labels&#x27;] h0, w0 = target[&#x27;image_info&#x27;] # orig hw scale = min(1. * input_h / h0, 1. * input_w / w0) # img 放大到input size img = cv2.resize( img, (int(w0 * scale), int(h0 * scale)), interpolation=cv2.INTER_LINEAR ) # generate output mosaic image (h, w, c) = img.shape[:3] # draw_box( # img, _labels[:, :4], # classes=_labels[:, -1], # category_index=self._dataset.name2num, # scores=np.ones(shape=(len(_labels[:, -1]))), # thresh=0 # ) if i_mosaic == 0: mosaic_img = np.full((input_h * 2, input_w * 2, c), 114, dtype=np.uint8) # suffix l means large image, while s means small image in mosaic aug. (l_x1, l_y1, l_x2, l_y2), (s_x1, s_y1, s_x2, s_y2) = get_mosaic_coordinate( mosaic_img, i_mosaic, xc, yc, w, h, input_h, input_w ) mosaic_img[l_y1:l_y2, l_x1:l_x2] = img[s_y1:s_y2, s_x1:s_x2] padw, padh = l_x1 - s_x1, l_y1 - s_y1 labels = _labels.copy() # Normalized xywh to pixel xyxy format if _labels.size &gt; 0: labels[:, 0] = scale * _labels[:, 0] + padw labels[:, 1] = scale * _labels[:, 1] + padh labels[:, 2] = scale * _labels[:, 2] + padw labels[:, 3] = scale * _labels[:, 3] + padh mosaic_labels.append(labels) if len(mosaic_labels): mosaic_labels = np.concatenate(mosaic_labels, 0) np.clip(mosaic_labels[:, 0], 0, 2 * input_w, out=mosaic_labels[:, 0]) np.clip(mosaic_labels[:, 1], 0, 2 * input_h, out=mosaic_labels[:, 1]) np.clip(mosaic_labels[:, 2], 0, 2 * input_w, out=mosaic_labels[:, 2]) np.clip(mosaic_labels[:, 3], 0, 2 * input_h, out=mosaic_labels[:, 3]) mosaic_img, mosaic_labels = random_perspective( mosaic_img, mosaic_labels, degrees=self.degrees, translate=self.translate, scale=self.scale, shear=self.shear, perspective=self.perspective, border=[-input_h // 2, -input_w // 2], ) # border to remove # ----------------------------------------------------------------- # CopyPaste: https://arxiv.org/abs/2012.07177 # ----------------------------------------------------------------- if ( self.enable_mixup and not len(mosaic_labels) == 0 and random.random() &lt; self.mixup_prob ): mosaic_img, mosaic_labels = self.mixup(mosaic_img, mosaic_labels, self.input_dim) # mix_img, padded_labels = self.preproc(mosaic_img, mosaic_labels, self.input_dim) img_info = (mosaic_img.shape[1], mosaic_img.shape[0]) draw_box( mosaic_img, mosaic_labels[:, :4], classes=mosaic_labels[:, -1], category_index=self._dataset.num2name, scores=np.ones(shape=(len(mosaic_labels[:, -1]))), thresh=0 ) # 想怎么输出怎么输出 return mosaic_img, mosaic_labels,img_info else: img, target = self._dataset.pull_item(idx) # img, label = self.preproc(img, label, self.input_dim) return img, target def mixup(self, origin_img, origin_labels, input_dim): jit_factor = random.uniform(*self.mixup_scale) FLIP = random.uniform(0, 1) &gt; 0.5 cp_labels = [] img=None while len(cp_labels) == 0: cp_index = random.randint(0, self.__len__() - 1) img,target = self._dataset.pull_item(cp_index) cp_labels=target[&#x27;labels&#x27;] draw_box(img,cp_labels[:,:4],cp_labels[:,-1],self._dataset.num2name,scores=np.ones(len(cp_labels[:,-1]))) if len(img.shape) == 3: cp_img = np.ones((input_dim[0], input_dim[1], 3), dtype=np.uint8) * 114 else: cp_img = np.ones(input_dim, dtype=np.uint8) * 114 cp_scale_ratio = min(input_dim[0] / img.shape[0], input_dim[1] / img.shape[1]) resized_img = cv2.resize( img, (int(img.shape[1] * cp_scale_ratio), int(img.shape[0] * cp_scale_ratio)), interpolation=cv2.INTER_LINEAR, ) cp_img[ : int(img.shape[0] * cp_scale_ratio), : int(img.shape[1] * cp_scale_ratio) ] = resized_img cp_img = cv2.resize( cp_img, (int(cp_img.shape[1] * jit_factor), int(cp_img.shape[0] * jit_factor)), ) cp_scale_ratio *= jit_factor if FLIP: cp_img = cp_img[:, ::-1, :] origin_h, origin_w = cp_img.shape[:2] target_h, target_w = origin_img.shape[:2] padded_img = np.zeros( (max(origin_h, target_h), max(origin_w, target_w), 3), dtype=np.uint8 ) padded_img[:origin_h, :origin_w] = cp_img x_offset, y_offset = 0, 0 if padded_img.shape[0] &gt; target_h: y_offset = random.randint(0, padded_img.shape[0] - target_h - 1) if padded_img.shape[1] &gt; target_w: x_offset = random.randint(0, padded_img.shape[1] - target_w - 1) padded_cropped_img = padded_img[ y_offset: y_offset + target_h, x_offset: x_offset + target_w ] cp_bboxes_origin_np = adjust_box_anns( cp_labels[:, :4].copy(), cp_scale_ratio, 0, 0, origin_w, origin_h ) if FLIP: cp_bboxes_origin_np[:, 0::2] = ( origin_w - cp_bboxes_origin_np[:, 0::2][:, ::-1] ) cp_bboxes_transformed_np = cp_bboxes_origin_np.copy() cp_bboxes_transformed_np[:, 0::2] = np.clip( cp_bboxes_transformed_np[:, 0::2] - x_offset, 0, target_w ) cp_bboxes_transformed_np[:, 1::2] = np.clip( cp_bboxes_transformed_np[:, 1::2] - y_offset, 0, target_h ) keep_list = box_candidates(cp_bboxes_origin_np.T, cp_bboxes_transformed_np.T, 5) if keep_list.sum() &gt;= 1.0: cls_labels = cp_labels[keep_list, 4:5].copy() box_labels = cp_bboxes_transformed_np[keep_list] labels = np.hstack((box_labels, cls_labels)) origin_labels = np.vstack((origin_labels, labels)) origin_img = origin_img.astype(np.float32) origin_img = 0.5 * origin_img + 0.5 * padded_cropped_img.astype(np.float32) return origin_img.astype(np.uint8), origin_labelsif __name__ == &#x27;__main__&#x27;: pass # vocdataset=VocDataSet(voc_root=r&#x27;E:\\py_exercise\\Dataset\\pear_dataset\\voc&#x27;,) vocdataset=VocDataSet( voc_root=r&#x27;E:\\py_exercise\\deep-learning-for-image-processing\\pytorch_object_detection\\faster_rcnn\\taboca\\Tobacco&#x27;, image_folder_name=&#x27;JPEGImages&#x27; ) dataset=MasaicDataset( dataset=vocdataset, ) next(iter(dataset))","categories":[{"name":"技术","slug":"技术","permalink":"https://dummerfu.top/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"trick","slug":"trick","permalink":"https://dummerfu.top/tags/trick/"}],"keywords":[{"name":"技术","slug":"技术","permalink":"https://dummerfu.top/categories/%E6%8A%80%E6%9C%AF/"}]},{"title":"2021数模国赛反思","slug":"2021数模国赛反思","date":"2021-09-17T00:00:00.000Z","updated":"2021-12-01T00:00:00.000Z","comments":true,"path":"p/49629.html","link":"","permalink":"https://dummerfu.top/p/49629.html","excerpt":"","text":"国赛已经过去一天了，评分细则也出来了，没有看评分细则时信心满满，看完之后就暴毙gg。 我们选的是C题，C题最关键的就是预测24周而评分细则说预测24周要结合前一天的订货和供货。 我们直接头铁莽供货量，用LSTM预测，虽然结果看起来还行。 因为使用ARIMA效果并不好，这种数据似乎不能用这个预测，不知别人是怎么做出来的，也可能单纯是我菜 目标函数本来是两个阶段的（我解的步骤是分两个阶段，但是论文列出来并不是，也不知道是好是坏） 最最最拉跨的就是没有分析第三问方案变动和第二问的区别….然后图还错位了两个。 第一次打也可能是最后一次 缺乏经验，也没有用程序检查最后结果的正确性（因为维度转换也可能是会错的） 总之就是gg了，国奖无了。 最后是省一，大概看了优秀论文，一三问方法都差不多，第二问有点不同，可能是图少了。","categories":[{"name":"随笔","slug":"随笔","permalink":"https://dummerfu.top/categories/%E9%9A%8F%E7%AC%94/"}],"tags":[{"name":"数模","slug":"数模","permalink":"https://dummerfu.top/tags/%E6%95%B0%E6%A8%A1/"}],"keywords":[{"name":"随笔","slug":"随笔","permalink":"https://dummerfu.top/categories/%E9%9A%8F%E7%AC%94/"}]},{"title":"Long Tail Classification Review","slug":"Long tail classification","date":"2021-09-16T00:00:00.000Z","updated":"2021-09-16T00:00:00.000Z","comments":true,"path":"p/27272.html","link":"","permalink":"https://dummerfu.top/p/27272.html","excerpt":"","text":"前言​ 暑假的比赛数据集分类极度不平衡，最多的有两万，最少的只有50多，因为是NLP，我个人是通过调百度接口回译来拓展数据集，耗时耗力还可能没效果。勉强将最少类别拓展到了5000，再重采样train的效果还行，最后还用伪标签训练了一波（这个稳定提升0.1%因为是测试集上过拟合）有大佬带飞最后也就第5名 差一名就有3000rmb了 但是数据不均衡这类问题总是很关键and常见（这类也被称为Long Tail Classification）故在此学习记录，日后实现过的会继续贴详细代码，当然遇到trick也会在此记录。 现在主要都是从知乎回答里总结出来的。 数据处理方法数据增强类重采样重采样是最简单和常见的方法了，但是越简单缺点越明显。 单纯的重采样： 少样本过采样，多样本欠采样。pandas.sample可以很方便实现 缺点是导致样本过多特征丢失，样本过少会过拟合，且数量差别越大缺点越明显。 但是仍有许多在此基础上改进的算法比如SMOTE见下文 SMOTE参考知乎 基本算法流程： 通过KNN寻找当前需要拓展点最近的K个点，随机0，1权重 新的点为K个点*权重平均 看似简单弊端很多，但是通过时间的‘洗礼’现在也渐渐变的成熟了，比如不再通过原始数据KNN，而是通过特征数据KNN。最后附上sklearn已经封装好的SMOTE的Github 生成数据​ 在NLP中可以通过提取近义词、关键字、回译来生成新的数据，来增加少数据这就是我2021.8.1比赛用的方法 高端点可以使用Gan或者其他半监督自监督模型Long-Tailed Classification by Keeping the Good and Removing the Bad Momentum Causal Effect诸如此类。 论文还是看少了啊 Mosaic​ 这个在ultralytics-YOLOv3被提出（有撞车现象），在CV方向中，小目标的AP一般比中目标和大目标低很多。虽然数据集中也包含大量的小目标类别，但比较麻烦的是小目标的分布并不均匀 也可以看作BBox类别不均衡。 ​ Mosaic要随机使用x张图片，随机缩放，再随机分布进行拼接，大大丰富了检测数据集，特别是随机缩放增加了很多小目标，让网络的鲁棒性更好。由于拼接图像的挑选组合是随机的，拼接图像的多样性防止了过拟合的发生。可以提升1% ​ 然后对loss设置一个阈值，如果小于这个阈值则采用拼接后的数据训练一个iterater否则采用原来数据训练一个iterater具体可参考Stitcher，代码分析可以看另一篇 Mix up​ 同样是CV方向，先读取一张图片，图像两侧填充，缩放到640*640大小，即Image_1，假设人脸检测框为红色框。再随机选取一张图片，图像上下填充，也缩放到640*640大小，即Image_2，假设人脸检测框为蓝色框。然后设置一个融合系数，比如上图中，设置为0.5，将Image_1和Image_2，加权融合，得到最终Image。最终的Image人脸的红色框和蓝色框是叠加存在的。 ​ 在训练的最后15个epoch，这Mix up，mosaic会被关闭掉不追求sota不关应该也没大问题吧。而在此之前，Mosaic和Mixup数据增强，都是打开的，这个细节需要注意。由于采取了更强的数据增强方式，作者在研究中发现，ImageNet预训练将毫无意义，因此，所有的模型，均是从头开始训练的。参考知乎yolox讲解 困难样本挖掘OHEM(online hard negative/example mining)听说是度量学习常用的方法。我也没学过 但是hard negative/example mining 你肯定听说过（RCNN里使用的）。 具体思想是先正负样本均衡训练一遍，再预测负样本，将hard negative分离出来加入负样本训练集中再重新训练。大众比喻是错题集针对训练 模型类focal loss​ 对于每一类出现的概率可能会不相同，直接修改loss函数，对loss进行加权，详情可见论文Focal Loss for Dense Object Detection 简单可以表示为 FL=\\sum_{t=1}^{n}-\\alpha(1-p_t)^\\gamma logp_t$\\gamma$​，$\\alpha$​为超参数，一般为1 模型融合对，模型融合也能降bias 模型融合最基本的就是投票法了，容易实现的效果都可见一般。 另一个就是使用最广泛的加权投票：先权重加权再相加，选取概率最大的，个人实验平均加权就投票多了0.3%。 当然这里面也有各种trick，比如有最简单的按照类别数目的倒数来做加权，按照“有效”样本数加权，根据样本数优化分类间距的loss加权（个人感觉不太行）等等。对于这类方法，还可以用bayesian对每个样本做uncertainty估计，来refine决策边界，再或者后面接一个线性回归层自己训练。这类方法目前应该是使用的最广泛的，可以看一下这个2015年的survey paper，但是哪一类最有效我也还没全试过 解耦 解耦特征和分类器（decoupling representation &amp; classifier）：最近的研究发现将特征学习和分类器学习解耦，把不平衡学习分为两个阶段，在特征学习阶段正常采样，在分类器学习阶段平衡采样，可以带来更好的长尾学习结果 To be Continued 读论文去了","categories":[{"name":"随笔","slug":"随笔","permalink":"https://dummerfu.top/categories/%E9%9A%8F%E7%AC%94/"}],"tags":[{"name":"trick","slug":"trick","permalink":"https://dummerfu.top/tags/trick/"}],"keywords":[{"name":"随笔","slug":"随笔","permalink":"https://dummerfu.top/categories/%E9%9A%8F%E7%AC%94/"}]},{"title":"【论文】深度学习CV方向论文解读","slug":"深度学习CVpaper","date":"2021-09-01T00:00:00.000Z","updated":"2022-01-11T00:00:00.000Z","comments":true,"path":"p/61340.html","link":"","permalink":"https://dummerfu.top/p/61340.html","excerpt":"","text":"前言本文章通过时间轴来按顺序整理CV方向的经典paper的优势和该paper对之前的改进以及个人吐槽。 每篇paper主要从网络架构和数据增强两方面来分析学习trick。 个人哔哔纯属吐槽，不具有专业性分析参考 PS：paper的时间按照arxiv最后时间为准，不代表论文最初发表时间。因为我也被弄糊涂了 后来发现要写的论文很多，都放在一篇文章不太合适不好水博客啊，以后就分开写算了，这样每篇篇幅也能更长一点。发现自己很容易就忘记之前总结的东西 2012 Alexnet Author：Alex Krizhevsky Alex Net网络将饱和非线性神经元（tanh，sigmod）换为了非饱和非线性神经元：训练快了6倍由于sigmod激活 ，如果hidden layer越来越小，梯度弥散，如果前面hidden layer 越来越大，则会导致梯度爆炸。使用LRN（local response normalization）局部响应归一化：有助于快速收敛，增加泛化能力侧抑制（lateral inhibitio），即指被激活的神经元抑制相邻的神经元。归一化（normaliazation）的目的就是“抑制”,LRN就是借鉴这种侧抑制来实现局部抑制，尤其是我们使用ReLU的时候，这种“侧抑制”很有效 ，由于ReLU的相应结果是无界的，所以需要归一化。 LRN因为不提高准确率参数量还很多，被VGG抛弃空间池化部分：采用重叠池化（overlap pooling） Overlap Pooling ：通过设置步长s小于池化的kernel size z，重复使用平均池化，更难过拟合。dropout：减少过拟合 ​ 算是现在很常见的一个东西了，不过有normalization layer后就没怎么用了。数据增强随机裁剪+镜像反射：提高准确率 通过对图像（255，255，3）四个角为中心进行随机裁剪（224，224，3）的图像，然后再水平翻转得到10张图像，通过softmax层后求precision的平均。主成分提取PCA：减少了top-1 error 1%在整个ImageNet训练集上对RGB像素值执行PCA。对于每幅图像加上多倍找到的主成分，大小成正比的对应特征值乘以一个随机变量，随机变量通过均值为0，标准差为0.1的高斯分布得到。 2014.2.24 Overfeat Author: Pierre Sermanet Overfeat这篇算法没有完整的流程图，没怎么看懂怎么实现的，无法细讲。似乎是通过回归来预测bounding box的位置？我主要问题是加滑动窗口pool是训练集就有吗？分类和定位是同时的话是网络再并联一个1*1卷积提取bbox参数回归？如果是这样感觉类似后面的decouple head思想。网络网络功能分为三个部分：分类（特征提取）、定位、检测。滑动窗口提取特征：因为考虑后面的定位和检测，没有像AlexNet把输入图像分五份随机裁剪再水平翻转：因为这样会打乱图片的空间特征（和以前的全连接层一样，被改进为卷积也有部分原因是强调图片空间特征），所以使用’’暴力”裁剪，stride分别为0，1，2移动，裁剪图片作为输入。这个窗口类似kernel只不过相当于裁剪？根据前5层layer进行特征提取共享特征权重，后面接上进行分类和定位的区分全连接层。定位：根据每个窗口裁剪出来的图片先分类，再回归bbox，预测的bbox iou&lt;50%为FP个人哔哔​ 好家伙，发现对比图里面居然有vgg，时间线被搞错乱了，难道vgg才是1*1卷积代替全连接的开山鼻祖？​ 注意这篇论文不是sota！这里我个人认为是由于AlexNet为网络架构（太浅了）更难提升准确率，所以文章说的时间限制应该是说没有时间尝试其他的模型。​ 这个类似遍历的方式裁剪图片|获取特征注定了复杂度会很高，将来会有更好的算法替代（如后篇的SS） 2014.3.4 Network in Network Author: Min Lin NIN介绍了多层感知机(mutilayer perceptrons)和线性激活函数，全连接层的劣势：线性函数针对特定函数才能近似不具有通用性，全连接层太容易过拟合，可解释性低。基于maxout net提出MLP conv：先在原始两个卷积层中多插入一个MLP层进行非线性提取特征，共享MLP层权重也使模型有更高的表达能力，然后在后面加个非线性函数relu。使凸函数近似变成通用函数近似。提出全局平均池化GAP(global average pooling)：原来的fc层因为要训练超参数容易过拟合，替换为GAP后直接取特征图的平均，也将特征图和类别联系了起来，而且没有超参数的训练，减少了过拟合和增加了模型的可解释性，还不用dropout(然后被googlenet打脸了)个人哔哔这篇论文是解决了fc层解释性差和fc层的过拟合问题，把卷积替换全连接怕不是借鉴了别人（感觉这篇和overfeat很像但是侧重点不同，时间线仍然错乱）。下面解释一下为什么能够替换，参考这篇1*1 conv 介绍，和这篇mlp conv先看如下两张图图片1图片2手动计算一下图二输入层数：No.Intput SizeconvstridepaddingOutput Size1224*224*311*11*964355*55*96255*55*961*1*961055*55*96355*55*961*1*961055*55*96由图1可见mlp conv就是加几个hidden layer 然后relu，输出和输入通道数不变，只增加了非线性性。同图2和上面推导，11卷积也可以实现上述功能，但是1\\1卷积也可不只实现上述功能。当1*1卷积通道数不变时+relu，则起到的是mlp conv作用。当1*1卷积通道数不等于输入维度时，起到升维降维作用（降低参数量）。当1*1卷积通道数等于分类数则是替代全连接层（前面一层会将输入变为1*1*channel，然后再是1*1*n_class的卷积） 2014.10.22 R-CNN Author：Ross Girshick RCNN网络提出迁移学习：在大数据集上进行有监督预训练，然后针对特定数据集进行微调（提升了8%！！！）采样selective search算法搜索region proposal：region proposal算法包含很多种，SS算法是最受欢迎的一种之一。Selective Search 源码分析，python源码github 非官方:先通过图像分隔（skimage.segmentation.felzenszwalb）将图片每一个pixel分到一个label（label是唯一的），第一次先遍历这些pixel得到区域信息，区域是矩形划分的。再求出每个区域之间的texure gradient，color histogarm，region size相似度，如果区域相邻且相似则合并（相似是通过判断区域矩形是否相交）。重复上述步骤。可以看出SS是通过先分隔再不停遍历来求出BBox的，复杂度比然很高，而且图片越大越难搞借鉴了A Deep Convolutional Activation Feature for Generic Visual Recognition把Alexnet当backbone用来提取特征的思想。只把卷积作为提取特征的工具，最后一层分类使用的是svm，每一类都用一个svm。分类的时候不光分类了种类，还将背景单独分了一类。（如今的two filter的启发可能来于这）困难负样本挖掘（hard negative mining）:因为detect会有很多负样本，正负样本不均衡。这也是目标识别的一大通病，所以要增加负样本的’’质量’’ 。hard negative就是每次把那些顽固的棘手的错误,再送回去继续练,练到你的成绩不再提升为止.这一个过程就叫做’hard negative mining.具体可以参考知乎使用不同网络做backbone效果会有差别，把VGG和AlexNet对比：map增加了8%，训练时间长了7倍。数据处理先固定图像尺寸为500pixels，然后再输入到ss算法中由于backbone为AlexNet，ss的输出大小都是不同的要将图像变为224*224的大小输入，scale采用的方法如下：tightest square with context：是指在原始图像上找到这样一个可以包含整个proposal 的最小的正方形，然后将这个正方形 rescale 为卷积网络可以接受的尺寸tightest square without contextwarp：直接rescale到输入尺寸个人哔哔​ 提出预训练和backbone的思想，region proposal使用ss提取，算法复杂度注定了还有改进空间，svm分类后来也被换为了卷积。然后就是hard negative mining 不会过拟合吗。​ 论文说和overfeat很相似，但是overfeat是rcnn的特例，只是RCNN是每一类用svm分离和每一类都有一个bbox的回归​ 这几篇代码都是matlab或C++写的，我刚好就是看不惯matlab。 matlab果然是上个时代的产物 2014.9.17 GoogleNet Author: Christian Szegedy Google Net网络在1*1卷积降维基础上为了保留压缩信息提出了deep concat。NIN 说GAP可以不用dropout，但是googlenet网络最后还是用了。目标检测方面借鉴了RCNN的SS搜索：突然看到RCNN猝不及防通过ensemble 6个ConvNets 对每个proposal region进行分类，提高了近4个百分点，但是由于时间原因使用Bounding box回归。个人哔哔​ 个人觉得提出了deep concat是一个很好的创新点，因为每一个新的网络模型都能带来不同的思想方向，比如说后面的dw卷积说没有受到这篇的启发是不可能的。从这篇也看到了1*1卷积应用广泛，后面就不再单独提这个了 2015.4.10 Fully Convolutional Network Author：Jonathan Long FCN个人哔哔​ 如果目前时间顺序是对的话，个人感觉这篇没什么，全连接用卷积替代早在前面几篇就有所端倪了，不过是整合并证明了一下。也可能是我理论基础不太行，看不懂毕竟这篇几乎算图像分割的开山之作了​ 但是文章中出现了新词patch-wise（虽然文中说也可以不用patch-wise）：这篇stackoverflow关于patch-wise回答的挺好，可以看看：术语“Patchwise ”旨在避免完整图像训练的冗余。在语义分割中，假设您对图像中的每个像素进行分类，通过使用整个图像，您在输入中添加了大量冗余。在训练分割网络期间避免这种情况的标准方法是从训练集中向网络提供批量随机补丁（感兴趣对象周围的小图像区域）而不是完整图像。这种“逐块采样”确保输入具有足够的方差并且是训练数据集的有效表示（小批量应该与训练集具有相同的分布）。这种技术还有助于更快地收敛并平衡类。在这篇论文中，他们声称没有必要使用 patch-wise 训练，如果你想平衡类，你可以对损失进行加权或采样。从另一个角度来看，逐像素分割中的全图像训练的问题在于输入图像具有很多空间相关性。要解决此问题，您可以从训练集中采样补丁（patchwise 训练）或从整个图像中采样损失。这就是为什么该小节被称为“Patchwise training is loss sampling”。因此，通过“将损失限制为其空间项的随机采样子集，可以从梯度计算中排除补丁。”他们通过随机忽略最后一层的单元来尝试这种“损失采样”，因此不会在整个图像上计算损失。 2015.4.10 VGG Author：Karen Simonyan VGG网络吸收Alexnet经验，激活层全部换成relu。大部分没有使用LRN（只用了一层）：在imagenet 准确率没有提高，还带有很高的参数。更多的使用更小的卷积（3*3）：减少参数量的同时使网络更深，表达能力更强。两个3*3卷积感受野与一个5*5 卷积相同，三个3*3卷积感受野与7*7相同，但是相比之下用更小的卷积核参数量更少。而且两个3*3卷积强迫7*7卷积分开，中间的非线性激活相当于之前的正则化层。使用1*1卷积：与线性层本质和效果相同，起到代替全连接层，更快的运算的效果。空间池化部分：没有使用平均池化，全部使用最大池化层。数据增强随机采样+镜像翻转没有像AlexNet用PCA，而是图像减去rgb平均值来消除光照影响。个人哔哔单从论文写作的角度来说VGG与AlexNet没有说每一步trick增加的准确率，所以个人认为VGG更多的是网络架构优势：小卷积多卷。而不是池化等trick。ILSVRC以top-5 error 6.8%排第二也是惨，被谷歌截胡了。感受野确实很难理解，下面简单介绍一下，具体意义可以参考这篇感受野计算公式：RF_i=(RF_{i-1}-1)*\\Pi_{k=1}^{k=i-1}stride_k+kernel\\_size第一层感受野为kernel size，即$RF_0$=1 ，由上可见该层感受野与该层stride无关输出层size计算公式：n_{out}=\\lfloor{\\frac{(n_{in}+2*padding-kernel)}{stride}}\\rfloor+1其实这两个公式是卷积和反卷积的过程，本质是相同的。感受野是从最后一层向上逆推，输出size则是从输入向下正推。No.Layerinput sizekernel sizestridepaddingoutput sizeReceptive Field(感受野)1conv28*283*3102632conv24*243*3102453conv22*223*3102274conv20*203*3102095conv18*183*31018111conv28*285*5212451conv28*287*7212271conv28*2811*114 2015.5 Unet Author:Olaf Ronneberger Unet网络这个网络很简单，无非就是卷卷卷，然后concat。论文中有几点不是很方便：每次下采样的时候长宽维度会减小，concat的时候就会需要中心裁剪(示意图片中的虚线部分)然后再concat最后生成的图片维度可以发现与原图片维度不同，这就代表输入图片不能简单的按patch输入还需额外处理，原文中是使用镜像来解决的。这里解释一下patch：通常一张超大图片都是分割成一张张小图片输入的（显存不够输入一张大图片），并且每张图片直接会有重叠(overlap)，以防边缘信息不被利用。需要注意的是论文他没有使用padding，并且后面大火的batch normalization才刚出，论文中也没有使用。上采样采用的是转置卷积而不是现在常用的双线性插值。现在大家通常修改了卷积层下采样的部分：增加padding使卷积后尺寸不变，也不用crop了。然后在卷积和relu直接加上BN层。并且用双线性插值代码更好写且效果还变强了，当然自己魔改也可 修改后的网络维度如下图(输入维度随便写的)： dice loss数据增强​ “当只有很少的训练样本可用时，数据增强是网络所需的不变性和鲁棒性的关键。我们需要的是旋转不变性，以及对变形和灰色值变化的鲁棒性。特别是训练样本的随机弹性变形似乎是训练分段的关键概念”然而只是简单的使用随机位移向量处理了一下。个人哔哔看到这个网络肯定有人会比较和FCN的区别，但是FCN相当于分割的开山鼻祖相似也没办法我也觉得没什么大区别。细节还是有的：fcn没有解决大图片的问题（我感觉这只是需求不同导致的，毕竟医学图像都很大）fcn尺度不够多，只是一个尺度卷卷卷，没有使用FPN的想法。 2015.12.10 ResNet Author:Kaiming He ResNet网络完全去掉了LRN、dropout，并采用BN（batch normalization）层替代：标准化，可以增强表达能力，防止过拟合。想象一个sigmod激活，当数据范围分布差异很大时，sigmod激活不能很好的表现出数据的差异，就像轻轻打你一拳和重重打你一拳感觉差不多，这是很糟糕的情况。batch normalization通过均值方差标准化能够很好的处理这种情况，并且最后还会scale shift 还原。BN层具体作用看这篇增加残差结构：修正了深网络的梯度的问题。残差结构的好处就是，实现了一个恒等变换$h(x)=x$，这个恒等变换实际上是一个网络的目标函数，但是由于网络越深，虽然表达能力越强，但是梯度弥散和爆炸问题明显。所以本质上是解决梯度弥散和爆炸问题。可以理解为之前论文的加强正则化效果。数据增强直接就把AlexNet和VGG结合了采用和AlexNet相同的数据增强方法：随机在图片里选取224*224大小图片，再镜像翻转。采用和VGG相同的光照影响方法：减去rgb平均值The image is resized with its shorter side randomly sampled in [256, 480] for scale augmentation. A (224, 224) crop is randomly sampled from an image or its horizontal flip, with the per-pixel mean subtracted. 先依照短边随机缩放，然后再224*224采样，随机镜像翻转，最后减去rgb均值。pytorch实现与原文有点不一样，注意一下。具体pytorch实现细节可以参考这篇使用10-crop test，提高准确率个人哔哔2015 ILSVRC top-5 error 3.57%，直接拿第一。说明了残差网络确实nb，也算是解决了深度层网络的根本问题（梯度问题|恒等变换）。 2017.6 Attention Is All You Need Author:Ashish Vaswani Transformer论文解读原论文讲解的还是比较粗略，还是得看别人的讲解和图片，强烈推荐这篇，我个人觉得我对attention还是理解不够，还不能写自己的理解。一些问题为什么使用muti head关于different representation subspaces，举一个不一定妥帖的例子：当你浏览网页的时候，你可能在颜色方面更加关注深色的文字，而在字体方面会去注意大的、粗体的文字。这里的颜色和字体就是两个不同的表示子空间。同时关注颜色和字体，可以有效定位到网页中强调的内容。使用多头注意力，也就是综合利用各方面的信息/特征。pos embed是怎么实现的attention为什么要加scaled 参考这个回答 https://www.zhihu.com/question/339723385数量级对softmax得到的分布影响非常大。在数量级较大时，softmax将几乎全部的概率分布都分配给了最大值对应的标签设y=g(x)=softmax(x)\\\\\\frac{dg(x)}{x}=\\left[\\begin{matrix}y1 ~ \\dots ~ 0 \\\\\\vdots ~ \\ddots ~ \\vdots \\\\0 ~ \\dots ~ y_n \\\\\\end{matrix}\\right ]-\\left[\\begin{matrix}y1^2 ~ y_1y_2 ~ \\dots ~ y_1y_n \\\\\\vdots ~ \\ddots ~ \\vdots \\\\y_ny_1 ~ \\dots ~ y_n^2 \\\\\\end{matrix}\\right ]某个值很大时，其余都会很接近0(onehot 向量)，上式也就会很趋近于0。所以对于如果多层堆叠假设\\begin{cases}E(q)=E(k)=0 \\\\D(q)=D(k)=1 \\\\\\end{cases}\\rightarrow \\begin{cases}E(qk)=E(q)*E(k)=0 \\\\D(qk)=D(q)*D(k)-[E(q)*E(k)]^2=1\\end{cases} \\\\令z=qk则有：\\begin{cases}E(\\sum z)=\\sum E(z)=0 \\\\D(\\sum z)=\\sum D(z)=d & d=embeding\\_dim//head\\_num=head\\_dim\\end{cases}可知，当head_dim越大时方差越大，则最大值与最小值差距越大，就导致了上述的softmax梯度消失问题。为将方差变为1，故self-attention公式如下attention=softmax(q@k*\\sqrt{dim}^{-1})@v此时D(qk)'=\\frac{D(qk)}{\\sqrt{dim}}=1为什么平常softmax并没有这一步呢？平常都是最后一层增加softmax，这时输出信号与我们需要的信号相差无几不用scaleattention有add和muti，add需要scale吗？根据论文Massive Exploration of Neural Machine Translation Architectures，由于add是由tanh激活映射到[-1,1]，方差一般会在1之内，但是维度过大时（1000以上时）也需要scale。个人哔哔​ 我之前一直以为attention 和transformer是一个东西两个名字，好长一段后才知道这两个东西不一样…就和resnet与shortcut关系相似。attention只是transformer架构里的一个小模块。并且这个小模块还包含很多不同名的attention​ 在此之前nlp迫于时间序列都是基于lstm，rnn在研究，attention机制出来之后，不仅解决了lstm，rnn并行计算的缺陷，还提出了一种全新的思想架构transformer，使不需要cnn，rnn也能有很好的效果。之后的vit，swin transformer甚至将nlp领域转移到图像分类领域，也体现了attention机制的泛用性，也算是机器学习的一个大变革了。谷歌还是nb​ 但是随之影响到的肯定是我们这批穷鬼，attention的矩阵计算机制是通过全连接实现的（还记得线性回归吗，全连接就是矩阵相乘），参数量爆炸，没及几张好卡根本跑不动。比谁卡多的时代终究来临​ 代码实现的时候发现要加载预训练权重必须按照官网的名称写，还要手写attention…，麻烦但很有收获。要注意一点，dropout rate全部都是0，如果不小心传入了默认参数验证集准确率可能会降低（很玄学,不过我也就在小数据集上训练了一个epoch，不代表广泛性仅个人记录) 2021.7 Exceeding YOLO Series in 2021 Author:Zheng Ge YoloX网络（目前这些我没具体学，就不介绍了）大致讲解见知乎这篇Anchor free：可以参考这篇SimOTA：Muti positiveEnd-to-end Yolo数据增强可以参考这篇MosaicMix up加了这两个trick可以多2.9%AP就恐怖，赶快学着用起来。个人哔哔​ 感觉是钻Yolo的空子，全篇都是各种trick，最后还说由于时间原因没有加最近transformer的成果trick，真是争分夺秒。个人觉得这篇文章基本上可以算是一篇综述了，因为我从这参考文献递归知道了许多论文，是不是和综述paper效果一样。那我这篇不就是综述的综述了，害怕​ 不过能把别人的网络改成暂时的sota也是一种本事。代码能力极强，像我这水平现在写个网络都不知道能不能写对 To be Continued","categories":[{"name":"技术","slug":"技术","permalink":"https://dummerfu.top/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"论文","slug":"论文","permalink":"https://dummerfu.top/tags/%E8%AE%BA%E6%96%87/"}],"keywords":[{"name":"技术","slug":"技术","permalink":"https://dummerfu.top/categories/%E6%8A%80%E6%9C%AF/"}]},{"title":"【数模】2020B 穿越沙漠","slug":"2020B题穿越沙漠","date":"2021-08-18T00:00:00.000Z","updated":"2021-08-18T00:00:00.000Z","comments":true,"path":"p/54346.html","link":"","permalink":"https://dummerfu.top/p/54346.html","excerpt":"","text":"许久不见动态规划，没想到数模碰到了，就想水篇久违的题解。 至于为什么不放完整论文？肯定是做的不是很好啦，话说原来数模出题人也会是ACMer吗 穿越沙漠题意​ 考虑如下的小游戏：玩家凭借一张地图，利用初始资金购买一定数量的水和食物（包括食品和其他日常用品），从起点出发，在沙漠中行走。途中会遇到不同的天气，也可在矿山、村庄补充资金或资源，目标是在规定时间内到达终点，并保留尽可能多的资金。 游戏的基本规则如下： （1）以天为基本时间单位，游戏的开始时间为第0天，玩家位于起点。玩家必须在截止日期或之前到达终点，到达终点后该玩家的游戏结束。 （2）穿越沙漠需水和食物两种资源，它们的最小计量单位均为箱。每天玩家拥有的水和食物质量之和不能超过负重上限。若未到达终点而水或食物已耗尽，视为游戏失败。 （3）每天的天气为“晴朗”、“高温”、“沙暴”三种状况之一，沙漠中所有区域的天气相同。 （4）每天玩家可从地图中的某个区域到达与之相邻的另一个区域，也可在原地停留。沙暴日必须在原地停留。 （5）玩家在原地停留一天消耗的资源数量称为基础消耗量，行走一天消耗的资源数量为基础消耗量的2倍。 （6）玩家第0天可在起点处用初始资金以基准价格购买水和食物。玩家可在起点停留或回到起点，但不能多次在起点购买资源。玩家到达终点后可退回剩余的水和食物，每箱退回价格为基准价格的一半。 （7）玩家在矿山停留时，可通过挖矿获得资金，挖矿一天获得的资金量称为基础收益。如果挖矿，消耗的资源数量为基础消耗量的3倍；如果不挖矿，消耗的资源数量为基础消耗量。到达矿山当天不能挖矿。沙暴日也可挖矿。 （8）玩家用剩余的初始资金或挖矿获得的资金在村庄去其他地方是可以购买水和食物，每箱价格为基准价格的2倍。 请根据游戏的设定，假设只有一名玩家，在整个游戏时段内每天天气状况事先全部已知，试给出一般情况下玩家的最优路径。 关卡 1关卡 2 最优解为到终点还有10470金钱，用时24天 最优解为到终点时还有12730金钱，用时30天 思路很明显的一个动态规划 设状态dp[k][j][w][f]代表第k天时在第j个点剩余水为w箱剩余食物为f箱的最大资金，则： ans=max_{w,f,i} \\quad dp[k][zd][w][f]就是遍历第每天在终点的所有水、食物的状态求最大值。 初始值设定由于起始点可以在起点购买物资，则有初始状态： dp[0][qd][w][f]=10000-cost\\_water*w-cost\\_food*f \\quad w \\in [0,400] f\\in [0,600] 其中$cost_water$​​，$cost_food$​​​​ 为购买水和食物消耗的钱。 这里假设起始为第0天，则第一天天气影响的是从第0天到第1天。 状态转移方程当第k天人在村庄j时： 第k天为沙暴天气： dp[k+1][j][w+ww-xh_water[tq]][f+ff-xh_food[tq]]}=max(dp[k][j][w][f]-2*ww*cost_water-2*ff*cost_food 非沙暴天气： ​ 从j点走到jj点 dp[k+1][jj][w+ww-xh_water[tq]][f+ff-xh_food[tq]]}=max(dp[k][j][w][f]-2*ww*cost_water-2*ff*cost_food 当第k天人在矿山j时： 挖矿： dp[k+1][j][w-dig*xh_water[tq]][f-dig*xh_food[tq]]=max(dp[k][j][w][f]+1000) 第k天为沙暴天气： dp[k+1][j][w-xh_water[tq]][f-xh_food[tq]]=max(dp[k][j][w][f]) 第k天为非沙暴天气： dp[k+1][jj][w-walk*xh_water[tq]][f-walk*xh_food[tq]]=max(dp[k][jj][w][f]) 当第k天人在其他地区时 第k天为沙暴天气： dp[k+1][j][w-xh_water[tq]][f-xh_food[tq]]=max(dp[k][j][w][f]) 第k天为非沙暴天气： ​ 从j点走到jj点 dp[k+1][jj][w-walk*xh_water[tq]][f-walk*xh_food[tq]]=max(dp[k][j][w][f]) 优化​ 虽然没有评测姬，但是作为曾经的Acmer不能容忍运行样例大于1s，所以只会转移方程还是过不了这题。 显然由样例可知，点 太 多 了！！！，我们考虑删点。 稍微思考一下就知道这题有几个隐含条件： 除了回村庄补充物资，不会走回头路。 除了挖矿和沙尘暴不会在原地停留。 只会走关键点之间的最短路径 故我们只需要将关键点之间的最短路求出，最短路经过的点才被认为是有效点，最短路经过的边才被认为是有效边，这样就可以化简图了。 化简之后的路径图如下： ​ 可见有效点只有10个大大减少了时间复杂度，但是点数超过13仍会爆空间和时间，空间可以试试滚动数组优化，时间我是没什么好办法了。 代码第一关代码#include&lt;bits/stdc++.h&gt;#include&lt;iostream&gt;using namespace std;// 点数const int N=11,M=28,inf=0x3f3f3f,Day=30;int dp[32][N+1][405][605],zd,qd,FZ;int cost_water,cost_food,walk,dig,buy;int xh_water[3]=&#123;5,8,10&#125;,xh_food[3]=&#123;7,6,10&#125;;bool cz[N+1],ks[N+1];struct node&#123; short day; // i short from; // jj j int water,food; int money; bool operator!=(const node &amp;x)&#123; return x.day!=day || x.from!=from || x.water!=water || x.food!=food ; &#125;;&#125;path[31][N+1][405][605],lastpath;vector &lt;int&gt; weather;vector &lt;int&gt; g[N];map &lt;int,int&gt; mp;void push_back(int x,int y)&#123; g[x].push_back(y); g[y].push_back(x);&#125;void build_map()&#123; push_back(1,2); push_back(2,3); push_back(2,5); push_back(5,6); push_back(3,4); push_back(4,7); push_back(6,7); push_back(7,8); push_back(8,9); push_back(9,10); push_back(10,11); mp[1]=1; mp[2]=25; mp[3]=26; mp[4]=27; mp[5]=24; mp[6]=23; mp[7]=21; mp[8]=9; mp[9]=15; mp[10]=14; mp[11]=12; for(int i=1;i&lt;=N;i++) &#123; cz[i]=0; ks[i]=0; &#125; cz[9]=1; ks[11]=1; zd=4; qd=1; return ;&#125;void init()&#123; memset(dp,-inf,sizeof(dp)); FZ=1200; cost_water=5; cost_food=10; walk=2; buy=2; dig=3; for(int k=0;k&lt;=405;k++) &#123; for(int l=0;l&lt;=601;l++) &#123; if(k*3+l*2&lt;=FZ) &#123; dp[0][qd][k][l]=10000-k*cost_water-l*cost_food; &#125; &#125; &#125; printf(&quot;init %d\\n&quot;,dp[0][1][178][333]); path[0][1][0][0]=&#123;0,0,0,0&#125;; return ;&#125;int main()&#123; weather=&#123; 1,1,0,2,0,1,2,0,1,1, 2,1,0,1,1,1,2,2,1,1, 0,0,1,0,2,1,0,0,1,1, &#125;; build_map(); init(); for(int i=0;i&lt;Day;i++) &#123; printf(&quot;第%d天\\n&quot;,i); int tq=weather[i]; for(int j=1;j&lt;=N;j++) &#123; if(cz[j])// 村庄 &#123; for(int w=0;w&lt;=405;w++) &#123; for(int f=0;w*3+f*2&lt;=1200;f++) &#123; //购买或不够买物资(ww=0,ff=0就是不购买) if(tq==2) //停留 &#123; int money=dp[i][j][w][f]; for(int ww=0;ww&lt;=money/cost_water;ww++) &#123; for(int ff=0;ff&lt;=(FZ-(w+ww)*3)/2-f;ff++) &#123; if(w+ww-xh_water[tq]&gt;=0&amp;&amp;f+ff-xh_food[tq]&gt;=0&amp;&amp;dp[i][j][w][f]-2*ww*cost_water-2*ff*cost_food&gt;=0) &#123; if(dp[i+1][j][w+ww-xh_water[tq]][f+ff-xh_food[tq]]&lt;dp[i][j][w][f]-2*ww*cost_water-2*ff*cost_food) &#123; dp[i+1][j][w+ww-xh_water[tq]][f+ff-xh_food[tq]]=dp[i][j][w][f]-2*ww*cost_water-2*ff*cost_food; path[i+1][j][w+ww-xh_water[tq]][f+ff-xh_food[tq]]=&#123;i,j,w,f,dp[i][j][w][f]-2*ww*cost_water-2*ff*cost_food&#125;; &#125; &#125; &#125; &#125; &#125; else //从j走到jj &#123; for(auto jj:g[j]) &#123; int money=dp[i][j][w][f]; for(int ww=0;ww&lt;=money/cost_water;ww++) &#123; for(int ff=0;ff&lt;=(FZ-(w+ww)*3)/2-f;ff++) &#123; if(w+ww-walk*xh_water[tq]&gt;=0&amp;&amp;f+ff-walk*xh_food[tq]&gt;=0&amp;&amp;dp[i][j][w][f]-buy*ww*cost_water-buy*ff*cost_food&gt;=0) &#123; if(dp[i+1][jj][w+ww-walk*xh_water[tq]][f+ff-walk*xh_food[tq]]&lt;dp[i][j][w][f]-buy*ww*cost_water-buy*ff*cost_food) &#123; dp[i+1][jj][w+ww-walk*xh_water[tq]][f+ff-walk*xh_food[tq]]=dp[i][j][w][f]-buy*ww*cost_water-buy*ff*cost_food; path[i+1][jj][w+ww-walk*xh_water[tq]][f+ff-walk*xh_food[tq]]=&#123;i,j,w,f,dp[i][j][w][f]-buy*ww*cost_water-buy*ff*cost_food&#125;; &#125; &#125; &#125; &#125; &#125; &#125; &#125; &#125; &#125; else if (ks[j])// 矿山 &#123; for(int w=0;w&lt;=405;w++) &#123; for(int f=0;w*3+f*2&lt;=1200;f++) &#123; // 已经停留一天了，可以挖矿 if(w-dig*xh_water[tq]&gt;=0&amp;&amp;f-dig*xh_food[tq]&gt;=0) &#123; if(dp[i+1][j][w-dig*xh_water[tq]][f-dig*xh_food[tq]]&lt;dp[i][j][w][f]+1000&amp;&amp;dp[i][j][w][f]&gt;=0) &#123; dp[i+1][j][w-dig*xh_water[tq]][f-dig*xh_food[tq]]=dp[i][j][w][f]+1000; path[i+1][j][w-dig*xh_water[tq]][f-dig*xh_food[tq]]=&#123;i,j,w,f,dp[i][j][w][f]+1000&#125;; &#125; &#125; // 在矿山不挖矿或 不允许挖矿 if(tq==2) //停留但不挖矿 &#123; if(w-xh_water[tq]&gt;=0&amp;&amp;f-xh_food[tq]&gt;=0) &#123; if(dp[i+1][j][w-xh_water[tq]][f-xh_food[tq]]&lt;dp[i][j][w][f]&amp;&amp;dp[i][j][w][f]&gt;=0) &#123; dp[i+1][j][w-xh_water[tq]][f-xh_food[tq]]=dp[i][j][w][f]; path[i+1][j][w-xh_water[tq]][f-xh_food[tq]]=&#123;i,j,w,f,dp[i][j][w][f]&#125;; &#125; &#125; &#125; else &#123; if(w-walk*xh_water[tq]&gt;=0&amp;&amp;f-walk*xh_food[tq]&gt;=0) &#123; for(auto jj:g[j]) &#123; if(dp[i+1][jj][w-walk*xh_water[tq]][f-walk*xh_food[tq]]&lt;dp[i][j][w][f]&amp;&amp;dp[i][j][w][f]&gt;=0) &#123; dp[i+1][jj][w-walk*xh_water[tq]][f-walk*xh_food[tq]]=dp[i][j][w][f]; path[i+1][jj][w-walk*xh_water[tq]][f-walk*xh_food[tq]]=&#123;i,j,w,f,dp[i][j][w][f]&#125;; &#125; &#125; &#125; &#125; &#125; &#125; &#125; else //普通区 &#123; for(int w=0;w&lt;=405;w++) &#123; for(int f=0;w*3+f*2&lt;=1200;f++) &#123; if(tq==2) //在j点停留 &#123; if(w-xh_water[tq]&gt;=0&amp;&amp;f-xh_food[tq]&gt;=0&amp;&amp;dp[i][j][w][f]&gt;=0) &#123; if(dp[i+1][j][w-xh_water[tq]][f-xh_food[tq]]&lt;dp[i][j][w][f]) &#123; dp[i+1][j][w-xh_water[tq]][f-xh_food[tq]]=dp[i][j][w][f]; path[i+1][j][w-xh_water[tq]][f-xh_food[tq]]=&#123;i,j,w,f,dp[i][j][w][f]&#125;; &#125; &#125; &#125; else// 走到jj点 &#123; for(auto jj:g[j]) &#123; if(w-walk*xh_water[tq]&gt;=0&amp;&amp;f-walk*xh_food[tq]&gt;=0&amp;&amp;dp[i][j][w][f]&gt;=0) &#123; if(dp[i+1][jj][w-walk*xh_water[tq]][f-walk*xh_food[tq]]&lt;dp[i][j][w][f]) &#123; dp[i+1][jj][w-walk*xh_water[tq]][f-walk*xh_food[tq]]=dp[i][j][w][f]; path[i+1][jj][w-walk*xh_water[tq]][f-walk*xh_food[tq]]=&#123;i,j,w,f,dp[i][j][w][f]&#125;; &#125; &#125; &#125; &#125; &#125; &#125; &#125; &#125; &#125; int ans=-inf; node lastpath; int last_water=0,last_food=0,last_day=Day; for(int i=0;i&lt;=Day;i++) &#123; for(int w=0;w&lt;=405;w++) for(int f=0;w*3+2*f&lt;=1200;f++) &#123; if(dp[i][zd][w][f]&gt;ans) &#123; ans=dp[i][zd][w][f]; lastpath=path[i][zd][w][f]; last_water=w; last_food=f; last_day=i; &#125; &#125; &#125; stack&lt;node&gt; s; stack&lt;int&gt; my; printf(&quot;??day:%d weather:%d %d water:%d food:%d money:%d\\n&quot;,last_day,weather[Day],zd,last_water,last_food,ans); s.push((node)&#123;last_day,zd,last_water,last_food,ans&#125;); while(lastpath!=path[0][1][0][0]) &#123; s.push(lastpath); printf(&quot;??day:%d weather:%d %d water:%d food:%d money:%d\\n&quot;,lastpath.day,weather[lastpath.day],mp[lastpath.from],lastpath.water,lastpath.food,lastpath.money); my.push(lastpath.money); lastpath=path[lastpath.day][lastpath.from][lastpath.water][lastpath.food]; &#125; freopen(&quot;output.txt&quot;,&quot;w&quot;,stdout); my.push(my.top()); while (!s.empty()) &#123; node t=s.top(); int money=my.top(); printf(&quot;Day:%d weather:%d point:%d water:%d food:%d money:%d\\n&quot;,t.day,weather[t.day],mp[t.from],t.water,t.food,money); s.pop(); my.pop(); &#125; printf(&quot;%d\\n&quot;,ans); return 0;&#125; 结果 日期 所在区域 剩余资金数 剩余水量 剩余食物量 0 1 5780 178 333 1 25 5780 162 321 2 26 5780 146 309 3 27 5780 136 295 4 27 5780 126 285 5 21 5780 116 271 6 9 5780 100 259 7 9 5780 90 249 8 15 5780 80 235 9 14 4150 227 223 10 12 4150 211 211 11 12 5150 181 181 12 12 6150 157 163 13 12 7150 142 142 14 12 8150 118 124 15 12 9150 94 1106 16 12 10150 70 88 17 12 10150 60 78 18 12 10150 50 68 19 12 11150 26 50 20 14 11150 10 38 21 15 11150 0 24 22 9 10470 26 26 23 21 10470 10 14 24 27 10470 0 0 第二关代码​ 与第一关不同的是点的数量变多了，空间复杂度过不去。我只好把path删了一个变量money才勉强过去。就是后面要手算money很麻烦 ​ 后来想应该可以滚动数组的，但是不想写了。毕竟已经退役了 #include&lt;bits/stdc++.h&gt;#include&lt;iostream&gt;using namespace std;const short N=27,inf=20000,Day=30;short dp[31][N+1][401][601],zd,qd,FZ;short cost_water,cost_food,walk,dig,buy;short xh_water[3]=&#123;5,8,10&#125;,xh_food[3]=&#123;7,6,10&#125;;bool cz[N+1],ks[N+1];struct node&#123; char day; // i char from; // jj j short water,food; bool operator!=(const node &amp;x)&#123; return (x.day-&#x27;0&#x27;)!=(day-&#x27;0&#x27;) || (x.from-&#x27;0&#x27;!=from-&#x27;0&#x27;) || (x.water-&#x27;0&#x27;)!=(water-&#x27;0&#x27;) || (x.food-&#x27;0&#x27;!=food-&#x27;0&#x27;) ; &#125;;&#125;path[31][N+1][401][601],lastpath;vector &lt;short&gt; weather;vector &lt;short&gt; g[N+1];map &lt;short,short&gt; mp;void push_back(short x,short y)&#123; g[x].push_back(y); g[y].push_back(x);&#125;void build_map(short flag)&#123; if(flag==2) &#123; push_back(1,2); push_back(2,3); push_back(3,4); push_back(4,5); push_back(5,6); push_back(6,7); push_back(7,8); push_back(8,9); push_back(9,10); push_back(10,11); push_back(11,12); push_back(7,13); push_back(13,14); push_back(14,15); push_back(15,16); push_back(15,10); push_back(15,11); push_back(16,12); push_back(3,17); push_back(17,18); push_back(18,19); push_back(19,20); push_back(20,21); push_back(21,22); push_back(22,23); push_back(15,23); push_back(23,16); mp[1]=1; mp[2]=2; mp[3]=3; mp[4]=4; mp[5]=12; mp[6]=21; mp[7]=29; mp[8]=30; mp[9]=39; mp[10]=47; mp[11]=56; mp[12]=64; mp[13]=38; mp[14]=46; mp[15]=55; mp[16]=63; mp[17]=11; mp[18]=20; mp[19]=28; mp[20]=37; mp[21]=45; mp[22]=54; mp[23]=62; for(short i=1;i&lt;=N;i++) &#123; cz[i]=0; ks[i]=0; &#125; cz[9]=cz[23]=1; ks[8]=ks[15]=1; qd=1; zd=12; &#125; return ;&#125;void init()&#123; FZ=1200; cost_water=5; cost_food=10; walk=2; buy=2; dig=3; for(short i=0;i&lt;=Day;i++) &#123; for(short j=1;j&lt;=N;j++) &#123; for(short w=0;w&lt;=400;w++) &#123; for(short f=0;f&lt;=600;f++) &#123; if(w*3+f*2&lt;=FZ) &#123; dp[i][j][w][f]=-inf; &#125; &#125; &#125; &#125; &#125; for(short k=10;k&lt;=405;k++) &#123; for(short l=0;k*3+l*2&lt;=FZ;l++) &#123; dp[0][qd][k][l]=10000-k*cost_water-l*cost_food; &#125; &#125; path[0][1][0][0]=&#123;0,0,0,0&#125;; return ;&#125;int main()&#123; weather=&#123; 1,1,0,2,0,1,2,0,1,1, 2,1,0,1,1,1,2,2,1,1, 0,0,1,0,2,1,0,0,1,1, &#125;; build_map(2); init(); // dp [i][j][w][f] // 第i天 在j个点 w 箱水 f 箱食物 时最大利润， // max_k_l (dp[30][27][k][l]) // 第i天的天气决定 i+1天能否移动 // 如：第0天天气决定第1天能否移动 // 先不考虑非矿山停留自愿停留情况 // for(short i=1;i&lt;N;i++) // &#123; // printf(&quot;第%d个点&quot;,i); // for(auto j:mp[i]) // &#123; // printf(&quot;%d &quot;,j); // &#125; // printf(&quot;\\n&quot;); // &#125; // printf(&quot;???%d %d %d %d\\n&quot;,xh_food[0],xh_food[2],xh_water[0],xh_water[1]); for(short i=0;i&lt;Day;i++) &#123; printf(&quot;第%d天\\n&quot;,i); short tq=weather[i]; for(short j=1;j&lt;=N;j++) &#123; if(cz[j])// 村庄 &#123; for(short w=0;w&lt;=405;w++) &#123; for(short f=0;w*3+f*2&lt;=1200;f++) &#123; //购买或不够买物资(ww=0,ff=0就是不购买) if(tq==2) //停留 &#123; short money=dp[i][j][w][f]; for(short ww=0;ww&lt;=money/cost_water;ww++) &#123; for(short ff=0;ff&lt;=(FZ-(w+ww)*3)/2-f;ff++) &#123; if(w+ww-xh_water[tq]&gt;=0&amp;&amp;f+ff-xh_food[tq]&gt;=0&amp;&amp;dp[i][j][w][f]-2*ww*cost_water-2*ff*cost_food&gt;=0) &#123; if(dp[i+1][j][w+ww-xh_water[tq]][f+ff-xh_food[tq]]&lt;dp[i][j][w][f]-2*ww*cost_water-2*ff*cost_food) &#123; dp[i+1][j][w+ww-xh_water[tq]][f+ff-xh_food[tq]]=dp[i][j][w][f]-2*ww*cost_water-2*ff*cost_food; // path[i+1][j][w+ww-xh_water[tq]][f+ff-xh_food[tq]]=&#123;i,j,w,f,dp[i][j][w][f]-2*ww*cost_water-2*ff*cost_food&#125;; path[i+1][j][w+ww-xh_water[tq]][f+ff-xh_food[tq]]=&#123;i,j,w,f&#125;; &#125; &#125; &#125; &#125; &#125; else //从j走到jj &#123; for(auto jj:g[j]) &#123; short money=dp[i][j][w][f]; for(short ww=0;ww&lt;=money/cost_water;ww++) &#123; for(short ff=0;ff&lt;=(FZ-(w+ww)*3)/2-f;ff++) &#123; if(w+ww-walk*xh_water[tq]&gt;=0&amp;&amp;f+ff-walk*xh_food[tq]&gt;=0&amp;&amp;dp[i][j][w][f]-buy*ww*cost_water-buy*ff*cost_food&gt;=0) &#123; if(dp[i+1][jj][w+ww-walk*xh_water[tq]][f+ff-walk*xh_food[tq]]&lt;dp[i][j][w][f]-buy*ww*cost_water-buy*ff*cost_food) &#123; dp[i+1][jj][w+ww-walk*xh_water[tq]][f+ff-walk*xh_food[tq]]=dp[i][j][w][f]-buy*ww*cost_water-buy*ff*cost_food; // path[i+1][jj][w+ww-walk*xh_water[tq]][f+ff-walk*xh_food[tq]]=&#123;i,j,w,f,(short)dp[i][j][w][f]-buy*ww*cost_water-buy*ff*cost_food&#125;; path[i+1][jj][w+ww-walk*xh_water[tq]][f+ff-walk*xh_food[tq]]=&#123;i,j,w,f&#125;; &#125; &#125; &#125; &#125; &#125; &#125; &#125; &#125; &#125; else if (ks[j])// 矿山 &#123; for(short w=0;w&lt;=405;w++) &#123; for(short f=0;w*3+f*2&lt;=1200;f++) &#123; // 已经停留一天了，可以挖矿 if(w-dig*xh_water[tq]&gt;=0&amp;&amp;f-dig*xh_food[tq]&gt;=0) &#123; if(dp[i+1][j][w-dig*xh_water[tq]][f-dig*xh_food[tq]]&lt;dp[i][j][w][f]+1000&amp;&amp;dp[i][j][w][f]&gt;=0) &#123; dp[i+1][j][w-dig*xh_water[tq]][f-dig*xh_food[tq]]=dp[i][j][w][f]+1000;// path[i+1][j][w-dig*xh_water[tq]][f-dig*xh_food[tq]]=&#123;i,j,w,f,(short)dp[i][j][w][f]+1000&#125;; path[i+1][j][w-dig*xh_water[tq]][f-dig*xh_food[tq]]=&#123;i,j,w,f&#125;; &#125; &#125; // 在矿山不挖矿或 不允许挖矿 if(tq==2) //停留但不挖矿 &#123; if(w-xh_water[tq]&gt;=0&amp;&amp;f-xh_food[tq]&gt;=0) &#123; if(dp[i+1][j][w-xh_water[tq]][f-xh_food[tq]]&lt;dp[i][j][w][f]&amp;&amp;dp[i][j][w][f]&gt;=0) &#123; dp[i+1][j][w-xh_water[tq]][f-xh_food[tq]]=dp[i][j][w][f]; // path[i+1][j][w-xh_water[tq]][f-xh_food[tq]]=&#123;i,j,w,f,dp[i][j][w][f]&#125;; path[i+1][j][w-xh_water[tq]][f-xh_food[tq]]=&#123;i,j,w,f&#125;; &#125; &#125; &#125; else &#123; if(w-walk*xh_water[tq]&gt;=0&amp;&amp;f-walk*xh_food[tq]&gt;=0) &#123; for(auto jj:g[j]) &#123; if(dp[i+1][jj][w-walk*xh_water[tq]][f-walk*xh_food[tq]]&lt;dp[i][j][w][f]&amp;&amp;dp[i][j][w][f]&gt;=0) &#123; dp[i+1][jj][w-walk*xh_water[tq]][f-walk*xh_food[tq]]=dp[i][j][w][f]; // path[i+1][jj][w-walk*xh_water[tq]][f-walk*xh_food[tq]]=&#123;i,j,w,f,dp[i][j][w][f]&#125;; path[i+1][jj][w-walk*xh_water[tq]][f-walk*xh_food[tq]]=&#123;i,j,w,f&#125;; &#125; &#125; &#125; &#125; &#125; &#125; &#125; else //普通区 &#123; for(short w=0;w&lt;=405;w++) &#123; for(short f=0;w*3+f*2&lt;=1200;f++) &#123; if(tq==2) //在j点停留 &#123; if(w-xh_water[tq]&gt;=0&amp;&amp;f-xh_food[tq]&gt;=0&amp;&amp;dp[i][j][w][f]&gt;=0) &#123; if(dp[i+1][j][w-xh_water[tq]][f-xh_food[tq]]&lt;dp[i][j][w][f]) &#123; dp[i+1][j][w-xh_water[tq]][f-xh_food[tq]]=dp[i][j][w][f]; // path[i+1][j][w-xh_water[tq]][f-xh_food[tq]]=&#123;i,j,w,f,dp[i][j][w][f]&#125;; path[i+1][j][w-xh_water[tq]][f-xh_food[tq]]=&#123;i,j,w,f&#125;; &#125; &#125; &#125; else// 走到jj点 &#123; for(auto jj:g[j]) &#123; if(w-walk*xh_water[tq]&gt;=0&amp;&amp;f-walk*xh_food[tq]&gt;=0&amp;&amp;dp[i][j][w][f]&gt;=0) &#123; if(dp[i+1][jj][w-walk*xh_water[tq]][f-walk*xh_food[tq]]&lt;dp[i][j][w][f]) &#123; dp[i+1][jj][w-walk*xh_water[tq]][f-walk*xh_food[tq]]=dp[i][j][w][f]; // path[i+1][jj][w-walk*xh_water[tq]][f-walk*xh_food[tq]]=&#123;i,j,w,f,dp[i][j][w][f]&#125;; path[i+1][jj][w-walk*xh_water[tq]][f-walk*xh_food[tq]]=&#123;i,j,w,f&#125;; &#125; &#125; &#125; &#125; &#125; &#125; &#125; &#125; &#125; short ans=-inf; node lastpath; short last_water=0,last_food=0,last_day=Day; for(short i=0;i&lt;=Day;i++) &#123; for(short w=0;w&lt;=405;w++) for(short f=0;w*3+2*f&lt;=1200;f++) &#123; if(dp[i][zd][w][f]&gt;ans) &#123; ans=dp[i][zd][w][f]; lastpath=path[i][zd][w][f]; last_water=w; last_food=f; last_day=char(i); &#125; &#125; &#125; stack&lt;node&gt; s;// freopen(&quot;outputQ2.txt&quot;,&quot;w&quot;,stdout); printf(&quot;ans:%d\\n&quot;,ans); printf(&quot;day:%d weather:%d point:%d water:%d food:%d\\n&quot;,last_day,weather[Day],zd,last_water,last_food); node temppath=(node)&#123;last_day,zd,last_water,last_food&#125;; s.push(temppath); while(lastpath!=path[0][1][0][0]) &#123; s.push(lastpath); printf(&quot;day:%d weather:%d point %d water:%d food:%d\\n&quot;,lastpath.day,(int)weather[lastpath.day],(int)mp[lastpath.from],lastpath.water,lastpath.food); temppath=lastpath; lastpath=path[lastpath.day][lastpath.from][lastpath.water][lastpath.food]; &#125;&#125; 结果 日期 所在区域 剩余资金数 剩余水量 剩余食物量 0 1 5300 130 405 1 2 5300 114 393 2 3 5300 98 381 3 4 5300 88 367 4 4 5300 78 357 5 12 5300 68 343 6 21 5300 52 331 7 21 5300 42 321 8 29 5300 32 307 9 30 5300 16 295 10 39 5300 0 283 11 39 5200 0 273 12 30 3410 163 261 13 30 4410 148 240 14 30 5410 124 222 15 30 6410 100 204 16 30 7410 76 186 17 30 8410 46 156 18 30 9410 16 126 19 39 9410 0 114 20 47 5730 180 188 21 55 5730 170 174 22 55 6730 155 153 23 55 7730 131 135 24 55 8730 116 114 25 55 9730 86 84 26 55 10730 62 66 27 55 11730 47 45 28 55 12730 32 24 29 56 12730 16 12 30 12 12730 0 0 末尾的哔哔再优化​ 后来和lms交流后发现自己村庄搜索代码写挫了，因为是递推的所以不用枚举购买的水和食物量，而是分别购买1箱水和1箱食物的状态转移。这样就能控制程序1s了。 难度从oi来看的话我个人认为单纯dp应该有提高+难度？但是考虑到优化复杂度应该有黑题左右的难度了。我是有什么资格评价的哇 从ACM来看的话如果有时间限制的话应该是个银牌题吧，没有时间限制就是个铜牌题。本菜鸡做了大半天…","categories":[{"name":"技术","slug":"技术","permalink":"https://dummerfu.top/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"数模","slug":"数模","permalink":"https://dummerfu.top/tags/%E6%95%B0%E6%A8%A1/"}],"keywords":[{"name":"技术","slug":"技术","permalink":"https://dummerfu.top/categories/%E6%8A%80%E6%9C%AF/"}]},{"title":"Logistic回归","slug":"logistic回归","date":"2021-07-27T00:00:00.000Z","updated":"2021-07-27T00:00:00.000Z","comments":true,"path":"p/40721.html","link":"","permalink":"https://dummerfu.top/p/40721.html","excerpt":"","text":"前言​ 为什么又要写这个呢？😔弄个论文模板以防万一不让省心的论文队友啊 Logistic 介绍及应用领域​ 逻辑回归是一个比较经典的分类算法，可以说也是机器学习的入门必需课。虽然现在有许多分类的方法比如决策树、svm、神经网路等，但是逻辑回归仍应用领域广泛。 贷款违约情况（是否违约 广告点击情况（是否会点击 商品推荐（是否会购买 情感分析（正面情感or负面情感 疾病诊断（阴性还是阳性 逻辑回归的性质​ 逻辑回归本质是一个条件概率$P(Y|X)$即在X条件下情况为Y的概率是多少，X可以理解为特征。 既然是条件概率，那一定满足概率的定义： $0\\leq P(Y|X)\\leq 1$ $\\sum_y P(Y|X)=1$ 由此显而易见，线性回归$P(Y|X)=w^Tx+b$ 不能是逻辑回归。但是通过任意函数将P(Y|X)映射到[0,1]都可称为逻辑回归，最常用的就是逻辑函数。 逻辑函数 y=\\frac{1}{1+e^{-x}}这个简单又明了的就是大名鼎鼎的逻辑函数，在神经网络里也叫sigmod函数。他将$x\\in (-\\infty,\\infty)$映射到(0,1) 这就满足了概率的条件。即$P(Y|X)=\\frac{1}{1+e^{-{w^Tx+b}}}$ 逻辑回归是线性的​ 逻辑回归是否线性应该从其决策边界来判断： p(1|x)=p(0|x) \\rightarrow -w^tx+b=0可见其决策边界是线性的。 Pytorch 实现loss函数|目标函数由于: p(y=1|x,w,b)=\\frac{1}{1+e^{-{w^Tx+b}}} \\\\ p(y=0|x,w,b)=\\frac{e^{-{w^Tx+b}}}{1+e^{-{w^Tx+b}}}可以统一写成： p(y|x,w,b)=p(y=0|x)^{(1-y)}+p(y=1|x)^{y}\\\\ \\rightarrow \\ log \\ p(y|x)=(1-true_y)log\\ p(y=0|x)+true_ylog \\ p(y=1|x)从而我们只需要求解: w_{MLE},b_{MLE}=argmax_{w,b}( \\sum_{i=1}^{n} log\\ p(y_i|x_i))上式也叫目标函数 预测评估方法当样本种类不均衡时，准确率可能就没有那么客观，所以需要其他评价标准 对于一个分类模型，假设二分类，则一定有如下表格（1）： Correct 纵列之和为真实label=1的总量。 Not Correct 纵列之和为真实label=0的总量 Correct Not Correct Selected True Positive False Positive Not Selected False Negative True Negative 精确率(precision)预测正样本中 ground truth 的比例： P(selected)=\\frac{TP}{TP+FP}\\\\ P(not selected)=\\frac{FN}{FN+TN}召回率 (recall)ground truth中预测正确的比例： P(selected)=\\frac{TP}{TP+FN} \\\\ P(not selected)=\\frac{FN}{TP+FN}F1-score通过召回率和精确率综合评判模型的指标： P=\\frac{2*precision*recall}{precision+recall}mAP(mean Average Precision)数据参考：目标检测中的mAP是什么含义- 资质平平的AI的回答 - 知乎 ​ 对于目标检测类问题，总是会在评估里面看到mAP。从字面上来看就是precision的平均，但是怎么样平均呢？ ​ 首先还是介绍一下目标检测里的正样本：对于一个Bounding Box，IOU&gt;0.5则认为是一个正样本GT=1,否则为负样本。 ​ 按照confident 从大到小（数值相同序号小的在前没影响）然后就可以列出类似下表： 假设表为全部的Bounding Box，且GroundTruth总和为3 实际上GroundTruth总和是IOU&gt;thresh的样本总和 Rank Image id BoundBox预测概率 (confident) GroundTruth Sum of TP 1 5 0.95 1 1 2 7 0.95 0 1 3 3 0.91 1 2 4 1 0.88 0 2 5 6 0.84 0 2 6 1 0.80 0 2 7 4 0.78 0 2 8 2 0.74 0 2 9 2 0.71 0 2 10 1 0.70 1 3 根据confident的离散排列，可绘制多个上表 （1），下举几个例子方便理解。 Rank3Rank5规律confident_rank3 第三行之前包括第三行 预测为selected，否则为not selected。 Correct Not Correct Selected 2 1 Not Selected 1 6 此时 precision=0.66，recall=2/3=0.66confident_rank5 第五行包括第五行 同上规律列出下表 Correct Not Correct Selected 2 3 Not Selected 1 4 precision=0.4，recall=2/3=0.66由前面两个例子和表，可得如下规律： \\begin{cases} Precision=\\frac{sum\\ of\\ TP}{Rank} \\\\ Recall=\\frac{sum\\ of\\ TP}{sum\\ of\\ GT} \\end{cases} 通过上式可得到各个rank的精确率和召回率 Rank Precision Recall 1 1/1=1 1/3=0.33 2 1/2=0.5 1/3=0.33 3 2/3=0.66 2/3=0.66 4 2/4=0.50 2/3=0.66 5 2/5=0.40 2/3=0.66 6 2/6=0.33 2/3=0.66 7 2/7=0.2857 2/3=0.66 8 2/8=0.25 2/3=0.66 9 2/9=0.222 2/3=0.66 10 3/10=0.33 3/3=1 VOC2010以前VOC2010以后分别以$recall \\geq [0,0.1 \\ldots ,0.9,1] $​​​ 为横坐标，满足recall范围的最大Precision为纵坐标画图。 mAP=\\frac{\\sum_{i=0}^{10}Precision(recall[i])}{11}\\\\Precision(recall[i])是通过插值法求出的近似值 分别以$recall\\in[0.33,0.66.1] $​​​​​​​ 为横坐标，对于每个recall[i]，纵坐标为满足大于recall[i]范围的最大Precision，mAP即为直线下的’面积’： mAP=(0.33-0)*1 + (0.66-0.33)*0.66 + (1-0.66)*0.33横坐标选取根据计算出的recall去重得到。 MAP(Maximum A Posteriori)这个与前面完全不同可能也有点关系，注意m的大小写代表完全不同的含义！！ 代码就随便一写，数据自己看着造吧，precision好低 # -*- coding:utf-8 -*-# @Author : Dummerfu# @Contact : https://github.com/dummerchen # @Time : 2021/7/26 15:31import torchfrom torchvision import transformsfrom tqdm import tqdmimport numpy as npimport pandas as pdfrom sklearn.metrics import precision_score,recall_scoreimport matplotlib as mplfrom matplotlib import pyplot as pltmpl.rcParams[&#x27;font.sans-serif&#x27;] = &#x27;SimHei&#x27;mpl.rcParams[&#x27;axes.unicode_minus&#x27;] = Falseclass Logistic(nn.Module): def __init__(self,inputs): super(Logistic, self).__init__() self.fc1=nn.Linear(inputs,1) self.activation2=nn.Sigmoid() def forward(self,input): x=self.fc1(input) x=self.activation2(x) return xclass My_Dataset(Dataset): def __init__(self,data,transforms=None): self.data=data self.transforms=transforms def __len__(self): return len(self.data) def __getitem__(self, item): x=self.data[item,:-1] label=self.data[item,-1:] x=torch.tensor(x,dtype=torch.float) label=torch.tensor(label,dtype=torch.float) # if self.transforms!=None: # x=self.transforms(x) return x,labeldef main(Batchsize=1): device = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;) print(&#x27;use &#x27;, device) fea = pd.read_excel(&#x27;./fea1.xlsx&#x27;) # with open(&#x27;./data.txt&#x27;,&#x27;r&#x27;) as f: # data=f.readlines() data = fea.to_numpy() tot,dim=data.shape train_size=int(tot*0.7) val_size=tot-train_size data = My_Dataset(data=data) train_data, val_data = torch.utils.data.random_split(data, [train_size, val_size]) train_loader = torch.utils.data.DataLoader(train_data, batch_size=Batchsize, num_workers=0, shuffle=True) val_loader = torch.utils.data.DataLoader(val_data, batch_size=Batchsize, num_workers=0, shuffle=True) model = Logistic(dim-1) params = [i for i in model.parameters()] # optimizer = torch.optim.SGD(params=params, lr=0.03,momentum=0.9, weight_decay=0.0005) optimizer=torch.optim.Adam(params=params,lr=0.003) # loss_func=Loss_func() loss_func=torch.nn.BCELoss() Epoch = int(1e5+2) for epoch in range(Epoch): model.train() running_loss = 0 for data in train_loader: x, label = data pre_logits_list = model(x) loss = loss_func(pre_logits_list,label) optimizer.zero_grad() loss.backward() optimizer.step() running_loss = loss.item() + running_loss if epoch%100==0: model.eval() with torch.no_grad(): acc=0 true_label=[] pre_label=[] for data in val_loader: x,label=data pre_logits_list=model(x) predict_y =pre_logits_list.ge(0.5).float() # precisious F1_score acc += torch.eq(predict_y,label).sum().item() pre_label+=predict_y true_label+=label # w0, w1 = model.fc1.weight[0] # w0 = float(w0.item()) # w1 = float(w1.item()) # b = float(model.fc1.bias.item()) # plot_x = np.arange(-7, 7, 0.1) # plot_y = (-w0 * plot_x - b) / w1 # num = fea.to_numpy() # plt.scatter(num[:, 0], num[:, 1], c=num[:, 2]) # plt.plot(plot_x, plot_y) # plt.show() print(&#x27;loss:&#x27;, running_loss) print(&#x27;epoch:&#x27;,epoch,&#x27;acc:&#x27;,acc/val_size) pre_score=precision_score(y_pred=pre_label,y_true=true_label,average=&#x27;binary&#x27;) re_score=recall_score(y_true=true_label,y_pred=pre_label,average=&#x27;binary&#x27;) try: F1_score=2*pre_score*re_score/(pre_score+re_score) print(&#x27;精确率:&#x27;, pre_score, &#x27;召回率:&#x27;, re_score, &#x27;F1score:&#x27;, F1_score) except: passif __name__ == &#x27;__main__&#x27;: main(Batchsize=32)","categories":[{"name":"技术","slug":"技术","permalink":"https://dummerfu.top/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://dummerfu.top/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"keywords":[{"name":"技术","slug":"技术","permalink":"https://dummerfu.top/categories/%E6%8A%80%E6%9C%AF/"}]},{"title":"markdown公式记录","slug":"markdown公式记录","date":"2021-07-16T00:00:00.000Z","updated":"2021-12-03T00:00:00.000Z","comments":true,"path":"p/21773.html","link":"","permalink":"https://dummerfu.top/p/21773.html","excerpt":"","text":"每次打公式都要参考百度各种，遂记录 主要参考于mohu.org 特殊符号样式预览示例源码 普通省略号: $\\ldots$ 斜省略号: $\\ddots$ 波浪: $\\sim$ 度: $C^{\\circ}$ 下画线: $\\underline{saftext}$ 下取整: $\\lfloor ftext\\rfloor$ 撇: $^\\prime$​ $$ \\ldots \\\\\\ \\ddots \\\\\\ \\sim \\\\\\ \\circ \\\\\\ \\underline{text} \\lfloor ftext \\rfloor \\prime $$ 常用数学符号表数学字符二元关系符 1二元关系符 2箭头和大尺寸运算符花体typora里面可以直接使用只有两个 $\\mathbb{AF}和\\mathcal{AF}$ 引用样式预览示例源码这是一句话1 1. 脚注1，本博客渲染这个不是很美观，什么时候修改一下 &#8617; 这是一句话[^1] [^1]:脚注1 其他其他符号 杂项示例源码 大括号: $\\begin{cases} xxx \\end{cases}$ 矩阵括号 P=\\left\\{ \\begin{matrix} 0 & 0 & 0 & 0 & 1 \\\\ 0 & 0.3& 0 & 0 &0.7 \\\\ 0 & 0.4& 0.3&0 &0.3 \\\\ 0 & 0.2& 0.4&0.3&0.1\\\\ 0 & 0.1& 0.2&0.4&0.3\\\\ \\end{matrix}\\right\\}​ 等号对齐 $ \\begin{aligned}p&amp;=sadaf \\ q&amp;=sdfff \\ \\end{aligned} $ $$ \\begin{cases} xxx \\\\ \\end{cases} P=\\left{ \\\\begin{matrix}0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 \\\\0 &amp; 0.3&amp; 0 &amp; 0 &amp;0.7 \\\\0 &amp; 0.4&amp; 0.3&amp;0 &amp;0.3 \\\\0 &amp; 0.2&amp; 0.4&amp;0.3&amp;0.1\\\\0 &amp; 0.1&amp; 0.2&amp;0.4&amp;0.3 \\\\\\\\end{matrix}\\right} \\begin{aligned} p&amp;=sadaf \\\\ q&amp;=sdfff \\\\ \\end{aligned} $$","categories":[{"name":"转载","slug":"转载","permalink":"https://dummerfu.top/categories/%E8%BD%AC%E8%BD%BD/"}],"tags":[{"name":"转载,文档","slug":"转载-文档","permalink":"https://dummerfu.top/tags/%E8%BD%AC%E8%BD%BD-%E6%96%87%E6%A1%A3/"}],"keywords":[{"name":"转载","slug":"转载","permalink":"https://dummerfu.top/categories/%E8%BD%AC%E8%BD%BD/"}]},{"title":"基本无约束最优化实现代码","slug":"无约束最优化","date":"2021-07-15T00:00:00.000Z","updated":"2021-07-15T00:00:00.000Z","comments":true,"path":"p/51816.html","link":"","permalink":"https://dummerfu.top/p/51816.html","excerpt":"","text":"介绍数模总结写着写着发现最优化上机代码似乎还没留存😀发现有篇博客没水很不是滋味 遂附上啦，都封装好了自认为函数还行吧只需要自行修改输入x0就可以自用了： 最速下降法 牛顿法 拟牛顿法 修正牛顿法 单纯性法 坐标轮换法 CODEimport numpy as npimport matplotlib as mplfrom matplotlib import pyplot as pltfrom matplotlib import cmfrom mpl_toolkits.mplot3d import Axes3Dmpl.rcParams[&#x27;font.sans-serif&#x27;] = &#x27;SimHei&#x27;mpl.rcParams[&#x27;axes.unicode_minus&#x27;] = Falsedef num_grad(x, h): # 求梯度 # df=np.array() df = np.zeros(x.size) for i in range(x.size): x1, x2 = x.copy(), x.copy() # 这里需要用到复制，而不能用赋值号（=），原因是Python里面=号只是取别名，不是复制（c/c++里面是） x1[i] = x[i] - h x2[i] = x[i] + h y1, y2 = f(x1), f(x2) df[i] = (y2 - y1) / (2 * h) return dfdef num_hess(x, h): # 求hess矩阵 hess = np.zeros((x.size, x.size)) for i in range(x.size): x1 = x.copy() x1[i] = x[i] - h df1 = num_grad(x1, h) x2 = x.copy() x2[i] = x[i] + h df2 = num_grad(x2, h) d2f = (df2 - df1) / (2 * h) hess[i] = d2f return hessdef linesearch(x, pk:float,f): &#x27;&#x27;&#x27; 黄金分割法 &#x27;&#x27;&#x27; eps = 0.001 r = 500 l = -500 while r - l &gt; eps: t1 = l + 0.382 * (r - l) t2 = l + 0.618 * (r - l) x_1 = x+ t1 * pk x_2 = x + t2 * pk f1 = f(x_1) f2 = f(x_2) if f1 &lt; f2: r = t2 else: l = t1 if t2 - t1 &lt; eps: return t2def steepest(x,f,epsilon=0.01,h=10**-5,maxiter=10**4): &#x27;&#x27;&#x27; 最速下降法 :param x: 初始值 :param f: 函数 :param epsilon: eps :param h: 求导的delta x :param maxiter: 最大迭代次数 :return: 答案的list用于画图 &#x27;&#x27;&#x27; x_list=[] ans_list=[] x_list.append(x) ans_list.append(f(x)) for iter1 in range(maxiter): grad = num_grad(x, h) pk = -grad ak = linesearch(x, pk,f) x = x + ak * pk print(&#x27;grad:&#x27;, grad, &#x27;x_&#123;i+1&#125;:&#x27;, x, &#x27;t:&#x27;, ak,&#x27;ans:&#x27;,f(x)) x_list.append(x) ans_list.append(f(x)) if np.linalg.norm(grad) &lt; epsilon: return x_list,ans_list return x_list,ans_listdef newTonFuction(x,f,epsilon=0.01,h1=10**-5,h2=10**-5,maxiter=10**4): # 牛顿法 x_list=[] ans_list=[] x_list.append(x) ans_list.append(f(x)) for iter1 in range(maxiter): grad = num_grad(x, h1) hess = num_hess(x, h2) pk = -np.dot((np.linalg.inv(hess)), grad) x = x + pk x_list.append(x) ans_list.append(f(x)) print(&#x27;grad:&#x27;, grad, &#x27;x_&#123;i+1&#125;:&#x27;, x, &#x27;ans:&#x27;, f(x)) if np.linalg.norm(grad) &lt; epsilon: return x_list,ans_list return x_list,ans_listdef BFGS(x,f,epsilon=0.01,h=10**-5,maxiter=10**4): &#x27;&#x27;&#x27; 拟牛顿法 :param x: 初始点 :param f: 求解函数 :param epsilon: eps :param h: 求导的delta x :param maxiter: 最大迭代数 :return: 答案的list便于画图 &#x27;&#x27;&#x27; Bk = np.eye(x.size) x_list=[] ans_list=[] x_list.append(x) ans_list.append(f(x)) for i in range(maxiter): grad = num_grad(x, h) pk = -np.dot((np.linalg.inv(Bk)), grad) ak = linesearch(x, pk,f) x = x + pk * ak yk = num_grad(x, h) - grad sk = ak * pk if np.dot(yk.reshape(1, grad.shape[0]), sk) &gt; 0: Bk = Bk - np.dot(np.dot(np.dot(Bk, sk).reshape(sk.shape[0], 1), sk.reshape(1, sk.shape[0])), Bk)\\ / np.dot(np.dot(sk.reshape(1, sk.shape[0]), Bk), sk) + \\ np.dot(yk.reshape(yk.shape[0], 1),yk.reshape(1, yk.shape[0])) / \\ np.dot(yk.reshape(1, yk.shape[0]), sk) print(&#x27;grad&#123;%d&#125;:&#x27; % (i + 1), np.round(num_grad(x, h), 3), &#x27;p&#123;%d&#125;:&#x27; % (i + 1), np.round(pk, 3), &#x27;x_&#123;%d&#125;:&#x27; % (i + 1), np.round(x, 3), f(x)) x_list.append(x) ans_list.append(f(x)) if np.linalg.norm(grad) &lt; epsilon: return x_list,ans_list return x_list,ans_listdef modify_newton(x,f,epsilon=0.01,h1=10**-5,h2=10**-5,maxiter=10**4): ans_list=[] x_list=[] x_list.append(x) ans_list.append(f(x)) for i in range(maxiter): grad=num_grad(x,h1) hess = num_hess(x, h2) pk = -np.dot((np.linalg.inv(hess)), grad) t=linesearch(x,pk,f) x = x + pk*t print(&#x27;grad:&#x27;,np.round(grad,3),&#x27;pk:&#x27;,np.round(pk,3),&#x27;t:&#x27;,np.round(t,3),&#x27;x_&#123;%d&#125;:&#x27;%i,np.round(x,3),f(x)) x_list.append(x) ans_list.append(f(x)) if np.linalg.norm(grad)&lt;epsilon: return x_list,ans_list return x_list,ans_listdef conjugate_gradient(x,f,epsilon=0.01,h1=10**-5,h2=10**-5,maxiter=10**4): ans_list = [] x_list = [] x_list.append(x) ans_list.append(f(x)) pk=-num_grad(x,h1) if np.linalg.norm(pk)&lt;epsilon: return x for i in range(maxiter): grad=num_grad(x,h1) t=np.round(linesearch(x,pk,f),2) used_x=x.copy() x = x + pk*t pk=-num_grad(x,h1)+(np.linalg.norm(num_grad(x,h1))**2/np.linalg.norm(num_grad(used_x,h1))**2)*pk print(&#x27;grad&#123;%d&#125;:&#x27;%(i+1),np.round(num_grad(x,h1),3),&#x27;p&#123;%d&#125;:&#x27;%(i+1),np.round(pk,3),&#x27;t_&#123;%d&#125;:&#x27;%(i+1),np.round(t,3),&#x27;x_&#123;%d&#125;:&#x27;%(i+1),np.round(x,3),f(x)) x_list.append(x) ans_list.append(f(x)) if np.linalg.norm(grad)&lt;epsilon: return x_list,ans_list return x_list,ans_listdef simplex_method(x:list,f,maxiter:int=100,alpha:float=1.,beta:float=1.,epsilon:float=0.01): temp_x_list=x x_list=[] ans_list=[] for i in range(maxiter): l=[] for j in temp_x_list: l.append(f(j)) l=np.array(l) x_min = temp_x_list[l.argsort()[0]] x_mid = temp_x_list[l.argsort()[1]] x_max = temp_x_list[l.argsort()[2]] loss=sum([(f(j)-f(x_min))**2 for j in x]) tempx=(np.sum(x,axis=0)-x_max)/ (len(x)-1) reflect_x=2*tempx-x_max print(&#x27;reflect_x:&#x27;,reflect_x) if f(x_min)&gt;f(reflect_x): inflation_x=tempx+alpha*(reflect_x-tempx) if f(inflation_x)&lt;f(reflect_x): temp_x_list[l.argsort()[2]]=inflation_x else: temp_x_list[l.argsort()[2]]=reflect_x print(&#x27;f(x_min):%.3f&gt;f(reflect):%.3f&#x27;%(f(x_min),f(reflect_x))) print(&#x27;inflation_x:&#x27;,inflation_x) if f(x_min)&lt;=f(reflect_x) and f(reflect_x)&lt;f(x_mid): temp_x_list[l.argsort()[2]]=reflect_x print(&#x27;f(x_min):%.3f&lt;=f(reflect):%.3f&lt;=f(x_mid):%.3f&#x27; % (f(x_min), f(reflect_x),f(x_mid))) if f(x_mid)&lt;=f(reflect_x) and f(reflect_x)&lt;f(x_max): shrink_x=tempx+beta*(reflect_x-tempx) temp_x_list[l.argsort()[2]]=shrink_x print(&#x27;f(x_mid):%.3f&lt;=f (reflect):%.3f &lt;f(x_max):%.3f&#x27; % (f(x_mid),f(reflect_x), f(x_max))) print(&#x27;shrink_x:&#x27;,shrink_x) if f(reflect_x)&gt;=f(x_max): # 是xmax ！ shrink_x=tempx+beta*(x_max-tempx) if f(shrink_x)&gt;f(x_max): # shrink too less for j in x: j=(x_min+j)/2 temp_x_list=x else: temp_x_list[l.argsort()[2]]=shrink_x print(&#x27;f(reflect):%.3f&gt;f(x_max):%.3f&#x27; % (f(reflect_x),f(reflect_x))) print(&#x27;shrink_x:&#x27;,shrink_x) # print(&quot;xmin:&quot;,x_min,&#x27;xmid:&#x27;,x_mid,&#x27;xmax:&#x27;,x_max) # print(&#x27;min:&#x27;,f(x_min),&#x27;fmid&#x27;,f(x_mid),&#x27;fmax&#x27;,f(x_max)) print(&#x27;temp_x_list:&#x27;,temp_x_list) print(&#x27;loss:%.3f&#x27; % loss) if loss &lt; epsilon: break x_list.append(x_min) ans_list.append(f(x_min)) print() return x_list,ans_listdef cyclic_coordinate_method(x:list,f,epsilon:float=0.01,h1:float=1e-5,maxiter:int=100): ans_list = [] x_list = [] x_list.append(x) ans_list.append(f(x)) I=np.eye(2) for i in range(maxiter): used_x=x.copy() for pk in I: t = np.round(linesearch(x, pk,f),2) x = x + pk * t print(&#x27;p&#123;%d&#125;:&#x27; % (i + 1), np.round(pk, 3), &#x27;t_&#123;%d&#125;:&#x27; % (i + 1), np.round(t, 2), &#x27;x_&#123;%d&#125;:&#x27; % (i + 1), np.round(x, 3), f(x),&#x27;eps:&#x27;,np.linalg.norm(used_x-x)) x_list.append(x) ans_list.append(f(x)) if np.linalg.norm(used_x-x)&lt; epsilon: return x_list,ans_list return x_list,ans_listdef draw(x:list=None,y:list=None,ans:list=None): fig=plt.figure() ax = fig.gca(projection=&#x27;3d&#x27;) x1 = np.linspace(min(x),max(x), 100) x2 = np.linspace(min(x), max(x), 100) # print(f(x1,x2)) tempx, tempy = np.meshgrid(x1, x2) surf = ax.plot_surface(tempx, tempy, f([tempx,tempy]), cmap=cm.jet, zorder=10) scat=ax.scatter(x,y,ans,zorder=1000,marker=&#x27;x&#x27;) line=ax.plot(x,y,ans,zorder=100,linestyle=&#x27;--&#x27;) contour=ax.contour(tempx,tempy,f([tempx,tempy]),50,zorder=100000) plt.legend() plt.show() returndef f(x): # 目标函数 x1 = x[0] x2 = x[1] # test y=x1**2+x2**2+(x2-1)**2 # y=(x1-2)**4+(x1-2*x2)**2 # 修正牛顿法函数 # y = 4*(x1+1)**2 +2*(x2-1)**2+x1+x2+10 # 最速下降法函数 # y=x1**2+25*x2**2 # 牛顿法函数 # y=60-10*x1-4*x2+x1**2+x2**2-x1*x2 # 共轭梯度法函数 # y=x1**2+4*x2**2 # DFP函数 # y=4*(x1-5)**2+(x2-6)**2 # 坐标轮换法 # y=x1**2+2*x2**2-x1*x2-10*x1-4*x2+60 # 单纯形法 # y=x1**2+2*x2**2-4*x1-8*x2+5 return yif __name__ == &#x27;__main__&#x27;: # 后面不附重复代码和函数 x0 = np.array([1., 1.]) # 初始解 # x1= np.array([0.965,0.259]) # x2=np.array([0.259,0.965]) # x_list,ans_list=simplex_method([x0,x1,x2],f,epsilon=0.1,alpha=1.1,beta=0.5) x_list,ans_list=BFGS(x0,f,maxiter=100) draw([i[0] for i in x_list],[i[1] for i in x_list],ans_list) # 修正牛顿法 # x_list,ans_list=modify_newton(x0) # 共轭梯度 # x_list,ans_list=conjugate_gradient(x0) # 最速下降法 # x_list,ans_list = steepest(x0) # 调用牛顿法 # x_list,ans_list = newTonFuction(x0) # 调用拟牛顿法 # x_list,ans_list = BFGS(x0) 有bug可以自行修改一下linersearch范围试试，这种bug懂的都懂。","categories":[{"name":"随笔","slug":"随笔","permalink":"https://dummerfu.top/categories/%E9%9A%8F%E7%AC%94/"}],"tags":[{"name":"作业","slug":"作业","permalink":"https://dummerfu.top/tags/%E4%BD%9C%E4%B8%9A/"}],"keywords":[{"name":"随笔","slug":"随笔","permalink":"https://dummerfu.top/categories/%E9%9A%8F%E7%AC%94/"}]},{"title":"【转载】Tag Plugins Plus","slug":"Tag-Plugins-Plus","date":"2021-07-15T00:00:00.000Z","updated":"2021-07-15T00:00:00.000Z","comments":true,"path":"p/41070.html","link":"","permalink":"https://dummerfu.top/p/41070.html","excerpt":"","text":"本文档为🧊Akilarの糖果屋🍭出品，已经过作者同意转载。 若您在使用本帖教程后，发现样式无法完全还原，请重点排查您的其余第三方魔改css样式，例如css中是否存在.circle、.square等易重class名。 点开查看开发记录 本文所涉及的样式，主要参考的是各类已有主题，并对相应styl文件进行样式修改以及添加夜间模式适配。已尽可能追根溯源找到了各部分魔改内容最初的作者，如有错误和遗漏还请联系我修改。开发记录2020-11-14:内测版v0.05主要使用了Volantis的标签样式。引入[tag].js，并针对butterfly主题修改了相应的[tag].styl。在此鸣谢Volantis主题众开发者。主要参考内容Volantis文档:内置标签插件Butterfly 安装文档:标签外挂（Tag Plugins）小弋の生活馆全样式预览l-lin-font-awesome-animation小康的butterfly主题使用文档2020-11-15:正式版v1.0基本完成Volantis外挂标签移植。移除了btn标签，因为存在冲突。而且不如butterfly自带的button样式好看。适配了folding标签的夜间模式。打包了静态资源文件，上传蓝奏云。2020-11-16:正式版v1.1新增tip.js，将小康大佬的渐变色上标标签写法从HTML的方式改成用标签语法编写。新增动态标签样式anima，使用了fontawesome-animation项目。新增标签内容夜间模式适配。2020-12-03:正式版v1.2新增当初弃用的issues.js标签，以配合友链魔改教程中的issues自动更新功能。更新了静态资源文件，请之前的读者重新覆盖安装。修改了fontawesome-animation.min.css的引入方式，改成使用@import注入index.css。2020-12-07:正式版v1.21资源文件无任何改动。更新了动态标签的使用说明。补全参数配置，更换示例。使得教程更加通俗易懂。2020-12-13:正式版v1.3新增Butterfly_v3.4.0的配置文件。请读者根据自己的主题版本选择替换。2020-12-17:正式版v1.4新增两个样式标签poem和icon修复了folding标签嵌套字体逐级放大的bug。不再更新v3.4.0以下版本的适配内容。2020-12-31:正式版v1.5新增两个样式标签，github徽标ghbdage和特效标签wow移除静态资源中的fontawesome-animation.min.css以及issues.js，改为CDN引用。本帖不专门提供特效标签wow的配置方案，若有需要，请查看相关教程使用wowjs给博客添加动画效果2021-02-24:正式版v1.6新增一个样式标签，进度条progress2021-03-19:正式版v1.61修复行内图片换行错误。2021-07-07:发布插件版v1.0.0使用npm插件安装。测试版本为butterfly_v3.1.0、3.3.0、3.7.8、3.8.0插件写法调整为高内聚，理论上不受butterfly主题版本影响。为了获得完整效果，建议打开主题的beautify配置项和theme_color配置项。 npm插件安装方案（推荐）源码修改配置方案 安装插件,在博客根目录[Blogroot]下打开终端，运行以下指令：npm install hexo-butterfly-tag-plugins-plus --save 考虑到hexo自带的markdown渲染插件hexo-renderer-marked与外挂标签语法的兼容性较差，建议您将其替换成hexo-renderer-kramednpm uninstall hexo-renderer-marked --savenpm install hexo-renderer-kramed --save 添加配置信息，以下为写法示例 在站点配置文件_config.yml或者主题配置文件_config.butterfly.yml中添加# tag-plugins-plus# see https://akilar.top/posts/615e2dec/tag_plugins: enable: true # 开关 priority: 5 #过滤器优先权 issues: false #issues标签依赖注入开关 CDN: anima: https://cdn.jsdelivr.net/gh/l-lin/font-awesome-animation/dist/font-awesome-animation.min.css #动画标签anima的依赖 jquery: https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js #issues标签依赖 issues: https://cdn.jsdelivr.net/npm/hexo-theme-volantis@latest/source/js/issues.min.js #issues标签依赖 iconfont: //at.alicdn.com/t/font_2032782_8d5kxvn09md.js #参看https://akilar.top/posts/d2ebecef/ 参数释义 参数 备选值/类型 释义 enable true/false 【必选】控制开关 priority number 【可选】过滤器优先级，数值越小，执行越早，默认为10，选填 issues true/false 【可选】issues标签控制开关，默认为false CDN.anima URL 【可选】动画标签anima的依赖 CDN.jquery URL 【可选】issues标签依赖 CDN.issues URL 【可选】issues标签依赖 CDN.iconfont URL 【可选】iconfont标签symbol样式引入 下载资源文件 将下载的Tag_Plugins.zip解压得到butterfly文件夹。 将butterfly文件夹复制到[Blogroot]\\themes\\目录下，覆盖当前的butterfly主题文件夹，提示重复则选择替换。(如果担心覆盖自己的其他魔改内容，可以根据静态文件内容自主比对修改) 修改[Blogroot]\\_config.butterfly.yml的inject配置项，添加CDN依赖项。由于issues写入timeline和site-card标签要用到jquery，请务必根据注释指示的版本决定是否添加。inject: head: - &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/gh/l-lin/font-awesome-animation/dist/font-awesome-animation.min.css&quot; media=&quot;defer&quot; onload=&quot;this.media=&#x27;all&#x27;&quot;&gt; #动画标签anima的依赖 bottom: - &lt;script defer src=&quot;https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js&quot;&gt;&lt;/script&gt; # 自butterfly_v3.4.0+开始，主题基本实现去jquery化，需要自己添加引用，请读者根据版本自行决定是否添加这行引用。 - &lt;script defer src=&quot;https://cdn.jsdelivr.net/npm/hexo-theme-volantis@latest/source/js/issues.min.js&quot;&gt;&lt;/script&gt; #数据集合标签issues的依赖 考虑到hexo自带的markdown渲染插件hexo-renderer-marked与外挂标签语法的兼容性较差，建议您将其替换成hexo-renderer-kramednpm uninstall hexo-renderer-marked --savenpm install hexo-renderer-kramed --save 外挂标签使用方案请参阅下文。 行内文本样式 text标签语法样式预览示例源码&#123;% u 文本内容 %&#125;&#123;% emp 文本内容 %&#125;&#123;% wavy 文本内容 %&#125;&#123;% del 文本内容 %&#125;&#123;% kbd 文本内容 %&#125;&#123;% psw 文本内容 %&#125; 带 下划线 的文本 带 着重号 的文本 带 波浪线 的文本 带 删除线 的文本 键盘样式的文本 command + D 密码样式的文本：这里没有验证码 1. 带 &#123;% u 下划线 %&#125; 的文本2. 带 &#123;% emp 着重号 %&#125; 的文本3. 带 &#123;% wavy 波浪线 %&#125; 的文本4. 带 &#123;% del 删除线 %&#125; 的文本5. 键盘样式的文本 &#123;% kbd command %&#125; + &#123;% kbd D %&#125;6. 密码样式的文本：&#123;% psw 这里没有验证码 %&#125; 行内文本 span标签语法配置参数样式预览示例源码&#123;% span 样式参数(参数以空格划分), 文本内容 %&#125; 字体: logo, code 颜色: red,yellow,green,cyan,blue,gray 大小: small, h4, h3, h2, h1, large, huge, ultra 对齐方向: left, center, right 彩色文字在一段话中方便插入各种颜色的标签，包括：红色、黄色、绿色、青色、蓝色、灰色。 超大号文字文档「开始」页面中的标题部分就是超大号文字。VolantisA Wonderful Theme for Hexo - 彩色文字在一段话中方便插入各种颜色的标签，包括：&#123;% span red, 红色 %&#125;、&#123;% span yellow, 黄色 %&#125;、&#123;% span green, 绿色 %&#125;、&#123;% span cyan, 青色 %&#125;、&#123;% span blue, 蓝色 %&#125;、&#123;% span gray, 灰色 %&#125;。- 超大号文字文档「开始」页面中的标题部分就是超大号文字。&#123;% span center logo large, Volantis %&#125;&#123;% span center small, A Wonderful Theme for Hexo %&#125; 段落文本 p标签语法配置参数样式预览示例源码&#123;% p 样式参数(参数以空格划分), 文本内容 %&#125; 字体: logo, code 颜色: red,yellow,green,cyan,blue,gray 大小: small, h4, h3, h2, h1, large, huge, ultra 对齐方向: left, center, right 彩色文字在一段话中方便插入各种颜色的标签，包括：红色、黄色、绿色、青色、蓝色、灰色。 超大号文字文档「开始」页面中的标题部分就是超大号文字。Volantis A Wonderful Theme for Hexo - 彩色文字在一段话中方便插入各种颜色的标签，包括：&#123;% p red, 红色 %&#125;、&#123;% p yellow, 黄色 %&#125;、&#123;% p green, 绿色 %&#125;、&#123;% p cyan, 青色 %&#125;、&#123;% p blue, 蓝色 %&#125;、&#123;% p gray, 灰色 %&#125;。- 超大号文字文档「开始」页面中的标题部分就是超大号文字。&#123;% p center logo large, Volantis %&#125;&#123;% p center small, A Wonderful Theme for Hexo %&#125; 引用 note最新版butterfly标签支持引用fontawesome V5图标，效果上已经优于volantis的note标签。故不再额外引入volantis的note样式。做样式适配好麻烦的啊，能偷懒就偷懒吧 以下是butterfly主题的note写法。 通用配置语法格式配置参数样式预览示例源码修改主题配置文件note: # Note tag style values: # - simple bs-callout old alert style. Default. # - modern bs-callout new (v2-v3) alert style. # - flat flat callout style with background, like on Mozilla or StackOverflow. # - disabled disable all CSS styles import of note tag. style: simple icons: false border_radius: 3 # Offset lighter of background in % for modern and flat styles (modern: -12 | 12; flat: -18 | 6). # Offset also applied to label tag variables. This option can work with disabled note tag. light_bg_offset: 0Note标签外挂有两种用法。icons和light_bg_offset只对方法一生效。 方法一 &#123;% note [class] [no-icon] [style] %&#125;Any content (support inline tags too.io).&#123;% endnote %&#125; 方法二 &#123;% note [color] [icon] [style] %&#125;Any content (support inline tags too.io).&#123;% endnote %&#125; 方法一 参数用法class【可选】标识，不同的标识有不同的配色（ default / primary / success / info / warning / danger ）no-icon【可选】不显示 iconstyle【可选】可以覆盖配置中的 style（simple/modern/flat/disabled） 方法二 参数用法class【可选】标识，不同的标识有不同的配色（ default / primary / success / info / warning / danger ）no-icon【可选】可配置自定义 icon (只支持 fontawesome 图标, 也可以配置 no-icon )style【可选】可以覆盖配置中的 style（simple/modern/flat/disabled） 方法一 simple样式默认 提示块标签default 提示块标签primary 提示块标签success 提示块标签info 提示块标签warning 提示块标签danger 提示块标签modern样式默认 提示块标签default 提示块标签primary 提示块标签success 提示块标签info 提示块标签warning 提示块标签danger 提示块标签flat样式默认 提示块标签default 提示块标签primary 提示块标签success 提示块标签info 提示块标签warning 提示块标签danger 提示块标签disabled样式默认 提示块标签default 提示块标签primary 提示块标签success 提示块标签info 提示块标签warning 提示块标签danger 提示块标签no-icon样式默认 提示块标签default 提示块标签primary 提示块标签success 提示块标签info 提示块标签warning 提示块标签danger 提示块标签 方法二 simple样式你是刷 Visa 还是 UnionPay2021年快到了….小心开车 安全至上这是三片呢？还是四片？你是刷 Visa 还是 UnionPay剪刀石头布前端最讨厌的浏览器modern样式你是刷 Visa 还是 UnionPay2021年快到了….小心开车 安全至上这是三片呢？还是四片？你是刷 Visa 还是 UnionPay剪刀石头布前端最讨厌的浏览器flat样式你是刷 Visa 还是 UnionPay2021年快到了….小心开车 安全至上这是三片呢？还是四片？你是刷 Visa 还是 UnionPay剪刀石头布前端最讨厌的浏览器disabled样式你是刷 Visa 还是 UnionPay2021年快到了….小心开车 安全至上这是三片呢？还是四片？你是刷 Visa 还是 UnionPay剪刀石头布前端最讨厌的浏览器no-icon样式你是刷 Visa 还是 UnionPay2021年快到了….小心开车 安全至上这是三片呢？还是四片？你是刷 Visa 还是 UnionPay剪刀石头布前端最讨厌的浏览器 方法一 simple样式&#123;% note simple %&#125;默认 提示块标签&#123;% endnote %&#125;&#123;% note default simple %&#125;default 提示块标签&#123;% endnote %&#125;&#123;% note primary simple %&#125;primary 提示块标签&#123;% endnote %&#125;&#123;% note success simple %&#125;success 提示块标签&#123;% endnote %&#125;&#123;% note info simple %&#125;info 提示块标签&#123;% endnote %&#125;&#123;% note warning simple %&#125;warning 提示块标签&#123;% endnote %&#125;&#123;% note danger simple %&#125;danger 提示块标签&#123;% endnote %&#125;modern样式&#123;% note modern %&#125;默认 提示块标签&#123;% endnote %&#125;&#123;% note default modern %&#125;default 提示块标签&#123;% endnote %&#125;&#123;% note primary modern %&#125;primary 提示块标签&#123;% endnote %&#125;&#123;% note success modern %&#125;success 提示块标签&#123;% endnote %&#125;&#123;% note info modern %&#125;info 提示块标签&#123;% endnote %&#125;&#123;% note warning modern %&#125;warning 提示块标签&#123;% endnote %&#125;&#123;% note danger modern %&#125;danger 提示块标签&#123;% endnote %&#125;flat样式&#123;% note flat %&#125;默认 提示块标签&#123;% endnote %&#125;&#123;% note default flat %&#125;default 提示块标签&#123;% endnote %&#125;&#123;% note primary flat %&#125;primary 提示块标签&#123;% endnote %&#125;&#123;% note success flat %&#125;success 提示块标签&#123;% endnote %&#125;&#123;% note info flat %&#125;info 提示块标签&#123;% endnote %&#125;&#123;% note warning flat %&#125;warning 提示块标签&#123;% endnote %&#125;&#123;% note danger flat %&#125;danger 提示块标签&#123;% endnote %&#125;disabled样式&#123;% note disabled %&#125;默认 提示块标签&#123;% endnote %&#125;&#123;% note default disabled %&#125;default 提示块标签&#123;% endnote %&#125;&#123;% note primary disabled %&#125;primary 提示块标签&#123;% endnote %&#125;&#123;% note success disabled %&#125;success 提示块标签&#123;% endnote %&#125;&#123;% note info disabled %&#125;info 提示块标签&#123;% endnote %&#125;&#123;% note warning disabled %&#125;warning 提示块标签&#123;% endnote %&#125;&#123;% note danger disabled %&#125;danger 提示块标签&#123;% endnote %&#125;no-icon样式&#123;% note no-icon %&#125;默认 提示块标签&#123;% endnote %&#125;&#123;% note default no-icon %&#125;default 提示块标签&#123;% endnote %&#125;&#123;% note primary no-icon %&#125;primary 提示块标签&#123;% endnote %&#125;&#123;% note success no-icon %&#125;success 提示块标签&#123;% endnote %&#125;&#123;% note info no-icon %&#125;info 提示块标签&#123;% endnote %&#125;&#123;% note warning no-icon %&#125;warning 提示块标签&#123;% endnote %&#125;&#123;% note danger no-icon %&#125;danger 提示块标签&#123;% endnote %&#125; 方法二 simple样式&#123;% note &#x27;fab fa-cc-visa&#x27; simple %&#125;你是刷 Visa 还是 UnionPay&#123;% endnote %&#125;&#123;% note blue &#x27;fas fa-bullhorn&#x27; simple %&#125;2021年快到了....&#123;% endnote %&#125;&#123;% note pink &#x27;fas fa-car-crash&#x27; simple %&#125;小心开车 安全至上&#123;% endnote %&#125;&#123;% note red &#x27;fas fa-fan&#x27; simple%&#125;这是三片呢？还是四片？&#123;% endnote %&#125;&#123;% note orange &#x27;fas fa-battery-half&#x27; simple %&#125;你是刷 Visa 还是 UnionPay&#123;% endnote %&#125;&#123;% note purple &#x27;far fa-hand-scissors&#x27; simple %&#125;剪刀石头布&#123;% endnote %&#125;&#123;% note green &#x27;fab fa-internet-explorer&#x27; simple %&#125;前端最讨厌的浏览器&#123;% endnote %&#125;modern样式&#123;% note &#x27;fab fa-cc-visa&#x27; modern %&#125;你是刷 Visa 还是 UnionPay&#123;% endnote %&#125;&#123;% note blue &#x27;fas fa-bullhorn&#x27; modern %&#125;2021年快到了....&#123;% endnote %&#125;&#123;% note pink &#x27;fas fa-car-crash&#x27; modern %&#125;小心开车 安全至上&#123;% endnote %&#125;&#123;% note red &#x27;fas fa-fan&#x27; modern%&#125;这是三片呢？还是四片？&#123;% endnote %&#125;&#123;% note orange &#x27;fas fa-battery-half&#x27; modern %&#125;你是刷 Visa 还是 UnionPay&#123;% endnote %&#125;&#123;% note purple &#x27;far fa-hand-scissors&#x27; modern %&#125;剪刀石头布&#123;% endnote %&#125;&#123;% note green &#x27;fab fa-internet-explorer&#x27; modern %&#125;前端最讨厌的浏览器&#123;% endnote %&#125;flat样式&#123;% note &#x27;fab fa-cc-visa&#x27; flat %&#125;你是刷 Visa 还是 UnionPay&#123;% endnote %&#125;&#123;% note blue &#x27;fas fa-bullhorn&#x27; flat %&#125;2021年快到了....&#123;% endnote %&#125;&#123;% note pink &#x27;fas fa-car-crash&#x27; flat %&#125;小心开车 安全至上&#123;% endnote %&#125;&#123;% note red &#x27;fas fa-fan&#x27; flat%&#125;这是三片呢？还是四片？&#123;% endnote %&#125;&#123;% note orange &#x27;fas fa-battery-half&#x27; flat %&#125;你是刷 Visa 还是 UnionPay&#123;% endnote %&#125;&#123;% note purple &#x27;far fa-hand-scissors&#x27; flat %&#125;剪刀石头布&#123;% endnote %&#125;&#123;% note green &#x27;fab fa-internet-explorer&#x27; flat %&#125;前端最讨厌的浏览器&#123;% endnote %&#125;disabled样式&#123;% note &#x27;fab fa-cc-visa&#x27; disabled %&#125;你是刷 Visa 还是 UnionPay&#123;% endnote %&#125;&#123;% note blue &#x27;fas fa-bullhorn&#x27; disabled %&#125;2021年快到了....&#123;% endnote %&#125;&#123;% note pink &#x27;fas fa-car-crash&#x27; disabled %&#125;小心开车 安全至上&#123;% endnote %&#125;&#123;% note red &#x27;fas fa-fan&#x27; disabled %&#125;这是三片呢？还是四片？&#123;% endnote %&#125;&#123;% note orange &#x27;fas fa-battery-half&#x27; disabled %&#125;你是刷 Visa 还是 UnionPay&#123;% endnote %&#125;&#123;% note purple &#x27;far fa-hand-scissors&#x27; disabled %&#125;剪刀石头布&#123;% endnote %&#125;&#123;% note green &#x27;fab fa-internet-explorer&#x27; disabled %&#125;前端最讨厌的浏览器&#123;% endnote %&#125;no-icon样式&#123;% note no-icon %&#125;你是刷 Visa 还是 UnionPay&#123;% endnote %&#125;&#123;% note blue no-icon %&#125;2021年快到了....&#123;% endnote %&#125;&#123;% note pink no-icon %&#125;小心开车 安全至上&#123;% endnote %&#125;&#123;% note red no-icon %&#125;这是三片呢？还是四片？&#123;% endnote %&#125;&#123;% note orange no-icon %&#125;你是刷 Visa 还是 UnionPay&#123;% endnote %&#125;&#123;% note purple no-icon %&#125;剪刀石头布&#123;% endnote %&#125;&#123;% note green no-icon %&#125;前端最讨厌的浏览器&#123;% endnote %&#125; 上标标签 tip主要样式参考自小康的butterfly渐变背景标签,自己写了个tip.js来渲染标签，精简了一下代码。 标签语法配置参数样式预览示例源码&#123;% tip [参数，可选] %&#125;文本内容&#123;% endtip %&#125; 样式: success,error,warning,bolt,ban,home,sync,cogs,key,bell 自定义图标: 支持fontawesome。 默认情况 success error warning bolt ban home sync cogs key bell 自定义font awesome图标 &#123;% tip %&#125;默认情况&#123;% endtip %&#125;&#123;% tip success %&#125;success&#123;% endtip %&#125;&#123;% tip error %&#125;error&#123;% endtip %&#125;&#123;% tip warning %&#125;warning&#123;% endtip %&#125;&#123;% tip bolt %&#125;bolt&#123;% endtip %&#125;&#123;% tip ban %&#125;ban&#123;% endtip %&#125;&#123;% tip home %&#125;home&#123;% endtip %&#125;&#123;% tip sync %&#125;sync&#123;% endtip %&#125;&#123;% tip cogs %&#125;cogs&#123;% endtip %&#125;&#123;% tip key %&#125;key&#123;% endtip %&#125;&#123;% tip bell %&#125;bell&#123;% endtip %&#125;&#123;% tip fa-atom %&#125;自定义font awesome图标&#123;% endtip %&#125; 动态标签 anima动态标签的实质是引用了font-awesome-animation的css样式，不一定局限于tip标签，也可以是其他标签。只不过这里tip.js是我自己写的，所以我清楚它会怎么被渲染成html，才用的这个写法。可以熟读文档，使用html语言来编写其他标签类型。 标签语法配置参数样式预览示例源码&#123;% tip [参数，可选] %&#125;文本内容&#123;% endtip %&#125;更多详情请参看font-awesome-animation文档 将所需的CSS类添加到图标（或DOM中的任何元素）。 对于父级悬停样式，需要给目标元素添加指定CSS类，同时还要给目标元素的父级元素添加CSS类faa-parent animated-hover。（详情见示例及示例源码）You can regulate the speed of the animation by adding the CSS class or . faa-fastfaa-slow 可以通过给目标元素添加CSS类faa-fast或faa-slow来控制动画快慢。 On DOM load当页面加载时显示动画 On hover当鼠标悬停时显示动画 On parent hover当鼠标悬停在父级元素时显示动画 &nbsp;faa-wrench animated &nbsp;faa-wrench animated-hover &nbsp;faa-wrench &nbsp;faa-ring animated &nbsp;faa-ring animated-hover &nbsp;faa-ring &nbsp;faa-horizontal animated &nbsp;faa-horizontal animated-hover &nbsp;faa-horizontal &nbsp;faa-vertical animated &nbsp;faa-vertical animated-hover &nbsp;faa-vertical &nbsp;faa-flash animated &nbsp;faa-flash animated-hover &nbsp;faa-flash &nbsp;faa-bounce animated &nbsp;faa-bounce animated-hover &nbsp;faa-bounce &nbsp;faa-spin animated &nbsp;faa-spin animated-hover &nbsp;faa-spin &nbsp;faa-tada animated &nbsp;faa-tada animated-hover &nbsp;faa-tada &nbsp;faa-pulse animated &nbsp;faa-pulse animated-hover &nbsp;faa-pulse &nbsp;faa-shake animated &nbsp;faa-shake animated-hover &nbsp;faa-shake &nbsp;faa-tada animated &nbsp;faa-tada animated-hover &nbsp;faa-tada &nbsp;faa-passing animated &nbsp;faa-passing animated-hover &nbsp;faa-passing &nbsp;faa-passing-reverse animated &nbsp;faa-passing-reverse animated-hover &nbsp;faa-passing-reverse &nbsp;faa-burst animated &nbsp;faa-burst animated-hover &nbsp;faa-burst &nbsp;faa-falling animated &nbsp;faa-falling animated-hover &nbsp;faa-falling &nbsp;faa-rising animated &nbsp;faa-rising animated-hover &nbsp;faa-rising On DOM load（当页面加载时显示动画） warning ban 调整动画速度。 warning ban On hover（当鼠标悬停时显示动画） warning ban On parent hover（当鼠标悬停在父级元素时显示动画） warning ban On DOM load（当页面加载时显示动画） &#123;% tip warning faa-horizontal animated %&#125;warning&#123;% endtip %&#125;&#123;% tip ban faa-flash animated %&#125;ban&#123;% endtip %&#125; 调整动画速度 &#123;% tip warning faa-horizontal animated faa-fast %&#125;warning&#123;% endtip %&#125;&#123;% tip ban faa-flash animated faa-slow %&#125;ban&#123;% endtip %&#125; On hover（当鼠标悬停时显示动画） &#123;% tip warning faa-horizontal animated-hover %&#125;warning&#123;% endtip %&#125;&#123;% tip ban faa-flash animated-hover %&#125;ban&#123;% endtip %&#125; On parent hover（当鼠标悬停在父级元素时显示动画） &#123;% tip warning faa-parent animated-hover %&#125;&lt;p class=&quot;faa-horizontal&quot;&gt;warning&lt;/p&gt;&#123;% endtip %&#125;&#123;% tip ban faa-parent animated-hover %&#125;&lt;p class=&quot;faa-flash&quot;&gt;ban&lt;/p&gt;&#123;% endtip %&#125; 复选列表 checkbox标签语法配置参数样式预览示例源码&#123;% checkbox 样式参数（可选）, 文本（支持简单md） %&#125; 样式: plus, minus, times 颜色: red,yellow,green,cyan,blue,gray 选中状态: checked 纯文本测试 支持简单的 markdown 语法 支持自定义颜色 绿色 + 默认选中 黄色 + 默认选中 青色 + 默认选中 蓝色 + 默认选中 增加 减少 叉 &#123;% checkbox 纯文本测试 %&#125;&#123;% checkbox checked, 支持简单的 [markdown](https://guides.github.com/features/mastering-markdown/) 语法 %&#125;&#123;% checkbox red, 支持自定义颜色 %&#125;&#123;% checkbox green checked, 绿色 + 默认选中 %&#125;&#123;% checkbox yellow checked, 黄色 + 默认选中 %&#125;&#123;% checkbox cyan checked, 青色 + 默认选中 %&#125;&#123;% checkbox blue checked, 蓝色 + 默认选中 %&#125;&#123;% checkbox plus green checked, 增加 %&#125;&#123;% checkbox minus yellow checked, 减少 %&#125;&#123;% checkbox times red checked, 叉 %&#125; 单选列表 radio标签语法配置参数样式预览示例源码&#123;% radio 样式参数（可选）, 文本（支持简单md） %&#125; 颜色: red,yellow,green,cyan,blue,gray 选中状态: checked 纯文本测试 支持简单的 markdown 语法 支持自定义颜色 绿色 黄色 青色 蓝色 &#123;% radio 纯文本测试 %&#125;&#123;% radio checked, 支持简单的 [markdown](https://guides.github.com/features/mastering-markdown/) 语法 %&#125;&#123;% radio red, 支持自定义颜色 %&#125;&#123;% radio green, 绿色 %&#125;&#123;% radio yellow, 黄色 %&#125;&#123;% radio cyan, 青色 %&#125;&#123;% radio blue, 蓝色 %&#125; 时间轴 timeline标签语法样式预览示例源码&#123;% timeline 时间线标题（可选） %&#125;&#123;% timenode 时间节点（标题） %&#125;正文内容&#123;% endtimenode %&#125;&#123;% timenode 时间节点（标题） %&#125;正文内容&#123;% endtimenode %&#125;&#123;% endtimeline %&#125; 2020-07-24 2.6.6 -&gt; 3.0 如果有 hexo-lazyload-image 插件，需要删除并重新安装最新版本，设置 lazyload.isSPA: true。2.x 版本的 css 和 js 不适用于 3.x 版本，如果使用了 use_cdn: true 则需要删除。2.x 版本的 fancybox 标签在 3.x 版本中被重命名为 gallery 。2.x 版本的置顶 top: true 改为了 pin: true，并且同样适用于 layout: page 的页面。如果使用了 hexo-offline 插件，建议卸载，3.0 版本默认开启了 pjax 服务。 2020-05-15 2.6.3 -&gt; 2.6.6 不需要额外处理。 2020-04-20 2.6.2 -&gt; 2.6.3 全局搜索 seotitle 并替换为 seo_title。group 组件的索引规则有变，使用 group 组件的文章内，group: group_name 对应的组件名必须是 group_name。group 组件的列表名优先显示文章的 short_title 其次是 title。 &#123;% timeline %&#125;&#123;% timenode 2020-07-24 [2.6.6 -&gt; 3.0](https://github.com/volantis-x/hexo-theme-volantis/releases) %&#125;1. 如果有 `hexo-lazyload-image` 插件，需要删除并重新安装最新版本，设置 `lazyload.isSPA: true`。2. 2.x 版本的 css 和 js 不适用于 3.x 版本，如果使用了 `use_cdn: true` 则需要删除。3. 2.x 版本的 fancybox 标签在 3.x 版本中被重命名为 gallery 。4. 2.x 版本的置顶 `top: true` 改为了 `pin: true`，并且同样适用于 `layout: page` 的页面。5. 如果使用了 `hexo-offline` 插件，建议卸载，3.0 版本默认开启了 pjax 服务。&#123;% endtimenode %&#125;&#123;% timenode 2020-05-15 [2.6.3 -&gt; 2.6.6](https://github.com/volantis-x/hexo-theme-volantis/releases/tag/2.6.6) %&#125;不需要额外处理。&#123;% endtimenode %&#125;&#123;% timenode 2020-04-20 [2.6.2 -&gt; 2.6.3](https://github.com/volantis-x/hexo-theme-volantis/releases/tag/2.6.3) %&#125;1. 全局搜索 `seotitle` 并替换为 `seo_title`。2. group 组件的索引规则有变，使用 group 组件的文章内，`group: group_name` 对应的组件名必须是 `group_name`。2. group 组件的列表名优先显示文章的 `short_title` 其次是 `title`。&#123;% endtimenode %&#125;&#123;% endtimeline %&#125; 链接卡片 link标签语法样式预览示例源码&#123;% link 标题, 链接, 图片链接（可选） %&#125;糖果屋教程贴,&#123;% link 糖果屋教程贴, https://akilar.top/posts/615e2dec/, https://cdn.jsdelivr.net/gh/Akilarlxh/akilarlxh.github.io/img/siteicon/favicon.ico %&#125; 按钮 btnsVolantis的按钮使用的是btn和btns标签。btns和butterfly的button不冲突，但是btn会被强制渲染，导致部分参数失效,而且btn的效果还是butterfly的button更好看些。所以就只适配了btns。 标签语法参数配置样式预览示例源码&#123;% btns 样式参数 %&#125;&#123;% cell 标题, 链接, 图片或者图标 %&#125;&#123;% cell 标题, 链接, 图片或者图标 %&#125;&#123;% endbtns %&#125; 圆角样式：rounded, circle 增加文字样式：可以在容器内增加 &lt;b&gt;标题&lt;/b&gt;和&lt;p&gt;描述文字&lt;/p&gt; 布局方式： 默认为自动宽度，适合视野内只有一两个的情况。 参数 含义 wide 宽一点的按钮 fill 填充布局，自动铺满至少一行，多了会换行 center 居中，按钮之间是固定间距 around 居中分散 grid2 等宽最多2列，屏幕变窄会适当减少列数 grid3 等宽最多3列，屏幕变窄会适当减少列数 grid4 等宽最多4列，屏幕变窄会适当减少列数 grid5 等宽最多5列，屏幕变窄会适当减少列数 如果需要显示类似「团队成员」之类的一组含有头像的链接： xaoxuu xaoxuu xaoxuu xaoxuu xaoxuu 或者含有图标的按钮： 下载源码 查看文档 圆形图标 + 标题 + 描述 + 图片 + 网格5列 + 居中 心率管家 专业版 心率管家 免费版 如果需要显示类似「团队成员」之类的一组含有头像的链接：&#123;% btns circle grid5 %&#125;&#123;% cell xaoxuu, https://xaoxuu.com, https://cdn.jsdelivr.net/gh/xaoxuu/cdn-assets/avatar/avatar.png %&#125;&#123;% cell xaoxuu, https://xaoxuu.com, https://cdn.jsdelivr.net/gh/xaoxuu/cdn-assets/avatar/avatar.png %&#125;&#123;% cell xaoxuu, https://xaoxuu.com, https://cdn.jsdelivr.net/gh/xaoxuu/cdn-assets/avatar/avatar.png %&#125;&#123;% cell xaoxuu, https://xaoxuu.com, https://cdn.jsdelivr.net/gh/xaoxuu/cdn-assets/avatar/avatar.png %&#125;&#123;% cell xaoxuu, https://xaoxuu.com, https://cdn.jsdelivr.net/gh/xaoxuu/cdn-assets/avatar/avatar.png %&#125;&#123;% endbtns %&#125; 或者含有图标的按钮：&#123;% btns rounded grid5 %&#125;&#123;% cell 下载源码, /, fas fa-download %&#125;&#123;% cell 查看文档, /, fas fa-book-open %&#125;&#123;% endbtns %&#125; 圆形图标 + 标题 + 描述 + 图片 + 网格5列 + 居中&#123;% btns circle center grid5 %&#125;&lt;a href=&#x27;https://apps.apple.com/cn/app/heart-mate-pro-hrm-utility/id1463348922?ls=1&#x27;&gt; &lt;i class=&#x27;fab fa-apple&#x27;&gt;&lt;/i&gt; &lt;b&gt;心率管家&lt;/b&gt; &#123;% p red, 专业版 %&#125; &lt;img src=&#x27;https://cdn.jsdelivr.net/gh/xaoxuu/cdn-assets/qrcode/heartmate_pro.png&#x27;&gt;&lt;/a&gt;&lt;a href=&#x27;https://apps.apple.com/cn/app/heart-mate-lite-hrm-utility/id1475747930?ls=1&#x27;&gt; &lt;i class=&#x27;fab fa-apple&#x27;&gt;&lt;/i&gt; &lt;b&gt;心率管家&lt;/b&gt; &#123;% p green, 免费版 %&#125; &lt;img src=&#x27;https://cdn.jsdelivr.net/gh/xaoxuu/cdn-assets/qrcode/heartmate_lite.png&#x27;&gt;&lt;/a&gt;&#123;% endbtns %&#125; github卡片 ghcardghcard使用了github-readme-stats的API，支持直接使用markdown语法来写。 标签语法配置参数样式预览示例源码&#123;% ghcard 用户名, 其它参数（可选） %&#125;&#123;% ghcard 用户名/仓库, 其它参数（可选） %&#125;更多参数可以参考：使用,分割各个参数。写法为：参数名=参数值以下只写几个常用参数值。 参数名 取值 释义 hide stars,commits,prs,issues,contribs 隐藏指定统计 count_private true 将私人项目贡献添加到总提交计数中 show_icons true 显示图标 theme 请查阅Available Themes 主题 用户信息卡片 仓库信息卡片 用户信息卡片 | &#123;% ghcard xaoxuu %&#125; | &#123;% ghcard xaoxuu, theme=vue %&#125; || -- | -- || &#123;% ghcard xaoxuu, theme=buefy %&#125; | &#123;% ghcard xaoxuu, theme=solarized-light %&#125; || &#123;% ghcard xaoxuu, theme=onedark %&#125; | &#123;% ghcard xaoxuu, theme=solarized-dark %&#125; || &#123;% ghcard xaoxuu, theme=algolia %&#125; | &#123;% ghcard xaoxuu, theme=calm %&#125; | 仓库信息卡片 | &#123;% ghcard volantis-x/hexo-theme-volantis %&#125; | &#123;% ghcard volantis-x/hexo-theme-volantis, theme=vue %&#125; || -- | -- || &#123;% ghcard volantis-x/hexo-theme-volantis, theme=buefy %&#125; | &#123;% ghcard volantis-x/hexo-theme-volantis, theme=solarized-light %&#125; || &#123;% ghcard volantis-x/hexo-theme-volantis, theme=onedark %&#125; | &#123;% ghcard volantis-x/hexo-theme-volantis, theme=solarized-dark %&#125; || &#123;% ghcard volantis-x/hexo-theme-volantis, theme=algolia %&#125; | &#123;% ghcard volantis-x/hexo-theme-volantis, theme=calm %&#125; | github徽标 ghbdage关于ghbdage参数的更多具体用法可以参看相关教程：添加github徽标 标签语法配置参数样式预览示例源码&#123;% bdage [right],[left],[logo]||[color],[link],[title]||[option] %&#125; left：徽标左边的信息，必选参数。 right: 徽标右边的信息，必选参数， logo：徽标图标，图标名称详见simpleicons，可选参数。 color：徽标右边的颜色，可选参数。 link：指向的链接，可选参数。 title：徽标的额外信息，可选参数。主要用于优化SEO，但object标签不会像a标签一样在鼠标悬停显示title信息。 option：自定义参数，支持shields.io的全部API参数支持，具体参数可以参看上文中的拓展写法示例。形式为name1=value2&amp;name2=value2。 本外挂标签的参数分为三组，用||分割。 基本参数 信息参数 拓展参数 本外挂标签的参数分为三组，用||分割。 基本参数,定义徽标左右文字和图标&#123;% bdage Theme,Butterfly %&#125;&#123;% bdage Frame,Hexo,hexo %&#125; 信息参数，定义徽标右侧内容背景色，指向链接&#123;% bdage CDN,JsDelivr,jsDelivr||abcdef,https://metroui.org.ua/index.html,本站使用JsDelivr为静态资源提供CDN加速 %&#125;//如果是跨顺序省略可选参数，仍然需要写个逗号,用作分割&#123;% bdage Source,GitHub,GitHub||,https://github.com/ %&#125; 拓展参数，支持shields的API的全部参数内容&#123;% bdage Hosted,Vercel,Vercel||brightgreen,https://vercel.com/,本站采用双线部署，默认线路托管于Vercel||style=social&amp;logoWidth=20 %&#125;//如果是跨顺序省略可选参数组，仍然需要写双竖线||用作分割&#123;% bdage Hosted,Vercel,Vercel||||style=social&amp;logoWidth=20&amp;logoColor=violet %&#125; 网站卡片 sites标签语法样式预览示例源码&#123;% sitegroup %&#125;&#123;% site 标题, url=链接, screenshot=截图链接, avatar=头像链接（可选）, description=描述（可选） %&#125;&#123;% site 标题, url=链接, screenshot=截图链接, avatar=头像链接（可选）, description=描述（可选） %&#125;&#123;% endsitegroup %&#125;xaoxuu简约风格 inkss这是一段关于这个网站的描述文字 MHuiG这是一段关于这个网站的描述文字 Colsrch这是一段关于这个网站的描述文字 Linhk1606这是一段关于这个网站的描述文字&#123;% sitegroup %&#125;&#123;% site xaoxuu, url=https://xaoxuu.com, screenshot=https://i.loli.net/2020/08/21/VuSwWZ1xAeUHEBC.jpg, avatar=https://cdn.jsdelivr.net/gh/xaoxuu/cdn-assets/avatar/avatar.png, description=简约风格 %&#125;&#123;% site inkss, url=https://inkss.cn, screenshot=https://i.loli.net/2020/08/21/Vzbu3i8fXs6Nh5Y.jpg, avatar=https://cdn.jsdelivr.net/gh/inkss/common@master/static/web/avatar.jpg, description=这是一段关于这个网站的描述文字 %&#125;&#123;% site MHuiG, url=https://blog.mhuig.top, screenshot=https://i.loli.net/2020/08/22/d24zpPlhLYWX6D1.png, avatar=https://cdn.jsdelivr.net/gh/MHuiG/imgbed@master/data/p.png, description=这是一段关于这个网站的描述文字 %&#125;&#123;% site Colsrch, url=https://colsrch.top, screenshot=https://i.loli.net/2020/08/22/dFRWXm52OVu8qfK.png, avatar=https://cdn.jsdelivr.net/gh/Colsrch/images/Colsrch/avatar.jpg, description=这是一段关于这个网站的描述文字 %&#125;&#123;% site Linhk1606, url=https://linhk1606.github.io, screenshot=https://i.loli.net/2020/08/21/3PmGLCKicnfow1x.png, avatar=https://i.loli.net/2020/02/09/PN7I5RJfFtA93r2.png, description=这是一段关于这个网站的描述文字 %&#125;&#123;% endsitegroup %&#125; 行内图片 inlineimage标签语法参数配置样式预览示例源码&#123;% inlineimage 图片链接, height=高度（可选） %&#125; 高度：height=20px 这是 一段话。 这又是 一段话。这是 &#123;% inlineimage https://cdn.jsdelivr.net/gh/volantis-x/cdn-emoji/aru-l/0000.gif %&#125; 一段话。这又是 &#123;% inlineimage https://cdn.jsdelivr.net/gh/volantis-x/cdn-emoji/aru-l/5150.gif, height=40px %&#125; 一段话。 单张图片 image标签语法参数配置样式预览示例源码&#123;% image 链接, width=宽度（可选）, height=高度（可选）, alt=描述（可选）, bg=占位颜色（可选） %&#125; 图片宽度高度：width=300px, height=32px 图片描述：alt=图片描述（butterfly需要在主题配置文件中开启图片描述） 占位背景色：bg=#f2f2f2 添加描述： 每天下课回宿舍的路，没有什么故事。 指定宽度： 指定宽度并添加描述： 每天下课回宿舍的路，没有什么故事。 设置占位背景色： 优化不同宽度浏览的观感 添加描述： &#123;% image https://cdn.jsdelivr.net/gh/volantis-x/cdn-wallpaper-minimalist/2020/025.jpg, alt=每天下课回宿舍的路，没有什么故事。 %&#125; 指定宽度：&#123;% image https://cdn.jsdelivr.net/gh/volantis-x/cdn-wallpaper-minimalist/2020/025.jpg, width=400px %&#125; 指定宽度并添加描述：&#123;% image https://cdn.jsdelivr.net/gh/volantis-x/cdn-wallpaper-minimalist/2020/025.jpg, width=400px, alt=每天下课回宿舍的路，没有什么故事。 %&#125; 设置占位背景色：&#123;% image https://cdn.jsdelivr.net/gh/volantis-x/cdn-wallpaper-minimalist/2020/025.jpg, width=400px, bg=#1D0C04, alt=优化不同宽度浏览的观感 %&#125; 音频 audio标签语法样式预览示例源码&#123;% audio 音频链接 %&#125;Your browser does not support the audio tag.&#123;% audio https://github.com/volantis-x/volantis-docs/releases/download/assets/Lumia1020.mp3 %&#125; 视频 video标签语法参数配置样式预览示例源码&#123;% video 视频链接 %&#125; 对其方向：left, center, right 列数：逗号后面直接写列数，支持 1 ～ 4 列。 100%宽度 Your browser does not support the video tag. 50%宽度 Your browser does not support the video tag. Your browser does not support the video tag. Your browser does not support the video tag. Your browser does not support the video tag. 25%宽度 Your browser does not support the video tag. Your browser does not support the video tag. Your browser does not support the video tag. Your browser does not support the video tag. Your browser does not support the video tag. Your browser does not support the video tag. Your browser does not support the video tag. Your browser does not support the video tag. 100%宽度 &#123;% video https://github.com/volantis-x/volantis-docs/releases/download/assets/IMG_0341.mov %&#125; 50%宽度 &#123;% videos, 2 %&#125;&#123;% video https://github.com/volantis-x/volantis-docs/releases/download/assets/IMG_0341.mov %&#125;&#123;% video https://github.com/volantis-x/volantis-docs/releases/download/assets/IMG_0341.mov %&#125;&#123;% video https://github.com/volantis-x/volantis-docs/releases/download/assets/IMG_0341.mov %&#125;&#123;% video https://github.com/volantis-x/volantis-docs/releases/download/assets/IMG_0341.mov %&#125;&#123;% endvideos %&#125; 25%宽度 &#123;% videos, 4 %&#125;&#123;% video https://github.com/volantis-x/volantis-docs/releases/download/assets/IMG_0341.mov %&#125;&#123;% video https://github.com/volantis-x/volantis-docs/releases/download/assets/IMG_0341.mov %&#125;&#123;% video https://github.com/volantis-x/volantis-docs/releases/download/assets/IMG_0341.mov %&#125;&#123;% video https://github.com/volantis-x/volantis-docs/releases/download/assets/IMG_0341.mov %&#125;&#123;% video https://github.com/volantis-x/volantis-docs/releases/download/assets/IMG_0341.mov %&#125;&#123;% video https://github.com/volantis-x/volantis-docs/releases/download/assets/IMG_0341.mov %&#125;&#123;% video https://github.com/volantis-x/volantis-docs/releases/download/assets/IMG_0341.mov %&#125;&#123;% video https://github.com/volantis-x/volantis-docs/releases/download/assets/IMG_0341.mov %&#125;&#123;% endvideos %&#125; 相册 galleryButterfly自带gallery相册，而且会根据图片大小自动调整排版，效果比Volantis的gallery更好，故不再收录Volantis的gallery标签。 以下为Butterfly自带的gallery标签写法。相册图库和相册配合使用。 标签语法参数配置样式预览示例源码 gallerygroup 相册图库 &lt;div class=&quot;gallery-group-main&quot;&gt;&#123;% galleryGroup name description link img-url %&#125;&#123;% galleryGroup name description link img-url %&#125;&#123;% galleryGroup name description link img-url %&#125;&lt;/div&gt; gallery 相册 &#123;% gallery %&#125;markdown 圖片格式&#123;% endgallery %&#125; gallerygroup 相册图库 参数名 释义 name 图库名字 description 图库描述 link 链接到对应相册的地址 img-url 图库封面 思维拓展一下，相册图库的实质其实就是个快捷方式，可以自定义添加描述、封面、链接。那么我们未必要把它当做一个相册，完全可以作为一个链接卡片，链接到视频、QQ、友链都是不错的选择。 gallery 相册区别于旧版的Gallery相册,新的Gallery相册会自动根据图片长度进行排版，书写也更加方便，与markdown格式一样。可根据需要插入到相应的md。无需再自己配置长宽。建议在粘贴时故意使用长短、大小、横竖不一的图片，会有更好的效果。（尺寸完全相同的图片只会平铺输出，效果很糟糕） gallerygroup 相册图库 MC 在Rikkaの六花服务器里留下的足迹 Gundam 哦咧哇gundam哒！ I-am-Akilar 某种意义上也算自拍吧 gallery 相册 对于很多同学提问的gallerygroup和gallery相册页的链接问题。这里说下我个人的使用习惯。一般使用相册图库的话，可以在导航栏加一个gallery的page(使用指令hexo new page gallery添加)，里面放相册图库作为封面。然后在[Blogroot]/source/gallery/下面建立相应的文件夹，例如若按照这里的示例，若欲使用/gallery/MC/路径访问MC相册，则需要新建[Blogroot]/source/gallery/MC/index.md，并在里面填入gallery相册内容。 gallerygroup 相册图库 &lt;div class=&quot;gallery-group-main&quot;&gt;&#123;% galleryGroup MC 在Rikkaの六花服务器里留下的足迹 &#x27;/gallery/MC/&#x27; https://cdn.jsdelivr.net/npm/akilar-candyassets/image/1.jpg %&#125;&#123;% galleryGroup Gundam 哦咧哇gundam哒！ &#x27;/gallery/Gundam/&#x27; https://cdn.jsdelivr.net/npm/akilar-candyassets/image/20200907110508327.png %&#125;&#123;% galleryGroup I-am-Akilar 某种意义上也算自拍吧 &#x27;/gallery/I-am-Akilar/&#x27; https://cdn.jsdelivr.net/npm/akilar-candyassets/image/20200907113116651.png %&#125;&lt;/div&gt; gallery 相册 &#123;% gallery %&#125;![](https://i.loli.net/2019/12/25/Fze9jchtnyJXMHN.jpg)![](https://i.loli.net/2019/12/25/ryLVePaqkYm4TEK.jpg)![](https://i.loli.net/2019/12/25/gEy5Zc1Ai6VuO4N.jpg)![](https://i.loli.net/2019/12/25/d6QHbytlSYO4FBG.jpg)![](https://i.loli.net/2019/12/25/6nepIJ1xTgufatZ.jpg)![](https://i.loli.net/2019/12/25/E7Jvr4eIPwUNmzq.jpg)![](https://i.loli.net/2019/12/25/mh19anwBSWIkGlH.jpg)![](https://i.loli.net/2019/12/25/2tu9JC8ewpBFagv.jpg)&#123;% endgallery %&#125; 折叠框 foldingButterfly虽然也有内置折叠框hideToggle标签，但是Volantis的folding折叠框更好看一些。 标签语法配置参数样式预览示例源码&#123;% folding 参数（可选）, 标题 %&#125;![](https://cdn.jsdelivr.net/gh/volantis-x/cdn-wallpaper/abstract/41F215B9-261F-48B4-80B5-4E86E165259E.jpeg)&#123;% endfolding %&#125; 颜色：blue, cyan, green, yellow, red 状态：状态填写 open 代表默认打开。 查看图片测试 查看默认打开的折叠框 这是一个默认打开的折叠框。 查看代码测试 ![](https://cdn.jsdelivr.net/gh/volantis-x/cdn-wallpaper/abstract/41F215B9-261F-48B4-80B5-4E86E165259E.jpeg) 查看列表测试 hahahehe 查看嵌套测试 查看嵌套测试2 查看嵌套测试3 hahaha &#123;% folding 查看图片测试 %&#125;![](https://cdn.jsdelivr.net/gh/volantis-x/cdn-wallpaper/abstract/41F215B9-261F-48B4-80B5-4E86E165259E.jpeg)&#123;% endfolding %&#125;&#123;% folding cyan open, 查看默认打开的折叠框 %&#125;这是一个默认打开的折叠框。&#123;% endfolding %&#125;&#123;% folding green, 查看代码测试 %&#125;假装这里有代码块（代码块没法嵌套代码块）&#123;% endfolding %&#125;&#123;% folding yellow, 查看列表测试 %&#125;- haha- hehe&#123;% endfolding %&#125;&#123;% folding red, 查看嵌套测试 %&#125;&#123;% folding blue, 查看嵌套测试2 %&#125;&#123;% folding 查看嵌套测试3 %&#125;hahaha &lt;span&gt;&lt;img src=&#x27;https://cdn.jsdelivr.net/gh/volantis-x/cdn-emoji/tieba/%E6%BB%91%E7%A8%BD.png&#x27; style=&#x27;height:24px&#x27;&gt;&lt;/span&gt;&#123;% endfolding %&#125;&#123;% endfolding %&#125;&#123;% endfolding %&#125; 分栏 tabButterfly的tab标签和Volantis的tab标签都是移值自NexT主题，所以写法和效果一模一样。 标签语法配置参数样式预览示例源码&#123;% tabs Unique name, [index] %&#125;&lt;!-- tab [Tab caption] [@icon] --&gt;Any content (support inline tags too).&lt;!-- endtab --&gt;&#123;% endtabs %&#125; Unique name : 选项卡块标签的唯一名称，不带逗号。 将在#id中用作每个标签及其索引号的前缀。 如果名称中包含空格，则对于生成#id，所有空格将由破折号代替。 仅当前帖子/页面的URL必须是唯一的！ [index]: 活动选项卡的索引号。 如果未指定，将选择第一个标签（1）。 如果index为-1，则不会选择任何选项卡。 可选参数。 [Tab caption]: 当前选项卡的标题。 如果未指定标题，则带有制表符索引后缀的唯一名称将用作制表符的标题。 如果未指定标题，但指定了图标，则标题将为空。 可选参数。 [@icon]: FontAwesome图标名称（全名，看起来像“ fas fa-font”） 可以指定带空格或不带空格； 例如’Tab caption @icon’ 和 ‘Tab caption@icon’. 可选参数。 Demo 1 - 预设选择第一个【默认】 test1 1test1 2test1 3This is Tab 1.This is Tab 2.This is Tab 3. Demo 2 - 预设选择tabs test2 1test2 2test2 3This is Tab 1.This is Tab 2.This is Tab 3. Demo 3 - 没有预设值 test3 1test3 2test3 3This is Tab 1.This is Tab 2.This is Tab 3. Demo 4 - 自定义Tab名 + 只有icon + icon和Tab名 第一个Tab炸弹tab名字为第一个Tab只有图标 没有Tab名字名字+iconDemo 1 - 预设选择第一个【默认】 &#123;% tabs test1 %&#125;&lt;!-- tab --&gt;**This is Tab 1.**&lt;!-- endtab --&gt;&lt;!-- tab --&gt;**This is Tab 2.**&lt;!-- endtab --&gt;&lt;!-- tab --&gt;**This is Tab 3.**&lt;!-- endtab --&gt;&#123;% endtabs %&#125; Demo 2 - 预设选择tabs &#123;% tabs test2, 3 %&#125;&lt;!-- tab --&gt;**This is Tab 1.**&lt;!-- endtab --&gt;&lt;!-- tab --&gt;**This is Tab 2.**&lt;!-- endtab --&gt;&lt;!-- tab --&gt;**This is Tab 3.**&lt;!-- endtab --&gt;&#123;% endtabs %&#125; Demo 3 - 没有预设值 &#123;% tabs test3, -1 %&#125;&lt;!-- tab --&gt;**This is Tab 1.**&lt;!-- endtab --&gt;&lt;!-- tab --&gt;**This is Tab 2.**&lt;!-- endtab --&gt;&lt;!-- tab --&gt;**This is Tab 3.**&lt;!-- endtab --&gt;&#123;% endtabs %&#125; Demo 4 - 自定义Tab名 + 只有icon + icon和Tab名 &#123;% tabs test4 %&#125;&lt;!-- tab 第一个Tab --&gt;**tab名字为第一个Tab**&lt;!-- endtab --&gt;&lt;!-- tab @fab fa-apple-pay --&gt;**只有图标 没有Tab名字**&lt;!-- endtab --&gt;&lt;!-- tab 炸弹@fas fa-bomb --&gt;**名字+icon**&lt;!-- endtab --&gt;&#123;% endtabs %&#125; 数据集合 issues 标签语法参数配置样式预览示例源码&#123;% issues type | api=url | group=key:value1,value2（可选） %&#125;type(类型)：根据需求不同，会将 issues 内容解析成不同的 HTML 标签，目前支持的类型有： 时间轴timeline: 解析成timeline标签，issue的标题对应timeline的时间，issue的内容对应timeline的内容。 网站卡片sites: 解析成sites标签，需要有JSON代码块,各参数对应sites标签参数: &#123; &quot;title&quot;: &quot;&quot;, &quot;screenshot&quot;: &quot;&quot;, &quot;url&quot;: &quot;&quot;, &quot;avatar&quot;: &quot;&quot;, &quot;description&quot;: &quot;&quot;, &quot;「keywords」&quot;: &quot;&quot;&#125; 参数 释义 title 网站名称 screenshot 网站预览图 url 网站链接，需要添加https://协议组成完整域名。否则可能被识别成站点相对路径。 avatar 站长头像 「keywords」 分组依据，未必要叫「keywords」，详见下文group(分组) api(接口)：url为可以调的通的API，例如：api=https://gitee.com/api/v5/repos/xaoxuu/friends/issues?sort=updated&amp;state=open&amp;page=1&amp;per_page=100&amp;labels=activeapi=https://api.github.com/repos/xaoxuu/friends/issues?sort=updated&amp;state=open&amp;page=1&amp;per_page=100&amp;labels=active 参数 释义 https://gitee.com/api/v5/ gitee仓库的api https://api.github.com/ github仓库的api repos/xaoxuu/friends/issues repos/用户名/仓库名/issues sort=updated&amp;state=open 界定哪些类型的issues会被读取过来渲染成相应的标签 page=1&amp;per_page=100 读取前100条issues labels=active 控制默认的issue不显示，只有自己审核通过添加了active标签之后才会显示 group(分组)：sites类型的issues默认不分组，如果需要分组，可指定分组依据「keywords」，和分组白名单「value1」、「value2」等，例如： group=version:v4,v3,v2# 此处的version就是上文中的「keywords」 这个参数的作用就是，筛选出JSON中包含&quot;version&quot;: &quot;v4&quot;或者&quot;version&quot;:&quot;v3&quot;或者&quot;version&quot;: &quot;v2&quot;的数据，并分组显示。 仓库ISSUES模板配置 Github仓库配置方案 新建一个仓库，仓库名随意，这里我命名为friend_link, 新建文件friend_link\\.github\\ISSUE_TEMPLATE.md, 并在其中输入以下内容作为issues模板。其中的json代码块前面的反斜杠记得删去。此处这么写主要是为了转义，否则无法嵌套代码块。---name: 友链模板about: 请根据指示规范填写友链格式。---&lt;!-- 请在下方代码块的双引号中填写 --&gt;\\```json&#123; &quot;title&quot;: &quot;&quot;, &quot;screenshot&quot;: &quot;&quot;, &quot;url&quot;: &quot;&quot;, &quot;avatar&quot;: &quot;&quot;, &quot;description&quot;: &quot;&quot;, &quot;keywords&quot;: &quot;&quot;&#125;\\```&lt;!--&quot;title&quot;: &quot;站点名称&quot;,&quot;screenshot&quot;: &quot;站点预览图链接&quot;,&quot;url&quot;: &quot;站点链接&quot;,&quot;avatar&quot;: &quot;头像链接&quot;,&quot;description&quot;: &quot;站点描述&quot;,&quot;keywords&quot;: &quot;关键词，作为分组名&quot;--&gt;&lt;!-- 示例 --&gt;&lt;!--&quot;title&quot;: &quot;Akilarの糖果屋&quot;,&quot;screenshot&quot;: &quot;https://cdn.jsdelivr.net/gh/Akilarlxh/ScreenShot@gh-pages/akilar.top.jpg&quot;,&quot;url&quot;: &quot;https://akilar.top/&quot;,&quot;avatar&quot;: &quot;https://akilar.top/img/siteicon/favicon.png&quot;,&quot;description&quot;: &quot;期待您的光临！&quot;,&quot;keywords&quot;: &quot;糖果屋&quot;--&gt;新建active label提交示例从审核通过到页面读取有一段api的缓存期，稍微有点耐心。 Gitee仓库配置方案 新建一个仓库，仓库名随意，这里我命名为friend_link, 新建文件friend_link\\.gitee\\ISSUE_TEMPLATE.md, 并在其中输入以下内容作为issues模板。其中的json代码块前面的反斜杠记得删去。此处这么写主要是为了转义，否则无法嵌套代码块。---name: 友链模板about: 请根据指示规范填写友链格式。---&lt;!-- 请在下方代码块的双引号中填写 --&gt;\\```json&#123; &quot;title&quot;: &quot;&quot;, &quot;screenshot&quot;: &quot;&quot;, &quot;url&quot;: &quot;&quot;, &quot;avatar&quot;: &quot;&quot;, &quot;description&quot;: &quot;&quot;, &quot;keywords&quot;: &quot;&quot;&#125;\\```&lt;!--&quot;title&quot;: &quot;站点名称&quot;,&quot;screenshot&quot;: &quot;站点预览图链接&quot;,&quot;url&quot;: &quot;站点链接&quot;,&quot;avatar&quot;: &quot;头像链接&quot;,&quot;description&quot;: &quot;站点描述&quot;,&quot;keywords&quot;: &quot;关键词，作为分组名&quot;--&gt;&lt;!-- 示例 --&gt;&lt;!--&quot;title&quot;: &quot;Akilarの糖果屋&quot;,&quot;screenshot&quot;: &quot;https://cdn.jsdelivr.net/gh/Akilarlxh/ScreenShot@gh-pages/akilar.top.jpg&quot;,&quot;url&quot;: &quot;https://akilar.top/&quot;,&quot;avatar&quot;: &quot;https://akilar.top/img/siteicon/favicon.png&quot;,&quot;description&quot;: &quot;期待您的光临！&quot;,&quot;keywords&quot;: &quot;糖果屋&quot;--&gt;新建active标签提交示例从审核通过到页面读取有一段api的缓存期，稍微有点耐心。 时间轴标签timeline渲染 对应的仓库issues链接: xaoxuu&#x2F;timeline, 网站卡片标签sites渲染 gitee仓库示例 对应的仓库issues链接: xaoxuu&#x2F;friends, 渲染后的标签： github仓库示例 对应的仓库issues链接: xaoxuu&#x2F;friends, 渲染后的标签： 网站卡片标签sites分组渲染 这是Volantis主题官网的「示例博客」页面的数据： 对应的仓库issues链接: 如何参与项目, 渲染后的标签： 时间轴标签timeline渲染 &#123;% issues timeline | api=https://gitee.com/api/v5/repos/xaoxuu/timeline/issues?state=open&amp;creator=xaoxuu&amp;sort=created&amp;direction=desc&amp;page=1&amp;per_page=100 %&#125; 网站卡片标签sites渲染 gitee仓库示例 &#123;% issues sites | api=https://gitee.com/api/v5/repos/xaoxuu/friends/issues?sort=updated&amp;state=open&amp;page=1&amp;per_page=100&amp;labels=active %&#125; github仓库示例 &#123;% issues sites | api=https://api.github.com/repos/xaoxuu/friends/issues?sort=updated&amp;state=open&amp;page=1&amp;per_page=100&amp;labels=active %&#125; 网站卡片标签sites分组渲染 这是Volantis主题官网的「示例博客」页面的数据： &#123;% issues sites | api=https://api.github.com/repos/volantis-x/examples/issues?sort=updated&amp;state=open&amp;page=1&amp;per_page=100 | group=version:版本：^4.0,版本：^3.0,版本：^2.0 %&#125; 诗词标签 poem标签语法参数配置样式预览示例源码&#123;% poem [title],[author] %&#125;诗词内容&#123;% endpoem %&#125; title：诗词标题 author：作者，可以不写 水调歌头苏轼明月几时有？把酒问青天。不知天上宫阙，今夕是何年？我欲乘风归去，又恐琼楼玉宇，高处不胜寒。起舞弄清影，何似在人间？转朱阁，低绮户，照无眠。不应有恨，何事长向别时圆？人有悲欢离合，月有阴晴圆缺，此事古难全。但愿人长久，千里共婵娟。 &#123;% poem 水调歌头,苏轼 %&#125;丙辰中秋，欢饮达旦，大醉，作此篇，兼怀子由。明月几时有？把酒问青天。不知天上宫阙，今夕是何年？我欲乘风归去，又恐琼楼玉宇，高处不胜寒。起舞弄清影，何似在人间？转朱阁，低绮户，照无眠。不应有恨，何事长向别时圆？人有悲欢离合，月有阴晴圆缺，此事古难全。但愿人长久，千里共婵娟。&#123;% endpoem %&#125; 阿里图标 icon本标签的图标需要自己额外引入阿里矢量图标库的样式，具体引入方案请移步：Hexo引入阿里矢量图标库 标签语法参数释义样式预览示例源码&#123;% icon [icon-xxxx],[font-size] %&#125; icon-xxxx：表示图标font-class,可以在自己的阿里矢量图标库项目的font-class引用方案内查询并复制。 font-size：表示图标大小，直接填写数字即可，单位为em。图标大小默认值为1em。 &#123;% icon icon-rat_zi %&#125;&#123;% icon icon-rat,2 %&#125;&#123;% icon icon-ox_chou,3 %&#125;&#123;% icon icon-ox,4 %&#125;&#123;% icon icon-tiger_yin,5 %&#125;&#123;% icon icon-tiger,6 %&#125;&#123;% icon icon-rabbit_mao,1 %&#125;&#123;% icon icon-rabbit,2 %&#125;&#123;% icon icon-dragon_chen,3 %&#125;&#123;% icon icon-dragon,4 %&#125;&#123;% icon icon-snake_si,5 %&#125;&#123;% icon icon-snake,6 %&#125;&#123;% icon icon-horse_wu %&#125;&#123;% icon icon-horse,2 %&#125;&#123;% icon icon-goat_wei,3 %&#125;&#123;% icon icon-goat,4 %&#125;&#123;% icon icon-monkey_shen,5 %&#125;&#123;% icon icon-monkey,6 %&#125;&#123;% icon icon-rooster_you %&#125;&#123;% icon icon-rooster,2 %&#125;&#123;% icon icon-dog_xu,3 %&#125;&#123;% icon icon-dog,4 %&#125;&#123;% icon icon-boar_hai,5 %&#125;&#123;% icon icon-boar,6 %&#125; 特效标签wow特效标签的静态资源未添加在本帖的配置内容中（因为多为cdn配置），请移步相关教程完成相关配置：使用wowjs给博客添加动画效果, 标签语法参数配置样式预览示例源码&#123;% wow [animete],[duration],[delay],[offset],[iteration] %&#125;内容&#123;% endwow %&#125; animate: 动画样式，效果详见animate.css参考文档 duration: 选填项，动画持续时间，单位可以是ms也可以是s。例如3s，700ms。 delay: 选填项，动画开始的延迟时间，单位可以是ms也可以是s。例如3s，700ms。 offset: 选填项，开始动画的距离（相对浏览器底部） iteration: 选填项，动画重复的次数 注意，后面四个虽然是选填项，但是当有跨位选填时，次序不能乱。详见示例。支持嵌套其他外挂标签。 flip动画效果。 &lt;div class=&quot;note green icon modern&quot;&gt;&lt;i class=&quot;note-icon fas fa-fan&quot;&gt;&lt;/i&gt;&lt;p&gt;&lt;code&gt;flip&lt;/code&gt;动画效果。&lt;/p&gt; &lt;/div&gt; zoomIn动画效果，持续5s，延时5s，离底部100距离时启动，重复10次。 &lt;div class=&quot;note blue icon modern&quot;&gt;&lt;i class=&quot;note-icon fas fa-bullhorn&quot;&gt;&lt;/i&gt;&lt;p&gt;&lt;code&gt;zoomIn&lt;/code&gt;动画效果，持续&lt;code&gt;5s&lt;/code&gt;，延时&lt;code&gt;5s&lt;/code&gt;，离底部&lt;code&gt;100&lt;/code&gt;距离时启动，重复&lt;code&gt;10&lt;/code&gt;次&lt;/p&gt; &lt;/div&gt; slideInRight动画效果，持续5s，延时5s。 &lt;div class=&quot;note orange icon modern&quot;&gt;&lt;i class=&quot;note-icon fas fa-car&quot;&gt;&lt;/i&gt;&lt;p&gt;&lt;code&gt;slideInRight&lt;/code&gt;动画效果，持续&lt;code&gt;5s&lt;/code&gt;，延时&lt;code&gt;5s&lt;/code&gt;。&lt;/p&gt; &lt;/div&gt; heartBeat动画效果，延时5s，重复10次。 &lt;div class=&quot;note red icon modern&quot;&gt;&lt;i class=&quot;note-icon fas fa-battery-half&quot;&gt;&lt;/i&gt;&lt;p&gt;&lt;code&gt;heartBeat&lt;/code&gt;动画效果，延时&lt;code&gt;5s&lt;/code&gt;，重复&lt;code&gt;10&lt;/code&gt;次。&lt;/p&gt; &lt;/div&gt; flip动画效果。&#123;% wow animate__flip %&#125;&#123;% note green &#x27;fas fa-fan&#x27; modern%&#125;`flip`动画效果。&#123;% endnote %&#125;&#123;% endwow %&#125; zoomIn动画效果，持续5s，延时5s，离底部100距离时启动，重复10次。&#123;% wow animate__zoomIn,5s,5s,100,10 %&#125;&#123;% note blue &#x27;fas fa-bullhorn&#x27; modern%&#125;`zoomIn`动画效果，持续`5s`，延时`5s`，离底部`100`距离时启动，重复`10`次&#123;% endnote %&#125;&#123;% endwow %&#125; slideInRight动画效果，持续5s，延时5s。&#123;% wow animate__slideInRight,5s,5s %&#125;&#123;% note orange &#x27;fas fa-car&#x27; modern%&#125;`slideInRight`动画效果，持续`5s`，延时`5s`。&#123;% endnote %&#125;&#123;% endwow %&#125; heartBeat动画效果，延时5s，重复10次。此处注意不用的参数位置要留空，用逗号间隔。&#123;% wow animate__heartBeat,,5s,,10 %&#125;&#123;% note red &#x27;fas fa-battery-half&#x27; modern%&#125;`heartBeat`动画效果，延时`5s`，重复`10`次。&#123;% endnote %&#125;&#123;% endwow %&#125; 进度条 progress进度条标签参考沂佰孜猫-给HEXO文章添加彩色进度条。源样式提取自Cuteen主题。 标签语法参数配置样式预览示例源码&#123;% progress [width] [color] [text] %&#125;width: 0到100的阿拉伯数字color: 颜色，取值有red,yellow,green,cyan,blue,graytext:进度条上的文字内容进度条样式预览 进度条样式预览 进度条样式预览 进度条样式预览 进度条样式预览 进度条样式预览&#123;% progress 10 red 进度条样式预览 %&#125;&#123;% progress 30 yellow 进度条样式预览 %&#125;&#123;% progress 50 green 进度条样式预览 %&#125;&#123;% progress 70 cyan 进度条样式预览 %&#125;&#123;% progress 90 blue 进度条样式预览 %&#125;&#123;% progress 100 gray 进度条样式预览 %&#125; 注释 notation标签语法参数配置样式预览示例源码&#123;% nota [label] , [text] %&#125;label: 注释词汇text: 悬停显示的注解内容本博客未适配~~&#123;% nota 把鼠标移动到我上面试试 ,可以看到注解内容出现在顶栏 %&#125;","categories":[{"name":"转载","slug":"转载","permalink":"https://dummerfu.top/categories/%E8%BD%AC%E8%BD%BD/"}],"tags":[{"name":"转载","slug":"转载","permalink":"https://dummerfu.top/tags/%E8%BD%AC%E8%BD%BD/"}],"keywords":[{"name":"转载","slug":"转载","permalink":"https://dummerfu.top/categories/%E8%BD%AC%E8%BD%BD/"}]},{"title":"【数模】从入门到入土","slug":"数模培训","date":"2021-07-07T00:00:00.000Z","updated":"2021-07-15T00:00:00.000Z","comments":true,"path":"p/50102.html","link":"","permalink":"https://dummerfu.top/p/50102.html","excerpt":"","text":"第一讲 模糊数学聚类基础练习 1题目思路CODE更普遍性的解肯定不能通过线性相关性来判定，思考模糊聚类。 ​ 通过题目数据可以得到一个矩阵方程组。常规归一化就有一个模糊矩阵，然后再通过格贴近度得到模糊相似矩阵，最后计算传递闭包求得模糊等价矩阵从而推出聚类关系。即可判断哪些气象站差别不大可删去。 PS: 模糊相似矩阵可以通过多种方法求得，不细讲了，通常有： 指数相似度法 最大值最小法 几何平均法 绝对值倒数法 数量积法 夹角余弦法 相关系数法 一般越复杂越nbimport numpy as npimport matplotlib as mplfrom matplotlib import pyplot as pltfrom mpl_toolkits.mplot3d import Axes3Dfrom matplotlib import cmmpl.rcParams[&#x27;font.sans-serif&#x27;] = &#x27;SimHei&#x27;mpl.rcParams[&#x27;axes.unicode_minus&#x27;] = Falsedef data_process(): a = &#x27;276.2 324.5 158.6 412.5 292.8 258.4 334.1 303.2 292.9 243.2 159.7 331.2 \\251.5 287.3 349.5 297.4 227.8 453.6 321.5 451.0 466.2 307.5 421.1 455.1 \\192.7 433.2 289.9 366.3 466.2 239.1 357.4 219.7 245.7 411.1 357.0 353.2 \\246.2 232.4 243.7 372.5 460.4 158.9 298.7 314.5 256.6 327.0 296.5 423.0 \\291.7 311.0 502.4 254.0 245.6 324.8 401.0 266.5 251.3 289.9 255.4 362.1 \\466.5 158.9 223.5 425.1 251.4 321.0 315.4 317.4 246.2 277.5 304.2 410.7 \\258.6 327.4 432.1 403.9 256.6 282.9 389.7 413.2 466.5 199.3 282.1 387.6 \\453.4 365.5 357.6 258.1 278.8 467.2 355.2 228.5 453.6 315.6 456.3 407.2 \\158.2 271.0 410.2 344.2 250.0 360.7 376.4 179.4 159.2 342.4 331.2 377.7 \\324.8 406.5 235.7 288.8 192.6 284.9 290.5 343.7 283.4 281.2 243.7 411.1&#x27; temp = a.replace(&#x27; &#x27;, &#x27;,&#x27;) a = np.array(eval(temp)) a = a.reshape((10, 12)) return adef get_mean_var(matrix): matrix_mean = np.mean(matrix, axis=0) matrix_b = [] for i in range(len(matrix_mean)): temp = (matrix[:, i] - matrix_mean[i]) matrix_b.append(np.round(np.sqrt(sum(np.multiply(temp, temp))) / 3, 2)) return matrix_mean,matrix_bdef muti(a:np.array): x,y=a.shape R=[] for i in range(x): temp=[] for j in range(y): m=np.fmin(a[i,:],a[:,j]) temp.append(np.max(m)) R.append(temp) return np.array(R)def get_R(a:np.array,b:np.array): &#x27;&#x27;&#x27; :param matrix: :param a: mean :param b: var :return: R 模糊等价矩阵 &#x27;&#x27;&#x27; x,y=len(a),len(b) R=[] for i in range(x): temp=[] for j in range(y): temp.append(np.round(np.exp(-((a[j]-a[i])/(b[i]+b[j]))**2),3)) R.append(temp) R=np.array(R) # print(R) # print(muti(R)) t_R=muti(muti(R)) print(t_R) # 发现R^4 =R^8 R^4 是传递闭包,也可以写个循环判断 return t_Rif __name__ == &#x27;__main__&#x27;: # temp=np.load(&#x27;./bingcha.npy&#x27;,allow_pickle=True) # print(temp) matrix=data_process() matrix_mean,matrix_var=get_mean_var(matrix) R=get_R(a=matrix_mean,b=matrix_var) 并查集优化结果： class Unit_find(object): def __init__(self,matrix): self.matrix=copy.deepcopy(matrix) self.x, self.y = matrix.shape self.fa=[i for i in range(self.x)] self.f=[[] for i in range(self.x)] def build(self,l): x,y=self.matrix.shape for i in range(x): for j in range(y): if i&gt;j: continue if self.matrix[i,j]&gt;l: self.matrix[i,j]=1 self.f[i].append(j) self.f[j].append(i) else: self.matrix[i,j]=0 return def find(self,x): if self.fa[x]==x: return x self.fa[x]=self.find(self.fa[x]) return self.fa[x] def solve(self): for i in range(self.x): for j in self.f[i]: r1=self.find(i) r2=self.find(j) if r1!=r2: self.fa[r1]=r2 return# 配合上面的代码,输出每个点的father（0开始编号uf=Unit_find(R)prinf(uf.fa) 第二讲 排队论练习题目题解​ 某店有一个修理工人，顾客到达过程为Poisson流，平均每小时3人，修理时间服从负指数分布，平均需10分钟，求： 店内空闲的时间； 有4个顾客的概率； 至少有一个顾客的概率； 店内顾客的平均数； 等待服务的顾客数； 平均等待修理的时间； 一个顾客在店内逗留时间超过15分钟的概率 啥也不会，跟着zzy抄就完事了 此题满足排队论里的 $M|M|1|\\infty|\\infty$模型 \\lambda=3 ,\\mu=60/10=6, \\rho=\\frac{\\lambda}{\\mu}=0.5 店里空闲时间$P_0=0.05$ 四个顾客概率$p_4=\\rho^4(1-\\rho)=0.5^5$ 至少有一个顾客的概率$p_{n\\geq1}=1-p_0=0.95$ 店内顾客平均人数$L_s=\\frac{\\lambda}{\\mu-\\lambda}=1$ 等候服务顾客人数$L_q=L_s-(1-p_0)=0.05$ 第三、四讲 简单图论练习题目思路CODE题意有点奇怪，理解有两种题意： 疑问：因为有4-5年的维修费意思是买来就要付第一年的维修费？黑心 题意1：维修费与机器使用时间有关，逐年递增比如维修三年需要（5+6+8）。 题意2：维修费用和机器使用时间无关，只与每年行情有关，第一年买的机器和第四年买的机器都只需要18的维修费。 如果题意1：可以从当前点向前分别连接5条边，权值分别为 [5,11,19,30,48] ，然后逐年连 [11,11,12,12,13]的边权，建图跑1-5的最短路就行了。 如果题意2：感觉和最短路没什么关系了，直接贪心？因为要求是用最短路解决，所以我默认是题意1 from queue import PriorityQueueinf =0x3f3f3f3fclass Pair(object): def __init__(self,node,dis): self.node=node self.dis=dis def __lt__(self, other): return self.dis&lt;other.disclass Dij(object): def __init__(self,num): self.num=num self.f=[[] for i in range(num)] self.dis=[inf for i in range(num)] self.use=[False for i in range(num)] def build(self,a,b): for i in range(self.num): for j in range(len(a)): if i+j+1&gt;5: continue self.f[i].append((i+j+1,a[i]+b[j])) def solve(self,qx,zx): q=PriorityQueue() q.put(Pair(qx,0)) self.dis[qx]=0 while not q.empty(): # get 会自动remove temp=q.get() if self.use[temp.node]: continue self.use[temp.node]=True for i in self.f[temp.node]: if self.dis[i[0]]&gt;self.dis[temp.node]+i[1]: self.dis[i[0]]=self.dis[temp.node]+i[1] q.put(Pair(i[0],self.dis[i[0]])) ans=self.dis[zx] return ansa=[11,11,12,12,13]b=[5,11,19,30,48]dij=Dij(6)dij.build(a,b)print(dij.solve(0,5))print(dij.dis) 第五讲 方差分析练习 1题目思路CODE就是一个显著性检验，SPSS分析就完事了。概率论全忘光， 第六讲 机器学习​ ppt乱死了，也没看到他有作业 😥。 第七讲 整数规划练习 1题目思路CODEimport numpy as npimport geatpy as eafrom geatpy import Problem, crtfld, Populationclass LX1(Problem): # 继承Problem父类 def __init__(self): name = &#x27;练习&#x27; # 初始化name（函数名称，可以随意设置） M = 1 # 初始化M（目标维数） maxormins = [-1] # 初始化maxormins（目标最小最大化标记列表，1：最小化该目标；-1：最大化该目标） self.Dim = 12 # 初始化Dim（决策变量维数） varTypes = [1] * self.Dim # 初始化varTypes（决策变量的类型，0：实数；1：整数） lb = [0]*self.Dim # 决策变量下界 ub = [120]*3+[1]*9 # 决策变量上界 lbin = [1] * self.Dim # 决策变量下边界（0表示不包含该变量的下边界，1表示包含） ubin = [1] * self.Dim # 决策变量上边界（0表示不包含该变量的上边界，1表示包含） # 调用父类构造方法完成实例化 Problem.__init__(self, name, M, maxormins, self.Dim, varTypes, lb, ub, lbin, ubin) def aimFunc(self, pop): # 目标函数 Vars = pop.Phen # 得到决策变量矩阵 # 行向量 x=[Vars[:, [i]] for i in range(self.Dim)] f = (12-10*x[3]-9*x[4]-8*x[5]-7*x[6])*x[0]+(7-6*x[7]-4*x[8]-3*x[9])*x[1]+(6-5*x[10]-4*x[11])*x[2] pop.ObjV = f # 把结果赋值给ObjV # 小于等于等式或不等式约束 M=0x3f3f3f3f pop.CV = np.hstack([ x[0] + 2 * x[1] + x[2]-100, 10 * x[0] + 4 * x[1] + 5 * x[2]-700, 3 * x[0] + 2 * x[1] + x[2]-400, x[3] + x[4] + x[5] + x[6]-1, x[7] + x[8] + x[9]-1, x[10] + x[11]-1, -(40 + M * (1 - x[3]) - x[0]), 41 - M * (1 - x[4])-x[0], -(100 + M * (1 - x[4])-x[0]), x[1]-50 -M * (1 - x[7]), x[2]-100 -M * (1 - x[10]), ])if __name__ == &#x27;__main__&#x27;: problem = LX1() NIND = 40 Encoding = &#x27;RI&#x27; Field = ea.crtfld(Encoding, problem.varTypes, problem.ranges, problem.borders) # 创建区域描述器 population = ea.Population(Encoding, Field, NIND) myAlgorithm = ea.soea_DE_rand_1_L_templet(problem, population) # 实例化一个算法模板对象 myAlgorithm.MAXGEN = 1e11 # 最大进化代数 myAlgorithm.mutOper.F = 0.5 # 差分进化中的参数F myAlgorithm.recOper.XOVR = 0.2 # 重组概率 myAlgorithm.trappedValue = 1e-6 # “进化停滞”判断阈值 myAlgorithm.maxTrappedCount = 1000 # 进化停滞计数器最大上限值，如果连续maxTrappedCount代被判定进化陷入停滞，则终止进化 myAlgorithm.logTras = 0 # 设置每隔多少代记录日志，若设置成0则表示不记录日志 myAlgorithm.verbose = True # 设置是否打印输出日志信息 myAlgorithm.drawing = 1 # 设置绘图方式（0：不绘图；1：绘制结果图；2：绘制目标空间过程动画；3：绘制决策空间过程动画） &quot;&quot;&quot;===========================调用算法模板进行种群进化=======================&quot;&quot;&quot; [BestIndi, population] = myAlgorithm.run() # 执行算法模板，得到最优个体以及最后一代种群 BestIndi.save() # 把最优个体的信息保存到文件中 &quot;&quot;&quot;==================================输出结果==============================&quot;&quot;&quot; print(&#x27;用时：%f 秒&#x27; % myAlgorithm.passTime) print(&#x27;评价次数：%d 次&#x27; % myAlgorithm.evalsNum) if BestIndi.sizes != 0: print(&#x27;最优的目标函数值为：%s&#x27; % BestIndi.ObjV[0][0]) print(&#x27;最优的控制变量值为：&#x27;) for i in range(BestIndi.Phen.shape[1]): print(BestIndi.Phen[0, i]) else: print(&#x27;没找到可行解。&#x27;) # 877# [62 19 0]# [0 0 0 0 0 0 0 0 0] 练习 2题目思路CODE 方便起见都设为1好了，就是一个整数01线性规划。import numpy as npfrom pulp import *x=[[LpVariable(&#x27;x&#x27;+str(i)+str(j),cat=LpInteger,lowBound=0,upBound=None) for j in range(1,5)] for i in range(1,4)]y=[LpVariable(&#x27;y&#x27;+str(i),cat=LpBinary) for i in range(1,4)]c=[[1 for j in range(1,5)] for i in range(1,4) ]d=[1 for i in range(1,5)]k=p=A=[1 for i in range(1,4)]pro=LpProblem(&#x27;练习 2&#x27;,LpMinimize)sub1=sub2=sub3=Nonefor i in range(3): sub1+=k[i]*y[i] for j in range(4): sub2+=c[i][j]*x[i][j] sub3+=p[i]*x[i][j]pro+=0.1*sub1+sub2+sub3pro+= x[0][0]+x[1][0]&gt;=d[0]pro+= x[0][1]+x[1][1]+x[2][1]&gt;=d[1]pro+= x[1][1]+x[2][2]&gt;=d[2]pro+= x[0][3]+x[1][3]+x[2][3]&gt;=d[3]pro+= x[0][0]+x[0][1]+x[0][3]&lt;=A[0]*y[0]pro+= x[1][0]+x[1][1]+x[1][2]+x[1][3]&lt;=A[1]*y[1]pro+= x[2][1]+x[2][2]+x[2][3]&lt;=A[2]*y[2]pro.solve()s=[]print(&#x27;status&#x27;,LpStatus[pro.status])for v in pro.variables(): print(v.name, &quot;=&quot;, v.varValue) s.append(v.varValue)print(&quot;objective=&quot;, value(pro.objective)) 第八讲 BP神经网络无作业 撞专业了导致看ppt有莫名的感觉 😒 第九讲 多目标优化多目标优化的性能度量标准： 必须收敛到pareto 优解集 pareto优解集的均匀性和稳定性 C-度量方法D-度量方法​ 反映了一个算法得到的最优解被另一个算法得到的最优解支配的比例。设 A 和 B 分别是算法 A 和算法 B 得到的非支配解集或 Pareto 最优解集: C(A,B)=\\frac{|\\{b\\in B | \\exist \\ a\\in A, a \\ covers \\ b\\}|}{|B|}其中 |B|表示集合 B中的元素个数，a covers b表示a支配b或a与b同样好。 若C(A,B)&gt;C(B,A)，则算法 A 求得的 Pareto 最优解集优于算法 B 求得的 Pareto 最优解集。​ 为测量 A 的均匀性和宽广性，设 $P^\\star$是Pareto 前沿面上均匀分布的一组解，$P^\\star$到 A的平均距离定义为： D(A,P^\\star)=\\frac{\\sum_{v\\in P^\\star} d(v,A)}{|P^\\star|}d(v,A)表示v与A中的点的最小欧式距离， $D(A,P^\\star)$越小，说明A 越接近 Pareto 前沿面 练习 1遗传算法yyds 题目思路CODE设生产$x_0$,$x_1$个A，B型号润滑油，分别加工生产$x_3$，$ x_4$个A，B型号润滑油，观察题目数据，发现必须会有加工生产。 \\begin{cases} F=min (3x_0+2x_1,-100x_0-90x_2-80x_1-70x_3) \\\\ 3x_0+2x_1=30\\\\ x_i>=0 \\quad i\\in [0,4] \\end{cases}这里使用的是Geatpy库实现，不同库的对比可以参考这篇知乎自行选择 import numpy as npimport geatpy as eafrom geatpy import Problem,crtfld,Populationclass LX1(Problem): # 继承Problem父类 def __init__(self): name = &#x27;练习 1&#x27; # 初始化name（函数名称，可以随意设置） M = 2 # 初始化M（目标维数） maxormins = [1,-1] # 初始化maxormins（目标最小最大化标记列表，1：最小化该目标；-1：最大化该目标） Dim = 4 # 初始化Dim（决策变量维数） varTypes = [1] * Dim # 初始化varTypes（决策变量的类型，0：实数；1：整数） lb = [0] * Dim # 决策变量下界 ub = [60] * Dim # 决策变量上界 lbin = [1] * Dim # 决策变量下边界（0表示不包含该变量的下边界，1表示包含） ubin = [1] * Dim # 决策变量上边界（0表示不包含该变量的上边界，1表示包含） # 调用父类构造方法完成实例化 Problem.__init__(self, name, M, maxormins, Dim, varTypes, lb, ub, lbin, ubin) def aimFunc(self, pop): # 目标函数 Vars = pop.Phen # 得到决策变量矩阵 # 行向量 x0,x1,x2,x3 = Vars[:, 0],Vars[:,1],Vars[:,2],Vars[:,3] f = 3*x0+2*x1 g = 100*x0+90*x2+80*x1+70*x3 pop.ObjV = np.array([f, g]).T # 把结果赋值给ObjV # 小于等于等式或不等式约束 pop.CV=np.vstack([ 3*x0+2*x1-120, 3*x2+2*x3-48, 30-x1-x3, 30-x0-x2 ]).Tif __name__ == &#x27;__main__&#x27;: problem=LX1() NIND=40 Encoding=&#x27;RI&#x27; Field=ea.crtfld(Encoding, problem.varTypes, problem.ranges, problem.borders) # 创建区域描述器 population=ea.Population(Encoding,Field,NIND) myalgorithm=ea.moea_NSGA2_templet(problem,population) myalgorithm.MAXGEN = 100 # 最大进化代数 myalgorithm.logTras = 0 # 设置每多少代记录日志，若设置成0则表示不记录日志 myalgorithm.verbose = True # 设置是否打印输出日志信息 myalgorithm.drawing = 1 # 设置绘图方式（0：不绘图；1：绘制结果图；2：绘制目标空间过程动画；3：绘制决策空间过程动画） &quot;&quot;&quot;==========================调用算法模板进行种群进化========================= 调用run执行算法模板，得到帕累托最优解集NDSet以及最后一代种群。NDSet是一个种群类Population的对象。 NDSet.ObjV为最优解个体的目标函数值；NDSet.Phen为对应的决策变量值。 详见Population.py中关于种群类的定义。 &quot;&quot;&quot; [NDSet, population] = myalgorithm.run() # 执行算法模板，得到非支配种群以及最后一代种群 NDSet.save() # 把非支配种群的信息保存到文件中 print(&#x27;用时：%f 秒&#x27; % myalgorithm.passTime) print(NDSet.sizes) 练习 2题目思路CODE由题意可建得以下模型： \\begin{cases} f_1=max(10*x_a+20*x_b+12*x_c+14*x_d) \\\\ f2=min(0.015*x_a+0.02*x_b+0.018*x_c+0.011*x_d\\\\\\\\ 0.015x_a+0.02*x_b+0.018*x_c+0.011*x_d\\leq20 \\\\ 40*300\\leq 13*x_a+13.5*x_b+14*x_c+11.5*x_d\\leq 48*300\\\\\\\\ x_a\\in[0,270],x_b\\in[0,240],x_c\\in[150,460],x_d\\in[0,130] \\end{cases}import numpy as npimport geatpy as eafrom geatpy import Problem, crtfld, Populationclass LX1(Problem): # 继承Problem父类 def __init__(self): name = &#x27;练习 1&#x27; # 初始化name（函数名称，可以随意设置） M = 2 # 初始化M（目标维数） maxormins = [-1, 1] # 初始化maxormins（目标最小最大化标记列表，1：最小化该目标；-1：最大化该目标） Dim = 4 # 初始化Dim（决策变量维数） varTypes = [0] * Dim # 初始化varTypes（决策变量的类型，0：实数；1：整数） lb = [0,0,150,0] # 决策变量下界 ub = [270,240,460,130] # 决策变量上界 lbin = [1] * Dim # 决策变量下边界（0表示不包含该变量的下边界，1表示包含） ubin = [1] * Dim # 决策变量上边界（0表示不包含该变量的上边界，1表示包含） # 调用父类构造方法完成实例化 Problem.__init__(self, name, M, maxormins, Dim, varTypes, lb, ub, lbin, ubin) def aimFunc(self, pop): # 目标函数 Vars = pop.Phen # 得到决策变量矩阵 # 行向量 xa, xb, xc, xd = Vars[:, [0]], Vars[:, [1]], Vars[:, [2]], Vars[:, [3]] f1 = 10*xa+20*xb+12*xc+14*xd f2 = 0.015*xa+0.02*xb+0.018*xc+0.011*xd # 只要求目标函数shape要为 [xx，M]，前面随便弄 pop.ObjV = np.hstack([f1, f2]) # 把结果赋值给ObjV # 小于等于等式或不等式约束 pop.CV = np.hstack([ 0.015*xa+0.02*xb+0.018*xc+0.011*xd-20, 13*xa+13.5*xb+14*xc+11.5*xd-48*300, -(13*xa+13.5*xb+14*xc+11.5*xd-40*300) ])if __name__ == &#x27;__main__&#x27;: problem = LX1() NIND = 40 Encoding = &#x27;RI&#x27; Field = ea.crtfld(Encoding, problem.varTypes, problem.ranges, problem.borders) # 创建区域描述器 population = ea.Population(Encoding, Field, NIND) myalgorithm = ea.moea_NSGA2_templet(problem, population) myalgorithm.MAXGEN = 100 # 最大进化代数 myalgorithm.logTras = 0 # 设置每多少代记录日志，若设置成0则表示不记录日志 myalgorithm.verbose = True # 设置是否打印输出日志信息 myalgorithm.drawing = 1 # 设置绘图方式（0：不绘图；1：绘制结果图；2：绘制目标空间过程动画；3：绘制决策空间过程动画） &quot;&quot;&quot;==========================调用算法模板进行种群进化========================= 调用run执行算法模板，得到帕累托最优解集NDSet以及最后一代种群。NDSet是一个种群类Population的对象。 NDSet.ObjV为最优解个体的目标函数值；NDSet.Phen为对应的决策变量值。 详见Population.py中关于种群类的定义。 &quot;&quot;&quot; [NDSet, population] = myalgorithm.run() # 执行算法模板，得到非支配种群以及最后一代种群 NDSet.save(&#x27;solve1&#x27;) # 把非支配种群的信息保存到文件中 print(&#x27;用时：%f 秒&#x27; % myalgorithm.passTime) print(NDSet.sizes) 第十讲 过程预测与优化好家伙，全英文ppt，头看掉了 第十一讲 时间序列分析似乎没有作业，全程讲课 时间序列的学习我之前写过这一篇 第十二讲 马氏链模型练习题目思路每天的状态转移规律 X_{n+1}=\\begin{cases} X_n-D_{n+1} &&X_n-D_{n+1}>s\\\\ S && X_n-D_{n+1}","categories":[{"name":"技术","slug":"技术","permalink":"https://dummerfu.top/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"数模","slug":"数模","permalink":"https://dummerfu.top/tags/%E6%95%B0%E6%A8%A1/"}],"keywords":[{"name":"技术","slug":"技术","permalink":"https://dummerfu.top/categories/%E6%8A%80%E6%9C%AF/"}]},{"title":"Git Action 自动部署hexo","slug":"Git action自动部署hexo","date":"2021-07-04T00:00:00.000Z","updated":"2021-07-04T00:00:00.000Z","comments":true,"path":"p/15888.html","link":"","permalink":"https://dummerfu.top/p/15888.html","excerpt":"","text":"痛点日常水字数 hexo部署之后总是会觉得每次写完要一键三连比较麻烦，特别是文章写多了后generate会很慢，这个时候要是有个能写完文章或者push后自动一键三连岂不美哉？ 在git action出来之前，网上有这种脚本，什么加alias，监听deploy啊，但是这些还是会在自己本地上显示generate出来的东西影响观感~~ 下面简单介绍一下Git Action和我踩的坑，（没想到时隔半年，我居然会又部署一遍这个… 正文Git Action实现准备密匙在根目录下面.ssh里面生成一对名为github-action-deploy的密匙（公匙后缀为pub ssh-keygen -t rsa -b 4096 -f ~/.ssh/github-actions-deploy 在github主页面的 Settings-&gt;SSH and GPG keys添加刚刚生成的公钥，名称随意。 在blog仓库的Settings-&gt;Secrets里添加刚刚生成的私钥，名称为 ACTION_DEPLOY_KEY 这个一定要一样，不想后面直接复制yml文件后出问题萌新就不要名字了。 配置hexo# Deployment# Docs: https://hexo.io/docs/deployment.html# 目前不清楚第一个deploy有什么用，下面那样也行deploy:- type: git # 最好是git repo: git@github.com:xxxx.git # 使用仓库的ssh地址 branch: master # 分支名# backup# - type: git# repo: git@github.com:xxxx.git # 仓库地址# branch: 配置Git Action在配置私钥的仓库点击Action-&gt;new workflow 创建一个main.yml文件 name: Compile and Deploy to GitHub Pageon: push: branches: - master # 你的branch |一般是 masterjobs: build: runs-on: ubuntu-latest steps: - uses: actions/checkout@v1 - uses: actions/setup-node@v1 with: node-version: &#x27;13.x&#x27; #不同版本可能会有不兼容的npm包，后面会说坑 - name: Setup hexo env: # secrets选项中你配置私匙的名字，前面一样就不用改 ACTIONS_DEPLOY_KEY: $&#123;&#123; secrets.ACTIONS_DEPLOY_KEY &#125;&#125; run: | mkdir -p ~/.ssh/ echo &quot;$ACTIONS_DEPLOY_KEY&quot; &gt; ~/.ssh/id_rsa chmod 600 ~/.ssh/id_rsa ssh-keyscan github.com &gt;&gt; ~/.ssh/known_hosts git config --global user.email &quot;xxx&quot; # github邮箱 git config --global user.name &quot;xxx&quot; # github用户名 npm install hexo-cli -g npm install - name: Generate run: hexo clean &amp;&amp; hexo generate &amp;&amp; hexo deploy 坑点hexo-uitl之前Git Action用的好好的,换个主题突然就出bug了 这个错误很隐晦，表面上是这个highlight.js错误但是实际上是hexo-uitl不支持node12版本以下，这个在之前的setup hexo 里面有提到，因为不是error没有注意，弄我半天…也算是我水这篇博客的原因 在yml文件把node-version改高点就行了 弄我debug一天","categories":[{"name":"随笔","slug":"随笔","permalink":"https://dummerfu.top/categories/%E9%9A%8F%E7%AC%94/"}],"tags":[{"name":"主题美化","slug":"主题美化","permalink":"https://dummerfu.top/tags/%E4%B8%BB%E9%A2%98%E7%BE%8E%E5%8C%96/"}],"keywords":[{"name":"随笔","slug":"随笔","permalink":"https://dummerfu.top/categories/%E9%9A%8F%E7%AC%94/"}]},{"title":"内网穿透工具测评","slug":"内网穿透工具","date":"2021-06-15T00:00:00.000Z","updated":"2021-09-15T00:00:00.000Z","comments":true,"path":"p/23841.html","link":"","permalink":"https://dummerfu.top/p/23841.html","excerpt":"","text":"为什么要内网穿透​ 众所周知，不同网络下的电脑是无法访问别人本地ip挂载的web程序的，这就是因为内网（NAT）。 但是处于种种原因，比如你写了个程序想装逼又或你想挂载本地文件让他人访问下载又或想开个Minecraft服务器大家一起玩，这就需要一个人人都能访问的ip了（公网ip）。 ​ 我们通常是看不到这些ip且较难获得这种公网ip 这涉及到一系列知识就不细说了 但是有一些工具可以让我们不配置服务器和域名就可以较为简单的获得这种公网ip（域名映射后的）。 ​ 我找这种软件也找了不少，真正想完美白嫖还是挺困难的。（踩了许多广告坑，不能白踩，故在此记录 ​ 我包括但不仅限于下面几项来评测软件白嫖程度： 配置 带宽限制 流量限制 废话不多说，下面开始软件测评环节。绝对中立的评测，无恰饭（也没资本恰饭 常用工具ngrok|钉钉穿透这两个似乎是一个东西 出来的页面都一样，没怎么用不评判 花生壳全靠广告撑起来，本人没付费使用过，但是贵是确实 配置：无需配置，官网教程详细 这么贵还不详细谁会用啊 流量：有限，免费只有1G？ 带宽：1G带宽 协议：白嫖只有tcp 综合：白嫖不易，巨贵无比，学生党极不友好。 NATAPP 配置：简单易上手 流量：不限量 协议：tcp，http等都支持 带宽：免费只有1M带宽 综合：虽然不限量，只有1M带宽但是看情况还是可以用 Nat123 和 NetTunnel​ Net123不充值只能映射80端口，收费与花生壳相比还是便宜一点。页面还是上个年代的样子，丑不可言 NetTunnel就相对人性化，页面好看文档也全，和NetApp差不多，但是多了个客户端启动，带宽也还是1M。 FRP需要自带服务器等，不能白嫖，企业使用。 Zeroiter​ 知乎使用教程 ​ 私人用可以，是另类的内网穿透，是通过创建虚拟网卡，使安装这个软件的人可以加入到同一个局域网从而实现’’内网穿透’’效果，但是要至少两个设备。对于玩联机游戏等场景的十分好用 ​ 傻瓜安装操作，但是server端似乎需要fq，所以对于小白也不怎么好用。 Holoer 配置：难懂，未配置成功。 Sakura Frpnoionion推荐的，这么好的东西我都搜不到，看来我信息检索能力还有待提高 只能说完爆上面NatXX 配置：可以说是十分详细了，应该不会有人看不懂 流量：每天10G?,还有签到流量（上限100g）。 协议：tcp等都支持，而且支持自绑域名（绑域名太香了） 带宽：免费是限速10M，超流量后限速4M 还可以开机后台自启动：本地为服务器真的方便 吐槽：这页面做的和某机场一样让我第一眼还以为进错了网站， 首先这个不是完全白嫖，会有个需要1rmb的实名认证，实名认证之后才可以用。然后写着限速10M，但是我下载似乎是跑不满，可能是我自己的带宽不太够跑不满。这个你们可以自己测测。 总之还是非常好用的，毕竟只用1rmb就做到了常人难以做到的事滑稽。 不过注意一下，创建隧道时高级设置加密传输不能启用，启用就无法穿透成功。 NPS推荐的，功能是挺多的但是主要是应用场景与假设不符（因为还是需要一个公网ip udp，tcp，socket等主流协议都支持 什么都没有限制（毕竟是自己的服务器😀 总体感觉是大材小用了，更适合长期上线api等任务，因为主打穿透，功能也更全（vps要自己准备，如果上线web的话可以考虑 总结 白嫖无果 —- 相比之下NetApp和NetTunnel除了1M带宽还是好用的，学习或者测试web 1M带宽将就将就也还行。 微氪可以选择Sakura Frp，毕竟1rmb可以享受的权益和其他的相比确实挺多的，10M带宽还有待考量。 重氪玩家有硬需求还是买台服务器算了，自带公网ip，但是花生壳慎重。 日后还有什么好用的内网穿透工具还会再加的，大家有什么好用的也可以在评论区分享。 ​","categories":[{"name":"杂集","slug":"杂集","permalink":"https://dummerfu.top/categories/%E6%9D%82%E9%9B%86/"}],"tags":[{"name":"杂集","slug":"杂集","permalink":"https://dummerfu.top/tags/%E6%9D%82%E9%9B%86/"}],"keywords":[{"name":"杂集","slug":"杂集","permalink":"https://dummerfu.top/categories/%E6%9D%82%E9%9B%86/"}]},{"title":"Colab 实现本地连接","slug":"colab实现本地连接","date":"2021-06-01T00:00:00.000Z","updated":"2021-06-01T00:00:00.000Z","comments":true,"path":"p/64572.html","link":"","permalink":"https://dummerfu.top/p/64572.html","excerpt":"","text":"痛点​ 虽说colab可以挂载谷歌云，但是机器学习方面的数据集传输一直都是个麻烦事，更别说fq传网盘上了你上传速度快？那可以右上角了 ​ 再退一步，虽然可以共享文件，但是本地还是不能同步修改也算一个痛点，那么干脆直接将colab直接挂载在本地算了。然而看网上的奇淫技巧估计都是老博客了，也没有谈到这方面，所以干脆自己记录一下。 ​ ps: 似乎挂载本地就不能用colab的GPU了（虽然更改笔记本设置gpu还是会提示你重新连接，但是速度似乎是和本地一样快？）本地了个寂寞 安装依赖本实例都是在window环境下运行，未尝试linux 不多解释都学到用colab了别和我说还不会pip安装依赖 # 安装 安装jupyterpip install notebook# 启用jupyter_http_over_ws jupyter 扩展程序（连接到本地需要pip install jupyter_http_over_ws jupyter serverextension enable --py jupyter_http_over_ws# 启动jupyter 最后一行参数是为了挂载到本地后能打开自己的文件# 虽然缺乏安全性，但是是最快解决403的方法，有时间再找找其他替代方案jupyter notebook \\ --NotebookApp.allow_origin=&#x27;https://colab.research.google.com&#x27; \\ --port=8888 \\ --NotebookApp.port_retries=0 --NotebookApp.disable_check_xsrf=True 连接到本地直接点colab连接选择连接到本地然后就按照他的提示来就行了 注意挂载的目录是运行jupyter 里那个config.py里默认的目录 一点点优化先进入配置的jupyter_notebook_config.py文件 后面简称config文件 # 生成配置文件（有就不用生成了）jupyter notebook --generate-config# 进入上面显示的路径# 进入config.py 更换默认目录搜索 notebook_dir更改为自己的工作路径 c.Notebook_dir=&#x27;xxx&#x27; alias每次输入这么多参数多麻烦 搜索notebook.app，根据按照依赖里面的参数进行修改默认值，自己想改什么随便改不用按照我的来 # 我修改了下面几个的值（也没改动多少 c.NotebookApp.allow_origin = &#x27;https://colab.research.google.com&#x27;c.NotebookApp.port_retries=0c.NotebookApp.disable_check_xsrf = True# 默认就是8888，也可以不改c.NotebookApp.port = 8888 更改token因为每次连接到本地运行都要输入token，可以将token设置为固定值也相当于password了 不过这样运行的时候命令行里面不会显示token具体值 # 只会像这样显示http://localhost:8888/?token=... 还是再之前那个config.py里面设置 c.NotebookApp.token = &#x27;你的token&#x27; 后面还是会在命令行里面输出log日志，会显示token所以不是私人电脑千万别固定token 取消自动重定向每次打开一个new tab很烦人我又不用jupyter写代码 # config里面修改# 关闭自动打开browserc.NotebookApp.open_browser = False# 不想关闭也可以选择打开的方式# # - 2 opens a new tab,# - 1 opens a new window,# - 0 opens in an existing window.# c.NotebookApp.webbrowser_open_new = 2 后台运行每次命令行不能关闭好麻烦啊 不会杀进程的小白慎用 # 在上述命令的最后加一个 &amp; ，则该命令产生的进程在后台运行，不会影响当前终端的使用（我们在只有一个bash的环境下）。# ctrl c之后还在运行，但是关掉窗口就会停止jupyter notebook &amp;# 在命令的开头加一个nohup，忽略所有的挂断信号，如果当前bash关闭，则当前进程会挂载到init进程下，成为其子进程，这样即使退出当前bash，其8000端口也可以使用。nohup jupyter notebook &amp; 开机启动个人没兴趣，应该配置开机启动项之类的就行了","categories":[{"name":"随笔","slug":"随笔","permalink":"https://dummerfu.top/categories/%E9%9A%8F%E7%AC%94/"}],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://dummerfu.top/tags/%E9%9A%8F%E7%AC%94/"}],"keywords":[{"name":"随笔","slug":"随笔","permalink":"https://dummerfu.top/categories/%E9%9A%8F%E7%AC%94/"}]},{"title":"YoloV3 介绍","slug":"yolov3介绍","date":"2021-06-01T00:00:00.000Z","updated":"2021-06-01T00:00:00.000Z","comments":true,"path":"p/3028.html","link":"","permalink":"https://dummerfu.top/p/3028.html","excerpt":"","text":"yolo算法背景介绍Yolo算法是一些一阶段的目标检测算法，这一类的算法的特点是只用一个卷积神经网路(CNN)来直接预测不同目标的类别和位置。工业界中最常用的yolo版本为yolov3，其检测与识别速度与准确率已经在实践中证明可行。 Yolov3网络结构介绍​ 首先yolov3会将输入图片通过一系列带残差结构的卷积神经网络（backbone）进行特征提取，在论文中这个网络使用的是DarkNet-53，其结构示意如下： ​ 上图中的Convolutional为二维卷积和BN层以及LeakyReLU激活函数的堆叠。Residual为残差结构网络，如图所示，将输入经过1x1和3x3的卷积处理之后与原输入相加为新的输出。 ​ 此处是预训练时的网络结构，在图片分类的数据集中进行预训练，可以加载其预训练权重来迁移学习，缩短训练的时间。 ​ 得到DarkNet提取之后的特征，进一步对该特征进行卷积和上采样操作，提高了特征的细粒度，有利于我们的网络预测小目标，并且与来自darknet的中间层输出进行拼接（concatenate）以便于进行进一步的卷积，得到三种不同尺度大小的输出，分别用于大目标，中等大小目标，小目标的预测。下图为网络结构图： 上图为根据原论文以及官方源码所画出的示意图，我们可以根据以上示意图搭建出yolov3算法的主体网络。 yoloV3的预测​ 根据上图,可以发现输入一张416x416大小的图片，可以得到三种不同尺度的预测特征图: Predict one的size为(Batch_size,3*(1+4+classes),13,13), Predict two的size为(Batch_size,3*(1+4+classes),26,26), Predict three的size为(Batch_size,3*(1+4+classes),52,52). ​ 这些张量的channel上的维度（即size元组上第二位的值）的含义为，在每一个特征图上的点都进行3个bounding box的预测，bounding box即目标的预测框的候选框。三个bound ing box的大小如下图设置： ​ 对于每个bounding box，我们需要预测以下的指标：其一是置信度（confidence），这一指标的含义时bounding box中是否包含着目标，即候选框与实际框的IOU值。其二是候选框的中心坐标偏移量与在特征图上的宽高缩放比(tx,ty,tw,th)。其三为每个classes的置信度。故channel上的数值为3(bounding box数量)*(1(目标置信度)+4(确定框的坐标)+classes(classes个置信度))。 对于目标分类任务重点在于候选框参数的调整，yolov3采取和yolov2一致的候选框调整策略。下图展示了目标边界框的预测过程。图中虚线矩形框为预设边界框，实线矩形框为通过网络预测的偏移量计算得到的预测边界框。其中(cx,cy)为预设边界框在特征图上的中心坐标，(pw,ph)为预设边界框在特征图上的宽和高，(tx,ty,tw,th)分别为网络预测的边界框中心偏移量(tx,ty)以及宽高缩放比(tw,th)，(bx,by,bw,bh)为最终预测的目标边界框，从预设边界框到最终预测边界框的转换过程如图右侧公式所示，其中函数是sigmoid函数其目的是将预测偏移量缩放到0到1之间（这样能够将预设边界框的中心坐标固定在一个1x1大小的cell当中，这样能够加快网络收敛）。 损失函数YOLOv3 损失函数包括三部分：边界框回归损失，目标置信度损失，目标分类损失 L(O,o,C,c,l,g)=\\lambda_1L_{conf}(o,c)+\\lambda_2L_{cla}(O,C)+\\lambda_3L_{loc}(l,g)目标置信度损失​ 目标置信度可理解为预测目标是前景还是背景的概率（是否为待识别目标），显然可以看作是一个二分类，采用交叉熵回归损失： $L_{conf}(o,c)=-\\sum(o_iln(\\hat c))+(1-o_i)(ln(1-\\hat c_i)) $ 其中 $\\hat c=sigmod(c)$,$o_i \\in {0,1}$代表是否为目标，$c_i$代表预测目标框中存在目标的sigmod概率。 目标类别损失 判断前景和背景后就应该预测目标类别，所以目标类比损失是一个多分类损失，但是也可以用二分类损失。 因为可以认为一个物体可以被多个分类概括，比如牧羊犬既属于动物还属于狗，可以使算法更具有鲁棒性。 L_{cla}(O,C)=-\\sum_{i\\in pos}\\sum_{j\\in cla}(O_{ij}*ln(\\hat C_{ij} ))+(1-O_{ij})*ln(1-\\hat C_{ij})i属于第i个预测目标，cla代表预测目标的分类，O_{ij}代表是否存在第i个预测目标中第j类是否存在，$C_{ij}$代表第i个目标属于j的概率 目标定位损失​ 在一个目标检测算法中，既要衡量预测类比的准确率还要衡量边界框与预测类别是否对应。现在预测类别分类的损失函数已经知道了只需要计算边界框回归损失即可： L_{loc}(l,g)=\\sum_{i\\in pos}\\sum_{j \\in \\{x,y,w,h\\}} (\\hat l-\\hat g)^2这里使用的是SE损失函数，其中i代表第i个预测边界框，j属于第i个边界框的参数，l是预测的第i个边界框的参数，g是已知真实的预测边界框参数。","categories":[{"name":"技术","slug":"技术","permalink":"https://dummerfu.top/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://dummerfu.top/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"keywords":[{"name":"技术","slug":"技术","permalink":"https://dummerfu.top/categories/%E6%8A%80%E6%9C%AF/"}]},{"title":"Linux 文件传输","slug":"linux文件传输","date":"2021-05-27T00:00:00.000Z","updated":"2021-05-27T00:00:00.000Z","comments":true,"path":"p/14426.html","link":"","permalink":"https://dummerfu.top/p/14426.html","excerpt":"","text":"杂谈​ 昨日去实验室，发现电脑又换了每次去都要配次环境，佛了，在解压数据集的时候发现数据集损坏… 四处找工具传输，不得不吐槽Linuxqq页面和06年qq一样，qq是指望不上了。最后还是靠的U盘 ​ 现在发现一个好用的传输工具python包？，无需下载安装，可以跑满带宽，支持多下载方式，只需要提供数据源有python环境并且处在一个局域网下即可，它就是—— http.server！！ 这不比网上的fps，scp便捷？？？感觉是解决了U盘不够大的问题 ​ 7废话不多说直接上操作 共享文件http.server 的基本操作# 简单使用:# 关闭终端或ctrl C就会停止服务python http.server 端口号# 后台挂载# 在上述命令的最后加一个 &amp; ，则该命令产生的进程在后台运行，不会影响当前终端的使用（我们在只有一个bash的环境下）。python -m http.server 8000 &amp;# 在命令的开头加一个nohup，忽略所有的挂断信号，如果当前bash关闭，则当前进程会挂载到init进程下，成为其子进程，这样即使退出当前bash，其8000端口也可以使用。# windows 下无法这样，无论是start还是nohup都不行nohup python -m http.server 8000 &amp; python2 要将http.server 修改为 SimpleHTTPServer Windows快速上手打开cmd，cd到需要的共享文件夹的上一级目录，python -m http.server 9393 高级进阶查看端口是否开放 # 查看端口是否占用，无返回则未被占用netstat -ano |findstr &quot;端口号&quot;# 若占用找到PID，查看谁占用tasklist |findstr &quot;PID&quot;# 若无关紧要，终止进程taskkill /f /t /pid &quot;PID&quot; -t -f# 也可以用name终止,比如python.exetaskkill /f /t /im python.exe Linux# 查看ipifconfig -a# 查看端口netstat -nlt# 查看进程ps -ef# 杀死进程(-9强制杀死)kill -9 PID# 通过名字精确杀死killall firefox# 模糊查找，杀死所有包含firefox的进程pkill firefox 访问浏览器中输入：你的ip:9393就可以访问了，类似下面的样子，但是这样只能可以直接下载压缩文件 缺点就是只能同一个局域网访问，但是也可以做端口映射达到公网访问的效果（不建议办公网络使用 反正家庭网络也没什么值得攻击的，只要不设置80，3389，443这种端口映射就行 使用wget下载文件为什么用wget呢？因为wget什么都能下 就省去打包压缩这一步了 今天我才发现window也可以使用wget download is here! 因为可能会文件名字乱码出现invaid argument奇怪bug，所以建议文件夹不要用中文命名 wget -c -r -np -nH -nc -k --restrict-file-names=nocontrol &quot;url&quot;# 参数可以wget -h查看# 常用参数如下# 注意 -O 只能在下载单个文件的时候才能起到重命名的作用# -O newname 将文档写入newname# -c 断点续传# -r 递归下载# -t 设置重试次数# -np noparent# -nH 不要创建主目录。# -nc 不下载已经下载的文件# -k 修复相对链接为绝对链接# --restrict-file-names=nocontrol 网上都说能解决中文乱码问题（我没有解决/(ㄒoㄒ)/~~ 发现还是打包压缩再下载方便，弄什么文件夹递归下载，不好使","categories":[{"name":"杂集","slug":"杂集","permalink":"https://dummerfu.top/categories/%E6%9D%82%E9%9B%86/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://dummerfu.top/tags/Linux/"}],"keywords":[{"name":"杂集","slug":"杂集","permalink":"https://dummerfu.top/categories/%E6%9D%82%E9%9B%86/"}]},{"title":"信号之谜","slug":"信号之谜","date":"2021-05-10T00:00:00.000Z","updated":"2021-05-10T00:00:00.000Z","comments":true,"path":"p/22895.html","link":"","permalink":"https://dummerfu.top/p/22895.html","excerpt":"","text":"‘信号’之谜​ 虽然已经学习了近半个学期的信号与系统，但是我一直有个疑问，什么是信号？？？为什么光，电甚至一张图片也算是信号？ ​ 尤其是某一节课老师讲了图片可以被分离出高频低频信号，我的疑惑更深了。这次，借着老师的机会，想向大家分享一下我是如何理解图片也算信号及为何还可以被分为高频和低频信号的，希望自己解惑的同时也对大家有所帮助。 ​ 通常，我们课本里的信号大多都是和时间相关的函数，这给我们一种错觉就是信号都是和时间有关的单变量函数，但是图片没有时间变量啊，为什么也有高频和低频种信号呢？其实可以这么理解：变化快慢（频率）也不一定非要是相对时间而言的，任何一个变量都可以看作‘时间’，这样只要是一个函数都可以认为是一个信号，成功打破了我们的思维定势，拓展了信号的定义—只要是函数都可以认为是一种信号。 ​ 其实图片的本质是一个二维矩阵，可以表示为Z=F(x,y)的离散函数，Z可以认为是x，y位置处的灰度值（0-255）。z越大，即灰度值越大（靠近255），颜色越亮，灰度值越低（靠近0），颜色越暗。学过信号的人都知道，一维信号傅里叶级数展开可以看作无穷个的正弦波叠加，一维的高频信号可以简单的认为就是正弦波中带有’毛刺’，从而类比二维信号，是不是也可以这样认为，二维图像只不过是平面上的正弦波不同方向上叠加之后产生的（二维傅里叶变换）。 ​ 而图像的边缘轮廓就是正弦波的’毛刺’（导数较大），就是图片的高频信号，而图片z值变化不大的地方（导数较小）就是低频信号。 ​ ​ 图源知乎： 经过上述简单的类比推广，是不是窥伺到‘信号’的真颜了呢? 这个人水博客真是什么手段都用上了","categories":[{"name":"随笔","slug":"随笔","permalink":"https://dummerfu.top/categories/%E9%9A%8F%E7%AC%94/"}],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://dummerfu.top/tags/%E9%9A%8F%E7%AC%94/"}],"keywords":[{"name":"随笔","slug":"随笔","permalink":"https://dummerfu.top/categories/%E9%9A%8F%E7%AC%94/"}]},{"title":"美多商城","slug":"美多商城","date":"2021-04-21T00:00:00.000Z","updated":"2021-04-21T00:00:00.000Z","comments":true,"path":"p/6015.html","link":"","permalink":"https://dummerfu.top/p/6015.html","excerpt":"","text":"项目背景这几天一直琢磨着如何才能培养自己好的代码习惯和读源码能力 或者说是我大学以来一直担心的 但是感觉这件事如果不自己写一个’工程项目’是永远都不会懂的。 遂找了个以前毕业必会的项目练练手项目视频教程。 项目配置环境配置先在windows下创建虚拟环境 # 没装包pip install 一下mkvirtualenv django_projectworkon django_project 主要是django+redis+mysql+jinja2的框架进行前后端不分离开发，环境如下 Django 3.2django-redis 4.12.1Jinja2 2.11.3pip 20.1.1PyMySQL 1.0.2redis 3.5.3 github配置这个很简单，github建库，clone一下就完事了 目前为止的tree结构 ├─.idea└─meiduomall ├─readme└─.gitignore 因为是django项目在meiduomall里面执行 就有了基本框架 # 如果没有必要包先安装必要包# pip install django# pip install redis# pip install pymysql# pip install jinja2# 安装请忽略django-admin startproject meiduomall 开发环境配置这里涉及许多就不一一细说了，都是在setting文件里修改。 不过首先为了测试等方便，将原本的setting.py删除创建新的setting包，再在里面创建dev.py作为测试setting #!/usr/bin/env pythonimport osimport sysif __name__ == &quot;__main__&quot;: # 注意这里根据自己的文件夹名字不同设置不同 os.environ.setdefault(&quot;DJANGO_SETTINGS_MODULE&quot;, &quot;meiduomall.settings.dev&quot;) try: from django.core.management import execute_from_command_line except ImportError: # The above import may fail for some other reason. Ensure that the # issue is really that Django is missing to avoid masking other # exceptions on Python 2. try: import django except ImportError: raise ImportError( &quot;Couldn&#x27;t import Django. Are you sure it&#x27;s installed and &quot; &quot;available on your PYTHONPATH environment variable? Did you &quot; &quot;forget to activate a virtual environment?&quot; ) raise execute_from_command_line(sys.argv) 注意使用jinja2的框架要设置环境（在template那），新建utils包，在里面创建jinja2_env.py # -*- coding:utf-8 -*-# @Author : Dummerfu# @Contact : https://github.com/dummerchen # @Time : 2021/4/20 18:16from jinja2 import Environmentfrom django.urls import reversefrom django.contrib.staticfiles.storage import staticfiles_storagedef jinja2_env(**options): env=Environment(**options) env.globals.update(&#123; &#x27;static&#x27;:staticfiles_storage.url, # 获取静态文件前缀 &#x27;url&#x27;:reverse, # 反向解析路由 &#125;) return env 之后就是在setting中修改了，我主要改了 databases，templates，增加了redis，logging，static_url 别忘记建个mysql数据库 &quot;&quot;&quot;Django settings for meiduomall project.Generated by &#x27;django-admin startproject&#x27; using Django 1.11.11.For more information on this file, seehttps://docs.djangoproject.com/en/1.11/topics/settings/For the full list of settings and their values, seehttps://docs.djangoproject.com/en/1.11/ref/settings/&quot;&quot;&quot;import os# Build paths inside the project like this: os.path.join(BASE_DIR, ...)BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))# Quick-start development settings - unsuitable for production# See https://docs.djangoproject.com/en/1.11/howto/deployment/checklist/# SECURITY WARNING: keep the secret key used in production secret!SECRET_KEY = &#x27;r3jt$+_uq90)99sr-p#@u%=$y43cwh18%2sdac2(uh!w^oj@qg&#x27;# SECURITY WARNING: don&#x27;t run with debug turned on in production!DEBUG = TrueALLOWED_HOSTS = []# Application definitionINSTALLED_APPS = [ &#x27;django.contrib.admin&#x27;, &#x27;django.contrib.auth&#x27;, &#x27;django.contrib.contenttypes&#x27;, &#x27;django.contrib.sessions&#x27;, &#x27;django.contrib.messages&#x27;, &#x27;django.contrib.staticfiles&#x27;,]MIDDLEWARE = [ &#x27;django.middleware.security.SecurityMiddleware&#x27;, &#x27;django.contrib.sessions.middleware.SessionMiddleware&#x27;, &#x27;django.middleware.common.CommonMiddleware&#x27;, &#x27;django.middleware.csrf.CsrfViewMiddleware&#x27;, &#x27;django.contrib.auth.middleware.AuthenticationMiddleware&#x27;, &#x27;django.contrib.messages.middleware.MessageMiddleware&#x27;, &#x27;django.middleware.clickjacking.XFrameOptionsMiddleware&#x27;,]ROOT_URLCONF = &#x27;meiduomall.urls&#x27;TEMPLATES = [ &#123; &#x27;BACKEND&#x27;: &#x27;django.template.backends.jinja2.Jinja2&#x27;, &#x27;DIRS&#x27;: [os.path.join(BASE_DIR,&#x27;templates&#x27;)], &#x27;APP_DIRS&#x27;: True, &#x27;OPTIONS&#x27;: &#123; &#x27;context_processors&#x27;: [ &#x27;django.template.context_processors.debug&#x27;, &#x27;django.template.context_processors.request&#x27;, &#x27;django.contrib.auth.context_processors.auth&#x27;, &#x27;django.contrib.messages.context_processors.messages&#x27;, ], &#x27;environment&#x27;:&#x27;meiduomall.utils.jinja2_env.jinja2_env&#x27;, &#125;, &#125;, &#123; &#x27;BACKEND&#x27;: &#x27;django.template.backends.django.DjangoTemplates&#x27;, &#x27;DIRS&#x27;: [os.path.join(BASE_DIR,&#x27;templates&#x27;)], &#x27;APP_DIRS&#x27;: True, &#x27;OPTIONS&#x27;: &#123; &#x27;context_processors&#x27;: [ &#x27;django.template.context_processors.debug&#x27;, &#x27;django.template.context_processors.request&#x27;, &#x27;django.contrib.auth.context_processors.auth&#x27;, &#x27;django.contrib.messages.context_processors.messages&#x27;, ], &#125;, &#125;]# TEMPLATES = [# &#123;# &#x27;BACKEND&#x27;: &#x27;django.template.backends.django.DjangoTemplates&#x27;,# &#x27;DIRS&#x27;: [],# &#x27;APP_DIRS&#x27;: True,# &#x27;OPTIONS&#x27;: &#123;# &#x27;context_processors&#x27;: [# &#x27;django.template.context_processors.debug&#x27;,# &#x27;django.template.context_processors.request&#x27;,# &#x27;django.contrib.auth.context_processors.auth&#x27;,# &#x27;django.contrib.messages.context_processors.messages&#x27;,# ],# &#125;,# &#125;,# ]WSGI_APPLICATION = &#x27;meiduomall.wsgi.application&#x27;# Database# https://docs.djangoproject.com/en/1.11/ref/settings/#databasesDATABASES = &#123; &#x27;default&#x27;: &#123; &#x27;ENGINE&#x27;: &#x27;django.db.backends.mysql&#x27;, &#x27;HOST&#x27;:&#x27;127.0.0.1&#x27;, &#x27;PORT&#x27;:3306, &#x27;USER&#x27;:&#x27;mall_admin&#x27;, &#x27;PASSWORD&#x27;:&#x27;20010720&#x27;, &#x27;NAME&#x27;:&#x27;mall&#x27;, &#125;&#125;# 配置redisCACHES = &#123; &quot;default&quot;: &#123; &quot;BACKEND&quot;: &quot;django_redis.cache.RedisCache&quot;, &quot;LOCATION&quot;: &quot;redis://127.0.0.1:6379/1&quot;, &quot;OPTIONS&quot;: &#123; &quot;CLIENT_CLASS&quot;: &quot;django_redis.client.DefaultClient&quot;, &#125; &#125;, &quot;session&quot;: &#123; &quot;BACKEND&quot;: &quot;django_redis.cache.RedisCache&quot;, &quot;LOCATION&quot;: &quot;redis://127.0.0.1:6379/2&quot;, &quot;OPTIONS&quot;: &#123; &quot;CLIENT_CLASS&quot;: &quot;django_redis.client.DefaultClient&quot;, &#125; &#125;&#125;SESSION_ENGINE = &quot;django.contrib.sessions.backends.cache&quot;SESSION_CACHE_ALIAS = &quot;session&quot;# Password validation# https://docs.djangoproject.com/en/1.11/ref/settings/#auth-password-validatorsAUTH_PASSWORD_VALIDATORS = [ &#123; &#x27;NAME&#x27;: &#x27;django.contrib.auth.password_validation.UserAttributeSimilarityValidator&#x27;, &#125;, &#123; &#x27;NAME&#x27;: &#x27;django.contrib.auth.password_validation.MinimumLengthValidator&#x27;, &#125;, &#123; &#x27;NAME&#x27;: &#x27;django.contrib.auth.password_validation.CommonPasswordValidator&#x27;, &#125;, &#123; &#x27;NAME&#x27;: &#x27;django.contrib.auth.password_validation.NumericPasswordValidator&#x27;, &#125;,]# Internationalization# https://docs.djangoproject.com/en/1.11/topics/i18n/LANGUAGE_CODE = &#x27;en-us&#x27;TIME_ZONE = &#x27;UTC&#x27;USE_I18N = TrueUSE_L10N = TrueUSE_TZ = True# Static files (CSS, JavaScript, Images)# https://docs.djangoproject.com/en/1.11/howto/static-files/STATIC_URL = &#x27;/static/&#x27;STATICFILES_DIRS = [ os.path.join(BASE_DIR, &quot;static&quot;),]# loggers 配置LOGGING=&#123; &#x27;version&#x27;: 1, &#x27;disable_existing_loggers&#x27;: False, &#x27;formatters&#x27;:&#123; &#x27;verbose&#x27;:&#123; &#x27;format&#x27;: &#x27;%(levelname)s %(asctime)s %(module)s %(lineno)d %(message)s&#x27;, &#125;, &#x27;simple&#x27;:&#123; &#x27;format&#x27;:&#x27;%(levelname)s %(module)s %(lineno)d %(message)s&#x27; &#125;, &#125;, &#x27;filters&#x27;:&#123; &#x27;require_debug_true&#x27;:&#123;# django 在debug模式下输出日志 &#x27;()&#x27;: &#x27;django.utils.log.RequireDebugTrue&#x27;, &#125; &#125;, &#x27;handlers&#x27;:&#123; # 日志处理方法 &#x27;console&#x27;:&#123; &#x27;level&#x27;:&#x27;INFO&#x27;, &#x27;filters&#x27;:[&#x27;require_debug_true&#x27;], &#x27;class&#x27;:&#x27;logging.StreamHandler&#x27;, &#x27;formatter&#x27;:&#x27;simple&#x27;, &#125;, &#x27;file&#x27;:&#123; &#x27;level&#x27;:&#x27;INFO&#x27;, &#x27;class&#x27;:&#x27;logging.handlers.RotatingFileHandler&#x27;, &#x27;filename&#x27;:os.path.join(BASE_DIR,&#x27;logs/mall.log&#x27;), &#x27;maxBytes&#x27;: 300*1024*1024, &#x27;backupCount&#x27;: 10, &#x27;formatter&#x27;:&#x27;verbose&#x27;, &#125;, &#125;, &#x27;loggers&#x27;:&#123; &#x27;django&#x27;:&#123; # 定义日志器名字 &#x27;handlers&#x27;:[&#x27;console&#x27;,&#x27;file&#x27;], &#x27;propagate&#x27;:True, # 是否继续传递日志信息 &#x27;level&#x27;:&#x27;INFO&#x27;, &#125; &#125;,&#125; 加上templates，static，logs文件夹的tree如下（当然可以把logs文件夹放在和meiduomall同级目录） ├─.idea└─meiduomall └─meiduomall ├─logs ├─settings ├─static ├─templates ├─utils 用户注册okk，以上我们已经完成了项目配置，现在可以开始构建app了 apps为了方便管理，我们先在meiduomall目录下创建一个python package apps，然后再在里面创建项目子应用。 python ../../manage.py startapp users 然后在setting中注册子应用每次创建都有注册，后续就不再赘述了 # 用户子应用注册，如果不知道路径可以通过sys.path查看# 当然也可以sys.path.insert()插入新的导包路径# 这样就可以使用&#x27;users&#x27;,# 不加插入，直接用meiduomall.apps.users会说找不到&#x27;users&#x27;就很奇怪sys.path.insert(0,os.path.join(BASE_DIR,&#x27;apps&#x27;))INSTALLED_APPS = [ &#x27;django.contrib.admin&#x27;, &#x27;django.contrib.auth&#x27;, &#x27;django.contrib.contenttypes&#x27;, &#x27;django.contrib.sessions&#x27;, &#x27;django.contrib.messages&#x27;, &#x27;django.contrib.staticfiles&#x27;, &#x27;users&#x27;, ] 注册页面因为我主要还是从事后端所以所有html都默认已经写好了，直接用（现在templates里面已经有register.html) 在view.py中创建register视图类视图类可以理解为在当前页面发送请求所触发的相应的响应。后面在详细修改 from django.shortcuts import renderfrom django.views import View# Create your views here.class Register_View(View): &#x27;&#x27;&#x27; 用户注册 &#x27;&#x27;&#x27; def get(self,request): return render(request,&#x27;register.html&#x27;) 设置路由这里要闲话一下 urlpattern的匹配顺序 在根路由中顺序匹配，匹配成功则进入子应用路由匹配（可以多个匹配成功 子路由中匹配剩余的string 如果根路由正则为r’^register/‘ 子路由中正则为r’^register/$’ 输入路径为 xxxx:xxx/register/ ，会nofound 提示也有先匹配register/ 匹配成功，然后剩余字符串为’’,匹配子路由失败 这样是xxx:xx/register/register/才会匹配成功 &quot;&quot;&quot;meiduomall URL ConfigurationThe `urlpatterns` list routes URLs to views. For more information please see: https://docs.djangoproject.com/en/1.11/topics/http/urls/Examples:Function views 1. Add an import: from my_app import views 2. Add a URL to urlpatterns: url(r&#x27;^$&#x27;, views.home, name=&#x27;home&#x27;)Class-based views 1. Add an import: from other_app.views import Home 2. Add a URL to urlpatterns: url(r&#x27;^$&#x27;, Home.as_view(), name=&#x27;home&#x27;)Including another URLconf 1. Import the include() function: from django.conf.urls import url, include 2. Add a URL to urlpatterns: url(r&#x27;^blog/&#x27;, include(&#x27;blog.urls&#x27;))&quot;&quot;&quot;# 总路由from django.conf.urls import url,includefrom django.contrib import admin# 根路由中不能有严格的结束$，这样子路由就没有意义了urlpatterns = [ url(r&#x27;^admin/&#x27;, admin.site.urls), url(r&#x27;^&#x27;,include(&#x27;users.urls&#x27;)),] # 在users下创建urls.py文件# 里面内容如下from django.conf.urls import url,includefrom django.contrib import adminfrom . import viewsurlpatterns = [ url(r&#x27;^$&#x27;,views.Register_View.as_view()),] 现在打开即可看到注册页面 实现数据存储数据库创建user模型类完成注册登录并存储账号等信息到数据库，因为django已经有内置的用户类所以直接继承即可。 from django.db import modelsfrom django.contrib.auth.models import AbstractUser# Create your models here.class User(AbstractUser): mobile=models.CharField(max_length=11,unique=True,verbose_name=&#x27;phone number&#x27;) class Meta: # 表名规范 db_name db_table=&#x27;db_user&#x27; verbose_name=&#x27;user_name&#x27; verbose_name_plural=verbose_name 一般get是向服务器发送请求，post是向数据库发送请求 验证信息信息填写后还需要验证这一步骤，包括前端验证和后端验证，步骤是先前端初步判断信息十分符合，再使用axios发送get|post请求，然后后端向数据库得到数据检验信息是否符合规范。 可以建立一个verification子应用然后再里面修改。（添加子应用和前面步骤都一样 具体检验信息包括： 用户名检验（前端检验是否合法，后端检验是否重复 密码检验（前端后端检验两次密码是否相同 手机号检验（前端检验是否合法，后端检验是否重复 验证码检验（后端检验是否与用户输入相同 短信检验（后端检验是否符合 同意条款检验（前后端检验是否勾选 有条件最后都前后端都检验一下，以防恶意分子。 # View 代码# 检验用户名class Username_View(View): def get(self,request,username): count=User.objects.filter(username=username).count() return http.JsonResponse(&#123;&#x27;count&#x27;:count,&#x27;errormsg&#x27;:&#x27;ok&#x27;,&#x27;code&#x27;:0&#125;)# 检验手机号class Mobile_View(View): def get(self,request,mobile): count=User.objects.filter(mobile=mobile).count() return http.JsonResponse(&#123;&#x27;count&#x27;:count,&#x27;errormsg&#x27;:&#x27;ok&#x27;,&#x27;code&#x27;:0&#125;) // 检验手机号为例check_phone: function ()&#123; var re = /^1[345789]\\d&#123;9&#125;$/; if(re.test(this.mobile)) &#123; this.error_phone = false; &#125; else &#123; console.log(&quot;???&quot;) this.error_phone_message = &#x27;您输入的手机号格式不正确&#x27;; this.error_phone = true; &#125; if (this.error_phone == false) &#123; axios.get(&#x27;http://127.0.0.1:8000/mobiles/&#x27;+ this.mobile + &#x27;/count/&#x27;, &#123; responseType: &#x27;json&#x27; &#125;) .then(response =&gt; &#123; if (response.data.count &gt; 0) &#123; this.error_phone_message = &#x27;手机号已存在,请尝试登录&#x27;; this.error_phone = true; &#125; else &#123; this.error_phone = false; &#125; &#125;) .catch(error =&gt; &#123; console.log(error.response.data.code); &#125;) &#125; &#125;, 注意验证码是存放在redis中的，项目开始不要忘记开启redis和mysql 也可以再增加一个verify_code redis库，如果你的redis有密码还要配置密码 CACHES = &#123; &quot;default&quot;: &#123; &quot;BACKEND&quot;: &quot;django_redis.cache.RedisCache&quot;, &quot;LOCATION&quot;: &quot;redis://:20010720@127.0.0.1:6379/1&quot;, &quot;OPTIONS&quot;: &#123; &quot;CLIENT_CLASS&quot;: &quot;django_redis.client.DefaultClient&quot;, &quot;PASSWORD&quot;:&quot;XXXX&quot;, &#125; &#125;, &quot;session&quot;: &#123; &quot;BACKEND&quot;: &quot;django_redis.cache.RedisCache&quot;, &quot;LOCATION&quot;: &quot;redis://127.0.0.1:6379/2&quot;, &quot;OPTIONS&quot;: &#123; &quot;CLIENT_CLASS&quot;: &quot;django_redis.client.DefaultClient&quot;, &quot;PASSWORD&quot;:&#x27;XXXX&#x27;, &#125; &#125;, &quot;verify_code&quot;: &#123; &quot;BACKEND&quot;: &quot;django_redis.cache.RedisCache&quot;, &quot;LOCATION&quot;: &quot;redis://127.0.0.1:6379/3&quot;, &quot;OPTIONS&quot;: &#123; &quot;CLIENT_CLASS&quot;: &quot;django_redis.client.DefaultClient&quot;, &quot;PASSWORD&quot;:&#x27;XXXX&#x27;, &#125; &#125;&#125; 下面讲一讲验证码检验部分思路，其实很简单 短信验证用不起 定义view 定义url路由 前端访问对应路由 view接受get|post请求 view类里查询redis，check用户与后端数据库存储是否相同 后记你看到后记可能会问，唉？这就后记了？就这？没错 因为写到这里用户注册部分就已经差不多了，之后只是对注册页面的各种优化（虽然不知为什么我的axios的ajax请求会刷新页面）但算是把一个板块写完了吧，所以先告一段落。 由于5.1校赛选择了烟盒的目标识别，发现自己好多网络结构都不懂，trick也是现场yy，开始说好的k折也没实现菜鸡全靠大佬带飞。 当务之急是恶补ML基础所以接下来可能按这方面走了： Mobilenet学习和代码复现 Effient Net学习和代码复现 尝试VP VinBigData Chest X-ray Abnormalities Detection To be contiune…","categories":[{"name":"技术","slug":"技术","permalink":"https://dummerfu.top/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"python基础","slug":"python基础","permalink":"https://dummerfu.top/tags/python%E5%9F%BA%E7%A1%80/"}],"keywords":[{"name":"技术","slug":"技术","permalink":"https://dummerfu.top/categories/%E6%8A%80%E6%9C%AF/"}]},{"title":"深拷贝与浅拷贝","slug":"深拷贝与浅拷贝","date":"2021-04-08T00:00:00.000Z","updated":"2021-04-08T00:00:00.000Z","comments":true,"path":"p/12139.html","link":"","permalink":"https://dummerfu.top/p/12139.html","excerpt":"","text":"深拷贝与浅拷贝python的赋值与c++不同 问题缘由​ 之前被坑过一次，结果忘了总结。这次写元胞自动机的时候发现了这个bug，让我迷惑很久才想起来这个问题，遂记录。 具体如下： a=[1,2,3]b=aa.append(1)print(&#x27;a =&#x27;,a,&#x27;b=&#x27;,b)# a = [1, 2, 3, 1] b= [1, 2, 3, 1]b.append(11)print(&#x27;a =&#x27;,a,&#x27;b=&#x27;,b)# a = [1, 2, 3, 1, 11] b= [1, 2, 3, 1, 11]print(id(a),id(b))# 3002845450824 3002845450824 c++使用变量前会需要先声明变量，故每一个变量都会先有一个地址，而python不需要先命名故会发生这种奇怪的情况，于是就引出了python中的变量空间问题。 python中的拷贝可以理解为创建一个新的命名空间，而不是’真正的拷贝’ 浅拷贝 只会被可变类型第一项进行拷贝，不会对子对象进行拷贝。 什么是可变类型？list，dict，set都是可变类型，可以简单理解为可以动态增删改查的数据结构。 import copya=[1,2,3,[1,2,3]]b=ab.append(1)print(&#x27;a =&#x27;,a,&#x27;b=&#x27;,b)# a = [1, 2, 3, [1, 2, 3], 1] b= [1, 2, 3, [1, 2, 3], 1]print(id(a),id(b))# 2555694210504 2555694210504# 浅拷贝，只拷贝第一个可变类型b=copy.copy(a)b.append(2)print(&#x27;a =&#x27;,a,&#x27;b=&#x27;,b)# a = [1, 2, 3, [1, 2, 3], 1] b= [1, 2, 3, [1, 2, 3], 1, 2]print(id(a),id(b))# 2555694210504 2555694194440print(id(a[3]),id(b[3])) 深拷贝​ 可以对全部可变类型进行拷贝，所有子对象进行拷贝（可以理解真正的创建了一个变量） import copya=[1,2,3,[1,2,3]]b=ab.append(1)print(&#x27;a =&#x27;,a,&#x27;b=&#x27;,b)# a = [1, 2, 3, [1, 2, 3], 1] b= [1, 2, 3, [1, 2, 3], 1]print(id(a),id(b))# 2555694210504 2555694210504# 浅拷贝，只拷贝第一个可变类型b=copy.deepcopy(a)b.append(2)print(&#x27;a =&#x27;,a,&#x27;b=&#x27;,b)# a = [1, 2, 3, [1, 2, 3], 1] b= [1, 2, 3, [1, 2, 3], 1, 2]print(id(a),id(b))# 2555694210504 2555694194440print(id(a[3]),id(b[3])) 总之，deepcopy准没错","categories":[{"name":"随笔","slug":"随笔","permalink":"https://dummerfu.top/categories/%E9%9A%8F%E7%AC%94/"}],"tags":[{"name":"python基础","slug":"python基础","permalink":"https://dummerfu.top/tags/python%E5%9F%BA%E7%A1%80/"}],"keywords":[{"name":"随笔","slug":"随笔","permalink":"https://dummerfu.top/categories/%E9%9A%8F%E7%AC%94/"}]},{"title":"退役流水账","slug":"退役有感","date":"2021-04-05T00:00:00.000Z","updated":"2021-04-05T00:00:00.000Z","comments":true,"path":"p/11997.html","link":"","permalink":"https://dummerfu.top/p/11997.html","excerpt":"","text":"没想到这么快到了退役这一天 其实早就开始划水了，遂有感而发，写有此文。谁带的退役就要写博客的节奏啊 入坑起因我在高中竞赛成绩并不显赫，本来大学不想打acm无奈加分太香了 加上第一次的队友也想和我一起打下次，就又继续了一年，虽然这两年里毫无进步并且差点第一次爆零（还好最后水了分拿了个铜）但是总体来讲收获颇多。（还是加分太香了 退役赛2021.4.3 昆明icpc，战况–惨。全程靠队友带飞 开局签到没什么问题，然后就开始神奇的自闭，两个小时后才wa6做出了第二道题。期间疯狂划水也让我丧失了最后打下去的希望。 之后又自闭了，直到封榜最后15分钟和最后四分钟，我们才debug出来两道，太惊险了交题的时候我甚至开始了祈祷，交的时候心态本来都崩了，甚至没有输样例，没想到A了。最后四道题完结撒花。排名178应该有个铜吧 本来如果不wa6的话可以更高的，wa6心态崩了。 这次题全是临场发挥…什么都 好评的是免费午餐和打印机（队友70多面板子现场印的，xswl，整个教室就我们这嗡嗡的响，结果最后还是没用到） 关于acm本蒟蒻的一些建议如果让我说大学是否值得从零开始学acm，我的答案毫无疑问是NO！！，甚至碰都不要碰这门竞赛。因为他实在是太卷了大佬忽略。你可能拼死拼活学了两个月，不眠不休刷了别人两三年前就刷过的题，结果可能是发现自己还是不会做“新题”，（甚至你去问别人，别人还可能秒了）心里落差极大。我最初的一个队友就是被劝退了 拿这时间和精力去学习别的可能收入会比支出大的多。 再者，学习的算法数据结构对与大学甚至以后的工作几乎没用（如果有奖找工作还挺有用的），就好比小学奥数和数学，你可能到高中都没见过奥数里的题 甚至还不会写。 （再退一步说，有的学校可能加分的时候icpc区域赛是算省奖，让你费心费力还吃力不讨好… 结语以上都仅仅是建议和胡说，仅代表本人的想法，你大可不必看这篇文章。每个人有每个人的想法，求同存异就好。说不定也不退役了(●’◡’●)","categories":[{"name":"随笔","slug":"随笔","permalink":"https://dummerfu.top/categories/%E9%9A%8F%E7%AC%94/"}],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://dummerfu.top/tags/%E9%9A%8F%E7%AC%94/"}],"keywords":[{"name":"随笔","slug":"随笔","permalink":"https://dummerfu.top/categories/%E9%9A%8F%E7%AC%94/"}]},{"title":"【转载】初探docker","slug":"初探docker","date":"2021-03-15T00:00:00.000Z","updated":"2021-03-15T00:00:00.000Z","comments":true,"path":"p/21866.html","link":"","permalink":"https://dummerfu.top/p/21866.html","excerpt":"","text":"本文转载于http://www.ruanyifeng.com/blog/2018/02/docker-tutorial.html 2013年发布至今， Docker 一直广受瞩目，被认为可能会改变软件行业。 但是，许多人并不清楚 Docker 到底是什么，要解决什么问题，好处又在哪里？本文就来详细解释，帮助大家理解它，还带有简单易懂的实例，教你如何将它用于日常开发。 一、环境配置的难题软件开发最大的麻烦事之一，就是环境配置。用户计算机的环境都不相同，你怎么知道自家的软件，能在那些机器跑起来？ 用户必须保证两件事：操作系统的设置，各种库和组件的安装。只有它们都正确，软件才能运行。举例来说，安装一个 Python 应用，计算机必须有 Python 引擎，还必须有各种依赖，可能还要配置环境变量。 如果某些老旧的模块与当前环境不兼容，那就麻烦了。开发者常常会说：”它在我的机器可以跑了”（It works on my machine），言下之意就是，其他机器很可能跑不了。 环境配置如此麻烦，换一台机器，就要重来一次，旷日费时。很多人想到，能不能从根本上解决问题，软件可以带环境安装？也就是说，安装的时候，把原始环境一模一样地复制过来。 二、虚拟机虚拟机（virtual machine）就是带环境安装的一种解决方案。它可以在一种操作系统里面运行另一种操作系统，比如在 Windows 系统里面运行 Linux 系统。应用程序对此毫无感知，因为虚拟机看上去跟真实系统一模一样，而对于底层系统来说，虚拟机就是一个普通文件，不需要了就删掉，对其他部分毫无影响。 虽然用户可以通过虚拟机还原软件的原始环境。但是，这个方案有几个缺点。 （1）资源占用多 虚拟机会独占一部分内存和硬盘空间。它运行的时候，其他程序就不能使用这些资源了。哪怕虚拟机里面的应用程序，真正使用的内存只有 1MB，虚拟机依然需要几百 MB 的内存才能运行。 （2）冗余步骤多 虚拟机是完整的操作系统，一些系统级别的操作步骤，往往无法跳过，比如用户登录。 （3）启动慢 启动操作系统需要多久，启动虚拟机就需要多久。可能要等几分钟，应用程序才能真正运行。 三、Linux 容器由于虚拟机存在这些缺点，Linux 发展出了另一种虚拟化技术：Linux 容器（Linux Containers，缩写为 LXC）。 Linux 容器不是模拟一个完整的操作系统，而是对进程进行隔离。或者说，在正常进程的外面套了一个保护层。对于容器里面的进程来说，它接触到的各种资源都是虚拟的，从而实现与底层系统的隔离。 由于容器是进程级别的，相比虚拟机有很多优势。 （1）启动快 容器里面的应用，直接就是底层系统的一个进程，而不是虚拟机内部的进程。所以，启动容器相当于启动本机的一个进程，而不是启动一个操作系统，速度就快很多。 （2）资源占用少 容器只占用需要的资源，不占用那些没有用到的资源；虚拟机由于是完整的操作系统，不可避免要占用所有资源。另外，多个容器可以共享资源，虚拟机都是独享资源。 （3）体积小 容器只要包含用到的组件即可，而虚拟机是整个操作系统的打包，所以容器文件比虚拟机文件要小很多。 总之，容器有点像轻量级的虚拟机，能够提供虚拟化的环境，但是成本开销小得多。 四、Docker 是什么？Docker 属于 Linux 容器的一种封装，提供简单易用的容器使用接口。它是目前最流行的 Linux 容器解决方案。 Docker 将应用程序与该程序的依赖，打包在一个文件里面。运行这个文件，就会生成一个虚拟容器。程序在这个虚拟容器里运行，就好像在真实的物理机上运行一样。有了 Docker，就不用担心环境问题。 总体来说，Docker 的接口相当简单，用户可以方便地创建和使用容器，把自己的应用放入容器。容器还可以进行版本管理、复制、分享、修改，就像管理普通的代码一样。 五、Docker 的用途Docker 的主要用途，目前有三大类。 （1）提供一次性的环境。比如，本地测试他人的软件、持续集成的时候提供单元测试和构建的环境。 （2）提供弹性的云服务。因为 Docker 容器可以随开随关，很适合动态扩容和缩容。 （3）组建微服务架构。通过多个容器，一台机器可以跑多个服务，因此在本机就可以模拟出微服务架构。 六、Docker 的安装Docker 是一个开源的商业产品，有两个版本：社区版（Community Edition，缩写为 CE）和企业版（Enterprise Edition，缩写为 EE）。企业版包含了一些收费服务，个人开发者一般用不到。下面的介绍都针对社区版。 Docker CE 的安装请参考官方文档。 Mac Windows Ubuntu Debian CentOS Fedora 其他 Linux 发行版 安装完成后，运行下面的命令，验证是否安装成功。 $ docker version# 或者$ docker info Docker 需要用户具有 sudo 权限，为了避免每次命令都输入sudo，可以把用户加入 Docker 用户组（官方文档）。 $ sudo usermod -aG docker $USER Docker 是服务器——客户端架构。命令行运行docker命令的时候，需要本机有 Docker 服务。如果这项服务没有启动，可以用下面的命令启动（官方文档）。 # service 命令的用法$ sudo service docker start# systemctl 命令的用法$ sudo systemctl start docker 六、image 文件Docker 把应用程序及其依赖，打包在 image 文件里面。只有通过这个文件，才能生成 Docker 容器。image 文件可以看作是容器的模板。Docker 根据 image 文件生成容器的实例。同一个 image 文件，可以生成多个同时运行的容器实例。 image 是二进制文件。实际开发中，一个 image 文件往往通过继承另一个 image 文件，加上一些个性化设置而生成。举例来说，你可以在 Ubuntu 的 image 基础上，往里面加入 Apache 服务器，形成你的 image。 # 列出本机的所有 image 文件。$ docker image ls# 删除 image 文件$ docker image rm [imageName] image 文件是通用的，一台机器的 image 文件拷贝到另一台机器，照样可以使用。一般来说，为了节省时间，我们应该尽量使用别人制作好的 image 文件，而不是自己制作。即使要定制，也应该基于别人的 image 文件进行加工，而不是从零开始制作。 为了方便共享，image 文件制作完成后，可以上传到网上的仓库。Docker 的官方仓库 Docker Hub 是最重要、最常用的 image 仓库。此外，出售自己制作的 image 文件也是可以的。 七、实例：hello world下面，我们通过最简单的 image 文件”hello world”，感受一下 Docker。 需要说明的是，国内连接 Docker 的官方仓库很慢，还会断线，需要将默认仓库改成国内的镜像网站，具体的修改方法在下一篇文章的第一节。有需要的朋友，可以先看一下。 首先，运行下面的命令，将 image 文件从仓库抓取到本地。 $ docker image pull library/hello-world 上面代码中，docker image pull是抓取 image 文件的命令。library/hello-world是 image 文件在仓库里面的位置，其中library是 image 文件所在的组，hello-world是 image 文件的名字。 由于 Docker 官方提供的 image 文件，都放在library组里面，所以它的是默认组，可以省略。因此，上面的命令可以写成下面这样。 $ docker image pull hello-world 抓取成功以后，就可以在本机看到这个 image 文件了。 $ docker image ls 现在，运行这个 image 文件。 $ docker container run hello-world docker container run命令会从 image 文件，生成一个正在运行的容器实例。 注意，docker container run命令具有自动抓取 image 文件的功能。如果发现本地没有指定的 image 文件，就会从仓库自动抓取。因此，前面的docker image pull命令并不是必需的步骤。 如果运行成功，你会在屏幕上读到下面的输出。 $ docker container run hello-worldHello from Docker!This message shows that your installation appears to be working correctly.... ... 输出这段提示以后，hello world就会停止运行，容器自动终止。 有些容器不会自动终止，因为提供的是服务。比如，安装运行 Ubuntu 的 image，就可以在命令行体验 Ubuntu 系统。 $ docker container run -it ubuntu bash 对于那些不会自动终止的容器，必须使用docker container kill 命令手动终止。 $ docker container kill [containID] 八、容器文件image 文件生成的容器实例，本身也是一个文件，称为容器文件。也就是说，一旦容器生成，就会同时存在两个文件： image 文件和容器文件。而且关闭容器并不会删除容器文件，只是容器停止运行而已。 # 列出本机正在运行的容器$ docker container ls# 列出本机所有容器，包括终止运行的容器$ docker container ls --all 上面命令的输出结果之中，包括容器的 ID。很多地方都需要提供这个 ID，比如上一节终止容器运行的docker container kill命令。 终止运行的容器文件，依然会占据硬盘空间，可以使用docker container rm命令删除。 $ docker container rm [containerID] 运行上面的命令之后，再使用docker container ls --all命令，就会发现被删除的容器文件已经消失了。 九、Dockerfile 文件学会使用 image 文件以后，接下来的问题就是，如何可以生成 image 文件？如果你要推广自己的软件，势必要自己制作 image 文件。 这就需要用到 Dockerfile 文件。它是一个文本文件，用来配置 image。Docker 根据 该文件生成二进制的 image 文件。 下面通过一个实例，演示如何编写 Dockerfile 文件。 十、实例：制作自己的 Docker 容器下面我以 koa-demos 项目为例，介绍怎么写 Dockerfile 文件，实现让用户在 Docker 容器里面运行 Koa 框架。 作为准备工作，请先下载源码。 $ git clone https://github.com/ruanyf/koa-demos.git$ cd koa-demos 10.1 编写 Dockerfile 文件首先，在项目的根目录下，新建一个文本文件.dockerignore，写入下面的内容。 .gitnode_modulesnpm-debug.log 上面代码表示，这三个路径要排除，不要打包进入 image 文件。如果你没有路径要排除，这个文件可以不新建。 然后，在项目的根目录下，新建一个文本文件 Dockerfile，写入下面的内容。 FROM node:8.4COPY . /appWORKDIR /appRUN npm install --registry=https://registry.npm.taobao.orgEXPOSE 3000 上面代码一共五行，含义如下。 FROM node:8.4：该 image 文件继承官方的 node image，冒号表示标签，这里标签是8.4，即8.4版本的 node。 COPY . /app：将当前目录下的所有文件（除了.dockerignore排除的路径），都拷贝进入 image 文件的/app目录。 WORKDIR /app：指定接下来的工作路径为/app。 RUN npm install：在/app目录下，运行npm install命令安装依赖。注意，安装后所有的依赖，都将打包进入 image 文件。 EXPOSE 3000：将容器 3000 端口暴露出来， 允许外部连接这个端口。 10.2 创建 image 文件有了 Dockerfile 文件以后，就可以使用docker image build命令创建 image 文件了。 $ docker image build -t koa-demo .# 或者$ docker image build -t koa-demo:0.0.1 . 上面代码中，-t参数用来指定 image 文件的名字，后面还可以用冒号指定标签。如果不指定，默认的标签就是latest。最后的那个点表示 Dockerfile 文件所在的路径，上例是当前路径，所以是一个点。 如果运行成功，就可以看到新生成的 image 文件koa-demo了。 $ docker image ls 10.3 生成容器docker container run命令会从 image 文件生成容器。 $ docker container run -p 8000:3000 -it koa-demo /bin/bash# 或者$ docker container run -p 8000:3000 -it koa-demo:0.0.1 /bin/bash 上面命令的各个参数含义如下： -p参数：容器的 3000 端口映射到本机的 8000 端口。 -it参数：容器的 Shell 映射到当前的 Shell，然后你在本机窗口输入的命令，就会传入容器。 koa-demo:0.0.1：image 文件的名字（如果有标签，还需要提供标签，默认是 latest 标签）。 /bin/bash：容器启动以后，内部第一个执行的命令。这里是启动 Bash，保证用户可以使用 Shell。 如果一切正常，运行上面的命令以后，就会返回一个命令行提示符。 root@66d80f4aaf1e:/app# 这表示你已经在容器里面了，返回的提示符就是容器内部的 Shell 提示符。执行下面的命令。 root@66d80f4aaf1e:/app# node demos/01.js 这时，Koa 框架已经运行起来了。打开本机的浏览器，访问 http://127.0.0.1:8000，网页显示&quot;Not Found”，这是因为这个 demo 没有写路由。 这个例子中，Node 进程运行在 Docker 容器的虚拟环境里面，进程接触到的文件系统和网络接口都是虚拟的，与本机的文件系统和网络接口是隔离的，因此需要定义容器与物理机的端口映射（map）。 现在，在容器的命令行，按下 Ctrl + c 停止 Node 进程，然后按下 Ctrl + d （或者输入 exit）退出容器。此外，也可以用docker container kill终止容器运行。 # 在本机的另一个终端窗口，查出容器的 ID$ docker container ls# 停止指定的容器运行$ docker container kill [containerID] 容器停止运行之后，并不会消失，用下面的命令删除容器文件。 # 查出容器的 ID$ docker container ls --all# 删除指定的容器文件$ docker container rm [containerID] 也可以使用docker container run命令的--rm参数，在容器终止运行后自动删除容器文件。 $ docker container run --rm -p 8000:3000 -it koa-demo /bin/bash 10.4 CMD 命令上一节的例子里面，容器启动以后，需要手动输入命令node demos/01.js。我们可以把这个命令写在 Dockerfile 里面，这样容器启动以后，这个命令就已经执行了，不用再手动输入了。 FROM node:8.4COPY . /appWORKDIR /appRUN npm install --registry=https://registry.npm.taobao.orgEXPOSE 3000CMD node demos/01.js 上面的 Dockerfile 里面，多了最后一行CMD node demos/01.js，它表示容器启动后自动执行node demos/01.js。 你可能会问，RUN命令与CMD命令的区别在哪里？简单说，RUN命令在 image 文件的构建阶段执行，执行结果都会打包进入 image 文件；CMD命令则是在容器启动后执行。另外，一个 Dockerfile 可以包含多个RUN命令，但是只能有一个CMD命令。 注意，指定了CMD命令以后，docker container run命令就不能附加命令了（比如前面的/bin/bash），否则它会覆盖CMD命令。现在，启动容器可以使用下面的命令。 $ docker container run --rm -p 8000:3000 -it koa-demo:0.0.1 10.5 发布 image 文件容器运行成功后，就确认了 image 文件的有效性。这时，我们就可以考虑把 image 文件分享到网上，让其他人使用。 首先，去 hub.docker.com 或 cloud.docker.com 注册一个账户。然后，用下面的命令登录。 $ docker login 接着，为本地的 image 标注用户名和版本。 $ docker image tag [imageName] [username]/[repository]:[tag]# 实例$ docker image tag koa-demos:0.0.1 ruanyf/koa-demos:0.0.1 也可以不标注用户名，重新构建一下 image 文件。 $ docker image build -t [username]/[repository]:[tag] . 最后，发布 image 文件。 $ docker image push [username]/[repository]:[tag] 发布成功以后，登录 hub.docker.com，就可以看到已经发布的 image 文件。 十一、其他有用的命令docker 的主要用法就是上面这些，此外还有几个命令，也非常有用。 （1）docker container start 前面的docker container run命令是新建容器，每运行一次，就会新建一个容器。同样的命令运行两次，就会生成两个一模一样的容器文件。如果希望重复使用容器，就要使用docker container start命令，它用来启动已经生成、已经停止运行的容器文件。 $ docker container start [containerID] （2）docker container stop 前面的docker container kill命令终止容器运行，相当于向容器里面的主进程发出 SIGKILL 信号。而docker container stop命令也是用来终止容器运行，相当于向容器里面的主进程发出 SIGTERM 信号，然后过一段时间再发出 SIGKILL 信号。 $ bash container stop [containerID] 这两个信号的差别是，应用程序收到 SIGTERM 信号以后，可以自行进行收尾清理工作，但也可以不理会这个信号。如果收到 SIGKILL 信号，就会强行立即终止，那些正在进行中的操作会全部丢失。 （3）docker container logs docker container logs命令用来查看 docker 容器的输出，即容器里面 Shell 的标准输出。如果docker run命令运行容器的时候，没有使用-it参数，就要用这个命令查看输出。 $ docker container logs [containerID] （4）docker container exec docker container exec命令用于进入一个正在运行的 docker 容器。如果docker run命令运行容器的时候，没有使用-it参数，就要用这个命令进入容器。一旦进入了容器，就可以在容器的 Shell 执行命令了。 $ docker container exec -it [containerID] /bin/bash （5）docker container cp docker container cp命令用于从正在运行的 Docker 容器里面，将文件拷贝到本机。下面是拷贝到当前目录的写法。 $ docker container cp [containID]:[/path/to/file] . 非常感谢你一直读到了这里，这个系列还有下一篇，介绍如何使用 Docker 搭建真正的网站，欢迎继续阅读。","categories":[{"name":"转载","slug":"转载","permalink":"https://dummerfu.top/categories/%E8%BD%AC%E8%BD%BD/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://dummerfu.top/tags/docker/"}],"keywords":[{"name":"转载","slug":"转载","permalink":"https://dummerfu.top/categories/%E8%BD%AC%E8%BD%BD/"}]},{"title":"线程与进程","slug":"线程与进程","date":"2021-03-03T00:00:00.000Z","updated":"2021-03-03T00:00:00.000Z","comments":true,"path":"p/52642.html","link":"","permalink":"https://dummerfu.top/p/52642.html","excerpt":"Here's something encrypted, password is required to continue reading.","text":"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 Hey, password is required here.","categories":[{"name":"随笔","slug":"随笔","permalink":"https://dummerfu.top/categories/%E9%9A%8F%E7%AC%94/"}],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://dummerfu.top/tags/%E9%9A%8F%E7%AC%94/"}],"keywords":[{"name":"随笔","slug":"随笔","permalink":"https://dummerfu.top/categories/%E9%9A%8F%E7%AC%94/"}]},{"title":"经典网络实现","slug":"经典网络实现","date":"2021-02-20T00:00:00.000Z","updated":"2021-08-23T00:00:00.000Z","comments":true,"path":"p/35344.html","link":"","permalink":"https://dummerfu.top/p/35344.html","excerpt":"","text":"前言看不懂别人的代码,自己实现一遍经典网络,熟悉keras api 水篇博客 没有训练测试过网络的效果,直接拿去用可能会出问题!!! 本意是了解如何自己构建网络,以防日后的模型迁移要再学一遍. 不要问为什么我知道要重学 可能网络会有错误,但是无伤大雅,知道如何构建就行 反正以后经典网络可以直接导入 不过在之前要先了解一下模型保存不同格式的区别以防模型实现了不会保存 模型保存TF官网 Save_model格式这个是最简单粗暴的模型保存方法了。 保存的模型将包括： 模型的架构/配置 模型的权重值（在训练过程中学习） 模型的编译信息（如果调用了 compile()） 优化器及其状态（如果有的话，使您可以从上次中断的位置重新开始训练） # 保存为dirname_path路径下文件名为dirname的文件夹model.save(dirname_path) H5格式 Keras 还支持保存单个 HDF5 文件，其中包含模型的架构、权重值和 compile() 信息。它是 SavedModel 的轻量化替代选择。 但是同时因为只有一个h5文件与 SavedModel 格式相比，H5 文件不包括以下两方面内容： 通过 model.add_loss() 和 model.add_metric() 添加的外部损失和指标不会被保存（这与 SavedModel 不同）。如果您的模型有此类损失和指标且您想要恢复训练，则您需要在加载模型后自行重新添加这些损失。请注意，这不适用于通过 self.add_loss() 和 self.add_metric() 在层内创建的损失指标。只要该层被加载，这些损失和指标就会被保留，因为它们是该层 call 方法的一部分。 已保存的文件中不包含自定义对象（如自定义层）的计算图。 # 只需要在文件名后加.h5后缀即可model.save(name.h5) checkpoints保存时附带签名class Model(tf.keras.Model): @tf.function def call(self, x): ... m = Model() tf.saved_model.save( m, &#x27;/tmp/saved_model/&#x27;, signatures=m.call.get_concrete_function( tf.TensorSpec(shape=[None, 3], dtype=tf.float32, name=&quot;inp&quot;))) ResNet手写实现不同的ResNet只有结构不同,unit是相同的只需要改变layer_dims就可以实现了 这里使用重写类来构建网络,虽然要写前向传播比较麻烦,但是自由度更高 import osos.environ[&#x27;TF_CPP_MIN_LOG_LEVEL&#x27;]=&#x27;2&#x27;import numpy as npimport tensorflow as tffrom tensorflow import kerasimport tensorboardfrom tensorflow.keras import layersimport datetimefrom matplotlib import pyplot as pltBATCHSIZE=64class BasicBlock(layers.Layer): def __init__(self,filter_num,stride=1): super(BasicBlock,self).__init__() self.conv1=layers.Conv2D(kernel_size=(3,3) ,filters=filter_num,strides=stride,padding=&#x27;same&#x27;) self.bn1=layers.BatchNormalization() self.relu=layers.Activation(&#x27;relu&#x27;) self.conv2=layers.Conv2D(kernel_size=(3,3) ,filters=filter_num,strides=1,padding=&#x27;same&#x27;) self.bn2 = layers.BatchNormalization() if(stride!=1): self.downsample = keras.Sequential() self.downsample.add(layers.Conv2D(filters=filter_num,kernel_size=(1,1),strides=stride)) else: self.downsample=lambda x:x def call(self,inputs,training=None): out=self.conv1(inputs) out=self.bn1(out) out=self.relu(out) out=self.conv2(out) out=self.bn2(out) identity=self.downsample(inputs) output=layers.add([out,identity]) output=self.relu(output) return outputclass ResNet(keras.Model): def __init__(self,layer_dims,num_classes=100): super(ResNet, self).__init__() # self.flatten=layers.Flatten(input_shape=(32,32,3)) self.stem=keras.Sequential([ layers.Conv2D(64,(3,3),strides=(1,1)), layers.BatchNormalization(), layers.Activation(&#x27;relu&#x27;), layers.MaxPool2D(pool_size=(2,2),strides=(1,1),padding=&#x27;same&#x27;) ]) self.layer1=self.build_resblock(filter_num=64,blocks=layer_dims[0]) self.layer2=self.build_resblock(filter_num=128,blocks=layer_dims[1],stride=2) self.layer3=self.build_resblock(filter_num=256,blocks=layer_dims[2],stride=2) self.layer4=self.build_resblock(filter_num=512,blocks=layer_dims[3],stride=2) self.avgpool=layers.GlobalAveragePooling2D() self.fc=layers.Dense(num_classes) def call(self,inputs,training=None): # x = tf.reshape(inputs, [-1, 32 * 32*3]) out=self.stem(inputs) out=self.layer1(out) out=self.layer2(out) out=self.layer3(out) out=self.layer4(out) out=self.avgpool(out) out=self.fc(out) return out def build_resblock(self,filter_num,blocks,stride=1): res_block=keras.Sequential() res_block.add(BasicBlock(filter_num,stride)) for _ in range(1,blocks): res_block.add(BasicBlock(filter_num,stride=1)) return res_blockdef resnet18(): return ResNet(layer_dims=[2,2,2,2])def preprocess(x,y): print(&#x27;pre:&#x27;, x.shape, y.shape) x=tf.cast(x,dtype=tf.float32)/255.0 y=tf.cast(y,dtype=tf.int32) y = tf.squeeze(y) y=tf.one_hot(y,depth=100) print(&#x27;after&#x27;, x.shape, y.shape) return x,ydef data2tensor(x,y): db=tf.data.Dataset.from_tensor_slices((x,y)) db=db.map(preprocess) db=db.shuffle(5000).batch(BATCHSIZE) return dbdef train_model(train_db,val_db,is_train=False): model = resnet18() model.build(input_shape=(None, 32, 32, 3)) model.summary() x=tf.random.normal([4,32,32,3]) out=model(x) print(out.shape) model.compile( optimizer=tf.optimizers.Adam(), loss=tf.losses.CategoricalCrossentropy(from_logits=True), metrics=[&#x27;accuracy&#x27;], ) path=os.path.abspath(&#x27;./&#x27;) log_dir = path + &#x27;\\\\logs\\\\&#x27; + datetime.datetime.now().strftime(&quot;%Y%m%d-%H%M&quot;) print(log_dir) tensorboard=keras.callbacks.TensorBoard(log_dir=log_dir,histogram_freq=1) model.summary() if is_train: model.fit(train_db,validation_data=val_db,validation_freq=1,epochs=5,callbacks=[tensorboard]) model.save_weights(&#x27;./resnet18.h5&#x27;)def main(): (x,y),(x_test,y_test)=keras.datasets.cifar100.load_data() l=int(len(x)*0.8) train_db=data2tensor(x[:l],y[:l]) val_db=data2tensor(x[l:],y[l:]) test_db=data2tensor(x_test,y_test) # sample=next(iter(train_db)) # print(sample[0].shape,sample[1].shape) # plt.imshow(sample[0]) # plt.show() train_model(train_db,val_db,is_train=False)main() 自带api实现因为application里面都有，功能都类似故后面不再赘述 tf.kears.application.resnet50.Resnet50与tf.kears.application.Resnet50的功能都一样 from tensorflow.keras.applications import *model=ResNet50(weights=&#x27;./resnet50_weights_tf_dim_ordering_tf_kernels.h5&#x27;)path=&#x27;./cat.jpg&#x27;# 读入图片image=image_preprocess.img_decoder(path)pre1=model.predict(image)# 这个能使标签对应起来pre=resnet50.decode_predictions(pre1)print(pre) VGG​ 这里使用keras的高级api来构建网络,当然使用Sequential也可以实现同样的效果. # -*- coding:utf-8 -*-# @Author : Dummerfu# @Contact : https://github.com/dummerchen # @Time : 2021/2/19 20:48import osos.environ[&#x27;TF_CPP_MIN_LOG_LEVEL&#x27;]=&#x27;2&#x27;import datetimeimport tensorflow as tffrom tensorflow import kerasBATCHSIZE=32def preprocess(x,y): print(&#x27;pre&#x27;,x.shape,y.shape) x=2*tf.cast(x,dtype=tf.float32)/255.0 -1 y = tf.squeeze(y) y=tf.cast(y,dtype=tf.int32) y=tf.one_hot(y,depth=100) print(&#x27;after:&#x27;,x.shape,y.shape) return x,ydef data2tensor(x,y): db=tf.data.Dataset.from_tensor_slices((x,y)) db=db.map(preprocess) db=db.shuffle(5000).batch(BATCHSIZE) return dbdef VGG(image_shape,n_class): print(image_shape[0],image_shape[1],image_shape[2]) inputs = keras.Input(shape=[image_shape[0],image_shape[1],image_shape[2]]) x=keras.layers.Conv2D(64, kernel_size=[3, 3], strides=[1, 1], activation=keras.activations.relu,padding=&#x27;same&#x27;)(inputs) x=keras.layers.Conv2D(64, kernel_size=[3, 3], strides=[1, 1], activation=keras.activations.relu,padding=&#x27;same&#x27;)(x) x=keras.layers.MaxPooling2D(pool_size=[2, 2], strides=[2, 2], padding=&#x27;same&#x27;)(x) x= keras.layers.Conv2D(128, kernel_size=[3, 3], strides=[1, 1], activation=keras.activations.relu,padding=&#x27;same&#x27;)(x) x= keras.layers.Conv2D(128, kernel_size=[3, 3], strides=[1, 1], activation=keras.activations.relu,padding=&#x27;same&#x27;)(x) x= keras.layers.MaxPooling2D(pool_size=[2, 2], strides=[2, 2], padding=&#x27;same&#x27;)(x) x= keras.layers.Conv2D(256, kernel_size=[3, 3], strides=[1, 1], activation=keras.activations.relu,padding=&#x27;same&#x27;)(x) x= keras.layers.Conv2D(256, kernel_size=[3, 3], strides=[1, 1], activation=keras.activations.relu,padding=&#x27;same&#x27;)(x) x= keras.layers.Conv2D(256, kernel_size=[3, 3], strides=[1, 1], activation=keras.activations.relu,padding=&#x27;same&#x27;)(x) x= keras.layers.Conv2D(256, kernel_size=[3, 3], strides=[1, 1], activation=keras.activations.relu,padding=&#x27;same&#x27;)(x) x= keras.layers.MaxPooling2D(pool_size=[2, 2], strides=[2, 2], padding=&#x27;same&#x27;)(x) x= keras.layers.Conv2D(512, kernel_size=[3, 3], strides=[1, 1], activation=keras.activations.relu,padding=&#x27;same&#x27;)(x) x= keras.layers.Conv2D(512, kernel_size=[3, 3], strides=[1, 1], activation=keras.activations.relu,padding=&#x27;same&#x27;)(x) x= keras.layers.Conv2D(512, kernel_size=[3, 3], strides=[1, 1], activation=keras.activations.relu,padding=&#x27;same&#x27;)(x) x= keras.layers.Conv2D(512, kernel_size=[3, 3], strides=[1, 1], activation=keras.activations.relu,padding=&#x27;same&#x27;)(x) x= keras.layers.MaxPooling2D(pool_size=[2, 2], strides=[2, 2], padding=&#x27;same&#x27;)(x) x= keras.layers.Conv2D(512, kernel_size=[3, 3], strides=[1, 1], activation=keras.activations.relu,padding=&#x27;same&#x27;)(x) x= keras.layers.Conv2D(512, kernel_size=[3, 3], strides=[1, 1], activation=keras.activations.relu,padding=&#x27;same&#x27;)(x) x= keras.layers.Conv2D(512, kernel_size=[3, 3], strides=[1, 1], activation=keras.activations.relu,padding=&#x27;same&#x27;)(x) x= keras.layers.Conv2D(512, kernel_size=[3, 3], strides=[1, 1], activation=keras.activations.relu,padding=&#x27;same&#x27;)(x) x= keras.layers.MaxPooling2D(pool_size=[2, 2], strides=[2, 2], padding=&#x27;same&#x27;)(x) x= keras.layers.Flatten()(x) x= keras.layers.Dense(4096, activation=keras.activations.relu, use_bias=True)(x) x= keras.layers.Dense(4096, activation=keras.activations.relu, use_bias=True)(x) outputs= keras.layers.Dense(n_class, activation=keras.activations.softmax, use_bias=True)(x) # 基于Model方法构建模型 model = keras.Model(inputs=inputs, outputs=outputs) return modeldef train(train_db,val_db,is_train=False): model = VGG([32,32,3],n_class=100) model.compile( optimizer=tf.optimizers.Adam(), loss=tf.losses.CategoricalCrossentropy(), metrics=[&#x27;accuracy&#x27;], ) path = os.path.abspath(&#x27;./&#x27;) log_dir = path + &#x27;\\\\logs\\\\&#x27; + datetime.datetime.now().strftime(&quot;%Y%m%d-%H%M&quot;) print(log_dir) tensorboard = keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1) model.summary() if is_train: model.fit(train_db, validation_data=val_db, validation_freq=1, epochs=5, callbacks=[tensorboard]) model.save_weights(&#x27;./vgg16.h5&#x27;)(x,y),(x_test,y_test)=keras.datasets.cifar100.load_data()print(&#x27;pre&#x27;,x.shape,y.shape)train_db=data2tensor(x,y)test_db=data2tensor(x_test,y_test)train(train_db=train_db,val_db=test_db,is_train=False) LSTMlayers.lstmcell和layers.lstm传参是不一样的 前者需要手动更新state参数($h{t-1}$,$c{t-1}$)但是后者自动更新，如果需要多层叠加则需要设置return_sequence=True , unroll=True # -*- coding:utf-8 -*-# @Author : Dummerfu# @Contact : https://github.com/dummerchen # @Time : 2021/2/21 17:46import osos.environ[&#x27;TF_CPP_MIN_LOG_LEVEL&#x27;]=&#x27;2&#x27;import numpy as npimport matplotlib as mplfrom matplotlib import pyplot as pltmpl.rcParams[&#x27;font.sans-serif&#x27;] = &#x27;SimHei&#x27;mpl.rcParams[&#x27;axes.unicode_minus&#x27;] = Falseimport tensorflow as tffrom tensorflow import keras# 最常见的前20000个单词max_features=20000# 一句话的最大长度max_len=100batchsize=64class Mylstm(keras.Model): def __init__(self,units): super(Mylstm,self).__init__() # [b,100] =&gt; [b,100,100] self.embeding=keras.layers.Embedding(input_dim=max_features,input_length=max_len,output_dim=100) self.rnn=keras.Sequential([ keras.layers.LSTM(units=units,dropout=0.5,return_sequences=True,unroll=True), keras.layers.LSTM(units=units,dropout=0.5,unroll=True) ]) self.fc=keras.layers.Dense(1,activation=keras.activations.sigmoid) def call(self,inputs,training=None): # [b,100] =&gt; [b,100,100] x=self.embeding(inputs) print(x.shape) # [b,100,100] =&gt; [b,64] x=self.rnn(x) x=self.fc(x) return xdef data2tensor(x,y): x=keras.preprocessing.sequence.pad_sequences(sequences=x,maxlen=max_len) x=tf.cast(x,dtype=tf.int32) y=tf.cast(y,dtype=tf.int32) print(x.shape,y.shape) db=tf.data.Dataset.from_tensor_slices((x,y)).shuffle(10000).batch(batchsize,drop_remainder=True) return dbdef train(db_train,db_val,db_test): model=Mylstm(64) model.compile( optimizer=tf.optimizers.Adam(), loss=tf.losses.BinaryCrossentropy(), metrics=[&#x27;accuracy&#x27;], ) model.fit(db_train,epochs=5,validation_data=db_val,validation_freq=1) model.evaluate(db_test) returndef main(): (x,y),(x_test,y_test)=keras.datasets.imdb.load_data(num_words=max_features) l=int(len(x)*0.8) db_train=data2tensor(x[:l],y[:l]) db_val=data2tensor(x[l:],y[l:]) db_test=data2tensor(x_test,y_test) train(db_train,db_val,db_test)if __name__ == &quot;__main__&quot;: main() AutoEncoder|VAE这里是自定义训练，当然相比之下更复杂但是自由度也更高。 autoencoder就是两个自定义网络，先降维得到特征向量h，再升到原本维度就行了没什么技术含量，就不写了，关键是它的思路非常具有启发性。 这里要注意的是mean,var Dense是两个Dense，即使计算方式一样但是要用两Dense,如果一个Dense算两次因为权重的原因结果是相同的，直接会导致图片越来越暗。 先附上tf.nn的几种损失函数区别再附代码 # -*- coding:utf-8 -*-# @Author : Dummerfu# @Contact : https://github.com/dummerchen # @Time : 2021/2/22 21:55import osos.environ[&#x27;TF_CPP_MIN_LOG_LEVEL&#x27;]=&#x27;2&#x27;import matplotlib as mplfrom matplotlib import pyplot as pltimport tensorflow as tffrom tensorflow import kerasfrom tensorflow.keras import layersfrom PIL import Imageimport numpy as npmpl.rcParams[&#x27;font.sans-serif&#x27;] = &#x27;SimHei&#x27;mpl.rcParams[&#x27;axes.unicode_minus&#x27;] = Falsetf.random.set_seed(2345)# autoencoder 计算量很小batch可以大一点batch_size=512# 特征维数z_dims=20class VAE(keras.Model): def __init__(self): super(VAE,self).__init__() #encoder self.encoder=keras.Sequential([ keras.layers.InputLayer(input_shape=(28*28)), keras.layers.Dense(128), ]) self.meanfc=keras.layers.Dense(z_dims) self.varfc=keras.layers.Dense(z_dims) #decoder self.decoder=keras.Sequential([ keras.layers.Dense(128, activation=tf.nn.relu), keras.layers.Dense(784), ]) def reparamize(self,mean,log_var): eps=tf.random.normal(log_var.shape) z=mean+eps*tf.exp(log_var*0.5) return z def call(self,inputs,training=None): h=self.encoder(inputs) mean=self.meanfc(h) log_var=self.varfc(h) z=self.reparamize(mean,log_var) outputs=self.decoder(z) return outputs,mean,log_vardef data2tensor(x,y): x=tf.cast(x,dtype=tf.float32)/255.0 db=tf.data.Dataset.from_tensor_slices(x) db=db.shuffle(batch_size*5).batch(batch_size) return dbdef save_images(imgs,name): new_im = Image.new(&#x27;L&#x27;, (280, 280)) index = 0 for i in range(0, 280, 28): for j in range(0, 280, 28): im = imgs[index] im = Image.fromarray(im, mode=&#x27;L&#x27;) new_im.paste(im, (i, j)) index += 1 new_im.save(name)def train_and_test(db_train,db_test): model=VAE() # model.build(input_shape=(4,784)) optimizer=tf.optimizers.Adam() for epoch in range(100): for step,x in enumerate(db_train): # print(x.shape) x=tf.reshape(x,[-1,784]) with tf.GradientTape() as tape: x_hat,mean,log_var=model(x) # 这里使用的这个loss是为了更好的收敛，使用其他的也行，但是要多训练 redu_loss=tf.nn.sigmoid_cross_entropy_with_logits(x,x_hat) # 这里其实随便，reduce_mean(),reduce_sum()应该都行反正都是minimize loss # reduce_mean()和reduce_sum()|reduce_sum/x.shape[0]训练结果完全不同.. # 但是后两者相似 redu_loss=tf.reduce_sum(redu_loss)/x.shape[0] kl=-0.5*(log_var+1-mean**2-tf.exp(log_var)) # prekl=tf.reduce_mean(kl) kl=tf.reduce_sum(kl)/x.shape[0] loss=redu_loss+kl*1.0 grads=tape.gradient(loss,model.trainable_variables) optimizer.apply_gradients(zip(grads,model.trainable_variables)) if step%50==0: print(epoch,step,&quot;kl_loss:&quot;,kl,&#x27;loss:&#x27;,loss,&#x27;x_shape0&#x27;,x.shape[0]) # evaluation z=tf.random.normal((batch_size,z_dims)) sample_x=model.decoder(z) sample_x=tf.nn.sigmoid(sample_x) sample_x = tf.reshape(sample_x, [-1, 28, 28]).numpy() * 255. sample_x= sample_x.astype(np.uint8) save_images(sample_x, &#x27;vae_images/sample_epoch_%d.png&#x27; % epoch) test_x = next(iter(db_test)) test_x,_,_= model(tf.reshape(test_x, [-1, 784])) # [b, 784] =&gt; [b, 28, 28] test_x=tf.nn.sigmoid(test_x) test_x = tf.reshape(test_x, [-1, 28, 28]) # [b, 28, 28] =&gt; [2b, 28, 28] test_x= test_x.numpy() * 255. test_x = test_x.astype(np.uint8) save_images(test_x, &#x27;vae_images/test_epoch_%d.png&#x27; % epoch) model.save_weights(&#x27;./vae.h5&#x27;)if __name__ == &quot;__main__&quot;: (x,y),(x_test,y_test)=keras.datasets.mnist.load_data() l=int(len(x)*0.8) print(x.shape, y.shape,l,28*28) db_train=data2tensor(x[:l],y[:l]) db_val=data2tensor(x[l:],y[l:]) db_test=data2tensor(x_test,y_test) train_and_test(db_train,db_val) GanWGAN原理GAN一直面临着G,D训练困难、G,D的损失函数与训练好坏无关(由于js散度，loss 常常是log2)等问题，在此基础上便提出了WGAN，相对于传统的GAN,WGAN只做了几点改动确有很好的效果 D的最后一层去掉sigmod G,Dloss不取log 每次更新D的参数后做一个梯度惩罚（gradient penalty） GAN的原本损失函数为 E_{z \\in p_z(z)}[log(1-D(G(z)))]但是这样导致了如果D太好了G则训练不到有效的梯度，G太好了D又训练不到有效的梯度 所以WGAN的损失函数改为了，在improve WGAN中还加入了gradient penalty E_{z\\in p_z(z)}[-logD(G(z))] = KL(P_g||P_{data})-2JS(P_{data}||P_g)+\\lambda gpWGAN理论上给出了GAN训练不稳定的原因，即交叉熵（JS散度）不适合衡量具有不相交部分的分布之间的距离，转而使用wassertein距离去衡量生成数据分布和真实数据分布之间的距离，理论上解决了训练不稳定的问题。 ​ WGAN相对于DCGAN，WGAN虽然收敛时间更长但是更稳定，所以对于更复杂网络来说更倾向于WGAN，比如使用resnet可以达到更好的结果。 codegenerator里的反卷积参数必须最后要计算结果能吻合Discriminator的input_shape 因为要在batchnorm后面做激活所以不能像之前一样在卷积层里面激活。 这是我自己的wgan跑3000个epoch后的结果，可以明显看出学习到了头发和眼睛(相比之下别人调的参太牛了) 数据集kaggle上随便找啊，kaggle真香，各方意义上， 龙书里面的提到的数据集在这里https://pan.baidu.com/s/1Yn53uxFLCbja13_6Ay44MA 数据集来源在这里,我开始没看issue没找到这个数据集，爬到一半才看到😓， 我爬的数据在https://pan.baidu.com/s/1JsUHx_1blY6pGx0DQfE0nQ 提取码：3621 （只有三万张图片… 我写的gan参数太差了，看龙书说跑3万次似乎能得到比较好的效果？算了直接上别人已经调好参的WGAN代码吧，知乎那个调好参的DCGAN太猛了，300epoch居然就成型了orz（虽然我没跑 train函数import osos.environ[&#x27;TF_CPP_MIN_LOG_LEVEL&#x27;]=&#x27;2&#x27;import globimport numpy as npimport matplotlib as mplfrom PIL import Imageimport tensorflow as tffrom tensorflow import kerasimport datasetimport tensorflow as tffrom tensorflow import kerasfrom tensorflow.keras import layersclass Generator(keras.Model): def __init__(self): super(Generator, self).__init__() # z: [b, 100] =&gt; [b, 3*3*512] =&gt; [b, 3, 3, 512] =&gt; [b, 64, 64, 3] self.fc = layers.Dense(3*3*512) self.conv1 = layers.Conv2DTranspose(256, 3, 3, &#x27;valid&#x27;) self.bn1 = layers.BatchNormalization() self.conv2 = layers.Conv2DTranspose(128, 5, 2, &#x27;valid&#x27;) self.bn2 = layers.BatchNormalization() self.conv3 = layers.Conv2DTranspose(3, 4, 3, &#x27;valid&#x27;) def call(self, inputs, training=None): # [z, 100] =&gt; [z, 3*3*512] x = self.fc(inputs) x = tf.reshape(x, [-1, 3, 3, 512]) x = tf.nn.leaky_relu(x) # x = tf.nn.leaky_relu(self.bn1(self.conv1(x), training=training)) x = tf.nn.leaky_relu(self.bn2(self.conv2(x), training=training)) x = self.conv3(x) x = tf.tanh(x) return xclass Discriminator(keras.Model): def __init__(self): super(Discriminator, self).__init__() # [b, 64, 64, 3] =&gt; [b, 1] self.conv1 = layers.Conv2D(64, 5, 3, &#x27;valid&#x27;) self.conv2 = layers.Conv2D(128, 5, 3, &#x27;valid&#x27;) self.bn2 = layers.BatchNormalization() self.conv3 = layers.Conv2D(256, 5, 3, &#x27;valid&#x27;) self.bn3 = layers.BatchNormalization() # [b, h, w ,c] =&gt; [b, -1] self.flatten = layers.Flatten() self.fc = layers.Dense(1) def call(self, inputs, training=None): x = tf.nn.leaky_relu(self.conv1(inputs)) x = tf.nn.leaky_relu(self.bn2(self.conv2(x), training=training)) x = tf.nn.leaky_relu(self.bn3(self.conv3(x), training=training)) # [b, h, w, c] =&gt; [b, -1] x = self.flatten(x) # [b, -1] =&gt; [b, 1] logits = self.fc(x) return logitsdef save_result(val_out, val_block_size, image_path, color_mode): def preprocess(img): img = ((img + 1.0) * 127.5).astype(np.uint8) # img = img.astype(np.uint8) return img preprocesed = preprocess(val_out) final_image = np.array([]) single_row = np.array([]) for b in range(val_out.shape[0]): # concat image into a row if single_row.size == 0: single_row = preprocesed[b, :, :, :] else: single_row = np.concatenate((single_row, preprocesed[b, :, :, :]), axis=1) # concat image row to final_image if (b+1) % val_block_size == 0: if final_image.size == 0: final_image = single_row else: final_image = np.concatenate((final_image, single_row), axis=0) # reset single row single_row = np.array([]) if final_image.shape[2] == 1: final_image = np.squeeze(final_image, axis=2) Image.fromarray(final_image).save(image_path)def celoss_ones(logits): return - tf.reduce_mean(logits)def celoss_zeros(logits): return tf.reduce_mean(logits)def gradient_penalty(discriminator, batch_x, fake_image): batchsz = batch_x.shape[0] # [b, h, w, c] t = tf.random.uniform([batchsz, 1, 1, 1]) # [b, 1, 1, 1] =&gt; [b, h, w, c] t = tf.broadcast_to(t, batch_x.shape) interplate = t * batch_x + (1 - t) * fake_image with tf.GradientTape() as tape: tape.watch([interplate]) d_interplote_logits = discriminator(interplate, training=True) grads = tape.gradient(d_interplote_logits, interplate) # grads:[b, h, w, c] =&gt; [b, -1] grads = tf.reshape(grads, [grads.shape[0], -1]) gp = tf.norm(grads, axis=1) #[b] gp = tf.reduce_mean( (gp-1)**2 ) return gpdef d_loss_fn(generator, discriminator, batch_z, batch_x, is_training): # 1. treat real image as real # 2. treat generated image as fake fake_image = generator(batch_z, is_training) d_fake_logits = discriminator(fake_image, is_training) d_real_logits = discriminator(batch_x, is_training) d_loss_real = celoss_ones(d_real_logits) d_loss_fake = celoss_zeros(d_fake_logits) gp = gradient_penalty(discriminator, batch_x, fake_image) loss = d_loss_real + d_loss_fake + 10. * gp return loss, gpdef g_loss_fn(generator, discriminator, batch_z, is_training): fake_image = generator(batch_z, is_training) d_fake_logits = discriminator(fake_image, is_training) loss = celoss_ones(d_fake_logits) return lossdef main(): tf.random.set_seed(233) np.random.seed(233) # hyper parameters z_dim = 100 epochs = 3000000 batch_size = 512 learning_rate = 0.0005 is_training = True img_path = glob.glob(&#x27;.\\animefacedataset\\images\\*.jpg&#x27;) assert len(img_path) &gt; 0 dataset, img_shape, _ = make_anime_dataset(img_path, batch_size) print(dataset, img_shape) sample = next(iter(dataset)) print(sample.shape, tf.reduce_max(sample).numpy(), tf.reduce_min(sample).numpy()) dataset = dataset.repeat() db_iter = iter(dataset) generator = Generator() generator.build(input_shape = (None, z_dim)) discriminator = Discriminator() discriminator.build(input_shape=(None, 64, 64, 3)) z_sample = tf.random.normal([100, z_dim]) g_optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0.5) d_optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0.5) for epoch in range(epochs): # 训练5次discriminator 再训练一次generator！！！不然就会出现像我一样的图 for _ in range(5): batch_z = tf.random.normal([batch_size, z_dim]) batch_x = next(db_iter) # train D with tf.GradientTape() as tape: d_loss, gp = d_loss_fn(generator, discriminator, batch_z, batch_x, is_training) grads = tape.gradient(d_loss, discriminator.trainable_variables) d_optimizer.apply_gradients(zip(grads, discriminator.trainable_variables)) batch_z = tf.random.normal([batch_size, z_dim]) with tf.GradientTape() as tape: g_loss = g_loss_fn(generator, discriminator, batch_z, is_training) grads = tape.gradient(g_loss, generator.trainable_variables) g_optimizer.apply_gradients(zip(grads, generator.trainable_variables)) if epoch % 100 == 0: print(epoch, &#x27;d-loss:&#x27;,float(d_loss), &#x27;g-loss:&#x27;, float(g_loss), &#x27;gp:&#x27;, float(gp)) z = tf.random.normal([100, z_dim]) fake_image = generator(z, training=False) img_path = os.path.join(&#x27;images&#x27;, &#x27;wgan-%d.png&#x27;%epoch) save_result(fake_image.numpy(), 10, img_path, color_mode=&#x27;P&#x27;)if __name__ == &#x27;__main__&#x27;: main() datasetload 函数import multiprocessingimport tensorflow as tfdef make_anime_dataset(img_paths, batch_size, resize=64, drop_remainder=True, shuffle=True, repeat=1): # @tf.function def _map_fn(img): img = tf.image.resize(img, [resize, resize]) # img = tf.image.random_crop(img,[resize, resize]) # img = tf.image.random_flip_left_right(img) # img = tf.image.random_flip_up_down(img) img = tf.clip_by_value(img, 0, 255) img = img / 127.5 - 1 #-1~1 return img dataset = disk_image_batch_dataset(img_paths, batch_size, drop_remainder=drop_remainder, map_fn=_map_fn, shuffle=shuffle, repeat=repeat) img_shape = (resize, resize, 3) len_dataset = len(img_paths) // batch_size return dataset, img_shape, len_datasetdef batch_dataset(dataset, batch_size, drop_remainder=True, n_prefetch_batch=1, filter_fn=None, map_fn=None, n_map_threads=None, filter_after_map=False, shuffle=True, shuffle_buffer_size=None, repeat=None): # set defaults if n_map_threads is None: n_map_threads = multiprocessing.cpu_count() if shuffle and shuffle_buffer_size is None: shuffle_buffer_size = max(batch_size * 128, 2048) # set the minimum buffer size as 2048 # [*] it is efficient to conduct `shuffle` before `map`/`filter` because `map`/`filter` is sometimes costly if shuffle: dataset = dataset.shuffle(shuffle_buffer_size) if not filter_after_map: if filter_fn: dataset = dataset.filter(filter_fn) if map_fn: dataset = dataset.map(map_fn, num_parallel_calls=n_map_threads) else: # [*] this is slower if map_fn: dataset = dataset.map(map_fn, num_parallel_calls=n_map_threads) if filter_fn: dataset = dataset.filter(filter_fn) dataset = dataset.batch(batch_size, drop_remainder=drop_remainder) dataset = dataset.repeat(repeat).prefetch(n_prefetch_batch) return datasetdef memory_data_batch_dataset(memory_data, batch_size, drop_remainder=True, n_prefetch_batch=1, filter_fn=None, map_fn=None, n_map_threads=None, filter_after_map=False, shuffle=True, shuffle_buffer_size=None, repeat=None): &quot;&quot;&quot;Batch dataset of memory data. Parameters ---------- memory_data : nested structure of tensors/ndarrays/lists &quot;&quot;&quot; dataset = tf.data.Dataset.from_tensor_slices(memory_data) dataset = batch_dataset(dataset, batch_size, drop_remainder=drop_remainder, n_prefetch_batch=n_prefetch_batch, filter_fn=filter_fn, map_fn=map_fn, n_map_threads=n_map_threads, filter_after_map=filter_after_map, shuffle=shuffle, shuffle_buffer_size=shuffle_buffer_size, repeat=repeat) return datasetdef disk_image_batch_dataset(img_paths, batch_size, labels=None, drop_remainder=True, n_prefetch_batch=1, filter_fn=None, map_fn=None, n_map_threads=None, filter_after_map=False, shuffle=True, shuffle_buffer_size=None, repeat=None): &quot;&quot;&quot;Batch dataset of disk image for PNG and JPEG. Parameters ---------- img_paths : 1d-tensor/ndarray/list of str labels : nested structure of tensors/ndarrays/lists &quot;&quot;&quot; if labels is None: memory_data = img_paths else: memory_data = (img_paths, labels) def parse_fn(path, *label): img = tf.io.read_file(path) img = tf.image.decode_jpeg(img, channels=3) # fix channels to 3 return (img,) + label if map_fn: # fuse `map_fn` and `parse_fn` def map_fn_(*args): return map_fn(*parse_fn(*args)) else: map_fn_ = parse_fn dataset = memory_data_batch_dataset(memory_data, batch_size, drop_remainder=drop_remainder, n_prefetch_batch=n_prefetch_batch, filter_fn=filter_fn, map_fn=map_fn_, n_map_threads=n_map_threads, filter_after_map=filter_after_map, shuffle=shuffle, shuffle_buffer_size=shuffle_buffer_size, repeat=repeat) return dataset 1000epoch之后是这样 后记​ 本来是想每一个经典网络都详细写的，但是感觉这样会导致太专业全是公式也不会有人去仔细看 其实是我不会。结果变成了现在这种类似板子的东西。水博客才是原动力 ​ 终于体会到电脑的苦了，cpu占用率99% 还要开多线程同时爬图片…（虽然现在字都显示不出来了 这里就随便总结一下学习的经验： 代码方面 keras.build(inputs_shape)：这里最好是使用tuple形式表示不然会报奇怪的错，tensorflow和pytorch不同这方面更加严格。 tf.losses： 这个模块里的函数大小写不同功能也是不同的，具体可以看官网，如果用complie建议用大写的函数，自定义loss使用小写的函数 sigmod和softmax： 当’分类’事物不完全相互独立可以使用sigmod否则softmax，softmax一定要onehot model.save：这个因为保存了网络结构只能用在纯自定义网络里，继承类是不行的。 layers.BatchNormalization:：这个函数有一个trainable参数,train=True|None，test=False|0,具体可以看源码说明，但是千万要设置正确原因可参考这里 layers.Flatten与Dense：flatten只是单纯的reshape维度是固定的，Dense还作了一次全连接 网络等方面​ 可以从代码中看出现有的几种网络构建格式。当初我也纠结了许多，最后还是准备使用gan网络的格式，毕竟框架好用是好用，但这是牺牲‘自由’换来的，对后期自主构建网络可能会起到反效果。每个人喜好不同，也不用太参考我的建议。 ​ k折验证等trick是视频里没有讲的（视频参考下面的学习资源），可以自己去看看相关trick。 学习资源我才不是看到Gan可以随机生成老婆才想学Gan的 日月光华的《tensorflow入门学习与实战的》资源弄不到，可惜了免费课程讲的确实好就是太贵了。 就跟着龙书学Gan顺便复习了一遍经典网络，顺便附上李宏毅讲解的Gan网络（每次看完这种视频都感觉概率论白学了，建议李宏毅的可以先看一半再看龙书。 emmm，再附上别人整理的深度学习路线吧 应该不会有人看的完","categories":[{"name":"技术","slug":"技术","permalink":"https://dummerfu.top/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://dummerfu.top/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"keywords":[{"name":"技术","slug":"技术","permalink":"https://dummerfu.top/categories/%E6%8A%80%E6%9C%AF/"}]},{"title":"北斗文献综述","slug":"北斗文献综述","date":"2021-01-18T00:00:00.000Z","updated":"2021-01-18T00:00:00.000Z","comments":true,"path":"p/60871.html","link":"","permalink":"https://dummerfu.top/p/60871.html","excerpt":"","text":"前言​ 我国北斗卫星导航系统是中国自行研制的全球卫星导航系统，现在已经全部组网。北斗也是继GPS、GLONASS之后的第三个成熟的卫星导航系统。北斗卫星导航系统（BDS）和美国GPS、俄罗斯GLONASS、欧盟GALILEO，是联合国卫星导航委员会已认定的供应商。 ​ 北斗卫星导航系统由空间段、地面段和用户段三部分组成，可在全球范围内全天候、全天时为各类用户提供高精度、高可靠定位、导航、授时服务，并且具备短报文通信能力，已经初步具备区域导航、定位和授时能力，定位精度为分米、厘米级别，测速精度0.2米/秒，授时精度10纳秒。 ​ 与GPS系统对比： ​ 1、覆盖范围：北斗导航系统是覆盖我国本土的区域导航系统。覆盖范围东经约70°一140°，北纬5°一55°。GPS是覆盖全球的全天候导航系统。能够确保地球上任何地点、任何时间能同时观测到6-9颗卫星(实际上最多能观测到11颗)。 ​ 2、卫星数量和轨道特性：北斗导航系统是在地球赤道平面上设置2颗地球同步卫星颗卫星的赤道角距约60°。GPS是在6个轨道平面上设置24颗卫星，轨道赤道倾角55°，轨道面赤道角距60°。航卫星为准同步轨道，绕地球一周11小时58分。 ​ 3、定位原理：北斗导航系统是主动式双向测距二维导航。地面中心控制系统解算，供用户三维定位数据。GPS是被动式伪码单向测距三维导航。由用户设备独立解算自位解算在那里而不是由用户设备完成的。为了弥补这种系统易损性，GPS正在发展星际横向数据链技术，使万一主控站被毁后GPS卫星可以独立运行。而“北斗一号”系统从原理上排除了这种可能性，一旦中心控制系统受损，系统就不能继续工作了。 ​ 4、实时性：“北斗一号”用户的定位申请要送回中心控制系统，中心控制系统解算出用户的三维位置数据之后再发回用户，其间要经过地球静止卫星走一个来回，再加上卫星转发，中心控制系统的处理，时间延迟就更长了，因此对于高速运动体，就加大了定位的误差。此外，“北斗一号”卫星导航系统也有一些自身的特点，其具备的短信通讯功能就是GPS所不具备的。 国内研究现状交通运输 1​ 交通运输业属于北斗系统最为核心的民用领域,是深入落实我国核心发展战略的前提条件。 对此,深入研究交通运输业中北斗卫星的导航系统的应用及其展望,对交通强国建设发展有着一定积极意义与现实作用,需得到国内交通运输及相应行业的广泛重视与关注。 道路运输: ​ 通过北斗开发的应用,道路运管部即可通过此平台来进行车辆信息查询,包含着车主位置信息、姓名、电话等,实时化了解行驶车速与方向,以对车辆实际行驶状态进行综合监控。并且利用北斗的高性能能够面向全国范围内自定义某区域车辆,并发布禁行或者路况等信息通知。同时对于运载贵重物品的车辆还可以达到实时全面监控的效果。 在城市或铁路交通方面，通过北斗还可以减少车量等待间隔时间，从而减少运输成本，提高运输效率，交通安全。 海上搜救: 通过报警通信、遇险定位、搜救指挥等各种技术手段，通过北斗卫星船装载终端自动把附带着定位信息的求救短信通过卫星发给岸上的救援队，实现了GPS+海事卫星电话的功能，能够为海上遇险类提供更多报警手段,救援力量科学调度得以有效促进,为开展移动式搜救及现场指挥操作提供了强大的技术支持力量。 信息查询方面： ​ 基于北斗定位，通过对类型、好评等进行筛选。用户通过语音或者屏幕键盘输入加油站，医院等固定地点的信息，迅速地查询目标，其查询的结果可以通过文字或者图像两种形式进行显示，并且使人们可以轻易查询到最短路线、当前距离等信息。 灾害预警​ 北斗卫星导航系统能够发挥精准定位的功能优势，快速确定灾害发生地的精确坐标，并据此划定需要接 收应急预警信息的特定区域，有针对性地向精准群体发布应急预警信息。并且卫星导航系统可以提供冗余的通信渠道，以向人们传播有关即将发生的危险和灾难风险的关键安全信息和警告消息。 2 其他方面 智能定位器： ​ 主要通过在北斗高精度的定位功能，配合移动端app的指令实现一系列定位功能，比如智能放牧 3,宠物防丢器设计 4,远程定位老年痴呆患者 5，共享物流箱 6，清洁机器人 7等。 智能小车环境测试系统 8： ​ 由于GPS成本提高，智能车成本使用十分高昂，但是基于北斗导航的导航定位、无线通信及低成本传感器的环境检测智能车系统，不仅提高了对复杂环境检测的能力，并且还降低了环境检测智能车的推广使用成本。 农作物生长监控 9： 农业生产中，农作物成长周期较长，其生长情况受到天气条件、土壤、水源以及施肥量等多种因素影 响。 在此过程中，针对农作物进行必要监控，强化种植过程管理工作，具有重要意义和价值。而BDS 系统的应用，可利用卫星定位技术发现目标农作物， 期间利用传感器装置传递农作物生长、病虫害信息。提升对农作物成长环境的技术监控，并对生产管理决策提供技术支撑。 基于5G和北斗的自动化： 基于 5G+ 北斗的高精度定位系统 10建成后，大幅降低北斗高精度应用的 技术门槛和成本门槛，推动北斗高精度应用从专业领域走向 大众，并为城市规划、国 土 测 绘 、地 籍 管理、 城乡建设、 环境监测、 防灾减灾、 交通监控等各类不同行业用户和应用提供毫米级、 厘米级、分米级的高精度位置支持，为国家经济和社会发 展注入新的活力。 通过5G的低延时和北斗的高精度定位和地图，自动驾驶，清洁机器等一系列概念重新被重视 11 12。 总结及展望​ 由以上研究方面可见，国内对于北斗的交通运输研究已经区域成熟，但是灾害预警方面可能限于现有灾害预警准确度的原因还是不够深入，有待开发，此外，北斗与5G结合已经是必然趋势，随着5G的发展和北斗的问世，机械自动化必然更能够趋于成熟。可以相信在未来，凭借北斗与5G无人机等小型便携机械的优势会被有效的发挥，为人民提供便利。 参考文献 1. 杨秀锋.浅谈北斗卫星导航系统在交通运输行业的应用及展望.科技风,2020, (3):89. &#8617; 2. 罗政.北斗卫星导航系统在应急预警信息发布中的应用.数字通信世界,2020, (2):27-28. &#8617; 3. 王雅琴,曾逸翔,肖遥.基于北斗导航的智能牧导系统.农村经济与科技,2020, 31(22):4-6. &#8617; 4. 汤致远,沈亮,余子龙等.基于北斗的智能宠物防丢器设计.物联网技术,2020, 10(11):89-90,93. &#8617; 5. 吴建章,周缤灿,黄文乐.北斗卫星智能远程定位老年痴呆患者科学与财富.2016, (3):433-433. &#8617; 6. 阮宏梁,卜晓斌,鲍秋杰.北斗定位智能共享物流箱系统设计.物流工程与管理.2020, 42(9):76-78. &#8617; 7. 基龙鑫,袁练,荣忆宁等,于5G和北斗系统的高楼清洁机器人的设计和研究.通信电源技术,2020, 37(15):35-37. &#8617; 8. 张树宁,王尔申,徐嵩等.基于北斗卫星导航的环境检测智能车系统设计.电子器件,2020, 43(5):1168-1172. &#8617; 9. 郑巍 ,黄盛杰 ,陈智.北斗卫星导航系统在农业领域上的发展现状分析.农业装备技术,2020, 46(4):4-6. &#8617; 10. 李金柱.一种基于5G+北斗的高精度定位系统.信息通信,2020, (1):85-86. &#8617; 11. 宋思颖,徐纪曈,傅嘉滢 .“北斗3卫星系统+人工智能”构建未来智慧交通解决方案.中国航天.2018, (5):50-55. &#8617; 12. 沈沛鸿 ,董强.一种基于5G+北斗的自动驾驶解决方案.信息通信,2020, (6):21-22. &#8617; 13. 于利娟,宋荣权,曹伟.基于北斗系统的银行智能提款箱锁研究数码设计(上).2020, 9(3):60-61. &#8617;","categories":[{"name":"随笔","slug":"随笔","permalink":"https://dummerfu.top/categories/%E9%9A%8F%E7%AC%94/"}],"tags":[{"name":"杂项","slug":"杂项","permalink":"https://dummerfu.top/tags/%E6%9D%82%E9%A1%B9/"}],"keywords":[{"name":"随笔","slug":"随笔","permalink":"https://dummerfu.top/categories/%E9%9A%8F%E7%AC%94/"}]},{"title":"pyecharts模板","slug":"pyecharts模板","date":"2021-01-18T00:00:00.000Z","updated":"2021-08-24T00:00:00.000Z","comments":true,"path":"p/57635.html","link":"","permalink":"https://dummerfu.top/p/57635.html","excerpt":"","text":"pyecharts ThemeLIGHT = &quot;light&quot;DARK = &quot;dark&quot;WHITE = &quot;white&quot;CHALK: str = &quot;chalk&quot;ESSOS: str = &quot;essos&quot;INFOGRAPHIC: str = &quot;infographic&quot;MACARONS: str = &quot;macarons&quot;PURPLE_PASSION: str = &quot;purple-passion&quot;ROMA: str = &quot;roma&quot;ROMANTIC: str = &quot;romantic&quot;SHINE: str = &quot;shine&quot;VINTAGE: str = &quot;vintage&quot;WALDEN: str = &quot;walden&quot;WESTEROS: str = &quot;westeros&quot;WONDERLAND: str = &quot;wonderland&quot;HALLOWEEN: str = &quot;halloween&quot; 个人比较喜欢chalk，infographic，purple-passion 常用配置项官网文档 初始化配置项class InitOpts( # 图表画布宽度，css 长度单位。 width: str = &quot;900px&quot;, # 图表画布高度，css 长度单位。 height: str = &quot;500px&quot;, # 图表 ID，图表唯一标识，用于在多图表时区分。 chart_id: Optional[str] = None, # 渲染风格，可选 &quot;canvas&quot;, &quot;svg&quot; # # 参考 `全局变量` 章节 renderer: str = RenderType.CANVAS, # 网页标题 page_title: str = &quot;Awesome-pyecharts&quot;, # 图表主题 theme: str = &quot;white&quot;, # 图表背景颜色 bg_color: Optional[str] = None, # 远程 js host，如不设置默认为 https://assets.pyecharts.org/assets/&quot; # 参考 `全局变量` 章节 js_host: str = &quot;&quot;, # 画图动画初始化配置，参考 `global_options.AnimationOpts` animation_opts: Union[AnimationOpts, dict] = AnimationOpts(),) 工具箱配置项class ToolboxOpts( # 是否显示工具栏组件 is_show: bool = True, # 工具栏 icon 的布局朝向。 # 可选：&#x27;horizontal&#x27;, &#x27;vertical&#x27; orient: str = &quot;horizontal&quot;, # 工具栏组件离容器左侧的距离。 # left 的值可以是像 20 这样的具体像素值，可以是像 &#x27;20%&#x27; 这样相对于容器高宽的百分比， # 也可以是 &#x27;left&#x27;, &#x27;center&#x27;, &#x27;right&#x27;。 # 如果 left 的值为&#x27;left&#x27;, &#x27;center&#x27;, &#x27;right&#x27;，组件会根据相应的位置自动对齐 pos_left: str = &quot;80%&quot;, # 工具栏组件离容器右侧的距离。 # right 的值可以是像 20 这样的具体像素值，可以是像 &#x27;20%&#x27; 这样相对于容器高宽的百分比。 pos_right: Optional[str] = None, # 工具栏组件离容器上侧的距离。 # top 的值可以是像 20 这样的具体像素值，可以是像 &#x27;20%&#x27; 这样相对于容器高宽的百分比， # 也可以是 &#x27;top&#x27;, &#x27;middle&#x27;, &#x27;bottom&#x27;。 # 如果 top 的值为&#x27;top&#x27;, &#x27;middle&#x27;, &#x27;bottom&#x27;，组件会根据相应的位置自动对齐。 pos_top: Optional[str] = None, # 工具栏组件离容器下侧的距离。 # bottom 的值可以是像 20 这样的具体像素值，可以是像 &#x27;20%&#x27; 这样相对于容器高宽的百分比。 pos_bottom: Optional[str] = None, # 各工具配置项，参考 `global_options.ToolBoxFeatureOpts` feature: Union[ToolBoxFeatureOpts, dict] = ToolBoxFeatureOpts(),)# 通常只用一个.set_global_opts(toolbox_opts=opts.ToolboxOpts(is_show=True)) visualmap_opts可以实现某一段一种颜色，相比较markline更简洁，在不连续数据中更常用。 max, min在自定义颜色可以不用 如果要自定义颜色，需要is_piecewise=True，并且每一段都要设置颜色 也可以自定义颜色和透明度，range_color,range_opacity 附上颜色渐变的好网站webgradients和mycolor visualmap_opts=opts.VisualMapOpts( # type_=&quot;color&quot;, max_=220, min_=0, dimension=1, # range_color=[&#x27;#F2FEDC&#x27;,&#x27;#E7E750&#x27;], is_piecewise=True, pieces=[&#123;&#x27;min&#x27;:80,&#x27;max&#x27;:120,&#x27;color&#x27;:&#x27;black&#x27;&#125;]), Graphgraph的点必须唯一，不然会报index的错误 模板： links=[]nodes=[]def get_graph_node(nodename, position, category,symbol_size,symbol): one_node=opts.GraphNode( name=nodename, x=position[0], y=position[1], category=category, symbol_size=symbol_size, symbol=symbol, label_opts=opts.LabelOpts(is_show=True,position=&#x27;inside&#x27;,color=&#x27;white&#x27;), ) return one_nodedef get_graph_link(source,target,value,width): node_link=opts.GraphLink( source=source,target=target,value=int(value), linestyle_opts=opts.LineStyleOpts( # 线宽 width=int(width), # 线的弯曲程度 curve=0.3, # 线的透明度 opacity=&quot;0.7&quot;, # 线的颜色 color=&#x27;grey&#x27;, ), label_opts=opts.LabelOpts( is_show=False, ) ) return node_linkgraph=( ct.Graph( init_opts=opts.InitOpts( bg_color=&#x27;white&#x27;, ) ) .add( &quot;&quot;,nodes,links, categories=category, repulsion=800, edge_symbol=[&#x27;circle&#x27;,&#x27;arrow&#x27;], layout=&#x27;none&#x27;, edge_length=500, itemstyle_opts=opts.ItemStyleOpts(opacity=0.7) ) .set_global_opts(toolbox_opts=opts.ToolboxOpts(is_show=True)))graph.render_notebook()# graph.render(&#x27;1.html&#x27;) Radar模板 radar=( ct.Radar(init_opts=opts.InitOpts(width=&quot;860px&quot;, height=&quot;720px&quot;,bg_color=&quot;white&quot;)) .add_schema( schema=[ opts.RadarIndicatorItem(name=&quot;主因子1&quot;, max_=2,min_=-2), opts.RadarIndicatorItem(name=&quot;主因子2&quot;, max_=3,min_=-2), opts.RadarIndicatorItem(name=&quot;主因子3&quot;, max_=0,min_=-2), opts.RadarIndicatorItem(name=&quot;主因子4&quot;, max_=0,min_=-1), opts.RadarIndicatorItem(name=&quot;主因子5&quot;, max_=0,min_=-0.1), ], # 改变位置，但是有Page的话可以去掉 center=[&quot;50%&quot;, &quot;50%&quot;], # 分隔线设置，感觉对雷达图没用 splitarea_opt=opts.SplitAreaOpts( is_show=True, areastyle_opts=opts.AreaStyleOpts(opacity=1) ), # 文本设置 textstyle_opts=opts.TextStyleOpts(color=&quot;black&quot;), ) .add( series_name=&quot;Huskies15&quot;, data=hus15, # 线型设置 linestyle_opts=opts.LineStyleOpts(color=&quot;#CD0000&quot;,width=2,opacity=0.5), # 区域颜色设置 areastyle_opts=opts.AreaStyleOpts(opacity=0.5,color=&#x27;#CD0000&#x27;), ) .add( series_name=&quot;Oppen15&quot;, data=opp15, linestyle_opts=opts.LineStyleOpts(color=&quot;#5CACEE&quot;,width=2,opacity=0.5), areastyle_opts=opts.AreaStyleOpts(opacity=0.5,color=&#x27;#5CACEE&#x27;), ) .set_series_opts(label_opts=opts.LabelOpts(is_show=True,color=&#x27;black&#x27;)) .set_global_opts( title_opts=opts.TitleOpts(title=&quot;队伍能力比较&quot;), legend_opts=opts.LegendOpts() ) .render(&quot;radar_chart.html&quot;)) Line要注意的是x轴的type，不光是list，list里面还必须是有序的python int类型或string类型 numpy.int32都识别不了 如果x是数字，要指定type_=value(默认是category) from pyecharts import options as optsfrom pyecharts import charts as cty=[6.106,6.037,5.934,5.967,5.955,6.024,6.031,5.825,5.740,5.700]year=[&#x27;1920&#x27;,&#x27;1930&#x27;,&#x27;1940&#x27;,&#x27;1950&#x27;,&#x27;1960&#x27;,&#x27;1970&#x27;,&#x27;1980&#x27;,&#x27;1990&#x27;,&#x27;2000&#x27;,&#x27;2010&#x27;]line=( ct.Line(init_opts=opts.InitOpts(bg_color=&#x27;white&#x27;)) .add_xaxis(xaxis_data=year) .add_yaxis( series_name=i, y_axis=y, # 连线是否平滑 is_smooth=False, # 是否显示点 is_symbol_show=True, # 点的形状样式 symbol=&quot;circle&quot;, # 大小 symbol_size=10, # 点上方标签的样式 label_opts=opts.LabelOpts(is_show=True,font_size=13,position=&quot;top&quot;, color=&quot;#2F4858&quot;), # 点的风格样式 # 放上去是否显示坐标 tooltip_opts=opts.TooltipOpts(is_show=True), ) .set_global_opts( title_opts=opts.TitleOpts( title=&quot;1920-2020 music score trend &quot;, pos_top=&quot;5%&quot;, pos_left=&quot;center&quot;, title_textstyle_opts=opts.TextStyleOpts(font_size=16,color=&#x27;#2F4858&#x27;), ), xaxis_opts=opts.AxisOpts( boundary_gap=True, axisline_opts=opts.AxisLineOpts(is_show=False), # axistick_opts=opts.AxisTickOpts( # is_show=True, # length=25, # ), splitline_opts=opts.SplitLineOpts( is_show=True ), ), yaxis_opts=opts.AxisOpts( type_=&quot;value&quot;, position=&quot;left&quot;, # max_=6.2, #min_=5.5, ), toolbox_opts=opts.ToolboxOpts(is_show=True), legend_opts=opts.LegendOpts(is_show=False), ))line.render_notebook() Scatter和line差不多，就少了几个配置项（linestyle,areastyle..) scatter=( ct.Scatter(init_opts=opts.InitOpts(bg_color=&#x27;white&#x27; ,theme=ThemeType.LIGHT)) .add_xaxis( xaxis_data=pinf_list[:3500], ) .add_yaxis( series_name=&quot;&quot;, y_axis=artist_list[:3500], symbol_size=10, label_opts=opts.LabelOpts(is_show=False), tooltip_opts=opts.TooltipOpts(is_show=True), markline_opts=opts.MarkLineOpts( data=[ opts.MarkLineItem(x=0.5,symbol=[&#x27;None&#x27;,&#x27;None&#x27;])], linestyle_opts=opts.LineStyleOpts(width=2,type_=&#x27;dashed&#x27;,color=&#x27;#2F4858&#x27;), ), ) .set_global_opts( title_opts=opts.TitleOpts( title=&quot;Influencer and Genre affect&quot;, pos_left=&quot;center&quot;, title_textstyle_opts=opts.TextStyleOpts(color=&quot;#ED6087&quot;, font_size=16), ), xaxis_opts=opts.AxisOpts( type_=&quot;value&quot;, splitline_opts=opts.SplitLineOpts(is_show=True), boundary_gap=False, ), yaxis_opts=opts.AxisOpts( type_=&quot;value&quot;, position=&quot;left&quot;, axislabel_opts=opts.LabelOpts(is_show=False), axistick_opts=opts.AxisTickOpts(is_show=False), splitline_opts=opts.SplitLineOpts(is_show=False), ), toolbox_opts=opts.ToolboxOpts(is_show=True), legend_opts=opts.LegendOpts(is_show=False), )) Bar2DBarbar=( ct.Bar(init_opts=opts.InitOpts(bg_color=&#x27;white&#x27;)) .add_xaxis(xaxis_data=idx) .add_yaxis( &#x27;进港航班数&#x27;, jg, # 点上方标签的样式 label_opts=opts.LabelOpts(is_show=True,font_size=13,position=&quot;top&quot;), # 放上去是否显示坐标 tooltip_opts=opts.TooltipOpts(is_show=True), ) .set_global_opts( title_opts=opts.TitleOpts( title=&quot;8.22 日进港航班数&quot;, pos_top=&quot;5%&quot;, pos_left=&quot;center&quot;, title_textstyle_opts=opts.TextStyleOpts(font_size=16), ), xaxis_opts=opts.AxisOpts( boundary_gap=True, axisline_opts=opts.AxisLineOpts(is_show=False), splitline_opts=opts.SplitLineOpts( is_show=True ), ), toolbox_opts=opts.ToolboxOpts(is_show=True), legend_opts=opts.LegendOpts(is_show=False), ))bar.render_notebook() 3Dbarbar3d=( ct.Bar3D(init_opts=opts.InitOpts(bg_color=&#x27;white&#x27;)) .add( series_name=&quot;&quot;, data=data, xaxis3d_opts=opts.Axis3DOpts(name=&#x27;xxx&#x27;,type_=&quot;value&quot;, data=v0), yaxis3d_opts=opts.Axis3DOpts(name=&#x27;xxx&#x27;,type_=&quot;value&quot;, data=d), zaxis3d_opts=opts.Axis3DOpts(type_=&quot;value&quot;), ) .set_global_opts( visualmap_opts=opts.VisualMapOpts( max_=1, range_color=[ &quot;#313695&quot;, &quot;#4575b4&quot;, &quot;#74add1&quot;, &quot;#abd9e9&quot;, &quot;#e0f3f8&quot;, &quot;#ffffbf&quot;, &quot;#fee090&quot;, &quot;#fdae61&quot;, &quot;#f46d43&quot;, &quot;#d73027&quot;, &quot;#a50026&quot;, ], ) ))bar3d.render_notebook() Heatmapheatmap=( ct.HeatMap(init_opts=opts.InitOpts(bg_color=&#x27;white&#x27;)) .add_xaxis(t) .add_yaxis( series_name=&quot;&quot;, yaxis_data=[str(i) for i in range(1,150)], value=y, # label_opts=opts.LabelOpts(is_show=True,font_size=13,position=&quot;top&quot;), ) .set_global_opts( title_opts=opts.TitleOpts(title=&quot;蓄车池数量对决策的影响&quot;,pos_left=&#x27;40%&#x27;), xaxis_opts=opts.AxisOpts( name=&#x27;时间&#x27;, type_=&quot;category&quot;, splitarea_opts=opts.SplitAreaOpts( is_show=True, areastyle_opts=opts.AreaStyleOpts(opacity=1) ), ), yaxis_opts=opts.AxisOpts( name=&#x27;蓄车池数量&#x27;, type_=&quot;category&quot;, splitarea_opts=opts.SplitAreaOpts( is_show=True, areastyle_opts=opts.AreaStyleOpts(opacity=0.5) ), ), visualmap_opts=opts.VisualMapOpts( max_=1, range_color=[ &quot;#e0f3f8&quot;, &quot;#ffffbf&quot;, &quot;#fee090&quot;, ], ), toolbox_opts=opts.ToolboxOpts(is_show=True) ))heatmap.render(&#x27;./pic/question2.html&#x27;)s Sunshine# data是这种json格式color=[&quot;#f89a80&quot;,&quot;#f37674&quot;,&quot;#e75b68&quot;,&quot;#ef5a78&quot;,&quot;#03a653&quot;,&quot;#9ea718&quot;,&quot;#d0b24f&quot;,&quot;#8eb646&quot;,&quot;#faef07&quot; &quot;#8f1c53&quot;,&quot;#b34039&quot;,&quot;#8b6439&quot;,&quot;#a2b029&quot;,&quot;#718933&quot;]data=[ &#123;&#x27;name&#x27;:&#x27;star Five&#x27;, &quot;itemStyle&quot;: &#123;&quot;color&quot;: &quot;#da0d68&quot;&#125;, &#x27;children&#x27;:[ &#123; &#x27;name&#x27;:&#x27;helpful_votes&#x27;, # itemstyle #&#x27;value&#x27; &#x27;children&#x27;:[] &#125;, &#123; &#x27;name&#x27;:&#x27;unhelpful_votes&#x27;, &#x27;children&#x27;:[] &#125; ] &#125;, &#123; &#x27;name&#x27;:&#x27;star Four&#x27;, &quot;itemStyle&quot;: &#123;&quot;color&quot;: &quot;#da1d23&quot;&#125;, &#x27;children&#x27;:[ &#123; &#x27;name&#x27;: &#x27;helpful_votes&#x27;, # itemstyle # &#x27;value&#x27; &#x27;children&#x27;: [] &#125;, &#123; &#x27;name&#x27;: &#x27;unhelpful_votes&#x27;, &#x27;children&#x27;: [] &#125; ] &#125;, &#123; &#x27;name&#x27;:&#x27;star Three&#x27;, &quot;itemStyle&quot;: &#123;&quot;color&quot;: &quot;#c94a44&quot;&#125;, &#x27;children&#x27;:[ &#123; &#x27;name&#x27;: &#x27;helpful_votes&#x27;, # itemstyle # &#x27;value&#x27; &#x27;children&#x27;: [] &#125;, &#123; &#x27;name&#x27;: &#x27;unhelpful_votes&#x27;, &#x27;children&#x27;: [] &#125; ] &#125;, &#123; &#x27;name&#x27;:&#x27;star Two&#x27;, &quot;itemStyle&quot;: &#123;&quot;color&quot;: &quot;#f7a128&quot;&#125;, &#x27;children&#x27;:[ &#123; &#x27;name&#x27;: &#x27;helpful_votes&#x27;, # itemstyle # &#x27;value&#x27; &#x27;children&#x27;: [] &#125;, &#123; &#x27;name&#x27;: &#x27;unhelpful_votes&#x27;, &#x27;children&#x27;: [] &#125; ] &#125;, &#123; &#x27;name&#x27;:&#x27;star One&#x27;, &quot;itemStyle&quot;: &#123;&quot;color&quot;: &quot;#ad213e&quot;&#125;, &#x27;children&#x27;:[ &#123; &#x27;name&#x27;: &#x27;helpful_votes&#x27;, # itemstyle # &#x27;value&#x27; &#x27;children&#x27;: [] &#125;, &#123; &#x27;name&#x27;: &#x27;unhelpful_votes&#x27;, &#x27;children&#x27;: [] &#125; ] &#125;, ]c = ( ct.Sunburst( init_opts=opts.InitOpts(width=&quot;1000px&quot;, height=&quot;600px&quot;,bg_color=&#x27;white&#x27;) ) .add( &quot;&quot;, data_pair=data, highlight_policy=&quot;ancestor&quot;, radius=[0, &quot;95%&quot;], sort_=&quot;null&quot;, levels=[ &#123;&#125;, &#123; &quot;r0&quot;: &quot;15%&quot;, &quot;r&quot;: &quot;35%&quot;, &quot;itemStyle&quot;: &#123;&quot;borderWidth&quot;: 2&#125;, &quot;label&quot;: &#123;&quot;rotate&quot;: &quot;tangential&quot;&#125;, &#125;, &#123;&quot;r0&quot;: &quot;35%&quot;, &quot;r&quot;: &quot;70%&quot;, &quot;label&quot;: &#123;&quot;align&quot;: &quot;right&quot;&#125;&#125;, &#123; &quot;r0&quot;: &quot;70%&quot;, &quot;r&quot;: &quot;72%&quot;, &quot;label&quot;: &#123;&quot;position&quot;: &quot;outside&quot;, &quot;padding&quot;: 3, &quot;silent&quot;: False&#125;, &quot;itemStyle&quot;: &#123;&quot;borderWidth&quot;: 3&#125;, &#125;, ], ) .set_global_opts(title_opts=opts.TitleOpts(title=&quot;Sunburst-官方示例&quot;)) .set_series_opts(label_opts=opts.LabelOpts(formatter=&quot;&#123;b&#125;&quot;)) .set_global_opts(toolbox_opts=opts.ToolboxOpts(is_show=True)) .render(&quot;hairdryer.html&quot;) ) 页面布局Page本来只能垂直叠加，但是根据初始化的width，height也可以达到水平布局的效果，但是通过Page.DraggablePageLayout布局可以实现任意位置、大小布局，简称神器。 但是如果有背景色图表重叠时会相互覆盖，此时效果不如grid，背景透明时，图表覆盖则不会产生问题，优于grid。 # 使用浏览器打开渲染后的 .html 文件，默认为 render.html。拖拉/调整图表位置和大小，当调整到一个适合# 的布局时，点击左上方的 `Save Config` 按钮，下载 chart_config.json 配置文件，假设存放位置为# ~/chart_config.json。再次渲染图表并指定其布局配置# Warning: 请注释掉上面的的所有渲染代码，就是以下三行。因为 html 已经生成，并不需要再重新渲染一遍。page=ct.Page(layout=ct.Page.DraggablePageLayout)page.add(Radar15(),Radar9())page.render(&#x27;render.html&#x27;)# render.html：第一步生成的原 html 文件# chart_config.json：第二步下载的配置文件# my_new_charts.html：新 html 文件路径Page.save_resize_html(&quot;render.html&quot;, cfg_file=&quot;path/chart_config.json&quot;, dest=&quot;my_new_charts.html&quot;)# 或者可以使用 json 数据# cfg_dict 为 json 文件里面的内容Page.save_resize_html(&quot;render.html&quot;, cfg_dict=cfg_dict, dest=&quot;my_new_charts.html&quot;)# Question：能否复用渲染模板？# Answer: 可以的，渲染配置 json 数据中是以 chart_id 来作为一个图形的唯一标识符的，所以只需要在# 第一次渲染的时候指定 chart_id 就可以啦。# example:# bar = bar_datazoom_slider()# bar.chart_id = &quot;1&quot;# line = line_markpoint()# line.chart_id = &quot;2&quot;# pie = pie_rosetype()# pie.chart_id = &quot;3&quot;# 然后只要以后都按这个 chart_id 来渲染图表的时候，你的布局配置就可以复用啦。# cat chart_config.json，会发现 chart_id 是固定的啦。 Grid​ grid布局一定需要一个有坐标轴的图，如果都没有坐标轴，比如玫瑰图，可以通过设置center参数实现布局 对于不需要初始就显示完美图的可以使用Page.DraggablePageLayout手动调整位置，更为方便。","categories":[{"name":"随笔","slug":"随笔","permalink":"https://dummerfu.top/categories/%E9%9A%8F%E7%AC%94/"}],"tags":[{"name":"pyecharts","slug":"pyecharts","permalink":"https://dummerfu.top/tags/pyecharts/"}],"keywords":[{"name":"随笔","slug":"随笔","permalink":"https://dummerfu.top/categories/%E9%9A%8F%E7%AC%94/"}]},{"title":"hexo-sakura 安装twikoo","slug":"hexo-sakura 安装twikoo","date":"2021-01-08T00:00:00.000Z","updated":"2021-01-08T00:00:00.000Z","comments":true,"path":"p/64378.html","link":"","permalink":"https://dummerfu.top/p/64378.html","excerpt":"","text":"why twikoo ？ 操作简单，配置方便小白友好。valine各种自己改配置 基于腾讯云开发，安全有保障。 valine和artitalk兼容性并不是很好… valine v1.4.0停止更新！！！ hexo-sakura 安装twikoo老样子，先附上官网 其实官网已经详细的不能再详细了…所以这篇文章主要是面向sakura主题还不会自己魔改的小白 搭建twikoo分两步： 在本地的博客主题中配置 Twikoo； 在腾讯云配置环境和云函数； 腾讯云配置官网说的已经很清楚了，不再赘述 本地配置config.yml主题下的_config.yml增加类似和valine增加enable项 代表启用twikoo，envid是腾讯云里面的环境里面那个envId 一般是appname-xxx这种形式 head.ejs在mashiro_option那一串增加一项 mashiro_option.t_envID = &quot;&lt;%= theme.twikoo.envId %&gt;&quot;; comment.ejs这里的valine本来是honjun改php的残留，可以顺便删了 Sakura-app.js创建函数TO() 这里有个坑，el如过有的话会加载失败，把官网瞄点id是tcomment改成twikoo就行了，神奇的bug 然后在pjax渲染里面增加相应的函数初始化就行了 因为每个页面都可能要渲染所以要加两个 最后在footer加上twikoo的cdn就行了我是引用的本地，你换成 https://cdn.jsdelivr.net/npm/twikoo@0.6.0/dist/twikoo.all.min.js 就行了，位置在script那一块 完结撒花​ 可以享受评论了，虽然限流量，但是官网说10000次/日以内是免费的，所以这个看个人吧。我很放心😜。 其他进阶设置比如表情cdn啊之类的，官网都已经在设置里配置好了很方便。","categories":[{"name":"随笔","slug":"随笔","permalink":"https://dummerfu.top/categories/%E9%9A%8F%E7%AC%94/"}],"tags":[{"name":"主题美化","slug":"主题美化","permalink":"https://dummerfu.top/tags/%E4%B8%BB%E9%A2%98%E7%BE%8E%E5%8C%96/"}],"keywords":[{"name":"随笔","slug":"随笔","permalink":"https://dummerfu.top/categories/%E9%9A%8F%E7%AC%94/"}]},{"title":"hexo-sakura踩坑记","slug":"hexo-sakura踩坑记","date":"2021-01-08T00:00:00.000Z","updated":"2021-01-08T00:00:00.000Z","comments":true,"path":"p/52131.html","link":"","permalink":"https://dummerfu.top/p/52131.html","excerpt":"","text":"hexo-sakura 踩坑记关于主题建议clone其他人已经美化好的(直接白嫖美化好的不香吗 本人用的是Sakura主题并且已经自己魔改了许多，也碰到许多坑，故在此记录 说说板块|artitalkartitalk官网 已经说的很全了这里补充几点： 官网说：如果要把valine和artitalk同时打开用在一个leancloud应用就行了 但是！！！我出错了，一个应用里面还是报appId can’t redefine（就是artitalk调用的是valine的id）很神奇。 解决方法： 根据这篇文章来 似乎是廖雪峰的？？原文没找到 但是本蒟蒻太菜了，没有看懂（里面还说了一种解决方法是可以放一个app里面用同一个class？怎么和官网不大一样…） 将valine和artitalk分开，二者不同时使用（判断下window.loaction.pathname!=’/shuoshuo/‘就行了） 其他操作可参考： Artitalk说说心情发布页面（个性定制）这个里面部署是老版本的建议看美化部分就行了 然后发现valine安全性不高，我选择twikoo😂喂喂，还不到一个小时吧 可以参考hexo-sakura部署twikoo 1 . 比如这个博主的 &#8617; 页首滑动swiper个人无聊的魔改 swiper官网 基本上也是跟着来就行了，具体可以用js实现多图索引随机头图这些效果，不过官网似乎有现成的api？我没仔细研究） lazyload个人觉得这个比较坑 swiper的lazyload和普通的imglazyload不一样，具体样式也可以看官网 不过坑点来了： 坑点1// 网上大多数initswiper是这样的var myswiper=new Swiper(&#x27;.swiper-container&#x27;,&#123; autoplay: false, lazyLoadingInPrevNext: true, lazyLoadingInPrevNextAmount:1, lazyLoading: true, // lazyLoadingOnTransitionStart : true, direction:&#x27;horizontal&#x27;, navigation:&#123; nextEl: &#x27;.bg-next&#x27;, prevEl: &#x27;.bg-pre&#x27;, &#125;, loop: true, &#125;)// 但是lazyload应该这样定义var myswiper=new Swiper(&#x27;.swiper-container&#x27;,&#123; autoplay: false, // 不同点！！！ lazy:&#123; lazyLoadingInPrevNext: true, lazyLoadingInPrevNextAmount:1, lazyLoading: true, &#125;, // lazyLoadingOnTransitionStart : true, direction:&#x27;horizontal&#x27;, navigation:&#123; nextEl: &#x27;.bg-next&#x27;, prevEl: &#x27;.bg-pre&#x27;, &#125;, loop: true, &#125;) 不然你会发现怎么样有不会加载出图片的 坑点2如果图片还没加载出来 别忘记设置图片的height属性，因为默认是0 代码高亮首先如果你的代码高亮不了十分正常maybe？因为我初始化就是这样的 你需要在根目录的__config下面把highlight 全部改为false，因为这里的highlight是hexo的highlight而不是highlightjs的，之后就按照网上的配置就行了。","categories":[{"name":"随笔","slug":"随笔","permalink":"https://dummerfu.top/categories/%E9%9A%8F%E7%AC%94/"}],"tags":[{"name":"主题美化","slug":"主题美化","permalink":"https://dummerfu.top/tags/%E4%B8%BB%E9%A2%98%E7%BE%8E%E5%8C%96/"}],"keywords":[{"name":"随笔","slug":"随笔","permalink":"https://dummerfu.top/categories/%E9%9A%8F%E7%AC%94/"}]},{"title":"今天我就是马克思","slug":"我就是马克思","date":"2021-01-06T00:00:00.000Z","updated":"2021-01-06T00:00:00.000Z","comments":true,"path":"p/15308.html","link":"","permalink":"https://dummerfu.top/p/15308.html","excerpt":"","text":"练习题三：简答题简述马克思主义的三个组成部分及其相互关系？（第2页） ​ 马克思主义哲学，马克思主义政治经济学和科学社会主义是马克思主义的三个基本组成部分，有机统一并构成了马克思主义基本理论的主体内容。 哲学基本问题是什么？（第20-21页） ​ 哲学基本问题是思维和存在的关系问题，存在和思维的关系问题包括两个方面的内容：其一，存在和思维究竟谁是世界的本源，即物质和精神何者是第一性，何者是第二性的问题。其二，存在和思维有没有统一性，即思维能否正确认识存在的问题。 简述意识对物质的反作用（第26页） ​ 意识对物质的反作用就是能动作用，主要表现在： 意识活动具有目的性和计划性。人在认识客观世界、尊重客观规律的同时还总是根据一定的目的和要求去确定反应什么、不反应什么，以及怎样反应，从而表现出主体的选择性。人的整个实践过程，就围绕意识活动所构建的目标和蓝图来进行的。 意识活动具有创造性。人的意识不仅采取感觉，知觉、表象等形式，反映事物的外部形象，而且运用概念、判断、推理等形式对感性材料进行加工制作和选择建构，在思维中构造一个现实中所没有的理想世界。 意识具有指导实践改造客观世界的作用。意识的能动作用不限于从实践中形成一定的思想，形成活动的目的、计划、方法等观念的东西，更重要的是在于以这些观念的东西为指导，通过实践使之一步步变成客观现实。 意识具有调控人的行为和生理活动的作用。 简述如何处理主观能动性和客观规律性的关系（27-28） 尊重客观规律是正确发挥主观能动性的前提。 只有充分发挥主观能动性，才能正确认识和利用客观规律。 尊重事物发展的客观规律性与发挥人的主观能动性是辩证统一的，实践是客观规律性和主观能动性统一的基础。 为什么说对立统一规律是唯物辩证法的实质和核心？（第37页） 对立统一规律揭示了事物普遍联系的根本内容和变化发展的内在动力，从根本上回答了事物为什么会发展的问题。 对立统一规律是 贯穿量变质变规律、否定之否定规律以及唯物辩证法基本范畴 的中心线索，也是理解这些的钥匙。 对立统一规律提供了人们认识世界和改造世界的根本方法–矛盾分析法。 简述量变与质变的辩证关系（第40页） 量变是质变的必要准备，没有量变的积累，质变就不会发生。 质变是量变的必然结果。单纯的量变不会永远持续下去，量变达到一定程度必然引起质变。 量变和质变是相互渗透的。一方面量变过程中有阶段性和局部性的部分质变，另一方面，在质变过程中也有旧质在量上的收缩与新质在量上的扩张。 量变与质变是相互依存，相互贯通的，量变引起质变，在新质的基础上又开始新的量变。 简述如何坚持对立统一规律“两点论”和“重点论”的统一？（教材第39页） 两点论是指在分析事物的矛盾时不仅要看到矛盾双方的对立而且要看到统一，不仅看到主要矛盾还要看到次要矛盾 重点论是指要着重把握主要矛盾，并以此作为解决问题的出发点。 两点论和重点论的统一要求我们，看问题既要全面地看又要看主流、发展大势。 简述实践在认识活动中的决定作用？（第61-63页） 实践是认识的来源：认识的内容是在实践活动的基础上产生和发展的。 实践是认识发展的动力：实践的需要 推动认识的产生，推动人类的科学发现和技术发明，推动人类的思想进步和理论创新。 实践是认识的目的。 实践是检验认识真理性的唯一标准：认识是否具有真理性，既不能从认识本身得到证实，也不能从认识对象中得到回答，只有在实践中才能得到验证。 简述感性认识和理性认识的辩证统一关系？（第68-69页） 感性认识有待于发展和深化为理性认识：感性认识是认识的初级阶段，是对事物外部联系的认识，因而感性认识还不是完全的认识。 理性认识依赖于感性认识：感性认识是认识过程的起点，是达到理性认识的必经阶段，没有感性认识就没有理性认识。 感性认识与理性认识相互渗透，相互包含，二者没有绝对分明的界限。 感性认识和理性认识的辩证同一关系是在实践的基础上形成的，也需要在实践中发展。 简述实践与认识的辩证运动及规律。（第72页） 实践与认识的辩证运动，是一个由感性认识到理性认识，又由理性认识到实践的飞跃，是实践，认识再实践，再认识，循环往复至无穷的辩证发展过程。 简述价值的基本特征。（第86-88页） 价值具有主体性、客观性、多维性和社会历史性四个基本特性。他们是价值本质的表现。 价值的主体性：价值主体性是指价值直接同主体相联系，始终以主体为中心，其一，价值关系的形成依赖于主体的存在。其二价值关系的形成依赖于主体的创造。 价值的客观性：价值的客观性是指在一定条件下客体对于主体的意义不依赖于主体的主观意识而存在。 价值的多维性：是指价值每个主体的价值关系具有多样性，同一客体对于主体的不同需要会产生不同的价值。 价值的社会历史性：主体和客体的不断变化决定了价值的社会历史性的特点。 为什么物质资料生产方式是社会历史发展的决定力量？（第108页） 物质生产活动及生产方式是人类社会赖以存在和发展的基础，是人类进行其他一切活动的首要前提。 物质生产活动及生产方式决定着社会的结构、性质和面貌。 物质生产活动及生产方式的变化发展决定整个社会历史的变化发展，决定社会形态从低级向高级的更替和发展。 简述社会意识的相对独立性的具体表现。（第112-113页） 社会意识与社会 存在发展的不完全同步性和不平衡性。 社会意识内部各种形式之间的相互影响 及各自具有的历史继承性。 社会意识对社会存在能动的反作用，这是社会意识性相对独立的突出表现。 简述生产关系一定要适合生产力状况的规律。（第118-120页） 生产力和生产关系是社会生产不可分割的两个方面 生产力决定生产关系 生产关系对生产力具有能动的反作用 社会基本矛盾在历史发展中的作用主要表现在哪些方面？（第131-132页） 社会基本矛盾是社会发展的根本动力，主要作用表现在： 生产力是社会基本矛盾运动中最基本的动力因素，是人类社会发展进步的最终决定力量。 生产力是社会进步的根本内容，是衡量社会进步的根本尺度。 社会基本矛盾特别是生产力和生产关系的矛盾，决定着社会中其他矛盾的存在和发展。 经济基础和上层建筑的矛盾也会影响和制约生产力和生产关系矛盾。 社会基本矛盾具有不同的表现形式和解决方式，并从根本上影响和促进社会形态的变化和发展。 简述科学技术在社会发展中的作用（第144-147页） 科技革命推动了社会历史的进步，并对生产方式产生了深刻的影响。 科学技术对我们的生活方式产生了巨大的影响，促进了思维方式的变革，成为了社会发展的重要动力。 简述商品的二因素（使用价值和价值）之间的对立统一关系（162-163） 对立性：要获得商品的价值就必须放弃商品的使用价值，要得到商品的使用价值就不能得到商品的价值。商品生产者生产商品并不是为了取得使用价值，而是为了取得价值。 统一性：作为商品，必须同时具有使用价值和价值两个因素，使用价值是价值的物质承担者，价值寓于使用价值之中。一种物品如果没有使用价值就是无用之物，即使人们为他付出了大量劳动，也没有价值。 简述人民群众在创造历史过程中的决定作用？（第150-151页） 人民群众是社会历史实践的主体，是历史的创造者：人民群众的总体意愿和行动代表了历史发展的方向，人民群众的社会事件最终决定了历史发展的结局。 人民群众是社会物质财富的创造者。 人民群众是社会精神财富的创造者。 人民群众是社会变革的革命力量。 简述价值规律及其作用（第166-169页） 价值的规律：商品的价值量由生产商品的社会必要劳动时间决定，商品交换以价值量为基础，按照等价交换的原则进行。 价值规律的作用表现在： 自发的调节生产资料和劳动力在社会各生产部门之间的分配比例 自发的刺激社会生产力的发展 自发的调节社会收入的分配 简述经济全球化的表现。（第228-230页） 国际分工进一步深化 贸易全球化 金融全球化 企业生产经营全球化 简述什么是辩证否定观？（第40页） 否定是事物的自我否定， 是事物内部矛盾运动的结果。 否定是事物发展的环节，是旧事物向新事物的转变，是旧质到新质的飞跃。 否定是新旧事物联系的环节，新事物孕育产生于旧事物，新旧事物是通过否定环节联系起来的。 辩证否定的实质是扬弃，即新事物对旧事物既批判又继承，既克服其消极因素又保留其积极因素。 简述劳动二重性与商品二因素之间的关系（第162-163页） 生产商品的具体劳动创造商品的使用价值，抽象劳动形成商品的价值。具体劳动和抽象劳动是同一劳动的两种规定。任何一种劳动，一方面是特殊的具体劳动，另一方面是一般的抽象劳动这就是劳动的二重性。正是劳动的二重性决定了商品的二因素。","categories":[{"name":"随笔","slug":"随笔","permalink":"https://dummerfu.top/categories/%E9%9A%8F%E7%AC%94/"}],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://dummerfu.top/tags/%E9%9A%8F%E7%AC%94/"}],"keywords":[{"name":"随笔","slug":"随笔","permalink":"https://dummerfu.top/categories/%E9%9A%8F%E7%AC%94/"}]},{"title":"pandas基本操作","slug":"pandas基本操作","date":"2020-12-20T00:00:00.000Z","updated":"2021-08-07T00:00:00.000Z","comments":true,"path":"p/40218.html","link":"","permalink":"https://dummerfu.top/p/40218.html","excerpt":"","text":"pandas 基础属性pandas.series自带了三个’’属性”，管理分类的cat，管理字符串的str，管理时间的dt str pd.series.str：返回的是一个series的字符串列，但是复杂函数还是要apply写。 pd.series.str.contain(str)：查找列是否包含该str，包含则返回行。 pd.series.str.len()：返回该series列所有str的长度。 dt首先要把格式转为datatime格式 pd.to_datetime(“series”) pd.series.dt：返回的是一个series的datetime类型列，可以做datatime类型操作 pd.series.dt:有几个内置属性 hour：返回datetime的时 day: 返回datetime的天 second：返回datetime的秒 quarter：返回第几季度 month：返回月 year：返回年 datatime类型还可以进行加减操作哦 pandas 读写文件1read_csv读取txt | tsv*等类似类型文件也可以用，sep设置为空格 | \\t 就行了 当然pandas的series也可以写入或读取 Pandas.read_csv(filepath_or_buffer,sep,header,dtype,engine,converters,skiprows,skipfooter,nrows)2 filepath:：读取的文件地址或url地址 sep：str类型，默认’,’ 指定分隔符。如果不指定参数，则会尝试使用默认值逗号分隔。分隔符长于一个字符并且不是‘\\s+’,将使用python的语法分析器。并且忽略数据中的逗号，并且可以用正则匹配！ header：指定第几行作为列名(忽略注解行)，如果没有指定列名，默认header=0; 如果指定了列名header=None dtype：例子： {‘a’: np.float64, ‘b’: np.int32} 指定每一列的数据类型，a,b表示列名 engine：使用的分析引擎。可以选择C或者是python，C引擎快但是Python引擎功能更多一些。并且如果sep本意不是正则可以用这个来区别 比如：sep=’::’没有engine时会被识别为正则，本意是数据确实就是以::分隔的，用engine=python来区别 converters：置指定列的处理函数，可以用”序号”也可以使用“列名”进行列的指定 skiprows：默认值 None 需要忽略的行数即header的后xx行开始，，或需要跳过的行号列表（从0开始） 如果是一个csv文件，excel打开默认header为第一行，要从第15行开始读取则设置skiprows=14，但这样header也会被跳过，所以一般是skiprows=[i for i in rang(1,14)] skipfooters：从文件尾部开始忽略 nrows：从文件中只读取多少数据行，需要读取的行数（从文件头开始算起） 对应的是Dataframe.to_csv()，参数都类似， # 设置index=None，写入时除去index，这样正常读入就没有unnamed了df.to_csv(xxx,index=None) 写入txt这个要提一下，因为很多人都会忽略to_csv的sep参数。 csv本质是：分割的txt文件，所以实质上pandas也兼容了写入txt # 常用模板如下# 只需声明分割符就行了df.to_csv(&#x27;path&#x27;,sep=&#x27;\\t&#x27;,header=None,index=None) read_excelPandas.read_excel(io,sheet_name,sep,header,dtype,engine,converters,skiprows,skipfooter,nrows) 与read_csv参数基本相同，这里只介绍额外增加的参数 io：文件类对象 ，pandas Excel 文件或 xlrd 工作簿。该字符串可能是一个URL。URL包括http，ftp，s3和文件。例如，本地文件可写成file://localhost/path/to/workbook.xlsx sheet_name：默认是sheetname为0，返回多表使用sheetname=[0,1]，若sheetname=None是返回全表 。注意：int/string返回的是dataframe，而none和list返回的是dict of dataframe，表名用字符串表示，索引表位置用整数表示； read_jsonPandas.read_json(filepath_or_buffer,orient,header,type,dtype,convert_dates,keep_default_dates,numpy,encoding,lines) orient：预期的json字符串格式，orient的设置有以下几个值： ‘split’ : dict like {index -&gt; [index], columns -&gt; [columns], data -&gt; [values]} ‘records’ : list like [{column -&gt; value}, … , {column -&gt; value}] ‘index’ : dict like {index -&gt; {column -&gt; value}} ‘columns’ : dict like {column -&gt; {index -&gt; value}} ‘values’ : just the values array type：返回的格式(series or frame), 默认是 ‘frame’ dtype：同csv，列的数据类型 convert_dates：解析日期的列列表；如果为True，则尝试解析类似日期的列，默认值为True keep_default_dates：default True。如果解析日期，则解析默认的日期样列 numpy：直接解码为numpy数组。默认为False；仅支持数字数据，但标签可能是非数字的。 encoding：json编码 lines：将每行读取为一个json对象 read_htmlPandas.read_html(io,match,flavor,header,index_col,skiprows,attrs,parse_dates) io：接收网址、文件、字符串。网址不接受https，尝试去掉s后爬去 match：正则表达式，返回与正则表达式匹配的表格 flavor：html解释器 index_col：同csv skip_rows：同csv attrs：属性，比如 attrs = {‘id’: ‘table’}不是很懂 parse_dates：解析日期 pandas查询数据pandas.loc无敌好吧，我只能说无敌 dataframe.iloc和loc相似，不过只能接受整数的传参。而loc可以接受整数，字符串，bool的传参（注意先行后列就行了） 缺点就是必须按照顺序索引（比如muti index 必须先level 1再索引level 2），而且如果要按行操作需要reset index Dataframe.loc 初始表格 tuples = [ (&#x27;cobra&#x27;, &#x27;mark i&#x27;), (&#x27;cobra&#x27;, &#x27;mark ii&#x27;), (&#x27;sidewinder&#x27;, &#x27;mark i&#x27;), (&#x27;sidewinder&#x27;, &#x27;mark ii&#x27;), (&#x27;viper&#x27;, &#x27;mark ii&#x27;), (&#x27;viper&#x27;, &#x27;mark iii&#x27;)]index = pd.MultiIndex.from_tuples(tuples)values = [[12, 2], [0, 4], [10, 20], [1, 4], [7, 1], [16, 36]]df = pd.DataFrame(values, columns=[&#x27;max_speed&#x27;, &#x27;shield&#x27;], index=index)df 数据提取# 返回dataframedf.loc[[&#x27;viper&#x27;],:]# 返回seriesdf.loc[&#x27;viper&#x27;,:]# 间隔取(这样只能返回dataframe# 不加[]会报错df.loc[[&#x27;cobra&#x27;,&#x27;viper&#x27;],:] # 连续取值(只能返回dataframe)# 行切片则是前闭后闭，列切片也是前闭后闭（不然怎么取全列df.loc[&#x27;cobra&#x27;:&#x27;sidewinder&#x27;,&#x27;max_speed&#x27;:&#x27;temp&#x27;]# 只有单列查询才会返回series否则其他的全是dataframe# seriesdf.loc[&#x27;cobra&#x27;:&#x27;viper&#x27;,&#x27;shield&#x27;]# dataframedf.loc[&#x27;cobra&#x27;:&#x27;sidewinder&#x27;,[&#x27;shield&#x27;]]df.loc[[&#x27;cobra&#x27;,&#x27;viper&#x27;],&#x27;max_speed&#x27;:&#x27;shield&#x27;] bool类型传参dataframe.loc[bool]和dataframe[bool]不一样！！！ dataframe.loc[bool]是遍历行，dataframe[bool]是遍历所有元素，但是当index是muti index时不能用index # 列的bool值要带入新的loc的行部分df.loc[df.loc[:,&#x27;shield&#x27;]&gt;30,:]# 等效df[df.shield&gt;30]# 行的bool值要带入新的loc的列部分df.loc[(&#x27;cobra&#x27;,&#x27;mark ii&#x27;)]&gt;3df.loc[:,df.loc[(&#x27;cobra&#x27;,&#x27;mark ii&#x27;)]&gt;3]# 逻辑 判断# |是or，&amp;是and每个条件要括号括起df.loc[:,(df.loc[(&#x27;cobra&#x27;,&#x27;mark ii&#x27;)]&gt;3)&amp;(df.loc[(&#x27;cobra&#x27;,&#x27;mark ii&#x27;)]&lt;3)]# isin([xx,xx]) 是否存在# 通过~取反相当于!df.loc[:,df.loc[(&#x27;cobra&#x27;,&#x27;mark ii&#x27;)].isin([3,4,5])]df.loc[:,~(df.loc[(&#x27;cobra&#x27;,&#x27;mark ii&#x27;)].isin([3,4,5]))]# serise.str.contain(xxx|xx|x)# 不完全匹配字符串 设置valuesdf.loc[[&#x27;viper&#x27;, &#x27;sidewinder&#x27;], [&#x27;shield&#x27;]] = 50 dataframe.xs()函数pandas.DataFrame.xs(key,axis=0,level=None,drop_level=True) 4 key: 行index或列的name axis: index或columns level: 指定行的level等级 iter遍历 遍历整行:Dataframe.iterrows(): 遍历全部列:Dataframe.iteritems(): pandas数据处理nan的处理dataframe.fillna()DataFrame.fillna(value=None,method=None,axis=None,inplace=False, limit=None,downcast=None) value：将nan填充为的value method：填充方法bfill：向后寻找第一个非空进行填充, ffill：向前寻找第一个非空进行填充 axis：填充的坐标轴 inplace是否赋值到原dataframe 数据类型转换# 读入转换pd.read_csv(&#x27;xxx&#x27;,dtype=&#123;&#x27;columns_name&#x27;:columns_type,&#x27;xxx&#x27;:xx&#125;)# 强制转换df.column_name.astype(int) dataframe.dropna()DataFrame.dropna(axis=0, how=’any’,thresh=None, subset=None, inplace=False*) axis：axis=0丢掉包含nan值的行，axis=1则为丢掉列 how：决定是是所有行或列包含nan丢弃(all)还是只有一个就丢弃(any) dataframe.isnull()pandas.isnull(obj) 判断obj类里面所有值是否为null，返回bool类型 pandas.dropDataFrame.drop(labels=None,axis=0, index=None, columns=None,level=None,inplace=False, errors=’raise’ labels：字符串或数组，需要删去的对应关键字 axis：axis默认为0 ，即默认删除行 index：index=labels等价于labels=labels，axis=0 inplace：是否替换原数据 dataframe.reset_index()dataframe.reset_index(level=None,drop=False,inplace=False,col_level=0,col_fill=’’) level:从index 移除的level index，默认全部移除index重新标号 inplace：是否替换原数据 如果列是muti columns 则选择插入到第几个level col_fill:选择列插入时其他列的命名，默认repeat dataframe.rename()dataframe.rename(mapper=None,index=None,columns=None,axis=None,copy=True,inplace=False,level=None,errors=’ignore’) mapper:函数或字典 index：如果axis=0 则mapper作用与index columns：axis=1 mapper作用与columns axis:指定坐标轴 inplace：是否替换原数据 该函数也能用在series上 pandas 数据统计dataframe.info()函数Dataframe.info(verbose=None,buf=None,max_col=None,memory_usage=None,null_counts=None) verbose:是否返回全部信息 是否输出到文件，默认输出到屏幕 dataframe.describe()函数管他的，用默认参数就完事了 还有series.describe()，和这个类似 dataframe.value_counts()函数Dataframe.value_counts(subset=None,normalize=False,sort=True,ascending=False,dropna=True) subset: 需要计数的列 normalize：返回频数（False）还是比例（True） sort：是否排序 ascending：是否降序排列（默认降序） dropna:是否不统计na 返回的是去重后对应的key和value series.value_counts()和这个类似不过没有了subset而已。 但是奇怪的是用Dataframe会报错很神奇。 pandas 数据整理concatpandas.concat(objs=[],axis=0,join=outer,ignore_index=False) opt：需要合并的series或dataframe axis：合并的轴，1为列（横向拼接），0按为行（向下拼接） join：合并的方式 ignore_index: 是否忽略index，如果忽略新的index将按0，1…编号 感觉这一个万能，merge只能两个合并，这个可以多个合并 mergepandas.DataFrame.merge(left,right,how=’inner’, on=None, left_index=False,right_index=False,sort=False, validate=None) left :dataframe right: dataframe或者series （需要被merge的对象） left_index: 新index用左边的 right_index: 新index用右边的 how: left, right, outer, inner, cross, 默认inner， left：按左边关键字合并 right：按右边关键字合并 outer：取并集关键字合并，没有的关键字用na替代 inner：取交集关键字合并 cross： 笛卡尔积合并 sort：是否排序 validate：str，optional 对应关系 还有些append什么的就算了。 #df 1 # a b# 0 foo 1# 1 bar 2# df 2# a c# 0 foo 3# 1 cz 4df1.merge(df2, how=&#x27;inner&#x27;, on=&#x27;a&#x27;)# a b c# 0 foo 1 3 groupbyDataFrame.groupby(by=None, axis=0, level=None, as_index=True, sort=True, group_keys=True,observed=False, dropna=True) by:通过什么group 可以是function，list，dic… axis: 按行还是按列group，（通常是行 sort:是否按key值排序，默认排序 dropna：是否丢弃na值，默认丢弃 返回的是一个dataframe！！！ 当然series也有groupby，参数相同，只是返回的是一个series。 在pandas读取文件的过程中，最常出现的问题，就是中文问题与格式问题，希望当你碰到的时候，可以完美的解决。 applypd.DataFrame.apply(func,axis=0,raw=False,result_type=None,args=(),kwargs axis：0|index 传入按每行，1|columns依次按每列值传入（通常是axis=1来用） #dfA B0 4 91 4 92 4 9# axis=0 按行传入的值分别为[4,4,4],[9,9,9]# axis=1 按列传入的值分别为[4,9],[4,9],[4,9] raw：False 代表传入函数为一个Series，True代表传入函数的是一个np.arrary result_type：expand，reduce，broadcast，当axis=1才有效 进度条虽然官网上搜索不到了，但还可以用 from tqdm import tqdm tqdm.pandas(desc=&#x27;xxx&#x27;)# 与正常apply一样传参data.progress_apply() 最后附上pyechart可视化官方文档，配合pandas使用3^ Reference 1. 本文因上次训练拉跨了，遂有感而发，pandas基础学习主要是看这个视频，顺便附上pandas官网链接 &#8617; 2. 读取文件参数基本参考了：https://www.cnblogs.com/happymeng/p/10481293.html &#8617; 3. 上次训练又拉跨了，pyechart也该总结一下了…/(ㄒoㄒ)/~~ &#8617; 4. 索引部分参考 &#8617;","categories":[{"name":"随笔","slug":"随笔","permalink":"https://dummerfu.top/categories/%E9%9A%8F%E7%AC%94/"}],"tags":[{"name":"文档","slug":"文档","permalink":"https://dummerfu.top/tags/%E6%96%87%E6%A1%A3/"}],"keywords":[{"name":"随笔","slug":"随笔","permalink":"https://dummerfu.top/categories/%E9%9A%8F%E7%AC%94/"}]},{"title":"分赌注问题","slug":"分赌注问题","date":"2020-12-20T00:00:00.000Z","updated":"2020-12-20T00:00:00.000Z","comments":true,"path":"p/466.html","link":"","permalink":"https://dummerfu.top/p/466.html","excerpt":"","text":"分赌注问题问题背景​ 水平相同的两个赌徒A，B，约定先胜t局的人赢得赌注，在赌博的某时刻，两赌徒终止赌博，此时A胜r局，B胜s局，应如何分配赌注？ ​ 这个问题通常称为点数问题，是嗜好赌博的法国学者梅雷于1654年向数学家帕斯卡提出的。为此帕斯卡和法国数学家费马于1654年7月到10月之间进行了一系列通信讨论赌注分配问题，成为了概率论的起源 ​ 当荷兰数学家惠更斯到巴黎时，听说费马和帕斯卡在研究赌注问题，他也进行了研究，并在1657年撰写了《论赌博问题中的计算》一书，提出数学期望，推动了概率论的发展。 ​ 1713年，瑞士数学家伯努利的《猜度术》一书的面世，标示着概率论已成为数学的一个重要分支。 假设 显然赌注最少会在t-max(r,s)局结束，因为r，s相对大小不影响问题分析的结构，所以不妨假设r&gt;s 依据获胜概率来分赌注，即若记两人分别取得最后胜利的概率为$P_A$, $P_B$ ,且$P_A$ +$P_B$ = 1,则两人应按照$P_A : P_B$的比例分赌注。 没有人作弊，故假设两个人分别每一次博弈获胜的概率均为0.5，且博弈相互独立。 事件 事件说明 t 获得奖金最少需要获胜的次数 r A已经获胜的次数 s B已经获胜的次数 i 比赛结束时的比赛次数 $P_A$ A先获胜t局的概率 $P_B$ B先获胜t局的概率 $P_a$ A获胜一局的概率 $P_b$ B获胜一局的概率 M 总奖金数 问题分析显然，最少t-r局结束，最多2*t-r-s-1局结束所以 $i\\in [t-r,2t-r-s-1)$ 设第i场博弈后,A获胜$P{A(i)}=C{i-1}^{t-r-1} P_a^{t-r-1}P_b^{i-1-(t-r-1)} *P_a$ 将$Pa=P_b=0.5$带入化简得：$P{A(i)}=0.5^iC{i-1}^{t-r-1}$ 对其求和$P_A=\\sum{i=t-r}^{2t-r-s-1}P_{A(i)}$， 假设A，B每一局获胜概率相同，先赢得18局的人赢得赌注，并假设A胜10局且B胜7局的时候终止赌博，则有: \\begin{cases} t=18\\\\ r=10\\\\ s=7\\\\ P_a=0.5\\\\ P_b=0.5\\\\ P_A+P_B=1\\\\ P_{A(i)}=C_{i-1}^{t-r-1} P_a^{t-r-1}P_b^{i-1-(t-r-1)} *P_a\\\\ P_A=\\sum_{i=t-r}^{2t-r-s-1}P_{A(i)} \\end{cases}计算得P~A理论值~=0.7596588134765625，故A应拿走$M * P_A$的奖金，B拿走剩下的奖金 不妨设产生随机数为1则认为单局赌博A获胜，以A获胜频率/仿真次数视为概率可得仿真结果如下表 仿真次数 100 1000 1万 10万 A获胜频率 0.74 0.75 0.7633 0.76064 代码计算理论值概论代码#-*- coding:utf-8 -*-# @Author : Dummerfu# @Contact : https://github.com/dummerchen # @Time : 2020/12/20 12:35import numpy as npfrom scipy.special import perm,combt=18r=10s=7def P_a(x): s1=pow(0.5,x) s2=comb(x-1,t-r-1) print(&#x27;s1:%lf s2:%lf&#x27; %(s1,s2)) return s1*s2if __name__ == &quot;__main__&quot;: P_A=0 for i in range(t-r,2*t-r-s): print(&#x27;i:&#x27; ,i) P_A=P_A+P_a(i) print(P_A) 仿真代码#-*- coding:utf-8 -*-# @Author : Dummerfu# @Contact : https://github.com/dummerchen # @Time : 2020/12/20 12:55import matplotlib as mplimport numpy as npfrom matplotlib import pyplot as pltmpl.rcParams[&#x27;font.sans-serif&#x27;] = &#x27;SimHei&#x27;mpl.rcParams[&#x27;axes.unicode_minus&#x27;] = Falset=18r=10s=7if __name__ == &quot;__main__&quot;: Echo=[100,1000,10000,100000,1000000] for echo in Echo: print(&#x27;echo:&#x27;,echo) tot_A=0 tot_B=0 for i in range(echo): tempr=r temps=s for j in range(0,2*t-r-s+20): rad=np.random.randint(0,2) if rad==1: tempr+=1 else: temps+=1 if tempr==t: tot_A+=1 break if temps==t: tot_B+=1 break print(&#x27;tot_A:%d tot_B:%d P_A:%lf P_B:%lf&#x27; %(tot_A,tot_B,tot_A/echo,tot_B/echo))","categories":[{"name":"杂集","slug":"杂集","permalink":"https://dummerfu.top/categories/%E6%9D%82%E9%9B%86/"}],"tags":[{"name":"杂集","slug":"杂集","permalink":"https://dummerfu.top/tags/%E6%9D%82%E9%9B%86/"}],"keywords":[{"name":"杂集","slug":"杂集","permalink":"https://dummerfu.top/categories/%E6%9D%82%E9%9B%86/"}]},{"title":"时间序列","slug":"时间序列","date":"2020-12-19T00:00:00.000Z","updated":"2020-12-19T00:00:00.000Z","comments":true,"path":"p/65094.html","link":"","permalink":"https://dummerfu.top/p/65094.html","excerpt":"","text":"时间序列时间序列是按时间顺序排列的、随时间变化且相互关联的数据序列。分析时间序 列的方法构成数据分析的一个重要领域，即时间序列分析。 时间序列根据所研究的依据不同，可有不同的分类。 1．按所研究的对象的多少分，有一元时间序列和多元时间序列。 2．按时间的连续性可将时间序列分为离散时间序列和连续时间序列两种。 3．按序列的统计特性分，有平稳时间序列和非平稳时间序列。如果一个时间序列的概率分布与时间t无关，则称该序列为严格的（狭义的）平稳时间序列。如果序列的 一、二阶矩存在，而且对任意时刻t满足： （1）均值为常数 （2）协方差为时间间隔 的函数。 则称该序列为宽平稳时间序列，也叫广义平稳时间序列。我们以后所研究的时间序列主 要是宽平稳时间序列。 4．按时间序列的分布规律来分，有高斯型时间序列和非高斯型时间序列。 （1）均值为常数 （2）协方差为时间间隔$\\tau$的函数。 则称该序列为宽平稳时间序列，也叫广义平稳时间序列。我们以后所研究的时间序列主要是宽平稳时间序列。 时间序列的组成部分时间序列预测技术就是通过对预测目标自身时间序列的处理，来研究其变化趋势 的。一个时间序列往往是以下几类变化形式的叠加或耦合。 我们常认为一个时间序列可以分解为以下四大部分： （1）长期趋势变动。它是指时间序列朝着一定的方向持续上升或下降，或停留在 某一水平上的倾向，它反映了客观事物的主要变化趋势。 （2）季节变动。 （3）循环变动。通常是指周期为一年以上，由非季节因素引起的涨落起伏波形相 似的波动。 （4）不规则变动。通常它分为突然变动和随机变动。 三种时间序列模型设 设:\\\\ \\begin{cases} T_t &长期趋势项\\\\ S_t &季节变动趋势项\\\\ C_t &循环变动趋势项\\\\ R_t &随机干扰项 \\end{cases} 加法模型 y_t=T_t+S_t+R_t+C_t 乘法模型 Y_t=T_t*S_t*C_t*R_t 混合模型 \\begin{cases} Y_t=T_t*S_t+R_t\\\\ Y_t=S_t+T_t*C_t*R_t\\\\ \\end{cases} \\\\ Y_y是观测目标的观测记录,\\ E(R_t)=0 \\quad E(R_t^2)=\\sigma^2可以说这三个模型是适用于所有时间序列的 移动平均法​ 移动平均法是根据时间序列资料逐渐推移，依次计算包含一定项数的时序平均数，以反映长期趋势的方法。当时间序列的数值由于受周期变动和不规则变动的影响，起伏较大，不易显示出发展趋势时，可用移动平均法，消除这些因素的影响，分析、预测序列的长期趋势。移动平均法有简单移动平均法，加权移动平均法，趋势移动平均法等。 简单移动平均法 设观测序列 y_1..y_T,取移动平均项N","categories":[{"name":"随笔","slug":"随笔","permalink":"https://dummerfu.top/categories/%E9%9A%8F%E7%AC%94/"}],"tags":[{"name":"数模","slug":"数模","permalink":"https://dummerfu.top/tags/%E6%95%B0%E6%A8%A1/"}],"keywords":[{"name":"随笔","slug":"随笔","permalink":"https://dummerfu.top/categories/%E9%9A%8F%E7%AC%94/"}]},{"title":"【翻译】基于时频分析和卷积神经网路的模式识别","slug":"基于时频分析和卷积神经网路的模式识别","date":"2020-12-10T00:00:00.000Z","updated":"2020-12-10T00:00:00.000Z","comments":true,"path":"p/13246.html","link":"","permalink":"https://dummerfu.top/p/13246.html","excerpt":"","text":"Spectrum Analysis and Convolutional Neural Network for Automatic Modulation RecognitionYuan Zeng, Meng Zhang, Fei Han, Yi Gong , Senior Member, IEEE, and Jin Zhang AbstractRecent convolutional neural networks (CNNs)-based image processing methods have proven that CNNs are good at extracting features of spatial data. In this letter, we present a CNN-based modulation recognition framework for the detection of radio signals in communication systems……略 Introduction​ 在通信系统中,发射的信号通常会被用不同的方式调节来达到数据更高效的传输.作为信号侦察和信号解调的中间过程,自动调制识别(AMR)能提供信号调制后的信息,并在各个领域中起到了关键的作用。 ​ 在过去几十年里,已经有很多算法为AMR打下了基础,总的来说分为两大类：基于似然方法(likelihood based method)和特征匹配的方法。似然方法用了概率理论、假设检验理论和合适的决策标准(prob-ability theory, hypothesis testing theory and a proper decision criterion)来解决问题[1].而特征匹配方法通过特征提取和分类来解决问题.在特征匹配方法中识别的表现与人工设置的特征数量成正比,各种统计特征如瞬时振幅,频率相位已经被用到调制分类识别中,如高阶统计(HOS)[2],网络循环稳态特征曲线图[3].关于分类的过程(the classification process),目前存在的分类器已经有决策树(decision tree)[4]和机器学习算法，例如支持向量机(support vector machine)[5],神经网络(artificial neural network)[6]。 ​ 近来，深度学习作为一个强有力的机器学习方法，已经成功在图像识别和语音识别等中取得了成功。基于深度学习的方法是基于多层非线性处理单元的连接来做到特征的提取和转换.它也能自动优化提取的特征来达到分类误差最小.深度学习也被应用于调制识别。论文[7]概述了深度学习在无线电信号处理中的新兴应用，并使用GNU无线电生成了具有同相和正交(IQ)信息的调制信号的开放数据集，用于调制识别。O’Sheaet[8]等人研究了卷积神经网络(CNN)对数据集的适应性，并比较了所提出的CNN与基于专家循环矩特征的方法的识别性能(the expert cyclic moment features based methods.)。 后来，论文根据中的数据对CNN，残差网络，深度解析，长短期记忆网络神经网络(CNN-LSTM)进行了比较，实验结果表明调制识别不受到网络深度的限制。 ​ 此外，论文[10]提出了一种预处理信号表示，该信号利用IQ信息和调制信号的HOS特征来提高其呈现的深度学习架构的识别性能。 ​ CNNs在提取空间数据的特征取得了显著的效果比如图像处理中的图像分类、语义分割,利用图像的光谱特征进行调制识别等方面。论文[11]使用ambiguity function(AF)把图像作为信号表示，并使用栈式自动编码器[12]执行调制识别。这个使用spectral correlation function(SCF)作为signal representation和deep belief network (DBN)作为分类器来达到自动识别调制类型的方法广受好评[13]。本文提出了一种对调制信号进行时频分析的方法，利用短时傅立叶变换将一维信号转换为二维谱图图像，并设计一个CNN网络架构进行自动调制识别。我们把这个算法命名为spectrum CNN (SCNN)。此外我们使用高斯滤波来降噪。我们将这种方法称为SCNN2。我们利用公共数据集[7]和11种常用的调制类型对所提方法的识别性能进行评估，并将SCNN2与[8]和[10]方法进行识别精度的比较。此外我们还将评估三个方法的效果：使用基于CNN来比较用短时傅里叶变换图片，AF图片，SCF图片的性能差别。并从空间复杂度、学习参数和每个信号的在实验中的训练时间等方面计算了复杂度。 TIME-FREQUENCY ANALYSIS AND NOISE REDUCTIONTime-Frequency Analysis ​ 我们来考虑一个简单只由一个发射器(transmitter)，通道(channal)，接收器(receiver)的通讯系统(Fig. 1.),设s(t)表示要发送到接收方的传输符号，首先使用调制函数F将传输符号s(t)转换为传输信号，然后该信号通过通信信道h(t)传输到接收机。设y(t)表示传输符号s(t)在接收端的观测信号，将接收信号y(t) 给定为y(t) = x(t)+v(t)，其中$x(t)=F(s(t))*h(t)$为接收到的干净信号，v(t) 是the additive white Gaussian noise(AWGN，高斯白噪)。已知观测信号y(t)，调制识别的目的是预测调制函数F，从而提供从观测信号y(t)估计s(t)的调制信息(thus to provide modulation information for estimating the transmitted symbol s(t) from the observed signal y(t).)。设y(n)表示时间采样指标n处的离散观测信号。 y(n)可以通过在时间$\\frac{n}{fs}$采样连续时间信号y(t)来获得，即$y(n)= y(t)| t = \\frac{n}{f_s}$，并且$n \\in (-\\infty,\\infty)$。 ​ 本文，我们使用时频图作为观察到的信号随时间变化的频率谱的视觉表示。通过计算观测信号的短时离散傅里叶变换(STFT)的平方幅值，得到了谱图。设w(·)表示长度为J的窗口函数，K为窗口位移。利用短时傅立叶变换将观测信号加窗并转换到频域，即 Y(f,m)=\\sum_{n=mK+1}^{mK+J} y(n)w(n-mk)e^{-jw_f(n-mk)}\\quad,(1)​ 其中Y(f,m)是frequency bin index f和discrete-time frame index m处的DFT系数并且在f处的离散频率变量为$w_f=\\frac{2\\pi f}{J}$。频谱图为$\\tilde{Y}(f,m)=|Y(f,m)|^2$。$\\tilde{Y}(f,m)$是Y (n)的时频混合表示，因为$\\tilde{Y} (f,m)$上的每个位置对应于频率和时间上的一个点。 Noise reduction​ 附加噪声v(t)会严重影响调制识别的性能。由于发射的是基带信号，而噪声的功率谱密度与频率无关并且均匀分布于整个频域，用高斯滤波器 直接 对谱图图像进行降噪，只能得到模糊的图像，frequency rejection的能力有限。我们这里，在进行时频分析之前，使用低通滤波器来降低信号y(t)的噪声。为了降低观测信号的噪声，我们设计了一个高斯滤波器，即x(n)=y(n)G(n)，其中x(n)是滤波后的信号，$G(n)=\\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{n^2}{2}}$ CONVOLUTIONAL NEURAL NETWORK FOR MODULATION RECOGNITION ​ Fig. 2.展示了我们提出的CNN架构，这是一个具有多层非线性的神经网络，它们能很好的表示频谱图特征与调制方法之间的映射关系这种非线性的分类函数。(which is a neural network with many levels of non-linearities allowing them to represent a highly non-linear classification function that maps spectrogram features to modulation methods)。神经网络由一个输入层，4个卷积层组成，并且前三个卷积层还包含最大池化层(max-pooling)。卷积层后还连接着一个全连接层和Softmax层。该神经网络采用ReLU作为激活函数。输入图像的维数是(100,100,3),卷积层的filter个数分别是64，32，12，8，维数都是3X3，padding和stride都是1。池化层的pooling size都是2X2。全连接层包含128个神经元。这种网络架构的设计和图片分类中的推荐参数设置比如filter，filter size， the numbers oflayer 参考了[8]和[10]实验。之后，通过对不同的参数进行多次实验，比较它们的识别精度，确定网络架构。网络的输出是频谱图图像的调制方法。此外，网络使用随机梯度下降(SGD)来减小交叉熵损失函数14: W=argmin_w \\frac{1}{N}\\sum_{i=1}^{N}\\mathcal{L}(w;x^i,t^i)其中$N$是样本数量，$t^i$是正确的labels，$x^i$​​是预测的labels EXPERIMENTSData​ 这个实验使用RadioML2016.10a[7]作为基本数据集。它有11种被广泛应用于离散和连续二进制的实际通信系统中的调制方法：BPSK, QPSK, 8PSK, 16QAM, 64QAM, BFSK, CPFSK, PAM4, WB-FM, AM-SSB and AM-DSB。该数据集考虑20种从-20 dB到18 dB的不同的信噪比(SNRs)，每个调制模式每个信噪比有1000个信号(1000 signals per modulation mode per SNR.)。每个信号由128个包含实部和虚部的样本组成。 ​ 本论文号通过基于帧的处理转换为频谱图，帧长为40个样本，有90%重叠的Hann窗口。我们使用MATLAB R2017b中的spectrogram函数生成频谱图像，并保存为(200,200,3)维度的RGB图像。然后，利用最近邻插值方法( nearest interpolation)把(200,200,3)的光谱图图像的分辨率调整为(100,100,3)。我们把这个框架称作SCNN。关于降噪，我们使用size为7的高斯滤波器(Gaussian filter)对观测信号y(n)进行预处理，我们把带有降噪预处理的SCNN方法称为SCNN2。 Experimental setup​ 为了评估框架的识别性能，在这部分我们考虑了两个实验。首先我们将SCNN,SCNN2和CNN-IQ[8],CNN-IQFOC[10]进行了识别准确率的比较。本论文也将CNN-IQ,CNN-IQFOC在相同数据集上对模式识别进行了分类。此外，我们还将SCNN2与CNNR-IQ和CNNR-IQFOC进行了复杂度，内存消耗、学习参数个数和每个信号的训练时间等方面比较。 ​ 之后，为了评估所提出的调制信号频谱分析的有效性，我们进一步使用模糊函数图像和频谱相关函数图像作为信号表示，我们分别称为AF-CNN和SCF-CNN。我们也比较了SCNN2与AF-CNN和SCF-CNN在不同信噪比下的识别性能。 我们实验随机选取700 signals/modulation/SNR (700 signals per modulation mode per SNR)作为训练数据，剩下的信号分为验证数据(100 signals\\modulation\\SNR)(100 signals per modulation mode per SNR)和测试数据(200 signal/modulation/SNR)(200 signals per modulation mode per SNR)。具体来说，我们用(700,11)\\SNR (per SNR with 700 × 11 images)的图像训练分类模型。在处理前，先对所有图像进行正则化，学习率从0.0005开始并且每100次迭代除10。当交叉验证损失在15次迭代内不减少时停止训练并保存模型和最小的交叉验证损失。每步的SCNN2识别准确率如Fig.3.所示。 ​ 然后，利用训练好的模型对每个测试图像的调制类型进行预测。实验种的CNN是基于Tensorflow的Keras和Nvidia TITAN X GPU实现的。 Experiment result ​ 图4为SCNN、SCNN2、CNNR-IQ和CNNR-IQFOC与SNRs对比识别准确率的结果。从图4中可以看出，在18db信噪比下，SCNN2方法的识别精度比SCNN方法低约4%，但当信噪比低于4d时，比SCNN高出约2%。因为在信号严重失真和接近清洁的情况下，降噪算法提高信噪比的能力有限。此外，当信噪比在4db ~ 16db之间时，识别精度提高约10%。并且，我们观察到SCNN2和CNNR-IQFOC的识别精度都优于CNNR-IQ。更具体来讲，当信噪比低于4 dB时，SCNN2的识别性能比CNNR-IQ高出约5%，当信噪比高于2 dB时，SCNN2的识别性能比CNNR-IQ高出约15% ~ 20%。当信噪比低于8 dB时，SCNN2和CNNR-IQFOC的识别性能非常相似。在8d B、6 dB和4d B时，SCNN2的准确率比CNNR-IQFOC低5%左右。然而，当信噪比在2db - 18db之间时，SCNN2的精度比CNNR-IQFOC高出约8%。这表明，在信噪比低于2 dB时，SCNN2的性能总体上与CNNR-IQFOC相似或略差，但在信噪比高于2d B时，SCNN2的性能优于CNNR-IQFOC。 ​ 接下来，我们比较了SCNN2与AF-CNN和SCF-CNN的识别性能。图5中的实验结果表明，SCNN2的性能优于AF-CNN和SCF-CNN。具体来说，SCNN2的准确率比SCF-CNN高出15%左右并且当信噪比大于2 dB时比AF-CNN的精度高20%左右。当SNR电平低于8 dB时，SCNN2和SCF-CNN的识别性能非常相似。 这可以解释为，基于学习的分类方法的识别性能与输入数据的多样性成正比，而SCNN2中的频谱图分析提供了比模糊函数图像(AF-CNN)中信号更丰富的时频表示。 SCF-CNN中的频谱相关函数图像如Fig.6.所示 Computational Complexity ​ SCNN2、CNNR-IQ和CNNR-IQFOC的计算复杂度是通过比较空间消耗、学习参数的数量和每个信号的平均训练时间来评估的。从表I可以看出，SCNN2比CNNR-IQ和CNNR-IQFOC需要更多的内存，因为SCNN2、CNNR-IQ和CNNR-IQFOC的输入数据大小分别为(100,100,3)、(2,128)和(3,128)。然而，SCNN2学习参数的数量小于其他的方法，因为SCNN2少量的过滤层和使用池化访问每个卷积，而CNNR-IQ网络体系结构不包括池层，CNNR-IQFOC的每个卷积层使用更多的过滤器。另外，SCNN2的训练时间比CNNR-IQ大，但比CNNR-IQFOC小。 Conclusion​ 本文，我们提出了调制无线电信号的时频分析，并设计了一种新的基于频谱分析的卷积神经网络(SCNN)框架自动调制识别…略 个人哔哔个人尝试复现了一下，很多细节都没有讲所以挺难复现的。先在站在上帝视角看感觉是好水的一篇论文 References[1] W. Wei and J. M. Mendel, “Maximum-likelihood classification for digi-tal amplitude-phase modulations,”IEEE Trans. Commun., vol. 48, no. 2,pp. 189–193, Feb. 2000. [2] A. Swami and B. M. Sadler, “Hierarchical digital modulation clas-sification using cumulants,”IEEE Trans. Commun., vol. 48, no. 3,pp. 416–429, Mar. 2000. [3] L. Hong, “Classification of BPSK and QPSK signals in fading environ-ment using the ICA technique,” inProc. 37th Southeastern Symp. Syst.Theory (SSST), Tuskegee, AL, USA, Mar. 2005, pp. 491–494. [4] S. R. Safavian and D. Landgrebe, “A survey of decision tree classifiermethodology,”IEEE Trans. Syst., Man, Cybern., Syst., vol. 21, no. 3,pp. 660–674, May/Jun. 1991. [5] B. Scholkopf, K. Tsuda, and J. Vert,Advanced Application of SupportVector Machines. London, U.K.: MIT Press, 2004, p. 275. [6] R. Lippmann, “An introduction to computing with neural nets,”IEEEASSP Mag., vol. 4, no. 2, pp. 4–22, Apr. 1987 [7] T. J. O’Shea and N. West, “Radio machine learning dataset generationwith GNU radio,” inProc. GNU Radio Conf., vol. 1, 2016, pp. 1–6 [8] T. J. O’Shea, J. Corgan, and T. C. Clancy, “Convolutional radio modula-tion recognition networks,” inProc. Int. Conf. Eng. Appl. Neural Netw.,vol. 629. Aberdeen, U.K., 2016, pp. 213–226 [9] N. E. West and T. O’Shea, “Deep architectures for modulation recog-nition,” inProc. IEEE Int. Symp. Dyn. Spectr. Access Netw. (DySPAN),Mar. 2017, pp. 1–6 [10] M. Zhang, Y. Zeng, Z. Han, and Y. Gong, “Automatic modulationrecognition using deep learning architectures,” inProc. 19th IEEE Int.Workshop Signal Process. Adv. Wireless Commun. (SPAWC), Jun. 2018,pp. 1–5 [11] A. Dai, H. Zhang, and H. Sun, “Automatic modulation classificationusing stacked sparse auto-encoders,” inProc. IEEE 13th Int. Conf. SignalProcess. (ICSP), Chengdu, China, Nov. 2016, pp. 248–252. [12] Q. V. Leet al., “On optimization methods for deep learning,” inProc. 28th Int. Conf. Int. Conf. Mach. Learn. (ICML), Bellevue, WA,USA, 2011, pp. 265–272 [13] G. J. Mendis, J. Wei, and A. Madanayake, “Deep learning-based auto-mated modulation classification for cognitive radio,” inProc. IEEE Int.Conf. Commun. Syst. (ICCS), Shenzhen, China, Dec. 2016, pp. 1–6. [14]C.M.Bishop,PatternRecognitionandMachineLearning(InformationScienceandStatistics).Heidelberg,Germany:Springer-Verlag,2006.Authorized licensed use limited to: XIDIAN UNIVERSITY. Downloaded on October 01,2020 at 14:20:32 UTC from IEEE Xplore. Restrictions apply.","categories":[{"name":"转载","slug":"转载","permalink":"https://dummerfu.top/categories/%E8%BD%AC%E8%BD%BD/"}],"tags":[{"name":"论文","slug":"论文","permalink":"https://dummerfu.top/tags/%E8%AE%BA%E6%96%87/"}],"keywords":[{"name":"转载","slug":"转载","permalink":"https://dummerfu.top/categories/%E8%BD%AC%E8%BD%BD/"}]}]}