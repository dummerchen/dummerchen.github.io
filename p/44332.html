<!DOCTYPE html><html lang="zh-cn" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>百面机器学习 | Sakura        Momoko</title><meta name="keywords" content="面试"><meta name="author" content="dummerfu"><meta name="copyright" content="dummerfu"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="面试临时抱佛脚">
<meta property="og:type" content="article">
<meta property="og:title" content="百面机器学习">
<meta property="og:url" content="https://dummerfu.top/p/44332.html">
<meta property="og:site_name" content="Sakura        Momoko">
<meta property="og:description" content="面试临时抱佛脚">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/dummerchen/cdn@master/img/cover/3.jpg">
<meta property="article:published_time" content="2022-02-17T00:00:00.000Z">
<meta property="article:modified_time" content="2022-03-05T00:00:00.000Z">
<meta property="article:author" content="dummerfu">
<meta property="article:tag" content="面试">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/dummerchen/cdn@master/img/cover/3.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://dummerfu.top/p/44332"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//hm.baidu.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta name="google-site-verification" content="ul2nhVj6HNaI1d3xtFc7_eYD8Shq0bCu53fkA7a_7Bc"/><meta name="baidu-site-verification" content="code-584WEbZyly"/><link rel="manifest" href="/manifest.json"/><meta name="msapplication-TileColor" content="#212121"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?7cb70c60ee4da7f272c0d8059de063b7";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/4.1.1/animate.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Swiper/4.1.6/css/swiper.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"We didn't find any results for the search: ${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: {"limitDay":30,"position":"top","messagePrev":"It has been","messageNext":"days since the last update, the content of the article may be outdated."},
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":"70vh"},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: 'days',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"Traditional Chinese Activated Manually","cht_to_chs":"Simplified Chinese Activated Manually","day_to_night":"Dark Mode Activated Manually","night_to_day":"Light Mode Activated Manually","bgLight":"#49b1f5","bgDark":"#121212","position":"top-center"},
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: true,
  islazyload: true,
  isanchor: true
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-03-05 00:00:00'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    })(window)</script><meta http-equiv="content-type" content="text/html; charset=UTF-8" /><link rel="stylesheet" href="/css/mycss.css"><script src='https://cdn.jsdelivr.net/npm/butterfly-friend@1.0.4/dist/friend.min.js'></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/l-lin/font-awesome-animation/dist/font-awesome-animation.min.css"  media="defer" onload="this.media='all'"><link rel="stylesheet" href="https://at.alicdn.com/t/font_2134734_qu549vixs5f.css?spm=a313x.7781069.1998910419.60&file=font_2134734_qu549vixs5f.css" medis="defer" onload="this.media='all'"><script src="/js/lazyload.js"></script><meta name="generator" content="Hexo 5.4.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="wizard-scene"><div class="wizard-objects"><div class="wizard-square"></div><div class="wizard-circle"></div><div class="wizard-triangle"></div></div><div class="wizard"><div class="wizard-body"></div><div class="wizard-right-arm"><div class="wizard-right-hand"></div></div><div class="wizard-left-arm"><div class="wizard-left-hand"></div></div><div class="wizard-head"><div class="wizard-beard"></div><div class="wizard-face"><div class="wizard-adds"></div></div><div class="wizard-hat"><div class="wizard-hat-of-the-hat"></div><div class="wizard-four-point-star --first"></div><div class="wizard-four-point-star --second"></div><div class="wizard-four-point-star --third"></div></div></div></div></div></div><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" data-src="https://cdn.jsdelivr.net/gh/dummerchen/cdn@master/img/custom/avatar.jpg" src="/img/lazyload.svg" onerror="onerror=null;src='https://cdn.jsdelivr.net/gh/dummerchen/cdn/img/other/default_avatar.jpg'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">45</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">Tags</div><div class="length-num">18</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">Categories</div><div class="length-num">6</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/"><i class="fa-fw fas fa-home faa-tada"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/archives/"><i class="fa-fw fas fa-archive faa-tada"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/comment/"><i class="fa-fw fa fa-comments faa-tada"></i><span> 留言</span></a></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/links/"><i class="fa-fw fas fa-link faa-tada"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/circle/"><i class="fa-fw fas fa-user-friends faa-tada"></i><span> 朋友圈</span></a></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/about/"><i class="fa-fw fa-fw fas fa-heart faa-tada"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://cdn.jsdelivr.net/gh/dummerchen/My_Image_Bed03@image_bed_001/img/20211212145123.jpg')"><nav id="nav"><span id="blog_name"> <a id="site-name" onclick="btf.scrollToDest(0, 500)" data-title="面试临时抱佛脚">百面机器学习</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/"><i class="fa-fw fas fa-home faa-tada"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/archives/"><i class="fa-fw fas fa-archive faa-tada"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/comment/"><i class="fa-fw fa fa-comments faa-tada"></i><span> 留言</span></a></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/links/"><i class="fa-fw fas fa-link faa-tada"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/circle/"><i class="fa-fw fas fa-user-friends faa-tada"></i><span> 朋友圈</span></a></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/about/"><i class="fa-fw fa-fw fas fa-heart faa-tada"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">百面机器学习</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2022-02-17T00:00:00.000Z" title="Created 2022-02-17 00:00:00">2022-02-17</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2022-03-05T00:00:00.000Z" title="Updated 2022-03-05 00:00:00">2022-03-05</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E9%9D%A2%E8%AF%95/">面试</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">Word count:</span><span class="word-count">6.6k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">Reading time:</span><span>22min</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="百面机器学习"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post View:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>虽然是临时抱佛脚，但是这些面试题对我这种小白来说还是学到很多。后面没有星星的问题并不是原书上的，因为面试也常顺便就归类了。</p>
<h1 id="特征工程"><a href="#特征工程" class="headerlink" title="特征工程"></a>特征工程</h1><h2 id="为什么需要对数值类型的特征做归一化？-bigstar"><a href="#为什么需要对数值类型的特征做归一化？-bigstar" class="headerlink" title="为什么需要对数值类型的特征做归一化？$\bigstar$"></a>为什么需要对数值类型的特征做归一化？$\bigstar$</h2><p>归一化分为min-max和z-score归一化，前者只需要min和max即可归一，后者还需要均值和方差。效果也不一定会更好，但是通常z-score效果会更好一点 <del>因为计算均值和方差更麻烦</del>，对于需要梯度下降的算法如svm，线性回归，逻辑回归，神经网路等，在相同的学习率下，归一化能明显降低算法收敛速度。但决策树不适用</p>
<img src= "/img/lazyload.svg" data-src="https://cdn.jsdelivr.net/gh/dummerchen/My_Image_Bed03@image_bed_001/img/20220216124905.png" class="" title="，height&#x3D;0.3vh">
<h2 id="怎样处理类别型特征？-bigstar-bigstar"><a href="#怎样处理类别型特征？-bigstar-bigstar" class="headerlink" title="怎样处理类别型特征？$\bigstar\bigstar$"></a>怎样处理类别型特征？$\bigstar\bigstar$</h2><p>类别型特征分为两类：可比较和不可比较。</p>
<ul>
<li><p>对于可比较类别型特征映射为0，1，2这种当然是没有问题。因为也保留了可比较这种特征</p>
</li>
<li><p>但是对于不可比较特征如男女，应该使用不可比较映射如onehot或二进制编码<del>现在二进制编码不常用</del>等。</p>
<blockquote>
<p>对于onehot，如果特征过多会很冗余浪费空间可以用向量的稀疏表示节省空间。如[0,0,0,5,0,0,0,0,1]=&gt;(10,[3,9],[5,1])，代表第3和9位上有个5和1</p>
</blockquote>
</li>
</ul>
<h2 id="什么是组合特征？如何处理高维组合特征？-bigstar-bigstar"><a href="#什么是组合特征？如何处理高维组合特征？-bigstar-bigstar" class="headerlink" title="什么是组合特征？如何处理高维组合特征？$\bigstar\bigstar$"></a>什么是组合特征？如何处理高维组合特征？$\bigstar\bigstar$</h2><p>组合特征简单理解就是多个类别型特征对应一个label<del>就是常见的excel文件</del>。</p>
<p>我们通常处理都说分别使用onehot然后再拼接。比如：</p>
<blockquote>
<p>有m个用户，n个物品，label为是否点击，拼接后对应的就是m+n+2维onehot向量（label看情况拼接）</p>
<p>但是对于互联网来说m和n太大了，尽管向量稀疏表示可以节省空间但是网络的训练参数确不能节省（m*n)。这个时候就需要矩阵分解了，将m*n分解乘m*k+k*n，k&lt;&lt;m,n。训练参数也大大减少</p>
</blockquote>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/145120275">矩阵分解具体可以看这篇知乎</a></p>
<h2 id="怎样有效地找到组合特征-bigstar-bigstar"><a href="#怎样有效地找到组合特征-bigstar-bigstar" class="headerlink" title="怎样有效地找到组合特征?$\bigstar\bigstar$"></a>怎样有效地找到组合特征?$\bigstar\bigstar$</h2><p>可以通过决策树帮助来寻找。</p>
<p><img src= "/img/lazyload.svg" data-src="https://cdn.jsdelivr.net/gh/dummerchen/My_Image_Bed03@image_bed_001/img/20220216131620.png" alt="image-20220216131620391">比如通过上面的决策树可以筛选出如下四个特征：</p>
<ul>
<li>年龄&lt;=35”且“性别=女”。 </li>
<li>年龄&lt;=35”且“物品类别=护肤”。 </li>
<li>用户类型=付费”且“物品类型=食品”。 </li>
<li>用户类型=付费”且“年龄&lt;=40”。</li>
</ul>
<p>那么下面这条信息可以被视为[1，1，0，0] ：满足一二条不满足三四条</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>是否点击</th>
<th>年龄</th>
<th>性别</th>
<th>用户类型</th>
<th>物品类型</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>28</td>
<td>女</td>
<td>免费</td>
<td>护肤</td>
</tr>
</tbody>
</table>
</div>
<h2 id="有哪些文本表示模型？它们各有什么优缺点？-bigstar-bigstar"><a href="#有哪些文本表示模型？它们各有什么优缺点？-bigstar-bigstar" class="headerlink" title="有哪些文本表示模型？它们各有什么优缺点？$\bigstar\bigstar$"></a>有哪些文本表示模型？它们各有什么优缺点？$\bigstar\bigstar$</h2><h3 id="词袋模型"><a href="#词袋模型" class="headerlink" title="词袋模型"></a>词袋模型</h3><p>​    将整段文本以词为单位切分开[i,am,food]， 然后每篇文章可以表示成一个长向量[[a,b,c],[aa,bb,cc],[aaa,bbb,ccc]]，向量中的每一维代表一个单词，而该维对应的权重则反映了这个词在原文章中的重要程度。</p>
<p>​    可以看出权重计算极其关键，那如何计算权重呢？常用的是TF-IDF来计算文本的权重：TF-IDF=TF*IDF</p>
<p>TF为单词t在所有文章里的频率，IDF=$log \frac{文章总数}{包含单词t的文章总数+1}$。实际应用时可能不会直接按单词直接分割文本，而是可以word stemming（提取词干）和n-gram（提取短语）结合处理文本后再进行分割计算权重。</p>
<h3 id="主题模型"><a href="#主题模型" class="headerlink" title="主题模型"></a>主题模型</h3><p>LDA（隐迪利克雷模型）通过对所有文章训练然后将所有文章分为k个主题，每个主题n个关键词（k，n为参数）</p>
<h3 id="深度学习模型和词嵌入模型"><a href="#深度学习模型和词嵌入模型" class="headerlink" title="深度学习模型和词嵌入模型"></a>深度学习模型和词嵌入模型</h3><p>通过各种玄学的网络结构（如transformer）将文本映射为一系列向量，由于深度网络很大，能更深层的提取语义特征。</p>
<p>词嵌入模型作用也是和神经网络相同将词映射为向量最常用的就是谷歌提出的word2vec（本质也是个小型神经网路）</p>
<h2 id="Word2Vec是如何工作的？它和LDA有什么区别与联系？-bigstar-bigstar-bigstar"><a href="#Word2Vec是如何工作的？它和LDA有什么区别与联系？-bigstar-bigstar-bigstar" class="headerlink" title="Word2Vec是如何工作的？它和LDA有什么区别与联系？$\bigstar\bigstar\bigstar$"></a><strong>Word2Vec</strong>是如何工作的？它和<strong>LDA</strong>有什么区别与联系？$\bigstar\bigstar\bigstar$</h2><p>word2vec是将一个词映射为一个向量，属于文本表示模型中的词嵌入模型</p>
<p><img src= "/img/lazyload.svg" data-src="https://cdn.jsdelivr.net/gh/dummerchen/My_Image_Bed03@image_bed_001/img/20220223215430.png" alt="image-20220223215430575"></p>
<p>本质是一个神经网络，分为CBOW（根据前后预测中间的概率）和Skip-gram（通过中间预测前后的概率）两种实现方式，如上图</p>
<p>主题模型是一种基于概率图模型的生成式模型，其似然函数可以写成若干条件概率连乘的形式，其中包括需要推测的隐含变</p>
<p>量（即主题）；而词嵌入模型一般表达为神经网络的形式，似然函数定义在网络的输出之上，需要通过学习网络的权重以得</p>
<p>到单词的稠密向量表示。</p>
<h2 id="在图像分类任务中，训练数据不足会带来什么问题？如何缓解数据量不足带来的问题？-bigstar-bigstar"><a href="#在图像分类任务中，训练数据不足会带来什么问题？如何缓解数据量不足带来的问题？-bigstar-bigstar" class="headerlink" title="在图像分类任务中，训练数据不足会带来什么问题？如何缓解数据量不足带来的问题？$\bigstar\bigstar$"></a>在图像分类任务中，训练数据不足会带来什么问题？如何缓解数据量不足带来的问题？$\bigstar\bigstar$</h2><p>数据不足代表现验信息较少会导致训练集上效果可能还不错，测试集上蒙蔽（鲁棒性不强，过拟合)。</p>
<ul>
<li><p>向增加模型泛化能力着手：</p>
<p>  可以减少非线性层，增加惩罚项，调节dropout超参数等。</p>
</li>
<li><p>向增加现验信息着手，在保证特定信息条件下对数据进行扩充（Data Agumentation）：</p>
<p>  形态变换上可以：旋转，伸缩，裁剪（mask），平移，填充，<del>目标检测还可以重叠mosaic|mix up</del></p>
<p>  颜色饱和度等方面：噪声扰动，对颜色进行pca聚类得到三个主成分向量再在rgb添加主成分增量（可以参考Alex net）</p>
<p>  图像空间上可以：在特征空间上进行变换如通用的SMOTE（Synthetic Minority Over-sampling Technique）算法。</p>
<p>  增加样本上还可以使用Gan。</p>
</li>
</ul>
<h1 id="模型评估"><a href="#模型评估" class="headerlink" title="模型评估"></a>模型评估</h1><h2 id="准确率的局限性"><a href="#准确率的局限性" class="headerlink" title="准确率的局限性"></a>准确率的局限性</h2><p>精确率准确率召回率f1score就不再说了，值得一提的是可以找更好的评估指标，比如平均绝对百分比误差（Mean Absolute Percent Error，MAPE），它比RMSE的鲁棒性更好。</p>
<h1 id="降维"><a href="#降维" class="headerlink" title="降维"></a>降维</h1><h2 id="如何定义主成分？从这种定义出发，如何设计目标函数使得降维达到提取主成分的目的？针对这个目标函数，如何对PCA问题进行求解-bigstar-bigstar"><a href="#如何定义主成分？从这种定义出发，如何设计目标函数使得降维达到提取主成分的目的？针对这个目标函数，如何对PCA问题进行求解-bigstar-bigstar" class="headerlink" title="如何定义主成分？从这种定义出发，如何设计目标函数使得降维达到提取主成分的目的？针对这个目标函数，如何对PCA问题进行求解 $\bigstar \bigstar$"></a>如何定义主成分？从这种定义出发，如何设计目标函数使得降维达到提取主成分的目的？针对这个目标函数，如何对<strong>PCA</strong>问题进行求解 $\bigstar \bigstar$</h2><p>主成分从数学上来说是降维后特征向量对应的特征值最大的为候选，但具体为哪些要通过人为设置的阈值来决定。降维的目的是我们想降维后的样本距离间尽可能大，投影尽可能分开并且样本离超平面尽可能近(<strong>回归的角度</strong>)。虽然有两个目标但是最后推导出的目标函数是相同的，下面以样本间距离尽可能大来推导：</p>
<p>首先我们需要将样本进行中心化，即$\sum_{i=1}^m X_i=0$，这样样本方差可以表示为$W^TXX^TW$，而且$W^TW=I$:</p>
<script type="math/tex; mode=display">
\begin{cases}
min_w -tr(W^TXX^TW) \\
s.t. W^TW=I
\end{cases}</script><h2 id="对于具有类别标签的数据，应当如何设计目标函数使得降维的过程中不损失类别信息？在这种目标下，应当如何进行求解？（手推LDA）-bigstar-bigstar"><a href="#对于具有类别标签的数据，应当如何设计目标函数使得降维的过程中不损失类别信息？在这种目标下，应当如何进行求解？（手推LDA）-bigstar-bigstar" class="headerlink" title="对于具有类别标签的数据，应当如何设计目标函数使得降维的过程中不损失类别信息？在这种目标下，应当如何进行求解？（手推LDA）$\bigstar \bigstar$"></a>对于具有类别标签的数据，应当如何设计目标函数使得降维的过程中不损失类别信息？在这种目标下，应当如何进行求解？（手推LDA）$\bigstar \bigstar$</h2><p>​    又pca我们知道，它不管类别标签，在对于有标签情况下根本无法使用。而我们可以从pca中受到启发，目标为类内距离尽可能小，类间距离尽可能大，下面用两类标签情况来演示（fisher 线性判别分析）<del>多类则叫LDA</del></p>
<p>​    我们还是需要求解个超平面（二维是直线）W，满足上述条件：</p>
<p>假设低维类均值为$\bar\mu_i$,方差为$\bar\Sigma_i$，特征值为$y_i$，高维空间均值方差为$\mu_i,\Sigma_i$，特征值为x_i。目标函数为$max J_w=\frac{(\bar\mu_1-\bar\mu_2)^2}{\bar\Sigma_1^2+\bar\Sigma_2^2}$</p>
<p>投影后的类间距离可以表示为:</p>
<script type="math/tex; mode=display">
\bar\mu_1-\bar\mu_2=\frac{1}{n}\sum_{i=1}^ny_{1i}-\frac{1}{m}\sum_{i=1}^my_{2i}=\frac{1}{n}\sum W^Tx_1-\frac{1}{m}\sum W^Tx_2=W^T(\mu_1-\mu_2)</script><p>我们知道协方差矩阵可以写为:</p>
<script type="math/tex; mode=display">
\bar\Sigma_i^2=\sum_{j=1}^m(y_{2j}-\bar\mu_{1i})^2=W^T\sum(x_{2j}-\mu_1)^T(x_{2j}-\mu_1)W=W^T\Sigma_iW</script><p>故$L(w,\lambda)=W^T(\mu_1-\mu_2)(\mu_1-\mu_2)^TW+\lambda(W^T(\Sigma_1+\Sigma_2) W-c)$</p>
<p>$\frac{\partial L}{\partial w}=(\mu_1-\mu_2)(\mu_1-\mu_2)^TW+\lambda(\Sigma_1+\Sigma_2) W=0$</p>
<p>故$W=\frac{1}{\lambda}(\Sigma_1+\Sigma_2)^{-1}(\mu_1-\mu_2)R=(\Sigma_1+\Sigma_2)^{-1}(\mu_1-\mu_2)$</p>
<h2 id="LDA和PCA作为经典的降维算法，如何从应用的角度分析其原理的异同？从数学推导的角度，两种降维算法在目标函数上有何区别与联系？"><a href="#LDA和PCA作为经典的降维算法，如何从应用的角度分析其原理的异同？从数学推导的角度，两种降维算法在目标函数上有何区别与联系？" class="headerlink" title="LDA和PCA作为经典的降维算法，如何从应用的角度分析其原理的异同？从数学推导的角度，两种降维算法在目标函数上有何区别与联系？"></a><strong>LDA</strong>和<strong>PCA</strong>作为经典的降维算法，如何从应用的角度分析其原理的异同？从数学推导的角度，两种降维算法在目标函数上有何区别与联系？</h2><p>​    从应用角度来说，无监督使用PCA，因为PCA不涉及到类间距离，只人为类内距离越大隐含的信息越多，留下的主成分认为是最佳描述整体的特征（用于除去冗余信息如噪音）。而LDA需要标签来区别类间的距离，留下的主成分认为是每个类别的最佳描述特征。</p>
<p>​    从上面来看，LDA具有很大的优势，但由于涉及到不同领域（有监督和无监督）所整体来看还是各有千秋。</p>
<p>从算法流程来看，目标函数在一维下是相同的，且两者最后都是计算特征向量，非常相似，所以算法本质是相同的。</p>
<h2 id="除了pca传统的的特征降维方法有哪些，特征选择方法有哪些"><a href="#除了pca传统的的特征降维方法有哪些，特征选择方法有哪些" class="headerlink" title="除了pca传统的的特征降维方法有哪些，特征选择方法有哪些"></a>除了pca传统的的特征降维方法有哪些，特征选择方法有哪些</h2><p>LDA(linear discriminat analysis)，MDS(muti dimension scaling)，LLE(local linear embeding)。</p>
<p>特征选择有过滤式选择，包裹式选择和嵌入式选择。</p>
<p>过滤式选择是先人为选择好特征子集再训练，模型与特征选择无关。</p>
<p>包裹式选择是选择与模型匹配的最好特征，即每次随机选择特征给模型进行训练，最后效果肯定比过滤式选择好，但是更耗费时间。</p>
<p>嵌入式选择是在训练的时候删去某个特征，然后对比效果，简单来说就是增加L1正则化，正则化项中有一项为0就是代表删去了特征。L1正则化比L2正则化稀疏解更多，即w中0更多。由下图可知：</p>
<p><img src= "/img/lazyload.svg" data-src="https://cdn.jsdelivr.net/gh/dummerchen/My_Image_Bed03@image_bed_001/img/20220306125714.png" alt="image-20220306125714772"></p>
<p>L1的等值线与误差等值线交点更多在坐标轴上，L2则是在象限中。</p>
<h2 id="什么是流型学习，ISOmap和LLE的原理"><a href="#什么是流型学习，ISOmap和LLE的原理" class="headerlink" title="什么是流型学习，ISOmap和LLE的原理"></a>什么是流型学习，ISOmap和LLE的原理</h2><p>流型是指局部具有欧式空间同胚的<strong>空间</strong>，流型学习是指低维欧式空间嵌入到高维仍具有欧式空间的特性，通过计算高维空间的距离并利用流型空间的特性可以局部映射到低维空间，然后再把局部映射关系推广到全局。因为具有距离不变性，常常用来数据可视化。比如已知n个城市飞机飞行的距离（高维空间的距离），我们可以用ISOmap将城市映射到二维空间并可视化。</p>
<p>ISOmap(isometric map)等度量映射：实际上是将MDS在应用方向的另一个名称，算法本质就是MDS。具体步骤：已知高维空间坐标，计算高维空间两两距离，然后使用MDS映射到低维空间得到低维空间的坐标。</p>
<p>由于ISOmap只能离线处理(每次需要等数据输入完后再计算，且不能用于预测)，实际使用并不是很方便，比较流行的方法：</p>
<blockquote>
<p> 通过n个点高维坐标输入，低维坐标作为输出训练一个回归器，当第n+1个点输入时使用回归器预测n+1点低维的坐标。</p>
</blockquote>
<p>但是仍不能很好解决问题。</p>
<p> LLE(Local linear embedding)局部线性嵌入：与保持空间距离不变不同LLE旨在保持空间的线性性：假设高维空间的n节点可以用k近邻个节点线性表示，那么我们希望低维空间的n节点仍然有这个性质(组合系数w不变)。</p>
<p>即先后优化两个Loss：</p>
<script type="math/tex; mode=display">
L_w=argmin_w \sum_{i=1}^{n} ||x_i-\sum_{j=1}^K w^Tx_j||^2 \\
L_y'=argmin_y \sum_{i=1}^n ||y_i-\sum_{j=1}^K w^Ty_j||2</script><p>第一个目标函数求出组合系数w第二个目标函数求出低维坐标y。</p>
<h1 id="无监督学习"><a href="#无监督学习" class="headerlink" title="无监督学习"></a>无监督学习</h1><h2 id="K均值算法的优缺点是什么？如何对其进行调优？-bigstar-bigstar-bigstar"><a href="#K均值算法的优缺点是什么？如何对其进行调优？-bigstar-bigstar-bigstar" class="headerlink" title="K均值算法的优缺点是什么？如何对其进行调优？$\bigstar \bigstar\bigstar$"></a>K均值算法的优缺点是什么？如何对其进行调优？$\bigstar \bigstar\bigstar$</h2><p>优点：</p>
<ul>
<li>算法足够高效，复杂度低。</li>
<li>局部最优常常也能满足需求。</li>
</ul>
<p>缺点：</p>
<ul>
<li>离群值处理不太行。</li>
<li>对于数据分布不均匀处理不当。</li>
<li><strong>不太适用离散分布</strong>。</li>
<li>初始点选择很重要。</li>
<li>K值选择也很重要。</li>
</ul>
<p>调优：</p>
<ul>
<li>适用中位数代替平均数（k-media）和对数据进行预处理，能很好减少离群点的影响</li>
<li>多次尝试初始值可以缓解初始值的影响或适用Kmeans++来弥补。</li>
<li>可以通过手肘法或Gap Statistic方法选择K值。</li>
<li>通过核函数映射到高维（核kmeans）达到更准确的聚类结果</li>
</ul>
<h2 id="高斯混合模型的核心思想是什么？它是如何迭代计算的-bigstar-bigstar"><a href="#高斯混合模型的核心思想是什么？它是如何迭代计算的-bigstar-bigstar" class="headerlink" title="高斯混合模型的核心思想是什么？它是如何迭代计算的$\bigstar\bigstar$"></a>高斯混合模型的核心思想是什么？它是如何迭代计算的$\bigstar\bigstar$</h2><p>高斯混合模型和核心是假设数据是高斯分布生成出来的，但我们不知道均值方差和权重，故先假设已知再通过EM算法求出最合适（似然函数变化稳定）的均值方差和权重。</p>
<h2 id="以聚类问题为例，假设没有外部标签数据，如何评估两个聚类算法的优劣？-bigstar-bigstar-bigstar"><a href="#以聚类问题为例，假设没有外部标签数据，如何评估两个聚类算法的优劣？-bigstar-bigstar-bigstar" class="headerlink" title="以聚类问题为例，假设没有外部标签数据，如何评估两个聚类算法的优劣？$\bigstar\bigstar\bigstar$"></a>以聚类问题为例，假设没有外部标签数据，如何评估两个聚类算法的优劣？$\bigstar\bigstar\bigstar$</h2><h1 id="SVM"><a href="#SVM" class="headerlink" title="SVM"></a>SVM</h1><h2 id="推导SVM"><a href="#推导SVM" class="headerlink" title="推导SVM"></a>推导SVM</h2><p>我们需要一个超平面将两类点分隔开，且不同类别的点到直线距离都尽可能大。$max {min J(w)=\frac{|w^Tx+b|}{||w||}}$</p>
<p>设标签类别为$y_i$，由于对于正类$y_i&gt;0$且$w^Tx+b&gt;=1$对于负类$y_i&lt;0$, $w^Tx+b&lt;=-1$:故点到直线距离可去掉绝对值统一为$y_i*(w^Tx+b)$。</p>
<p>对于$|w^Tx+b|=1$这两条线，我们称为支持向量，<strong>如果点线性可分（下面讨论线性可分支持向量机）</strong>，则上述目标函数可转换为两个支持向量距离最长即：</p>
<script type="math/tex; mode=display">
max J_w=\frac{1}{||w||}\frac{(w^Tx+b-1)-(w^Tx+b+1)}{||w||}=\frac{2}{||w||^2}=min J_w=\frac{||w||^2}{2}</script><p>约束条件为：<strong>w,x为列向量</strong></p>
<script type="math/tex; mode=display">
y_i*(w^Tx+b)>=1</script><p>拉格朗日函数：</p>
<script type="math/tex; mode=display">
L(w,b,a)=\frac{||w||^2}{2}-\sum a_i(y_i(w^Tx_i+b)-1) \quad a_i>=0</script><p>此方程组的限制条件（又称KKT条件）为：</p>
<script type="math/tex; mode=display">
\begin{cases}
\frac{\partial L}{\partial w,b}=0 \\
y_i(w^Tx_i+b)-1>=0 \\
a_i>=0 \\
a_i*(y_i(w^Tx_i+b)-1)=0
\end{cases}</script><p>其中$a_i$为KKT乘数，如何判断KKT乘数的符号也有讲究：对于min问题，乘数项应该异号对于max问题，乘数项应该同号。</p>
<p>KKT条件实际上并不是条件，而是前提，存在不等式方程组求解时，如果可以求解则必须满足KKT条件，此时通过求解的拉格朗日方程组也叫KKT方程组。<del>自己理解，不一定对</del></p>
<p>对上式求偏导：</p>
<script type="math/tex; mode=display">
\begin{cases}
\frac{\partial L}{\partial w}=w-\sum a_iy_ix_i=0 \\
\frac{\partial L}{\partial b}=\sum a_iy_i=0 \\
\end{cases}</script><p>带入拉格朗日方程：</p>
<script type="math/tex; mode=display">
\begin{aligned}
min L&=\frac{1}{2}\sum_{i=1}^m a_ia_jy_iy_jx_i^Tx_j-\sum_{i=1}^ma_iy_iw^Tx_i-\sum_{i=1}^ma_iy_ib+\sum_{i=1}^m a_i \\
&=\frac{1}{2}\sum_{i=1}^m a_ia_jy_iy_jx_i^Tx_j-\sum_{i=1}^ma_iy_i\sum_{j=1}^ma_jy_jx_j^T x_i-\sum_{i=1}^ma_iy_ib+\sum_{i=1}^m a_i \\
&=-\frac{1}{2}\sum_{i=1}^ma_ia_jy_iy_jx_i^Tx_j+\sum_{i=1}^ma_i
\end{aligned}</script><p>其实这里已经可以求解出具体的w和b了。但是不同方法结果不同，我这里采用SMO方法求解(具体SMO还是得看书，比较麻烦）。</p>
<blockquote>
<p>选取$a<em>i,a_j$,其余$a_k$看成常数，$a_iy_i+a_jy_j=\sum</em>{k\neq i,j}^ma_ky_k$</p>
<p>用$a<em>i$表示$a_j$，对消去$a_j$的L求导可求出$a</em>{i}$。</p>
<p>关于b，我们可以通过支持向量的约束来求解$y<em>s(\sum</em>{i\in S}a_iy_ix_i^Tx_s+b)=1$</p>
<p>但每一个支持向量的点都能求出一个b，这里直接暴力去平均即可得到$b=\frac{1}{|S|}\sum<em>{i \in S} (y_s-\sum</em>{i\in S}a_iy_ix_i^Tx_s)$</p>
</blockquote>
<h2 id="在空间上线性可分的两类点，分别向SVM分类的超平面上做投影，这些点在超平面上的投影仍然是线性可分的吗？-bigstar-bigstar-bigstar"><a href="#在空间上线性可分的两类点，分别向SVM分类的超平面上做投影，这些点在超平面上的投影仍然是线性可分的吗？-bigstar-bigstar-bigstar" class="headerlink" title="在空间上线性可分的两类点，分别向SVM分类的超平面上做投影，这些点在超平面上的投影仍然是线性可分的吗？ $\bigstar \bigstar\bigstar$"></a>在空间上线性可分的两类点，分别向<strong>SVM</strong>分类的超平面上做投影，这些点在超平面上的投影仍然是线性可分的吗？ $\bigstar \bigstar\bigstar$</h2><p>结论：对于任意线性可分的两组点，它们在SVM分类的超平面上的投影都是线性不可分的。</p>
<p><img src= "/img/lazyload.svg" data-src="https://cdn.jsdelivr.net/gh/dummerchen/My_Image_Bed03@image_bed_001/img/20220224231854.png" alt="image-20220224231853997"></p>
<p>该问题可以通过凸优化理论中的超平面分离定理（Separating Hyperplane Theorem，SHT）更加轻巧地解决。该定理描述的是，对于不相交的两个凸集，存在一个超平面，将两个凸集分离。对于二维的情况，两个凸集间距离最短两点连线的中垂线就是一个将它们分离的超平面。</p>
<p>通过以上定理，我们可以将两组点先各自求凸包，可以发现分割两个凸包的超平面就是SVM所得出的支持向量（二维情况下就是两个凸包距离最小点的中垂线）。</p>
<p>遂有图3.12三种情况，对于任意一种情况，其投影都<strong>线性不可分</strong>。（在二维情况上就是两个点集投影在支持向量上，然后再用一条线将他们分开，显然不可能）</p>
<h1 id="Logistic-回归"><a href="#Logistic-回归" class="headerlink" title="Logistic 回归"></a>Logistic 回归</h1><h2 id="逻辑回归相比于线性回归，有何异同？-bigstar-bigstar"><a href="#逻辑回归相比于线性回归，有何异同？-bigstar-bigstar" class="headerlink" title="逻辑回归相比于线性回归，有何异同？$\bigstar \bigstar$"></a>逻辑回归相比于线性回归，有何异同？$\bigstar \bigstar$</h2><p>​    在此之前我们要知道广义的线性回归：满足$y=g(w^Tx+b)$，其中g为可微函数。</p>
<p>由于人们在考虑回归时也想用回归来进行分类任务，灵机一动想到阶跃函数，但是阶跃函数不可微，遂使用对数几率函数(Logistic Function)$y=\frac{1}{1+e^{-z}}$函数来代替，这个<strong>函数是Sigmod函数的一种</strong><del>只要是S形状的都是sigmod函数</del>。</p>
<p>​    我们将logistic function代替广义回归式中的g并做变换则有：</p>
<script type="math/tex; mode=display">
ln(\frac{y}{1-y})=w^Tx+b</script><p>若将y视为x为正例的可能性，1-y则是x为反例的可能性，他们比值就是几率反映了相对可能性，这就是对数几率回归(logistic regression)的由来。</p>
<p>然而逻辑回归的最优化函数与线性回归截然不同：</p>
<p>通过上述有$p(y=k|x)=e^{w^x+b}$，要求分类错误最小则最大化对数似然函数，估计w和b：</p>
<script type="math/tex; mode=display">
max L(w,b)=max \sum_{i=1}^{n}ln(y_ip(y=1|x)+(1-y_i)p(y=0|x)) \\
=max \sum_{i=1}^n ln(e^{w^Tx+b}y_i+(1-y_i)) -ln(1+e^{w^Tx+b})
\leftrightarrow min \sum_{i=1}^{n}-y_i*(w^Tx+b)+ln(1+e^{w^T+b})</script><p>则也是<strong>最小化$-L(w,b)$即等价于最小化CrossEntryloss</strong></p>
<p>总结以下，逻辑回归与线性回归相比：</p>
<ul>
<li>一个用于分类，一个用于回归，使用方向完全不同。</li>
<li>线性回归是求解均方差最小，而logistic regression是求解最大似然函数。</li>
<li>但他们求解方法都可以使用梯度下降法求解。</li>
</ul>
<h2 id="逻辑回归为什么不使用MSE作为loss"><a href="#逻辑回归为什么不使用MSE作为loss" class="headerlink" title="逻辑回归为什么不使用MSE作为loss"></a>逻辑回归为什么不使用MSE作为loss</h2><p>假设这是一个二分类，预测类别为0，实际类别为1。显然这个分类器完全错误，但是MSE loss仅仅为1！！！。对比交叉熵：</p>
<script type="math/tex; mode=display">
Entry loss=-1*log(0)\rightarrow\infin</script><p>其次，MSE会出现梯度消失现：</p>
<script type="math/tex; mode=display">
L_w=\sum (y_i-h(s_i))^2 \quad s=w^Tx+b \quad h=\frac{1}{1+e^{-s}} \\

L_w'=-2\sum_{i=1}^m (y_i-h(s_i))h(s_i)(1-h(s_i))*x_i</script><p>当$h(s_i)$为1或0时$L_w’\rightarrow0$，出现梯度消失。</p>
<p>更重要的是，它不是一个非凸函数，要知道梯度下降需要如果优化非凸函数并不能找到全局最优<del>虽然一般也找不到</del>：</p>
<script type="math/tex; mode=display">
\begin{aligned}
L_w''&=-2\sum_{i=1}^m [-h(s_i)+h^2(s_i)+(y-h(s_i)(1-2h(s_i))] (h(s_i)-h^2(s_i))x_i\\
    &=-2\sum_{i=1}^m[y-2yh(s_i)-2h(s_i)+3h^2(s_i)](h-h^2(s_i))x_i^2
\end{aligned}</script><p>当$h(s_i)\in (0,1)，y=0$时，$L’’$由$3h(s_i)^2-2h(s_i)$决定，这个在$h\in (0,1)$有正有负，所以$L_w$非凸。</p>
<h2 id="当使用逻辑回归处理多标签的分类问题时，有哪些常见做法，分别应用于哪些场景，它们之间又有怎样的关系？-bigstar-bigstar-bigstar"><a href="#当使用逻辑回归处理多标签的分类问题时，有哪些常见做法，分别应用于哪些场景，它们之间又有怎样的关系？-bigstar-bigstar-bigstar" class="headerlink" title="当使用逻辑回归处理多标签的分类问题时，有哪些常见做法，分别应用于哪些场景，它们之间又有怎样的关系？$\bigstar \bigstar \bigstar$"></a>当使用逻辑回归处理多标签的分类问题时，有哪些常见做法，分别应用于哪些场景，它们之间又有怎样的关系？$\bigstar \bigstar \bigstar$</h2><p>对于每类只有一个标签的多分类，我们假设每类都符合几何分布：</p>
<script type="math/tex; mode=display">
h_{\theta}(x)=\left[ \begin{matrix}
p(y=1|x;\theta)\\
\vdots  \\
p(y=n|x;\theta) \\
\end{matrix}\right] 
=\frac{1}{\sum_{j=1}^{k}e^{\theta_j^Tx}}\left[ \begin{matrix}
e^{\theta_1^Tx} \\
\vdots \\
e^{\theta_n^Tx} \\
\end{matrix}\right]</script><p>一般来说，多项逻辑回归具有参数冗余的特点，即将同时加减一个向量后预测结果不变。特别地，当类别数为2时。</p>
<script type="math/tex; mode=display">
h_{\theta}(x)
=\frac{1}{e^{\theta_1^Tx}+e^{\theta_2^Tx}}\left[ \begin{matrix}
e^{\theta_1^Tx} \\
e^{\theta_2^Tx} \\
\end{matrix}\right]</script><p>令所有参数减去$\theta_1$，则有</p>
<script type="math/tex; mode=display">
h_{\theta}(x)
=\frac{1}{1+e^{(\theta_2-\theta_1)^Tx}}\left[ \begin{matrix}
1 \\
e^{(\theta_2-\theta_1)^Tx} \\
\end{matrix}\right]</script><p>整理后发现与逻辑回归相同。因此，多标签分类逻辑回归实际上是二分类的一种拓展。而多元逻辑回归式子又叫softmax函数。</p>
<h1 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h1><h2 id="决策树有哪些常用的启发函数？-bigstar-bigstar"><a href="#决策树有哪些常用的启发函数？-bigstar-bigstar" class="headerlink" title="决策树有哪些常用的启发函数？$\bigstar \bigstar$"></a>决策树有哪些常用的启发函数？$\bigstar \bigstar$</h2><ul>
<li><p>IDF3(Iterater dichotomister 3) 最大信息增益：</p>
<blockquote>
<p>数据集D的经验熵：$H(D)=-\sum_{i=1}^SP(w_i|t)*log_2P(w_i|t)$</p>
<p>对于特征A经验条件熵$H(D|A)=\sum_i^n \frac{|D_i|}{|D|}H(D_i)$</p>
<p>判定停止条件为：$max {g(D)}=H(D)-H(D|A)$</p>
</blockquote>
</li>
<li><p>C4.5 最大信息增益比：</p>
<blockquote>
<p>判断停止条件为$g_r(D)=\frac{g(D)}{H_A(D)}$</p>
<p>其中取值熵：$H<em>A(D)=\sum</em>{i=1}^{n}\frac{|D_i|}{|D|}log_2\frac{|D_i|}{|D|}$</p>
</blockquote>
</li>
<li><p>CART(Classification And Regression Tree) 最大基尼系数：</p>
<blockquote>
<p>$G(D)=\sum<em>{i=1}^{n}p(x_i)(1-p</em>{x<em>i})=1-\sum</em>{i=1}^{n}p(x<em>i)^2=1-\sum</em>{i=1}^n(\frac{|C_k|}{|D|})^2$ k为所有特征种类如年龄性别等</p>
<p>代表从数据集D中随机抽取两个样本，其类别标记不一致的概率。因此G(D)越小，则数据集D的纯度越高。</p>
<p>特征A的基尼系数$G(D|A)=\sum_{i=1}^n\frac{|D_i|}{|D|}G(D_i)$，n为特征A的种类如年龄中的老少等。</p>
<p>划分点就是最小特征基尼系数。</p>
</blockquote>
</li>
</ul>
<p>首先，ID3是采用信息增益作为评价标准，会倾向于取值较多的特征。因为，信息增益反映的是给定条件以后不确定性减少的程度，特征取值越多就意味着确定性更高，也就是条件熵越小，信息增益越大。这导致泛化能力很弱。因此，C4.5实际上是对ID3进行优化，通过引入信息增益比，一定程度上对取值比较多的特征进行惩罚，避免ID3出现过拟合的特性，提升决策树的泛化能力。</p>
<p>其次，<strong>从样本类型的角度</strong>，ID3只能处理离散型变量（对于长度这种就不能了），而C4.5和CART都可以处理连续型变量。C4.5处理连续型变量时，通过对数据排序之后找到数值不同的点，根据切分点把连续属性转换为布尔型，从而将连续型变量转换多个取值区间的离散型变量。而对于CART，由于其构建时每次都会对特征进行二值划分，因此可以很好地适用于连续性变量。 </p>
<p>从<strong>应用角度</strong>，ID3和C4.5只能用于分类任务，而CART可以用于回归任务（回归树使用最小平方误差准则）。</p>
<p>此外，从<strong>实现细节、优化过程</strong>等角度：ID3对样本特征缺失值比较敏感，而C4.5和CART可以对缺失值进行不同方式的处理；ID3和C4.5可以在每个结点上产生出多叉分支，且每个特征在层级之间不会复用，而CART每个结点只会产生两个分支，因此最后会形成一颗二叉树，且每个特征可以被重复使用；ID3和C4.5通过剪枝来权衡树的准确性与泛化能力，而CART直接利用全部数据发现所有可能的树结构进行对比。</p>
<h2 id="如何对决策树进行剪枝？-bigstar-bigstar-bigstar"><a href="#如何对决策树进行剪枝？-bigstar-bigstar-bigstar" class="headerlink" title="如何对决策树进行剪枝？ $\bigstar \bigstar \bigstar$"></a>如何对决策树进行剪枝？ $\bigstar \bigstar \bigstar$</h2><p>预剪枝(pre-pruning)：</p>
<ul>
<li>做数据集划分，每次生成分支的时候通过验证集算损失，损失最小时则停止。</li>
<li>设置固定深度，到达深度时停止增长。</li>
<li>设置熵变化量阈值，熵变化量小于阈值时停止</li>
<li>信息增益显著性分析，如果当前增益不显著则停止划分。通常使用卡方检验。</li>
</ul>
<p>后剪枝(post-pruning):</p>
<ul>
<li><p>基于最小分类错误(Reduced Error Pruning，REP)：如果去掉该枝干错误率减小则剪枝。</p>
</li>
<li><p>最小长度准则：对决策树编码，剪枝得到编码最短的决策树（不是很明白）</p>
</li>
<li><p>基于代价和复杂性综合考虑(Cost Complexity Pruning，CCP)：如果去掉该枝干，综合错误率和复杂性综合考虑是否剪枝。</p>
<blockquote>
<p>设在t处剪枝的误差为：$\alpha=\frac{R(t)-R(T<em>t)}{|L</em>(t)|-1}$</p>
<p>L(t)代表以t节点为根的叶子数总数,R(t)代表t</p>
</blockquote>
</li>
</ul>
<h1 id="优化算法"><a href="#优化算法" class="headerlink" title="优化算法"></a>优化算法</h1><h2 id="监督学习的损失函数-bigstar"><a href="#监督学习的损失函数-bigstar" class="headerlink" title="监督学习的损失函数 $\bigstar$"></a>监督学习的损失函数 $\bigstar$</h2><p>最基础的肯定是0-1 loss，预测正确为0，错误为1，但是它不平滑不可导，就有了hinge loss替代它：</p>
<script type="math/tex; mode=display">
hingeloss= max(0,1-f*y)</script><p>同样，预测正确时损失为0，预测错误是hinge loss 是0-1 loss的凸上界。但是显然，某一点仍然不可导不能用梯度下降法进行优化。</p>
<p>0-1 loss 另一个替代就是logsitic loss：</p>
<script type="math/tex; mode=display">
logistic loss=log_2(1+e^{-fy})</script><p>它处处可导，但是在预测正确时仍有损失，还有一种就是交叉熵损失：</p>
<script type="math/tex; mode=display">
Entry loss= -log_2(\frac{1+fy}{2})</script><p>四种函数图像如下所示</p>
<p><img src= "/img/lazyload.svg" data-src="https://cdn.jsdelivr.net/gh/dummerchen/My_Image_Bed03@image_bed_001/img/20220306002750.png" alt="image-20220306002750188"></p>
</article><div class="essaySuffix-box"> <div class="essaySuffix-box-left"> <img src="https://cdn.jsdelivr.net/gh/dummerchen/cdn@master/img/custom/avatar.jpg" onerror="onerror=null;src='https://cdn.jsdelivr.net/gh/dummerchen/cdn/img/other/default_avatar.jpg'" alt="avatar"></div><div class="essaySuffix-box-right"> <span class="essaySuffix-right-title">本文作者：</span><strong> <span><a href="https:dummerfu.top" target="_blank" one-link-mark="yes">dummerfu</a></span></strong><br><span class="essaySuffix-right-title">本文链接：</span><a href="https://dummerfu.top/p/44332.html">https://dummerfu.top/p/44332.html</a><br><span class="essaySuffix-right-title">版权声明: </span>
本博客所有文章除特别声明外，均采用<a rel="noopener" target="_blank" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0许可协议</a>
转载请注明出处！</div></div><div class="tag_share"><div class="post_share"></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/p/33310.html"><img class="prev-cover" data-src="https://cdn.jsdelivr.net/gh/dummerchen/cdn@master/img/cover/4.jpg" src="/img/lazyload.svg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">最巧妙的算法之一--快速傅里叶变换</div></div></a></div><div class="next-post pull-right"><a href="/p/11693.html"><img class="next-cover" data-src="https://cdn.jsdelivr.net/gh/dummerchen/cdn@master/img/cover/5.jpg" src="/img/lazyload.svg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">放下鼠标，更高效的工作</div></div></a></div></nav><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> Comment</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-info-avatar is-center"><img class="avatar-img" data-src="https://cdn.jsdelivr.net/gh/dummerchen/cdn@master/img/custom/avatar.jpg" src="/img/lazyload.svg" onerror="this.onerror=null;this.src='https://cdn.jsdelivr.net/gh/dummerchen/cdn/img/other/default_avatar.jpg'" alt="avatar"/><div class="author-info__name">dummerfu</div><div class="author-info__description"></div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">45</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">Tags</div><div class="length-num">18</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">Categories</div><div class="length-num">6</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/dummerchen"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon faa-parent animated-hover" href="https://github.com/dummerchen" target="_blank" title="Github"><svg class="icon faa-tada" aria-hidden="true"><use xlink:href="#icon-rat"></use></svg></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>Announcement</span></div><div class="announcement_content">本博客由博客园<a href="https://www.cnblogs.com/cherrypill/" target=" _blank">cherrypill</a>迁移</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Catalog</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%89%8D%E8%A8%80"><span class="toc-number">1.</span> <span class="toc-text">前言</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B"><span class="toc-number"></span> <span class="toc-text">特征工程</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E9%9C%80%E8%A6%81%E5%AF%B9%E6%95%B0%E5%80%BC%E7%B1%BB%E5%9E%8B%E7%9A%84%E7%89%B9%E5%BE%81%E5%81%9A%E5%BD%92%E4%B8%80%E5%8C%96%EF%BC%9F-bigstar"><span class="toc-number">1.</span> <span class="toc-text">为什么需要对数值类型的特征做归一化？$\bigstar$</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%8E%E6%A0%B7%E5%A4%84%E7%90%86%E7%B1%BB%E5%88%AB%E5%9E%8B%E7%89%B9%E5%BE%81%EF%BC%9F-bigstar-bigstar"><span class="toc-number">2.</span> <span class="toc-text">怎样处理类别型特征？$\bigstar\bigstar$</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E7%BB%84%E5%90%88%E7%89%B9%E5%BE%81%EF%BC%9F%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86%E9%AB%98%E7%BB%B4%E7%BB%84%E5%90%88%E7%89%B9%E5%BE%81%EF%BC%9F-bigstar-bigstar"><span class="toc-number">3.</span> <span class="toc-text">什么是组合特征？如何处理高维组合特征？$\bigstar\bigstar$</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%8E%E6%A0%B7%E6%9C%89%E6%95%88%E5%9C%B0%E6%89%BE%E5%88%B0%E7%BB%84%E5%90%88%E7%89%B9%E5%BE%81-bigstar-bigstar"><span class="toc-number">4.</span> <span class="toc-text">怎样有效地找到组合特征?$\bigstar\bigstar$</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9C%89%E5%93%AA%E4%BA%9B%E6%96%87%E6%9C%AC%E8%A1%A8%E7%A4%BA%E6%A8%A1%E5%9E%8B%EF%BC%9F%E5%AE%83%E4%BB%AC%E5%90%84%E6%9C%89%E4%BB%80%E4%B9%88%E4%BC%98%E7%BC%BA%E7%82%B9%EF%BC%9F-bigstar-bigstar"><span class="toc-number">5.</span> <span class="toc-text">有哪些文本表示模型？它们各有什么优缺点？$\bigstar\bigstar$</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AF%8D%E8%A2%8B%E6%A8%A1%E5%9E%8B"><span class="toc-number">5.1.</span> <span class="toc-text">词袋模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BB%E9%A2%98%E6%A8%A1%E5%9E%8B"><span class="toc-number">5.2.</span> <span class="toc-text">主题模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E5%92%8C%E8%AF%8D%E5%B5%8C%E5%85%A5%E6%A8%A1%E5%9E%8B"><span class="toc-number">5.3.</span> <span class="toc-text">深度学习模型和词嵌入模型</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Word2Vec%E6%98%AF%E5%A6%82%E4%BD%95%E5%B7%A5%E4%BD%9C%E7%9A%84%EF%BC%9F%E5%AE%83%E5%92%8CLDA%E6%9C%89%E4%BB%80%E4%B9%88%E5%8C%BA%E5%88%AB%E4%B8%8E%E8%81%94%E7%B3%BB%EF%BC%9F-bigstar-bigstar-bigstar"><span class="toc-number">6.</span> <span class="toc-text">Word2Vec是如何工作的？它和LDA有什么区别与联系？$\bigstar\bigstar\bigstar$</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9C%A8%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1%E4%B8%AD%EF%BC%8C%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%E4%B8%8D%E8%B6%B3%E4%BC%9A%E5%B8%A6%E6%9D%A5%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%E5%A6%82%E4%BD%95%E7%BC%93%E8%A7%A3%E6%95%B0%E6%8D%AE%E9%87%8F%E4%B8%8D%E8%B6%B3%E5%B8%A6%E6%9D%A5%E7%9A%84%E9%97%AE%E9%A2%98%EF%BC%9F-bigstar-bigstar"><span class="toc-number">7.</span> <span class="toc-text">在图像分类任务中，训练数据不足会带来什么问题？如何缓解数据量不足带来的问题？$\bigstar\bigstar$</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0"><span class="toc-number"></span> <span class="toc-text">模型评估</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%87%86%E7%A1%AE%E7%8E%87%E7%9A%84%E5%B1%80%E9%99%90%E6%80%A7"><span class="toc-number">1.</span> <span class="toc-text">准确率的局限性</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E9%99%8D%E7%BB%B4"><span class="toc-number"></span> <span class="toc-text">降维</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E5%AE%9A%E4%B9%89%E4%B8%BB%E6%88%90%E5%88%86%EF%BC%9F%E4%BB%8E%E8%BF%99%E7%A7%8D%E5%AE%9A%E4%B9%89%E5%87%BA%E5%8F%91%EF%BC%8C%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9B%AE%E6%A0%87%E5%87%BD%E6%95%B0%E4%BD%BF%E5%BE%97%E9%99%8D%E7%BB%B4%E8%BE%BE%E5%88%B0%E6%8F%90%E5%8F%96%E4%B8%BB%E6%88%90%E5%88%86%E7%9A%84%E7%9B%AE%E7%9A%84%EF%BC%9F%E9%92%88%E5%AF%B9%E8%BF%99%E4%B8%AA%E7%9B%AE%E6%A0%87%E5%87%BD%E6%95%B0%EF%BC%8C%E5%A6%82%E4%BD%95%E5%AF%B9PCA%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E6%B1%82%E8%A7%A3-bigstar-bigstar"><span class="toc-number">1.</span> <span class="toc-text">如何定义主成分？从这种定义出发，如何设计目标函数使得降维达到提取主成分的目的？针对这个目标函数，如何对PCA问题进行求解 $\bigstar \bigstar$</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AF%B9%E4%BA%8E%E5%85%B7%E6%9C%89%E7%B1%BB%E5%88%AB%E6%A0%87%E7%AD%BE%E7%9A%84%E6%95%B0%E6%8D%AE%EF%BC%8C%E5%BA%94%E5%BD%93%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9B%AE%E6%A0%87%E5%87%BD%E6%95%B0%E4%BD%BF%E5%BE%97%E9%99%8D%E7%BB%B4%E7%9A%84%E8%BF%87%E7%A8%8B%E4%B8%AD%E4%B8%8D%E6%8D%9F%E5%A4%B1%E7%B1%BB%E5%88%AB%E4%BF%A1%E6%81%AF%EF%BC%9F%E5%9C%A8%E8%BF%99%E7%A7%8D%E7%9B%AE%E6%A0%87%E4%B8%8B%EF%BC%8C%E5%BA%94%E5%BD%93%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E6%B1%82%E8%A7%A3%EF%BC%9F%EF%BC%88%E6%89%8B%E6%8E%A8LDA%EF%BC%89-bigstar-bigstar"><span class="toc-number">2.</span> <span class="toc-text">对于具有类别标签的数据，应当如何设计目标函数使得降维的过程中不损失类别信息？在这种目标下，应当如何进行求解？（手推LDA）$\bigstar \bigstar$</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#LDA%E5%92%8CPCA%E4%BD%9C%E4%B8%BA%E7%BB%8F%E5%85%B8%E7%9A%84%E9%99%8D%E7%BB%B4%E7%AE%97%E6%B3%95%EF%BC%8C%E5%A6%82%E4%BD%95%E4%BB%8E%E5%BA%94%E7%94%A8%E7%9A%84%E8%A7%92%E5%BA%A6%E5%88%86%E6%9E%90%E5%85%B6%E5%8E%9F%E7%90%86%E7%9A%84%E5%BC%82%E5%90%8C%EF%BC%9F%E4%BB%8E%E6%95%B0%E5%AD%A6%E6%8E%A8%E5%AF%BC%E7%9A%84%E8%A7%92%E5%BA%A6%EF%BC%8C%E4%B8%A4%E7%A7%8D%E9%99%8D%E7%BB%B4%E7%AE%97%E6%B3%95%E5%9C%A8%E7%9B%AE%E6%A0%87%E5%87%BD%E6%95%B0%E4%B8%8A%E6%9C%89%E4%BD%95%E5%8C%BA%E5%88%AB%E4%B8%8E%E8%81%94%E7%B3%BB%EF%BC%9F"><span class="toc-number">3.</span> <span class="toc-text">LDA和PCA作为经典的降维算法，如何从应用的角度分析其原理的异同？从数学推导的角度，两种降维算法在目标函数上有何区别与联系？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%99%A4%E4%BA%86pca%E4%BC%A0%E7%BB%9F%E7%9A%84%E7%9A%84%E7%89%B9%E5%BE%81%E9%99%8D%E7%BB%B4%E6%96%B9%E6%B3%95%E6%9C%89%E5%93%AA%E4%BA%9B%EF%BC%8C%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9%E6%96%B9%E6%B3%95%E6%9C%89%E5%93%AA%E4%BA%9B"><span class="toc-number">4.</span> <span class="toc-text">除了pca传统的的特征降维方法有哪些，特征选择方法有哪些</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E6%B5%81%E5%9E%8B%E5%AD%A6%E4%B9%A0%EF%BC%8CISOmap%E5%92%8CLLE%E7%9A%84%E5%8E%9F%E7%90%86"><span class="toc-number">5.</span> <span class="toc-text">什么是流型学习，ISOmap和LLE的原理</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0"><span class="toc-number"></span> <span class="toc-text">无监督学习</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#K%E5%9D%87%E5%80%BC%E7%AE%97%E6%B3%95%E7%9A%84%E4%BC%98%E7%BC%BA%E7%82%B9%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%E5%A6%82%E4%BD%95%E5%AF%B9%E5%85%B6%E8%BF%9B%E8%A1%8C%E8%B0%83%E4%BC%98%EF%BC%9F-bigstar-bigstar-bigstar"><span class="toc-number">1.</span> <span class="toc-text">K均值算法的优缺点是什么？如何对其进行调优？$\bigstar \bigstar\bigstar$</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%AB%98%E6%96%AF%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%A0%B8%E5%BF%83%E6%80%9D%E6%83%B3%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%E5%AE%83%E6%98%AF%E5%A6%82%E4%BD%95%E8%BF%AD%E4%BB%A3%E8%AE%A1%E7%AE%97%E7%9A%84-bigstar-bigstar"><span class="toc-number">2.</span> <span class="toc-text">高斯混合模型的核心思想是什么？它是如何迭代计算的$\bigstar\bigstar$</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%A5%E8%81%9A%E7%B1%BB%E9%97%AE%E9%A2%98%E4%B8%BA%E4%BE%8B%EF%BC%8C%E5%81%87%E8%AE%BE%E6%B2%A1%E6%9C%89%E5%A4%96%E9%83%A8%E6%A0%87%E7%AD%BE%E6%95%B0%E6%8D%AE%EF%BC%8C%E5%A6%82%E4%BD%95%E8%AF%84%E4%BC%B0%E4%B8%A4%E4%B8%AA%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95%E7%9A%84%E4%BC%98%E5%8A%A3%EF%BC%9F-bigstar-bigstar-bigstar"><span class="toc-number">3.</span> <span class="toc-text">以聚类问题为例，假设没有外部标签数据，如何评估两个聚类算法的优劣？$\bigstar\bigstar\bigstar$</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#SVM"><span class="toc-number"></span> <span class="toc-text">SVM</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8E%A8%E5%AF%BCSVM"><span class="toc-number">1.</span> <span class="toc-text">推导SVM</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9C%A8%E7%A9%BA%E9%97%B4%E4%B8%8A%E7%BA%BF%E6%80%A7%E5%8F%AF%E5%88%86%E7%9A%84%E4%B8%A4%E7%B1%BB%E7%82%B9%EF%BC%8C%E5%88%86%E5%88%AB%E5%90%91SVM%E5%88%86%E7%B1%BB%E7%9A%84%E8%B6%85%E5%B9%B3%E9%9D%A2%E4%B8%8A%E5%81%9A%E6%8A%95%E5%BD%B1%EF%BC%8C%E8%BF%99%E4%BA%9B%E7%82%B9%E5%9C%A8%E8%B6%85%E5%B9%B3%E9%9D%A2%E4%B8%8A%E7%9A%84%E6%8A%95%E5%BD%B1%E4%BB%8D%E7%84%B6%E6%98%AF%E7%BA%BF%E6%80%A7%E5%8F%AF%E5%88%86%E7%9A%84%E5%90%97%EF%BC%9F-bigstar-bigstar-bigstar"><span class="toc-number">2.</span> <span class="toc-text">在空间上线性可分的两类点，分别向SVM分类的超平面上做投影，这些点在超平面上的投影仍然是线性可分的吗？ $\bigstar \bigstar\bigstar$</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Logistic-%E5%9B%9E%E5%BD%92"><span class="toc-number"></span> <span class="toc-text">Logistic 回归</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E7%9B%B8%E6%AF%94%E4%BA%8E%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%EF%BC%8C%E6%9C%89%E4%BD%95%E5%BC%82%E5%90%8C%EF%BC%9F-bigstar-bigstar"><span class="toc-number">1.</span> <span class="toc-text">逻辑回归相比于线性回归，有何异同？$\bigstar \bigstar$</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%8D%E4%BD%BF%E7%94%A8MSE%E4%BD%9C%E4%B8%BAloss"><span class="toc-number">2.</span> <span class="toc-text">逻辑回归为什么不使用MSE作为loss</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BD%93%E4%BD%BF%E7%94%A8%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E5%A4%84%E7%90%86%E5%A4%9A%E6%A0%87%E7%AD%BE%E7%9A%84%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98%E6%97%B6%EF%BC%8C%E6%9C%89%E5%93%AA%E4%BA%9B%E5%B8%B8%E8%A7%81%E5%81%9A%E6%B3%95%EF%BC%8C%E5%88%86%E5%88%AB%E5%BA%94%E7%94%A8%E4%BA%8E%E5%93%AA%E4%BA%9B%E5%9C%BA%E6%99%AF%EF%BC%8C%E5%AE%83%E4%BB%AC%E4%B9%8B%E9%97%B4%E5%8F%88%E6%9C%89%E6%80%8E%E6%A0%B7%E7%9A%84%E5%85%B3%E7%B3%BB%EF%BC%9F-bigstar-bigstar-bigstar"><span class="toc-number">3.</span> <span class="toc-text">当使用逻辑回归处理多标签的分类问题时，有哪些常见做法，分别应用于哪些场景，它们之间又有怎样的关系？$\bigstar \bigstar \bigstar$</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%86%B3%E7%AD%96%E6%A0%91"><span class="toc-number"></span> <span class="toc-text">决策树</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%86%B3%E7%AD%96%E6%A0%91%E6%9C%89%E5%93%AA%E4%BA%9B%E5%B8%B8%E7%94%A8%E7%9A%84%E5%90%AF%E5%8F%91%E5%87%BD%E6%95%B0%EF%BC%9F-bigstar-bigstar"><span class="toc-number">1.</span> <span class="toc-text">决策树有哪些常用的启发函数？$\bigstar \bigstar$</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E5%AF%B9%E5%86%B3%E7%AD%96%E6%A0%91%E8%BF%9B%E8%A1%8C%E5%89%AA%E6%9E%9D%EF%BC%9F-bigstar-bigstar-bigstar"><span class="toc-number">2.</span> <span class="toc-text">如何对决策树进行剪枝？ $\bigstar \bigstar \bigstar$</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95"><span class="toc-number"></span> <span class="toc-text">优化算法</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0-bigstar"><span class="toc-number">1.</span> <span class="toc-text">监督学习的损失函数 $\bigstar$</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/p/49081.html" title="【论文复现】Restormer"><img data-src="https://cdn.jsdelivr.net/gh/dummerchen/My_Image_Bed03@image_bed_001/img/20211212145136.jpg" src="/img/lazyload.svg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【论文复现】Restormer"/></a><div class="content"><a class="title" href="/p/49081.html" title="【论文复现】Restormer">【论文复现】Restormer</a><time datetime="2022-07-30T00:00:00.000Z" title="Created 2022-07-30 00:00:00">2022-07-30</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/p/3640.html" title="【论文复现】SwinIR"><img data-src="https://cdn.jsdelivr.net/gh/dummerchen/My_Image_Bed03@image_bed_001/img/20211212145155.jpg" src="/img/lazyload.svg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【论文复现】SwinIR"/></a><div class="content"><a class="title" href="/p/3640.html" title="【论文复现】SwinIR">【论文复现】SwinIR</a><time datetime="2022-07-30T00:00:00.000Z" title="Created 2022-07-30 00:00:00">2022-07-30</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/p/63048.html" title="图像理解与计算机视觉笔记"><img data-src="https://cdn.jsdelivr.net/gh/dummerchen/My_Image_Bed03@image_bed_001/img/20211212145212.jpg" src="/img/lazyload.svg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="图像理解与计算机视觉笔记"/></a><div class="content"><a class="title" href="/p/63048.html" title="图像理解与计算机视觉笔记">图像理解与计算机视觉笔记</a><time datetime="2022-06-18T00:00:00.000Z" title="Created 2022-06-18 00:00:00">2022-06-18</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/p/42559.html" title="代码审计工具"><img data-src="https://cdn.jsdelivr.net/gh/dummerchen/My_Image_Bed03@image_bed_001/img/20211212145136.jpg" src="/img/lazyload.svg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="代码审计工具"/></a><div class="content"><a class="title" href="/p/42559.html" title="代码审计工具">代码审计工具</a><time datetime="2022-05-20T00:00:00.000Z" title="Created 2022-05-20 00:00:00">2022-05-20</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/p/44311.html" title="【论文复现】卷积网络可视化Grad-cam和Guide backpropagation"><img data-src="https://cdn.jsdelivr.net/gh/dummerchen/My_Image_Bed03@image_bed_001/img/20211212120605.jpg" src="/img/lazyload.svg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【论文复现】卷积网络可视化Grad-cam和Guide backpropagation"/></a><div class="content"><a class="title" href="/p/44311.html" title="【论文复现】卷积网络可视化Grad-cam和Guide backpropagation">【论文复现】卷积网络可视化Grad-cam和Guide backpropagation</a><time datetime="2022-05-16T00:00:00.000Z" title="Created 2022-05-16 00:00:00">2022-05-16</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2022 By dummerfu</div><p id="ghbdages"><a class="github-badge" target="_blank" href="https://hexo.io/" style="margin-inline:5px"><img src="https://img.shields.io/badge/Frame-Hexo-blue?style=flat&amp;logo=hexo"/></a><a class="github-badge" target="_blank" href="https://butterfly.js.org/" style="margin-inline:5px"><img src="https://img.shields.io/badge/Theme-Butterfly-6513df?style=flat&amp;logo=bitdefender"/></a><a class="github-badge" target="_blank" href="https://www.jsdelivr.com/" style="margin-inline:5px"><img src="https://img.shields.io/badge/CDN-jsDelivr-orange?style=flat&amp;logo=jsDelivr"/></a><a class="github-badge" target="_blank" href="https://github.com/" style="margin-inline:5px"><img src="https://img.shields.io/badge/Source-Github-d021d6?style=flat&amp;logo=GitHub"/></a></p></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="Toggle Between Traditional Chinese And Simplified Chinese">简</button><button id="darkmode" type="button" title="Toggle Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="Scroll To Comments"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">Local search</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/vue@2.6.11"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script async="async">var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',preloader.endLoading())
setTimeout(function(){preloader.endLoading();}, 5000);</script></div><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    loader: {
      source: {
        '[tex]/amsCd': '[tex]/amscd'
      }
    },
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        addClass: [200,() => {
          document.querySelectorAll('mjx-container:not([display=\'true\']').forEach( node => {
            const target = node.parentNode
            if (!target.classList.contains('has-jax')) {
              target.classList.add('mathjax-overflow')
            }
          })
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/contrib/copy-tex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/contrib/copy-tex.css"><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', '', 'katex-wrap')
  })
})()</script><script>(()=>{
  const $countDom = document.getElementById('twikoo-count')
  const init = () => {
    twikoo.init(Object.assign({
      el: '#twikoo-wrap',
      envId: 'twikoo-8g53l3ue41b208dc',
      region: 'ap-shanghai'
    }, null))
  }

  const getCount = () => {
    twikoo.getCommentsCount({
      envId: 'twikoo-8g53l3ue41b208dc',
      region: 'ap-shanghai',
      urls: [window.location.pathname],
      includeReply: false
    }).then(function (res) {
      $countDom.innerText = res[0].count
    }).catch(function (err) {
      console.error(err);
    });
  }

  const loadTwikoo = (bool = false) => {
    if (typeof twikoo === 'object') {
      init()
      bool && $countDom && setTimeout(getCount,0)
    } else {
      getScript('https://cdn.jsdelivr.net/npm/twikoo@1.4.15/dist/twikoo.all.min.js').then(()=> {
        init()
        bool && $countDom && setTimeout(getCount,0)
      })
    }
  }

  if ('Twikoo' === 'Twikoo' || !true) {
    if (true) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo(true)
  } else {
    window.loadOtherComment = () => {
      loadTwikoo()
    }
  }
})()</script><script>var gitcalendar = new Vue({
  el: '#gitcalendar',
  data: {
    simplemode: false, 
    user: 'dummerchen',
    fixed: 'fixed',
    px: 'px',
    x: '',
    y: '',
    span1: '',
    span2: '',
    month: ['一月', '二月', '三月', '四月', '五月', '六月', '七月', '八月', '九月', '十月', '十一月', '十二月'],
    monthchange: [],
    oneyearbeforeday: '',
    thisday: '',
    amonthago: '',
    aweekago: '',
    weekdatacore: 0,
    datacore: 0,
    total: 0,
    datadate: '',
    data: [],
    positionplusdata: [],
    firstweek: [],
    lastweek: [],
    beforeweek: [],
    thisweekdatacore: 0,
    mounthbeforeday: 0,
    mounthfirstindex: 0,
    crispedges: 'crispedges',
    thisdayindex: 0,
    amonthagoindex: 0,
    amonthagoweek: [],
    firstdate: [],
    first2date: [],
    montharrbefore: [],
    monthindex: 0,
    color: ['#e4dfd7', '#f9f4dc', '#f7e8aa', '#f7e8aa', '#f8df72', '#fcd217', '#fcc515', '#f28e16', '#fb8b05', '#d85916', '#f43e06']
  },
  methods: {
    selectStyle(data, event) {
      document.querySelector('.angle-wrapper').style.display = 'block'
      this.span1 = data.date;
      this.span2 = data.count;
      this.x = event.clientX - 100;
      this.y = event.clientY - 60
    },
    outStyle() {
      document.querySelector('.angle-wrapper').style.display = 'none'
    },
    thiscolor(x) {
      if (x === 0) {
        let i = parseInt(x / 2);
        return this.color[0]
      } else if (x < 2) {
        return this.color[1]
      } else if (x < 20) {
        let i = parseInt(x / 2);
        return this.color[i]
      } else {
        return this.color[9]
      }
    },
  }
});
var apiurl = 'github-calendar-api.vercel.app' ? 'https://github-calendar-api.vercel.app/api?' : 'https://githubapi.ryanchristian.dev/user/'
var githubapiurl = apiurl + gitcalendar.user;
//canvas绘图
function responsiveChart() {
  let c = document.getElementById("gitcanvas");
  if (c) {
    let cmessage = document.getElementById("gitmessage");
    let ctx = c.getContext("2d");
    c.width = document.getElementById("gitcalendarcanvasbox").offsetWidth;
    let linemaxwitdh = 0.96 * c.width / gitcalendar.data.length;
    c.height = 9 * linemaxwitdh;
    let lineminwitdh = 0.8 * linemaxwitdh;
    let setposition = {
      x: 0.02 * c.width,
      y: 0.025 * c.width
    };
    for (let week in gitcalendar.data) {
      weekdata = gitcalendar.data[week];
      for (let day in weekdata) {
        let dataitem = {
          date: "",
          count: "",
          x: 0,
          y: 0
        };
        gitcalendar.positionplusdata.push(dataitem);
        ctx.fillStyle = gitcalendar.thiscolor(weekdata[day].count);
        setposition.y = Math.round(setposition.y * 100) / 100;
        dataitem.date = weekdata[day].date;
        dataitem.count = weekdata[day].count;
        dataitem.x = setposition.x;
        dataitem.y = setposition.y;
        ctx.fillRect(setposition.x, setposition.y, lineminwitdh, lineminwitdh);
        setposition.y = setposition.y + linemaxwitdh
      };
      setposition.y = 0.025 * c.width;
      setposition.x = setposition.x + linemaxwitdh
    };
    ctx.font = "600  Arial";
    ctx.fillStyle = '#aaa';
    ctx.fillText("日", 0, 1.9 * linemaxwitdh);
    ctx.fillText("二", 0, 3.9 * linemaxwitdh);
    ctx.fillText("四", 0, 5.9 * linemaxwitdh);
    ctx.fillText("六", 0, 7.9 * linemaxwitdh);
    let monthindexlist = c.width / 24;
    for (let index in gitcalendar.monthchange) {
      ctx.fillText(gitcalendar.monthchange[index], monthindexlist, 0.7 * linemaxwitdh);
      monthindexlist = monthindexlist + c.width / 12
    };
    cmessage.onmousemove = function(event) {
      document.querySelector('.angle-wrapper').style.display = 'none'
    };
    c.onmousemove = function(event) {
      document.querySelector('.angle-wrapper').style.display = 'none'
      getMousePos(c, event);
    };

    function getMousePos(canvas, event) {
      var rect = canvas.getBoundingClientRect();
      var x = event.clientX - rect.left * (canvas.width / rect.width);
      var y = event.clientY - rect.top * (canvas.height / rect.height);
      //console.log("x:"+x+",y:"+y);
      for (let item of gitcalendar.positionplusdata) {
        let lenthx = x - item.x;
        let lenthy = y - item.y;
        //console.log(lenthx,lenthy);
        if (0 < lenthx && lenthx < lineminwitdh) {
          if (0 < lenthy && lenthy < lineminwitdh) {
            //console.log(item.date,item.count)
            document.querySelector('.angle-wrapper').style.display = 'block'
            gitcalendar.span1 = item.date;
            gitcalendar.span2 = item.count;
            gitcalendar.x = event.clientX - 100;
            gitcalendar.y = event.clientY - 60
          }
        }
        //if(0< x - item.x <lineminwitdh&&0< y - item.y <lineminwitdh){
        //console.log(item.count,item.date);
        //}
      }
    }
  }
}
//数据统计算法
function addlastmonth() {
  if (gitcalendar.thisdayindex === 0) {
    thisweekcore(52);
    thisweekcore(51);
    thisweekcore(50);
    thisweekcore(49);
    thisweekcore(48);
    gitcalendar.thisweekdatacore += gitcalendar.firstdate[6].count;
    gitcalendar.amonthago = gitcalendar.firstdate[6].date
  } else {
    thisweekcore(52);
    thisweekcore(51);
    thisweekcore(50);
    thisweekcore(49);
    thisweek2core();
    gitcalendar.amonthago = gitcalendar.first2date[gitcalendar.thisdayindex - 1].date
  }
};

function thisweek2core() {
  for (let i = gitcalendar.thisdayindex - 1; i < gitcalendar.first2date.length; i++) {
    gitcalendar.thisweekdatacore += gitcalendar.first2date[i].count
  }
};

function thisweekcore(index) {
  for (let item of gitcalendar.data[index]) {
    gitcalendar.thisweekdatacore += item.count
  }
};

function addlastweek() {
  for (let item of gitcalendar.lastweek) {
    gitcalendar.weekdatacore += item.count
  }
};

function addbeforeweek() {
  for (let i = gitcalendar.thisdayindex; i < gitcalendar.beforeweek.length; i++) {
    gitcalendar.weekdatacore += gitcalendar.beforeweek[i].count
  }
};

function addweek(data) {
  if (gitcalendar.thisdayindex === 6) {
    gitcalendar.aweekago = gitcalendar.lastweek[0].date;
    addlastweek()
  } else {
    lastweek = data.contributions[51];
    gitcalendar.aweekago = lastweek[gitcalendar.thisdayindex + 1].date;
    addlastweek();
    addbeforeweek()
  }
}

fetch(githubapiurl)
  .then(data => data.json())
  .then(data => {
    gitcalendar.data = data.contributions;
    gitcalendar.total = data.total;
    gitcalendar.first2date = gitcalendar.data[48];
    gitcalendar.firstdate = gitcalendar.data[47];
    gitcalendar.firstweek = data.contributions[0];
    gitcalendar.lastweek = data.contributions[52];
    gitcalendar.beforeweek = data.contributions[51];
    gitcalendar.thisdayindex = gitcalendar.lastweek.length - 1;
    gitcalendar.thisday = gitcalendar.lastweek[gitcalendar.thisdayindex].date;
    gitcalendar.oneyearbeforeday = gitcalendar.firstweek[0].date;
    gitcalendar.monthindex = gitcalendar.thisday.substring(5, 7) * 1;
    gitcalendar.montharrbefore = gitcalendar.month.splice(gitcalendar.monthindex, 12 - gitcalendar.monthindex);
    gitcalendar.monthchange = gitcalendar.montharrbefore.concat(gitcalendar.month);
    addweek(data);
    addlastmonth();
    responsiveChart();
  })
  .catch(function(error) {
    console.log(error);
  });

//手机版更换为svg绘制
if (document.getElementById("gitcalendarcanvasbox") && (document.getElementById("gitcalendarcanvasbox").offsetWidth < 500)) {
  gitcalendar.simplemode = false
}
//当改变窗口大小时重新绘制canvas
window.onresize = function() {
  if (gitcalendar.simplemode) responsiveChart()
}

//解决滚动滑轮时出现的标签显示
window.onscroll = function() {
  if (document.querySelector('.angle-wrapper')) {
    document.querySelector('.angle-wrapper').style.display = 'none'
  }
};</script></div><script defer src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script defer src="https://cdn.jsdelivr.net/npm/hexo-theme-volantis@latest/source/js/issues.min.js"></script><script src="/js/moments.js"></script><canvas class="fireworks" mobile="false"></canvas><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/fireworks.min.js"></script><div class="js-pjax"><script async="async">var arr = document.getElementsByClassName('recent-post-item');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__zoomIn');
    arr[i].setAttribute('data-wow-duration', '1s');
    arr[i].setAttribute('data-wow-delay', '0');
    arr[i].setAttribute('data-wow-offset', '0');
    arr[i].setAttribute('data-wow-iteration', '1');
  }</script><script async="async">var arr = document.getElementsByClassName('card-widget');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__zoomIn');
    arr[i].setAttribute('data-wow-duration', '');
    arr[i].setAttribute('data-wow-delay', '');
    arr[i].setAttribute('data-wow-offset', '');
    arr[i].setAttribute('data-wow-iteration', '');
  }</script></div><script defer="defer" src="https://cdn.jsdelivr.net/gh/graingert/wow@1.3.0/dist/wow.min.js"></script><script defer="defer" src="/js/custom/wow_init.js"></script><div class="app-refresh" id="app-refresh" style="position: fixed;top: -2.2rem;left: 0;right: 0;z-index: 99999;padding: 0 1rem;font-size: 15px;height: 2.2rem;transition: all 0.3s ease;"><div class="app-refresh-wrap" style=" display: flex;color: #fff;height: 100%;align-items: center;justify-content: center;"><label>✨ 有文章更新啦！ 👉</label><a href="javascript:void(0)" onclick="location.reload()"><span style="color: #fff;text-decoration: underline;cursor: pointer;">🍭查看新品🍬</span></a></div></div><script>if ('serviceWorker' in navigator) {
if (navigator.serviceWorker.controller) {
navigator.serviceWorker.addEventListener('controllerchange', function() {
showNotification()
})
}
window.addEventListener('load', function() {
navigator.serviceWorker.register('/sw.js')
})
}
function showNotification() {
if (GLOBAL_CONFIG.Snackbar) {
var snackbarBg =
document.documentElement.getAttribute('data-theme') === 'light' ?
GLOBAL_CONFIG.Snackbar.bgLight :
GLOBAL_CONFIG.Snackbar.bgDark
var snackbarPos = GLOBAL_CONFIG.Snackbar.position
Snackbar.show({
text: '✨ 有文章更新啦！ 👉',
backgroundColor: snackbarBg,
duration: 500000,
pos: snackbarPos,
actionText: '🍭查看新品🍬',
actionTextColor: '#fff',
onActionClick: function(e) {
location.reload()
},
})
} else {
var showBg =
document.documentElement.getAttribute('data-theme') === 'light' ?
'#49b1f5' :
'#1f1f1f'
var cssText = `top: 0; background: ${showBg};`
document.getElementById('app-refresh').style.cssText = cssText
}
}</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>