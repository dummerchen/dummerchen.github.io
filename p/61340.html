<!DOCTYPE html><html lang="zh-cn" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>【论文】深度学习CV方向论文解读 | Sakura        Momoko</title><meta name="keywords" content="论文"><meta name="author" content="dummerfu"><meta name="copyright" content="dummerfu"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="按时间线（大概）整理CV方向论文">
<meta property="og:type" content="article">
<meta property="og:title" content="【论文】深度学习CV方向论文解读">
<meta property="og:url" content="https://dummerfu.top/p/61340.html">
<meta property="og:site_name" content="Sakura        Momoko">
<meta property="og:description" content="按时间线（大概）整理CV方向论文">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/dummerchen/cdn@master/img/cover/4.jpg">
<meta property="article:published_time" content="2021-09-01T00:00:00.000Z">
<meta property="article:modified_time" content="2022-01-11T00:00:00.000Z">
<meta property="article:author" content="dummerfu">
<meta property="article:tag" content="论文">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/dummerchen/cdn@master/img/cover/4.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://dummerfu.top/p/61340"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//hm.baidu.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta name="google-site-verification" content="ul2nhVj6HNaI1d3xtFc7_eYD8Shq0bCu53fkA7a_7Bc"/><meta name="baidu-site-verification" content="code-584WEbZyly"/><link rel="manifest" href="/manifest.json"/><meta name="msapplication-TileColor" content="#212121"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?7cb70c60ee4da7f272c0d8059de063b7";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/4.1.1/animate.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Swiper/4.1.6/css/swiper.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"We didn't find any results for the search: ${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: {"limitDay":30,"position":"top","messagePrev":"It has been","messageNext":"days since the last update, the content of the article may be outdated."},
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":"70vh"},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: 'days',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"Traditional Chinese Activated Manually","cht_to_chs":"Simplified Chinese Activated Manually","day_to_night":"Dark Mode Activated Manually","night_to_day":"Light Mode Activated Manually","bgLight":"#49b1f5","bgDark":"#121212","position":"top-center"},
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: true,
  islazyload: true,
  isanchor: true
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-01-11 00:00:00'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    })(window)</script><meta http-equiv="content-type" content="text/html; charset=UTF-8" /><link rel="stylesheet" href="/css/mycss.css"><script src='https://cdn.jsdelivr.net/npm/butterfly-friend@1.0.4/dist/friend.min.js'></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/l-lin/font-awesome-animation/dist/font-awesome-animation.min.css"  media="defer" onload="this.media='all'"><link rel="stylesheet" href="https://at.alicdn.com/t/font_2134734_qu549vixs5f.css?spm=a313x.7781069.1998910419.60&file=font_2134734_qu549vixs5f.css" medis="defer" onload="this.media='all'"><script src="/js/lazyload.js"></script><meta name="generator" content="Hexo 5.4.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="wizard-scene"><div class="wizard-objects"><div class="wizard-square"></div><div class="wizard-circle"></div><div class="wizard-triangle"></div></div><div class="wizard"><div class="wizard-body"></div><div class="wizard-right-arm"><div class="wizard-right-hand"></div></div><div class="wizard-left-arm"><div class="wizard-left-hand"></div></div><div class="wizard-head"><div class="wizard-beard"></div><div class="wizard-face"><div class="wizard-adds"></div></div><div class="wizard-hat"><div class="wizard-hat-of-the-hat"></div><div class="wizard-four-point-star --first"></div><div class="wizard-four-point-star --second"></div><div class="wizard-four-point-star --third"></div></div></div></div></div></div><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" data-src="https://cdn.jsdelivr.net/gh/dummerchen/cdn@master/img/custom/avatar.jpg" src="/img/lazyload.svg" onerror="onerror=null;src='https://cdn.jsdelivr.net/gh/dummerchen/cdn/img/other/default_avatar.jpg'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">45</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">Tags</div><div class="length-num">18</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">Categories</div><div class="length-num">6</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/"><i class="fa-fw fas fa-home faa-tada"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/archives/"><i class="fa-fw fas fa-archive faa-tada"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/comment/"><i class="fa-fw fa fa-comments faa-tada"></i><span> 留言</span></a></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/links/"><i class="fa-fw fas fa-link faa-tada"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/circle/"><i class="fa-fw fas fa-user-friends faa-tada"></i><span> 朋友圈</span></a></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/about/"><i class="fa-fw fa-fw fas fa-heart faa-tada"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://cdn.jsdelivr.net/gh/dummerchen/My_Image_Bed03@image_bed_001/img/20210807115649.jpg')"><nav id="nav"><span id="blog_name"> <a id="site-name" onclick="btf.scrollToDest(0, 500)" data-title="按时间线（大概）整理CV方向论文">【论文】深度学习CV方向论文解读</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/"><i class="fa-fw fas fa-home faa-tada"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/archives/"><i class="fa-fw fas fa-archive faa-tada"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/comment/"><i class="fa-fw fa fa-comments faa-tada"></i><span> 留言</span></a></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/links/"><i class="fa-fw fas fa-link faa-tada"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/circle/"><i class="fa-fw fas fa-user-friends faa-tada"></i><span> 朋友圈</span></a></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/about/"><i class="fa-fw fa-fw fas fa-heart faa-tada"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">【论文】深度学习CV方向论文解读</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2021-09-01T00:00:00.000Z" title="Created 2021-09-01 00:00:00">2021-09-01</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2022-01-11T00:00:00.000Z" title="Updated 2022-01-11 00:00:00">2022-01-11</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%8A%80%E6%9C%AF/">技术</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">Word count:</span><span class="word-count">5.8k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">Reading time:</span><span>18min</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="【论文】深度学习CV方向论文解读"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post View:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>本文章通过时间轴来按顺序整理CV方向的经典paper的优势和该paper对之前的改进以及个人吐槽。</p>
<p>每篇paper主要从网络架构和数据增强两方面来分析学习trick。</p>
<div class="tip warning"><p>个人哔哔纯属吐槽，不具有专业性分析参考</p>
</div>
<p>PS：paper的时间按照arxiv最后时间为准，不代表论文<strong>最初</strong>发表时间。<del>因为我也被弄糊涂了</del></p>
<hr>
<p>后来发现要写的论文很多，都放在一篇文章不太合适<del>不好水博客啊</del>，以后就分开写算了，这样每篇篇幅也能更长一点。<del>发现自己很容易就忘记之前总结的东西</del></p>
<div class="timeline">
<div class="timenode"><div class="meta"><p><p>2012 Alexnet Author<strong>：</strong>Alex Krizhevsky</p>
</p></div><div class="body"><h1 id="Alex-Net"><a href="#Alex-Net" class="headerlink" title="Alex Net"></a>Alex Net</h1><h2 id="网络"><a href="#网络" class="headerlink" title="网络"></a>网络</h2><ul><li><p>将饱和非线性神经元（tanh，sigmod）换为了非饱和非线性神经元：<strong>训练快了6倍</strong></p><blockquote><p>由于sigmod激活 ，如果hidden layer越来越小，梯度弥散，</p><p>如果前面hidden layer 越来越大，则会导致梯度爆炸。</p></blockquote></li><li><p>使用LRN（local response normalization）局部响应归一化：<strong>有助于快速收敛，增加泛化能力</strong></p><blockquote><p><strong>侧抑制（lateral inhibitio），即指被激活的神经元抑制相邻的神经元。</strong>归一化（normaliazation）的目的就是<strong>“抑制”</strong>,LRN就是借鉴这种侧抑制来实现局部抑制，尤其是我们使用ReLU的时候，这种“侧抑制”很有效 ，由于ReLU的相应结果是无界的，所以需要归一化。</p></blockquote><p>  <del>LRN因为不提高准确率参数量还很多，被VGG抛弃</del></p></li><li><p>空间池化部分：采用重叠池化（overlap pooling）</p><blockquote><p> Overlap Pooling ：通过设置步长s小于池化的kernel size z，重复使用平均池化，更难过拟合。</p></blockquote></li><li><p>dropout：<strong>减少过拟合</strong></p><p>  ​    算是现在很常见的一个东西了，不过有normalization layer后就没怎么用了。</p></li></ul><h2 id="数据增强"><a href="#数据增强" class="headerlink" title="数据增强"></a>数据增强</h2><ul><li><p>随机裁剪+镜像反射：提高准确率</p><p>  通过对图像（255，255，3）四个角为中心进行随机裁剪（224，224，3）的图像，然后再水平翻转得到10张图像，通过softmax层后求precision的平均。</p></li><li><p>主成分提取PCA：减少了top-1 error 1%</p><blockquote><p>在整个ImageNet训练集上对RGB像素值执行PCA。对于每幅图像加上多倍找到的主成分，大小成正比的对应特征值乘以一个随机变量，随机变量通过均值为0，标准差为0.1的高斯分布得到。</p></blockquote></li></ul></div></div>

<div class="timenode"><div class="meta"><p><p>2014.2.24 Overfeat Author: Pierre Sermanet</p>
</p></div><div class="body"><h1 id="Overfeat"><a href="#Overfeat" class="headerlink" title="Overfeat"></a>Overfeat</h1><p>这篇算法没有完整的流程图，没怎么看懂怎么实现的，无法细讲。</p><p>似乎是通过回归来预测bounding box的位置？</p><p>我主要问题是加滑动窗口pool是训练集就有吗？</p><p>分类和定位是同时的话是网络再并联一个1*1卷积提取bbox参数回归？如果是这样感觉类似后面的decouple head思想。</p><h2 id="网络"><a href="#网络" class="headerlink" title="网络"></a>网络</h2><p>网络功能分为三个部分：分类（特征提取）、定位、检测。</p><ul><li><p>滑动窗口提取特征：因为考虑后面的定位和检测，没有像AlexNet把输入图像分五份随机裁剪再水平翻转：</p><blockquote><p>因为这样会打乱图片的空间特征（和以前的全连接层一样，被改进为卷积也有部分原因是强调图片空间特征），所以使用’’暴力”裁剪，stride分别为0，1，2移动，裁剪图片作为输入。这个窗口类似kernel只不过相当于裁剪？</p></blockquote></li><li><p>根据前5层layer进行特征提取共享特征权重，后面接上进行分类和定位的区分全连接层。</p></li><li><p>定位：根据每个窗口裁剪出来的图片先分类，再回归bbox，预测的bbox iou&lt;50%为FP</p></li></ul><h2 id="个人哔哔"><a href="#个人哔哔" class="headerlink" title="个人哔哔"></a>个人哔哔</h2><p>​    <del>好家伙，发现对比图里面居然有vgg，时间线被搞错乱了，难道vgg才是1*1卷积代替全连接的开山鼻祖？</del></p><p>​    注意这篇论文不是sota！这里我个人认为是由于AlexNet为网络架构（太浅了）更难提升准确率，所以文章说的时间限制应该是说没有时间尝试其他的模型。</p><p>​    这个类似遍历的方式裁剪图片|获取特征注定了复杂度会很高，将来会有更好的算法替代（如后篇的SS）</p></div></div>



<div class="timenode"><div class="meta"><p><p>2014.3.4 Network in Network Author: Min Lin</p>
</p></div><div class="body"><h1 id="NIN"><a href="#NIN" class="headerlink" title="NIN"></a>NIN</h1><ul><li>介绍了多层感知机(mutilayer perceptrons)和线性激活函数，全连接层的劣势：线性函数针对特定函数才能近似不具有通用性，全连接层太容易过拟合，可解释性低。</li><li>基于maxout net提出MLP conv：先在原始两个卷积层中多插入一个MLP层进行非线性提取特征，共享MLP层权重也使模型有更高的表达能力，然后在后面加个非线性函数relu。使凸函数近似变成通用函数近似。</li><li>提出全局平均池化GAP(global average pooling)：原来的fc层因为要训练超参数容易过拟合，替换为GAP后直接取特征图的平均，也将特征图和类别联系了起来，而且没有超参数的训练，减少了过拟合和增加了模型的可解释性，还不用dropout(然后被googlenet打脸了)</li></ul><h2 id="个人哔哔"><a href="#个人哔哔" class="headerlink" title="个人哔哔"></a>个人哔哔</h2><p>这篇论文是解决了fc层解释性差和fc层的过拟合问题，把卷积替换全连接怕不是借鉴了别人（感觉这篇和overfeat很像但是侧重点不同，时间线仍然错乱）。</p><p>下面解释一下为什么能够替换，参考<a target="_blank" rel="noopener" href="https://blog.csdn.net/nefetaria/article/details/107977597">这篇1*1 conv 介绍</a>，和<a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_41137655/article/details/94138062">这篇mlp conv</a></p><p>先看如下两张图</p><div class="tabs" id="pic"><ul class="nav-tabs"><li class="tab active"><button type="button" data-href="#pic-1">图片1</button></li><li class="tab"><button type="button" data-href="#pic-2">图片2</button></li></ul><div class="tab-contents"><div class="tab-item-content active" id="pic-1"><div class="img-wrap"><div class="img-bg"><img class="img" src= "/img/lazyload.svg" data-src="https://cdn.jsdelivr.net/gh/dummerchen/My_Image_Bed03@image_bed_001/img/20210906152152.png" style="height:60vh;"/></div></div><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div><div class="tab-item-content" id="pic-2"><div class="img-wrap"><div class="img-bg"><img class="img" src= "/img/lazyload.svg" data-src="https://cdn.jsdelivr.net/gh/dummerchen/My_Image_Bed03@image_bed_001/img/20210906193238.png" style="height:60vh;"/></div></div><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div></div></div><p>手动计算一下图二输入层数：</p><div class="table-container"><table><thead><tr><th>No.</th><th>Intput Size</th><th style="text-align:center">conv</th><th style="text-align:center">stride</th><th style="text-align:center">padding</th><th style="text-align:center">Output Size</th></tr></thead><tbody><tr><td>1</td><td>224*224*3</td><td style="text-align:center">11*11*96</td><td style="text-align:center">4</td><td style="text-align:center">3</td><td style="text-align:center">55*55*96</td></tr><tr><td>2</td><td>55*55*96</td><td style="text-align:center">1*1*96</td><td style="text-align:center">1</td><td style="text-align:center">0</td><td style="text-align:center">55*55*96</td></tr><tr><td>3</td><td>55*55*96</td><td style="text-align:center">1*1*96</td><td style="text-align:center">1</td><td style="text-align:center">0</td><td style="text-align:center">55*55*96</td></tr></tbody></table></div><p>由图1可见mlp conv就是加几个hidden layer 然后relu，输出和输入通道数不变，只增加了非线性性。同图2和上面推导，1<em>1卷积也可以实现上述功能，但是1\</em>1卷积也可不只实现上述功能。</p><ul><li>当1*1卷积通道数不变时+relu，则起到的是mlp conv作用。</li><li>当1*1卷积通道数不等于输入维度时，起到升维降维作用（降低参数量）。</li><li>当1*1卷积通道数等于分类数则是替代全连接层（前面一层会将输入变为1*1*channel，然后再是1*1*n_class的卷积）</li></ul></div></div>



<div class="timenode"><div class="meta"><p><p>2014.10.22 R-CNN Author<strong>：</strong>Ross Girshick</p>
</p></div><div class="body"><h1 id="RCNN"><a href="#RCNN" class="headerlink" title="RCNN"></a>RCNN</h1><h2 id="网络"><a href="#网络" class="headerlink" title="网络"></a>网络</h2><ul><li><p>提出迁移学习：在大数据集上进行有监督预训练，然后针对特定数据集进行微调（提升了8%！！！）</p></li><li><p>采样selective search算法搜索region proposal：region proposal算法包含很多种，SS算法是最受欢迎的一种之一。</p><blockquote><p>Selective Search 源码分析，<a target="_blank" rel="noopener" href="https://github.com/AlpacaDB/selectivesearch">python源码github <del>非官方</del></a>:</p><ol><li>先通过图像分隔（skimage.segmentation.felzenszwalb）将图片每一个pixel分到一个label（label是唯一的），第一次先遍历这些pixel得到区域信息，区域是矩形划分的。</li><li>再求出每个区域之间的texure gradient，color histogarm，region size相似度，如果区域相邻且相似则合并（相似是通过判断区域矩形是否相交）。</li><li>重复上述步骤。</li></ol><p>可以看出SS是通过先分隔再不停遍历来求出BBox的，复杂度比然很高，而且图片越大越难搞</p></blockquote></li><li><p>借鉴了A Deep Convolutional Activation Feature for Generic Visual Recognition把Alexnet当backbone用来提取特征的思想。</p></li><li><p>只把卷积作为提取特征的工具，最后一层分类使用的是svm，每一类都用一个svm。</p></li><li><p>分类的时候不光分类了种类，还将背景单独分了一类。（如今的two filter的启发可能来于这）</p></li><li><p>困难负样本挖掘（hard negative mining）:因为detect会有很多负样本，正负样本不均衡。<del>这也是目标识别的一大通病</del>，所以要增加负样本的’’质量’’ 。</p><blockquote><p><strong>hard negative就是每次把那些顽固的棘手的错误,再送回去继续练,练到你的成绩不再提升为止.这一个过程就叫做’hard negative mining.</strong><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/46292829">具体可以参考知乎</a></p></blockquote></li><li><p>使用不同网络做backbone效果会有差别，把VGG和AlexNet对比：map增加了8%，训练时间长了7倍。</p></li></ul><h2 id="数据处理"><a href="#数据处理" class="headerlink" title="数据处理"></a>数据处理</h2><ul><li><p>先固定图像尺寸为500pixels，然后再输入到ss算法中</p></li><li><p>由于backbone为AlexNet，ss的输出大小都是不同的要将图像变为224*224的大小输入，scale采用的方法如下：</p><blockquote><ol><li>tightest square with context：是指在原始图像上找到这样一个可以包含整个proposal 的最小的正方形，然后将这个正方形 <em>rescale</em> 为卷积网络可以接受的尺寸</li><li>tightest square without context</li><li>warp：直接rescale到输入尺寸</li></ol></blockquote></li></ul><h2 id="个人哔哔"><a href="#个人哔哔" class="headerlink" title="个人哔哔"></a>个人哔哔</h2><p>​    提出预训练和backbone的思想，region proposal使用ss提取，算法复杂度注定了还有改进空间，svm分类后来也被换为了卷积。然后就是hard negative mining <del>不会过拟合吗</del>。</p><p>​    论文说和overfeat很相似，但是overfeat是rcnn的特例，只是RCNN是每一类用svm分离和每一类都有一个bbox的回归</p><p>​    这几篇代码都是matlab或C++写的，我刚好就是看不惯matlab。     <del>matlab果然是上个时代的产物</del></p></div></div>



<div class="timenode"><div class="meta"><p><p>2014.9.17 GoogleNet Author: Christian Szegedy</p>
</p></div><div class="body"><h1 id="Google-Net"><a href="#Google-Net" class="headerlink" title="Google Net"></a>Google Net</h1><h2 id="网络"><a href="#网络" class="headerlink" title="网络"></a>网络</h2><ul><li><p>在1*1卷积降维基础上为了保留压缩信息提出了deep concat。</p></li><li><p>NIN 说GAP可以不用dropout，但是googlenet网络最后还是用了。</p></li><li><p>目标检测方面借鉴了RCNN的SS搜索：<del>突然看到RCNN猝不及防</del></p><blockquote><p>通过ensemble 6个ConvNets 对每个proposal region进行分类，提高了近4个百分点，但是由于时间原因使用Bounding box回归。</p></blockquote></li></ul><h2 id="个人哔哔"><a href="#个人哔哔" class="headerlink" title="个人哔哔"></a>个人哔哔</h2><p>​    个人觉得提出了deep concat是一个很好的创新点，因为每一个新的网络模型都能带来不同的思想方向，比如说后面的dw卷积说没有受到这篇的启发是不可能的。</p><p><del>从这篇也看到了1*1卷积应用广泛，后面就不再单独提这个了</del></p></div></div>







<div class="timenode"><div class="meta"><p><p>2015.4.10 <strong>Fully Convolutional Network</strong> Author：Jonathan Long</p>
</p></div><div class="body"><h1 id="FCN"><a href="#FCN" class="headerlink" title="FCN"></a>FCN</h1><h2 id="个人哔哔"><a href="#个人哔哔" class="headerlink" title="个人哔哔"></a>个人哔哔</h2><p>​    如果目前时间顺序是对的话，个人感觉这篇没什么，全连接用卷积替代早在前面几篇就有所端倪了，不过是整合并证明了一下。<del>也可能是我理论基础不太行，看不懂毕竟这篇几乎算图像分割的开山之作了</del></p><p>​    但是文章中出现了新词patch-wise（虽然文中说也可以不用patch-wise）：<a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/42636685/patch-wise-training-and-fully-convolutional-training-in-fcn">这篇stackoverflow</a>关于patch-wise回答的挺好，可以看看：</p><blockquote><p>术语“Patchwise ”旨在避免完整图像训练的冗余。在语义分割中，假设您对图像中的每个像素进行分类，通过使用整个图像，您在输入中添加了大量冗余。在训练分割网络期间避免这种情况的标准方法是从训练集中向网络提供批量随机补丁（感兴趣对象周围的小图像区域）而不是完整图像。这种“逐块采样”确保输入具有足够的方差并且是训练数据集的有效表示（小批量应该与训练集具有相同的分布）。这种技术还有助于更快地收敛并平衡类。在这篇论文中，他们声称没有必要使用 patch-wise 训练，如果你想平衡类，你可以对损失进行加权或采样。从另一个角度来看，逐像素分割中的全图像训练的问题在于输入图像具有很多空间相关性。要解决此问题，您可以从训练集中采样补丁（patchwise 训练）或从整个图像中采样损失。这就是为什么该小节被称为“Patchwise training is loss sampling”。因此，通过“将损失限制为其空间项的随机采样子集，可以从梯度计算中排除补丁。”他们通过随机忽略最后一层的单元来尝试这种“损失采样”，因此不会在整个图像上计算损失。</p></blockquote></div></div>





<div class="timenode"><div class="meta"><p><p>2015.4.10 VGG <strong>Author</strong>：<strong>Karen Simonyan </strong></p>
</p></div><div class="body"><h1 id="VGG"><a href="#VGG" class="headerlink" title="VGG"></a>VGG</h1><h2 id="网络"><a href="#网络" class="headerlink" title="网络"></a>网络</h2><ul><li><p>吸收Alexnet经验，激活层全部换成relu。</p></li><li><p>大部分没有使用LRN（只用了一层）：在imagenet 准确率没有提高，还带有很高的参数。</p></li><li><p>更多的使用更小的卷积（3*3）：减少参数量的同时使网络更深，表达能力更强。</p><blockquote><p>两个3*3卷积感受野与一个5*5 卷积相同，三个3*3卷积感受野与7*7相同，但是相比之下用更小的卷积核参数量更少。而且两个3*3卷积强迫7*7卷积分开，中间的非线性激活相当于之前的正则化层。</p></blockquote></li><li><p>使用1*1卷积：与线性层本质和效果相同，起到代替全连接层，更快的运算的效果。</p></li><li><p>空间池化部分：没有使用平均池化，全部使用最大池化层。</p></li></ul><h2 id="数据增强"><a href="#数据增强" class="headerlink" title="数据增强"></a>数据增强</h2><ul><li>随机采样+镜像翻转</li><li>没有像AlexNet用PCA，而是图像减去rgb平均值来消除光照影响。</li></ul><h2 id="个人哔哔"><a href="#个人哔哔" class="headerlink" title="个人哔哔"></a>个人哔哔</h2><p>单从论文写作的角度来说VGG与AlexNet没有说每一步trick增加的准确率，所以个人认为VGG更多的是网络架构优势：小卷积多卷。<del>而不是池化等trick</del>。ILSVRC以top-5 error <strong>6.8%</strong>排第二也是惨，被谷歌截胡了。</p><p>感受野确实很难理解，下面简单介绍一下，具体意义可以<a target="_blank" rel="noopener" href="https://blog.csdn.net/u013000248/article/details/91493032">参考这篇</a></p><p>感受野计算公式：</p><script type="math/tex; mode=display">RF_i=(RF_{i-1}-1)*\Pi_{k=1}^{k=i-1}stride_k+kernel\_size</script><p><strong>第一层感受野为kernel size，即$RF_0$=1</strong> ，由上可见该层感受野与该层stride无关</p><p>输出层size计算公式：</p><script type="math/tex; mode=display">n_{out}=\lfloor{\frac{(n_{in}+2*padding-kernel)}{stride}}\rfloor+1</script><p>其实这两个公式是卷积和反卷积的过程，本质是相同的。</p><p>感受野是从最后一层向上逆推，输出size则是从输入向下正推。</p><div class="table-container"><table><thead><tr><th style="text-align:center">No.</th><th style="text-align:center">Layer</th><th style="text-align:center">input size</th><th style="text-align:center">kernel size</th><th style="text-align:center">stride</th><th style="text-align:center">padding</th><th style="text-align:center">output size</th><th style="text-align:center">Receptive Field(感受野)</th></tr></thead><tbody><tr><td style="text-align:center">1</td><td style="text-align:center">conv</td><td style="text-align:center">28*28</td><td style="text-align:center">3*3</td><td style="text-align:center">1</td><td style="text-align:center">0</td><td style="text-align:center">26</td><td style="text-align:center">3</td></tr><tr><td style="text-align:center">2</td><td style="text-align:center">conv</td><td style="text-align:center">24*24</td><td style="text-align:center">3*3</td><td style="text-align:center">1</td><td style="text-align:center">0</td><td style="text-align:center">24</td><td style="text-align:center">5</td></tr><tr><td style="text-align:center">3</td><td style="text-align:center">conv</td><td style="text-align:center">22*22</td><td style="text-align:center">3*3</td><td style="text-align:center">1</td><td style="text-align:center">0</td><td style="text-align:center">22</td><td style="text-align:center">7</td></tr><tr><td style="text-align:center">4</td><td style="text-align:center">conv</td><td style="text-align:center">20*20</td><td style="text-align:center">3*3</td><td style="text-align:center">1</td><td style="text-align:center">0</td><td style="text-align:center">20</td><td style="text-align:center">9</td></tr><tr><td style="text-align:center">5</td><td style="text-align:center">conv</td><td style="text-align:center">18*18</td><td style="text-align:center">3*3</td><td style="text-align:center">1</td><td style="text-align:center">0</td><td style="text-align:center">18</td><td style="text-align:center">11</td></tr><tr><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td></tr><tr><td style="text-align:center">1</td><td style="text-align:center">conv</td><td style="text-align:center">28*28</td><td style="text-align:center">5*5</td><td style="text-align:center">2</td><td style="text-align:center">1</td><td style="text-align:center">24</td><td style="text-align:center">5</td></tr><tr><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td></tr><tr><td style="text-align:center">1</td><td style="text-align:center">conv</td><td style="text-align:center">28*28</td><td style="text-align:center">7*7</td><td style="text-align:center">2</td><td style="text-align:center">1</td><td style="text-align:center">22</td><td style="text-align:center">7</td></tr><tr><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td></tr><tr><td style="text-align:center">1</td><td style="text-align:center">conv</td><td style="text-align:center">28*28</td><td style="text-align:center">11*11</td><td style="text-align:center">4</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td></tr><tr><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td></tr><tr><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td></tr></tbody></table></div></div></div>



<div class="timenode"><div class="meta"><p><p>2015.5 Unet <strong>Author:Olaf Ronneberger</strong></p>
</p></div><div class="body"><h1 id="Unet"><a href="#Unet" class="headerlink" title="Unet"></a>Unet</h1><h2 id="网络"><a href="#网络" class="headerlink" title="网络"></a>网络</h2><div class="img-wrap"><div class="img-bg"><img class="img" src= "/img/lazyload.svg" data-src="https://cdn.jsdelivr.net/gh/dummerchen/My_Image_Bed03@image_bed_001/img/20220111155605.png" style="height:50vh;"/></div></div><p>这个网络很简单，无非就是卷卷卷，然后concat。论文中有几点不是很方便：</p><ul><li><p>每次下采样的时候长宽维度会减小，concat的时候就会需要中心裁剪(示意图片中的虚线部分)然后再concat</p></li><li><p>最后生成的图片维度可以发现与原图片维度不同，这就代表输入图片不能简单的按patch输入还需额外处理，原文中是使用镜像来解决的。这里解释一下patch：</p><blockquote><p>通常一张超大图片都是分割成一张张小图片输入的（显存不够输入一张大图片），并且每张图片直接会有重叠(overlap)，以防边缘信息不被利用。</p></blockquote></li></ul><p>需要注意的是论文他没有使用padding，并且后面大火的batch normalization才刚出，论文中也没有使用。上采样采用的是转置卷积而不是现在常用的双线性插值。</p><p>现在大家通常修改了卷积层下采样的部分：增加padding使卷积后尺寸不变，也不用crop了。然后在卷积和relu直接加上BN层。并且用双线性插值<del>代码更好写且效果还变强了，当然自己魔改也可</del></p><p> 修改后的网络维度如下图(输入维度随便写的)： </p><div class="img-wrap"><div class="img-bg"><img class="img" src= "/img/lazyload.svg" data-src="https://cdn.jsdelivr.net/gh/dummerchen/My_Image_Bed03@image_bed_001/img/20220113160502.png" style="height:50vh;"/></div></div><h2 id="dice-loss"><a href="#dice-loss" class="headerlink" title="dice loss"></a>dice loss</h2><h2 id="数据增强"><a href="#数据增强" class="headerlink" title="数据增强"></a>数据增强</h2><p>​    “当只有很少的训练样本可用时，数据增强是网络所需的不变性和鲁棒性的关键。我们需要的是旋转不变性，以及对变形和灰色值变化的鲁棒性。特别是训练样本的随机弹性变形似乎是训练分段的关键概念”<del>然而只是简单的使用随机位移向量处理了一下。</del></p><h2 id="个人哔哔"><a href="#个人哔哔" class="headerlink" title="个人哔哔"></a>个人哔哔</h2><p>看到这个网络肯定有人会比较和FCN的区别，但是FCN相当于分割的开山鼻祖相似也没办法<del>我也觉得没什么大区别</del>。细节还是有的：</p><ul><li>fcn没有解决大图片的问题（我感觉这只是需求不同导致的，毕竟医学图像都很大）</li><li>fcn尺度不够多，只是一个尺度卷卷卷，没有使用FPN的想法。</li></ul></div></div>



<div class="timenode"><div class="meta"><p><p>2015.12.10 ResNet Author:Kaiming He</p>
</p></div><div class="body"><h1 id="ResNet"><a href="#ResNet" class="headerlink" title="ResNet"></a>ResNet</h1><h2 id="网络"><a href="#网络" class="headerlink" title="网络"></a>网络</h2><ul><li><p>完全去掉了LRN、dropout，并采用BN（batch normalization）层替代：标准化，可以增强表达能力，防止过拟合。</p><blockquote><p>想象一个sigmod激活，当数据范围分布差异很大时，sigmod激活不能很好的表现出数据的差异，就像轻轻打你一拳和重重打你一拳感觉差不多，这是很糟糕的情况。batch normalization通过均值方差标准化能够很好的处理这种情况，并且最后还会scale shift 还原。BN层具体作用看<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/93643523">这篇</a></p></blockquote></li><li><p><strong>增加残差结构</strong>：修正了深网络的梯度的问题。</p><blockquote><p>残差结构的好处就是，实现了一个恒等变换$h(x)=x$，这个恒等变换实际上是一个网络的目标函数，但是由于网络越深，虽然表达能力越强，但是梯度弥散和爆炸问题明显。所以本质上是解决梯度弥散和爆炸问题。可以理解为之前论文的加强正则化效果。</p></blockquote></li></ul><h2 id="数据增强"><a href="#数据增强" class="headerlink" title="数据增强"></a>数据增强</h2><p>直接就把AlexNet和VGG结合了</p><ul><li><p>采用和AlexNet相同的数据增强方法：随机在图片里选取224*224大小图片，再镜像翻转。</p></li><li><p>采用和VGG相同的光照影响方法：减去rgb平均值</p><blockquote><p>The image is resized with its shorter side randomly sampled in [256, 480] for scale augmentation. A (224, 224) crop is randomly sampled from an image or its horizontal flip, with the per-pixel mean subtracted. </p><p>先依照短边随机缩放，然后再224*224采样，随机镜像翻转，最后减去rgb均值。</p><p>pytorch实现与原文有点不一样，注意一下。具体pytorch实现细节可以参考<a target="_blank" rel="noopener" href="https://blog.csdn.net/FortiLZ/article/details/80851251">这篇</a></p></blockquote></li><li><p>使用10-crop test，提高准确率</p></li></ul><h2 id="个人哔哔"><a href="#个人哔哔" class="headerlink" title="个人哔哔"></a>个人哔哔</h2><p>2015 ILSVRC top-5 error <strong>3.57%</strong>，直接拿第一。说明了残差网络确实nb，也算是解决了深度层网络的根本问题（梯度问题|恒等变换）。</p></div></div>

<div class="timenode"><div class="meta"><p><p>2017.6 <strong>Attention Is All You Need</strong> Author:Ashish Vaswani</p>
</p></div><div class="body"><h1 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h1><h2 id="论文解读"><a href="#论文解读" class="headerlink" title="论文解读"></a>论文解读</h2><p><del>原论文讲解的还是比较粗略，还是得看别人的讲解和图片，</del><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_37541097/article/details/117691873">强烈推荐这篇</a>，我个人觉得我对attention还是理解不够，还不能写自己的理解。</p><h3 id="一些问题"><a href="#一些问题" class="headerlink" title="一些问题"></a>一些问题</h3><h4 id="为什么使用muti-head"><a href="#为什么使用muti-head" class="headerlink" title="为什么使用muti head"></a>为什么使用muti head</h4><blockquote><p>关于different representation subspaces，举一个<em>不一定妥帖</em>的例子：当你浏览网页的时候，你可能在<strong>颜色</strong>方面更加关注深色的文字，而在<strong>字体</strong>方面会去注意大的、粗体的文字。这里的颜色和字体就是两个不同的表示子空间。同时关注颜色和字体，可以有效定位到网页中强调的内容。<strong>使用多头注意力，也就是综合利用各方面的信息/特征</strong>。</p></blockquote><h4 id="pos-embed是怎么实现的"><a href="#pos-embed是怎么实现的" class="headerlink" title="pos embed是怎么实现的"></a>pos embed是怎么实现的</h4><h4 id="attention为什么要加scaled"><a href="#attention为什么要加scaled" class="headerlink" title="attention为什么要加scaled"></a>attention为什么要加scaled</h4><blockquote><p>  参考这个回答 <a target="_blank" rel="noopener" href="https://www.zhihu.com/question/339723385">https://www.zhihu.com/question/339723385</a></p></blockquote><p>数量级对softmax得到的分布影响非常大。<strong>在数量级较大时，softmax将几乎全部的概率分布都分配给了最大值对应的标签</strong></p><script type="math/tex; mode=display">设y=g(x)=softmax(x)\\\frac{dg(x)}{x}=\left[\begin{matrix}y1 ~ \dots ~ 0 \\\vdots ~ \ddots  ~ \vdots \\0 ~ \dots ~ y_n \\\end{matrix}\right ]-\left[\begin{matrix}y1^2 ~ y_1y_2 ~ \dots ~ y_1y_n \\\vdots ~ \ddots  ~ \vdots \\y_ny_1 ~ \dots ~ y_n^2 \\\end{matrix}\right ]</script><p>某个值很大时，其余都会很接近0(onehot 向量)，上式也就会很趋近于0。</p><p>所以对于如果多层堆叠</p><script type="math/tex; mode=display">假设\begin{cases}E(q)=E(k)=0 \\D(q)=D(k)=1 \\\end{cases}\rightarrow \begin{cases}E(qk)=E(q)*E(k)=0 \\D(qk)=D(q)*D(k)-[E(q)*E(k)]^2=1\end{cases} \\</script><p>令z=qk则有：</p><script type="math/tex; mode=display">\begin{cases}E(\sum z)=\sum E(z)=0 \\D(\sum z)=\sum D(z)=d  & d=embeding\_dim//head\_num=head\_dim\end{cases}</script><p>可知，当head_dim越大时方差越大，则最大值与最小值差距越大，就导致了上述的softmax梯度消失问题。</p><p>为将方差变为1，故self-attention公式如下</p><script type="math/tex; mode=display">attention=softmax(q@k*\sqrt{dim}^{-1})@v</script><p>此时</p><script type="math/tex; mode=display">D(qk)'=\frac{D(qk)}{\sqrt{dim}}=1</script><ul><li><p>为什么平常softmax并没有这一步呢？</p><blockquote><p>平常都是最后一层增加softmax，这时输出信号与我们需要的信号相差无几不用scale</p></blockquote></li><li><p>attention有add和muti，add需要scale吗？</p><blockquote><p>根据论文Massive Exploration of Neural Machine Translation Architectures，由于add是由tanh激活映射到[-1,1]，方差一般会在1之内，但是维度过大时（1000以上时）也需要scale。</p></blockquote></li></ul><h2 id="个人哔哔"><a href="#个人哔哔" class="headerlink" title="个人哔哔"></a>个人哔哔</h2><p>​    我之前一直以为attention 和transformer是一个东西两个名字，好长一段后才知道这两个东西不一样…就和resnet与shortcut关系相似。attention只是transformer架构里的一个小模块。<del>并且这个小模块还包含很多不同名的attention</del></p><p>​    在此之前nlp迫于时间序列都是基于lstm，rnn在研究，attention机制出来之后，不仅解决了lstm，rnn并行计算的缺陷，还提出了一种全新的思想架构transformer，使不需要cnn，rnn也能有很好的效果。之后的vit，swin transformer甚至将nlp领域转移到图像分类领域，也体现了attention机制的泛用性，也算是机器学习的一个大变革了。<del>谷歌还是nb</del></p><p>​    但是随之影响到的肯定是我们这批穷鬼，attention的矩阵计算机制是通过全连接实现的（还记得线性回归吗，全连接就是矩阵相乘），参数量爆炸，没及几张好卡根本跑不动。<del>比谁卡多的时代终究来临</del></p><p>​    代码实现的时候发现要加载预训练权重必须按照官网的名称写，还要手写attention…，麻烦但很有收获。要注意一点，dropout rate全部都是0，如果不小心传入了默认参数验证集准确率可能会降低（很玄学,不过我也就在小数据集上训练了一个epoch，不代表广泛性仅个人记录)</p></div></div>

<div class="timenode"><div class="meta"><p><p>2021.7 <strong>Exceeding YOLO Series in 2021</strong> Author:Zheng Ge</p>
</p></div><div class="body"><h1 id="YoloX"><a href="#YoloX" class="headerlink" title="YoloX"></a>YoloX</h1><h2 id="网络"><a href="#网络" class="headerlink" title="网络"></a>网络</h2><p>（目前这些我没具体学，就不介绍了）</p><p>大致讲解见知乎<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/397993315">这篇</a></p><ul><li>Anchor free：<del>可以参考<a target="_blank" rel="noopener" href="https://www.cnblogs.com/xuanyuyt/p/13858661.html">这篇</a></del></li><li>SimOTA：</li><li>Muti positive</li><li>End-to-end Yolo</li></ul><h2 id="数据增强"><a href="#数据增强" class="headerlink" title="数据增强"></a>数据增强</h2><p>可以参考<a href="https://dummerfu.top/p/27272.html">这篇</a></p><ul><li>Mosaic</li><li>Mix up</li></ul><p>加了这两个trick可以多2.9%AP就恐怖，赶快学着用起来。</p><h2 id="个人哔哔"><a href="#个人哔哔" class="headerlink" title="个人哔哔"></a>个人哔哔</h2><p>​    <del>感觉是钻Yolo的空子</del>，全篇都是各种trick，最后还说由于时间原因没有加最近transformer的成果trick，真是争分夺秒。个人觉得这篇文章基本上可以算是一篇综述了，因为我从这参考文献递归知道了许多论文，是不是和综述paper效果一样。<del>那我这篇不就是综述的综述了，害怕</del></p><p>​    不过能把别人的网络改成暂时的sota也是一种本事。<del>代码能力极强，像我这水平现在写个网络都不知道能不能写对</del></p></div></div>


</div>
<div class="tip info"><p>To be Continued</p>
</div>
</article><div class="essaySuffix-box"> <div class="essaySuffix-box-left"> <img src="https://cdn.jsdelivr.net/gh/dummerchen/cdn@master/img/custom/avatar.jpg" onerror="onerror=null;src='https://cdn.jsdelivr.net/gh/dummerchen/cdn/img/other/default_avatar.jpg'" alt="avatar"></div><div class="essaySuffix-box-right"> <span class="essaySuffix-right-title">本文作者：</span><strong> <span><a href="https:dummerfu.top" target="_blank" one-link-mark="yes">dummerfu</a></span></strong><br><span class="essaySuffix-right-title">本文链接：</span><a href="https://dummerfu.top/p/61340.html">https://dummerfu.top/p/61340.html</a><br><span class="essaySuffix-right-title">版权声明: </span>
本博客所有文章除特别声明外，均采用<a rel="noopener" target="_blank" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0许可协议</a>
转载请注明出处！</div></div><div class="tag_share"><div class="post_share"></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/p/54346.html"><img class="prev-cover" data-src="/img/lazyload.svg" src="/img/lazyload.svg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">【数模】2020B 穿越沙漠</div></div></a></div><div class="next-post pull-right"><a href="/p/27272.html"><img class="next-cover" data-src="https://cdn.jsdelivr.net/gh/dummerchen/cdn@master/img/cover/2.jpg" src="/img/lazyload.svg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">Long Tail Classification Review</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span> Related Articles</span></div><div class="relatedPosts-list"><div><a href="/p/49081.html" title="【论文复现】Restormer"><img class="cover" data-src="/img/lazyload.svg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-07-30</div><div class="title">【论文复现】Restormer</div></div></a></div><div><a href="/p/39020.html" title="【论文复现】SRGan"><img class="cover" data-src="https://cdn.jsdelivr.net/gh/dummerchen/cdn@master/img/cover/2.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-05-08</div><div class="title">【论文复现】SRGan</div></div></a></div><div><a href="/p/3640.html" title="【论文复现】SwinIR"><img class="cover" data-src="https://cdn.jsdelivr.net/gh/dummerchen/cdn@master/img/cover/5.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-07-30</div><div class="title">【论文复现】SwinIR</div></div></a></div><div><a href="/p/44311.html" title="【论文复现】卷积网络可视化Grad-cam和Guide backpropagation"><img class="cover" data-src="https://cdn.jsdelivr.net/gh/dummerchen/cdn@master/img/cover/5.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-05-16</div><div class="title">【论文复现】卷积网络可视化Grad-cam和Guide backpropagation</div></div></a></div><div><a href="/p/37004.html" title="【杂谈】 西电保研二三事"><img class="cover" data-src="/img/lazyload.svg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-05-16</div><div class="title">【杂谈】 西电保研二三事</div></div></a></div><div><a href="/p/13246.html" title="【翻译】基于时频分析和卷积神经网路的模式识别"><img class="cover" data-src="https://cdn.jsdelivr.net/gh/dummerchen/cdn@master/img/cover/4.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-12-10</div><div class="title">【翻译】基于时频分析和卷积神经网路的模式识别</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> Comment</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-info-avatar is-center"><img class="avatar-img" data-src="https://cdn.jsdelivr.net/gh/dummerchen/cdn@master/img/custom/avatar.jpg" src="/img/lazyload.svg" onerror="this.onerror=null;this.src='https://cdn.jsdelivr.net/gh/dummerchen/cdn/img/other/default_avatar.jpg'" alt="avatar"/><div class="author-info__name">dummerfu</div><div class="author-info__description"></div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">45</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">Tags</div><div class="length-num">18</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">Categories</div><div class="length-num">6</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/dummerchen"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon faa-parent animated-hover" href="https://github.com/dummerchen" target="_blank" title="Github"><svg class="icon faa-tada" aria-hidden="true"><use xlink:href="#icon-rat"></use></svg></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>Announcement</span></div><div class="announcement_content">本博客由博客园<a href="https://www.cnblogs.com/cherrypill/" target=" _blank">cherrypill</a>迁移</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Catalog</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%89%8D%E8%A8%80"><span class="toc-number">1.</span> <span class="toc-text">前言</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Alex-Net"><span class="toc-number"></span> <span class="toc-text">Alex Net</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BD%91%E7%BB%9C"><span class="toc-number">1.</span> <span class="toc-text">网络</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA"><span class="toc-number">2.</span> <span class="toc-text">数据增强</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Overfeat"><span class="toc-number"></span> <span class="toc-text">Overfeat</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BD%91%E7%BB%9C"><span class="toc-number">1.</span> <span class="toc-text">网络</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%AA%E4%BA%BA%E5%93%94%E5%93%94"><span class="toc-number">2.</span> <span class="toc-text">个人哔哔</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#NIN"><span class="toc-number"></span> <span class="toc-text">NIN</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%AA%E4%BA%BA%E5%93%94%E5%93%94"><span class="toc-number">1.</span> <span class="toc-text">个人哔哔</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#RCNN"><span class="toc-number"></span> <span class="toc-text">RCNN</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BD%91%E7%BB%9C"><span class="toc-number">1.</span> <span class="toc-text">网络</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86"><span class="toc-number">2.</span> <span class="toc-text">数据处理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%AA%E4%BA%BA%E5%93%94%E5%93%94"><span class="toc-number">3.</span> <span class="toc-text">个人哔哔</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Google-Net"><span class="toc-number"></span> <span class="toc-text">Google Net</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BD%91%E7%BB%9C"><span class="toc-number">1.</span> <span class="toc-text">网络</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%AA%E4%BA%BA%E5%93%94%E5%93%94"><span class="toc-number">2.</span> <span class="toc-text">个人哔哔</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#FCN"><span class="toc-number"></span> <span class="toc-text">FCN</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%AA%E4%BA%BA%E5%93%94%E5%93%94"><span class="toc-number">1.</span> <span class="toc-text">个人哔哔</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#VGG"><span class="toc-number"></span> <span class="toc-text">VGG</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BD%91%E7%BB%9C"><span class="toc-number">1.</span> <span class="toc-text">网络</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA"><span class="toc-number">2.</span> <span class="toc-text">数据增强</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%AA%E4%BA%BA%E5%93%94%E5%93%94"><span class="toc-number">3.</span> <span class="toc-text">个人哔哔</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Unet"><span class="toc-number"></span> <span class="toc-text">Unet</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BD%91%E7%BB%9C"><span class="toc-number">1.</span> <span class="toc-text">网络</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#dice-loss"><span class="toc-number">2.</span> <span class="toc-text">dice loss</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA"><span class="toc-number">3.</span> <span class="toc-text">数据增强</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%AA%E4%BA%BA%E5%93%94%E5%93%94"><span class="toc-number">4.</span> <span class="toc-text">个人哔哔</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#ResNet"><span class="toc-number"></span> <span class="toc-text">ResNet</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BD%91%E7%BB%9C"><span class="toc-number">1.</span> <span class="toc-text">网络</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA"><span class="toc-number">2.</span> <span class="toc-text">数据增强</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%AA%E4%BA%BA%E5%93%94%E5%93%94"><span class="toc-number">3.</span> <span class="toc-text">个人哔哔</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Transformer"><span class="toc-number"></span> <span class="toc-text">Transformer</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB"><span class="toc-number">1.</span> <span class="toc-text">论文解读</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98"><span class="toc-number">1.1.</span> <span class="toc-text">一些问题</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%BF%E7%94%A8muti-head"><span class="toc-number">1.1.1.</span> <span class="toc-text">为什么使用muti head</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#pos-embed%E6%98%AF%E6%80%8E%E4%B9%88%E5%AE%9E%E7%8E%B0%E7%9A%84"><span class="toc-number">1.1.2.</span> <span class="toc-text">pos embed是怎么实现的</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#attention%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%8A%A0scaled"><span class="toc-number">1.1.3.</span> <span class="toc-text">attention为什么要加scaled</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%AA%E4%BA%BA%E5%93%94%E5%93%94"><span class="toc-number">2.</span> <span class="toc-text">个人哔哔</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#YoloX"><span class="toc-number"></span> <span class="toc-text">YoloX</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BD%91%E7%BB%9C"><span class="toc-number">1.</span> <span class="toc-text">网络</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA"><span class="toc-number">2.</span> <span class="toc-text">数据增强</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%AA%E4%BA%BA%E5%93%94%E5%93%94"><span class="toc-number">3.</span> <span class="toc-text">个人哔哔</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/p/49081.html" title="【论文复现】Restormer"><img data-src="https://cdn.jsdelivr.net/gh/dummerchen/My_Image_Bed03@image_bed_001/img/20211212145136.jpg" src="/img/lazyload.svg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【论文复现】Restormer"/></a><div class="content"><a class="title" href="/p/49081.html" title="【论文复现】Restormer">【论文复现】Restormer</a><time datetime="2022-07-30T00:00:00.000Z" title="Created 2022-07-30 00:00:00">2022-07-30</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/p/3640.html" title="【论文复现】SwinIR"><img data-src="https://cdn.jsdelivr.net/gh/dummerchen/My_Image_Bed03@image_bed_001/img/20211212145155.jpg" src="/img/lazyload.svg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【论文复现】SwinIR"/></a><div class="content"><a class="title" href="/p/3640.html" title="【论文复现】SwinIR">【论文复现】SwinIR</a><time datetime="2022-07-30T00:00:00.000Z" title="Created 2022-07-30 00:00:00">2022-07-30</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/p/63048.html" title="图像理解与计算机视觉笔记"><img data-src="https://cdn.jsdelivr.net/gh/dummerchen/My_Image_Bed03@image_bed_001/img/20211212145212.jpg" src="/img/lazyload.svg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="图像理解与计算机视觉笔记"/></a><div class="content"><a class="title" href="/p/63048.html" title="图像理解与计算机视觉笔记">图像理解与计算机视觉笔记</a><time datetime="2022-06-18T00:00:00.000Z" title="Created 2022-06-18 00:00:00">2022-06-18</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/p/42559.html" title="代码审计工具"><img data-src="https://cdn.jsdelivr.net/gh/dummerchen/My_Image_Bed03@image_bed_001/img/20211212145136.jpg" src="/img/lazyload.svg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="代码审计工具"/></a><div class="content"><a class="title" href="/p/42559.html" title="代码审计工具">代码审计工具</a><time datetime="2022-05-20T00:00:00.000Z" title="Created 2022-05-20 00:00:00">2022-05-20</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/p/44311.html" title="【论文复现】卷积网络可视化Grad-cam和Guide backpropagation"><img data-src="https://cdn.jsdelivr.net/gh/dummerchen/My_Image_Bed03@image_bed_001/img/20211212120605.jpg" src="/img/lazyload.svg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【论文复现】卷积网络可视化Grad-cam和Guide backpropagation"/></a><div class="content"><a class="title" href="/p/44311.html" title="【论文复现】卷积网络可视化Grad-cam和Guide backpropagation">【论文复现】卷积网络可视化Grad-cam和Guide backpropagation</a><time datetime="2022-05-16T00:00:00.000Z" title="Created 2022-05-16 00:00:00">2022-05-16</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2022 By dummerfu</div><p id="ghbdages"><a class="github-badge" target="_blank" href="https://hexo.io/" style="margin-inline:5px"><img src="https://img.shields.io/badge/Frame-Hexo-blue?style=flat&amp;logo=hexo"/></a><a class="github-badge" target="_blank" href="https://butterfly.js.org/" style="margin-inline:5px"><img src="https://img.shields.io/badge/Theme-Butterfly-6513df?style=flat&amp;logo=bitdefender"/></a><a class="github-badge" target="_blank" href="https://www.jsdelivr.com/" style="margin-inline:5px"><img src="https://img.shields.io/badge/CDN-jsDelivr-orange?style=flat&amp;logo=jsDelivr"/></a><a class="github-badge" target="_blank" href="https://github.com/" style="margin-inline:5px"><img src="https://img.shields.io/badge/Source-Github-d021d6?style=flat&amp;logo=GitHub"/></a></p></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="Toggle Between Traditional Chinese And Simplified Chinese">简</button><button id="darkmode" type="button" title="Toggle Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="Scroll To Comments"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">Local search</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/vue@2.6.11"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script async="async">var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',preloader.endLoading())
setTimeout(function(){preloader.endLoading();}, 5000);</script></div><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    loader: {
      source: {
        '[tex]/amsCd': '[tex]/amscd'
      }
    },
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        addClass: [200,() => {
          document.querySelectorAll('mjx-container:not([display=\'true\']').forEach( node => {
            const target = node.parentNode
            if (!target.classList.contains('has-jax')) {
              target.classList.add('mathjax-overflow')
            }
          })
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/contrib/copy-tex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/contrib/copy-tex.css"><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', '', 'katex-wrap')
  })
})()</script><script>(()=>{
  const $countDom = document.getElementById('twikoo-count')
  const init = () => {
    twikoo.init(Object.assign({
      el: '#twikoo-wrap',
      envId: 'twikoo-8g53l3ue41b208dc',
      region: 'ap-shanghai'
    }, null))
  }

  const getCount = () => {
    twikoo.getCommentsCount({
      envId: 'twikoo-8g53l3ue41b208dc',
      region: 'ap-shanghai',
      urls: [window.location.pathname],
      includeReply: false
    }).then(function (res) {
      $countDom.innerText = res[0].count
    }).catch(function (err) {
      console.error(err);
    });
  }

  const loadTwikoo = (bool = false) => {
    if (typeof twikoo === 'object') {
      init()
      bool && $countDom && setTimeout(getCount,0)
    } else {
      getScript('https://cdn.jsdelivr.net/npm/twikoo@1.4.15/dist/twikoo.all.min.js').then(()=> {
        init()
        bool && $countDom && setTimeout(getCount,0)
      })
    }
  }

  if ('Twikoo' === 'Twikoo' || !true) {
    if (true) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo(true)
  } else {
    window.loadOtherComment = () => {
      loadTwikoo()
    }
  }
})()</script><script>var gitcalendar = new Vue({
  el: '#gitcalendar',
  data: {
    simplemode: false, 
    user: 'dummerchen',
    fixed: 'fixed',
    px: 'px',
    x: '',
    y: '',
    span1: '',
    span2: '',
    month: ['一月', '二月', '三月', '四月', '五月', '六月', '七月', '八月', '九月', '十月', '十一月', '十二月'],
    monthchange: [],
    oneyearbeforeday: '',
    thisday: '',
    amonthago: '',
    aweekago: '',
    weekdatacore: 0,
    datacore: 0,
    total: 0,
    datadate: '',
    data: [],
    positionplusdata: [],
    firstweek: [],
    lastweek: [],
    beforeweek: [],
    thisweekdatacore: 0,
    mounthbeforeday: 0,
    mounthfirstindex: 0,
    crispedges: 'crispedges',
    thisdayindex: 0,
    amonthagoindex: 0,
    amonthagoweek: [],
    firstdate: [],
    first2date: [],
    montharrbefore: [],
    monthindex: 0,
    color: ['#e4dfd7', '#f9f4dc', '#f7e8aa', '#f7e8aa', '#f8df72', '#fcd217', '#fcc515', '#f28e16', '#fb8b05', '#d85916', '#f43e06']
  },
  methods: {
    selectStyle(data, event) {
      document.querySelector('.angle-wrapper').style.display = 'block'
      this.span1 = data.date;
      this.span2 = data.count;
      this.x = event.clientX - 100;
      this.y = event.clientY - 60
    },
    outStyle() {
      document.querySelector('.angle-wrapper').style.display = 'none'
    },
    thiscolor(x) {
      if (x === 0) {
        let i = parseInt(x / 2);
        return this.color[0]
      } else if (x < 2) {
        return this.color[1]
      } else if (x < 20) {
        let i = parseInt(x / 2);
        return this.color[i]
      } else {
        return this.color[9]
      }
    },
  }
});
var apiurl = 'github-calendar-api.vercel.app' ? 'https://github-calendar-api.vercel.app/api?' : 'https://githubapi.ryanchristian.dev/user/'
var githubapiurl = apiurl + gitcalendar.user;
//canvas绘图
function responsiveChart() {
  let c = document.getElementById("gitcanvas");
  if (c) {
    let cmessage = document.getElementById("gitmessage");
    let ctx = c.getContext("2d");
    c.width = document.getElementById("gitcalendarcanvasbox").offsetWidth;
    let linemaxwitdh = 0.96 * c.width / gitcalendar.data.length;
    c.height = 9 * linemaxwitdh;
    let lineminwitdh = 0.8 * linemaxwitdh;
    let setposition = {
      x: 0.02 * c.width,
      y: 0.025 * c.width
    };
    for (let week in gitcalendar.data) {
      weekdata = gitcalendar.data[week];
      for (let day in weekdata) {
        let dataitem = {
          date: "",
          count: "",
          x: 0,
          y: 0
        };
        gitcalendar.positionplusdata.push(dataitem);
        ctx.fillStyle = gitcalendar.thiscolor(weekdata[day].count);
        setposition.y = Math.round(setposition.y * 100) / 100;
        dataitem.date = weekdata[day].date;
        dataitem.count = weekdata[day].count;
        dataitem.x = setposition.x;
        dataitem.y = setposition.y;
        ctx.fillRect(setposition.x, setposition.y, lineminwitdh, lineminwitdh);
        setposition.y = setposition.y + linemaxwitdh
      };
      setposition.y = 0.025 * c.width;
      setposition.x = setposition.x + linemaxwitdh
    };
    ctx.font = "600  Arial";
    ctx.fillStyle = '#aaa';
    ctx.fillText("日", 0, 1.9 * linemaxwitdh);
    ctx.fillText("二", 0, 3.9 * linemaxwitdh);
    ctx.fillText("四", 0, 5.9 * linemaxwitdh);
    ctx.fillText("六", 0, 7.9 * linemaxwitdh);
    let monthindexlist = c.width / 24;
    for (let index in gitcalendar.monthchange) {
      ctx.fillText(gitcalendar.monthchange[index], monthindexlist, 0.7 * linemaxwitdh);
      monthindexlist = monthindexlist + c.width / 12
    };
    cmessage.onmousemove = function(event) {
      document.querySelector('.angle-wrapper').style.display = 'none'
    };
    c.onmousemove = function(event) {
      document.querySelector('.angle-wrapper').style.display = 'none'
      getMousePos(c, event);
    };

    function getMousePos(canvas, event) {
      var rect = canvas.getBoundingClientRect();
      var x = event.clientX - rect.left * (canvas.width / rect.width);
      var y = event.clientY - rect.top * (canvas.height / rect.height);
      //console.log("x:"+x+",y:"+y);
      for (let item of gitcalendar.positionplusdata) {
        let lenthx = x - item.x;
        let lenthy = y - item.y;
        //console.log(lenthx,lenthy);
        if (0 < lenthx && lenthx < lineminwitdh) {
          if (0 < lenthy && lenthy < lineminwitdh) {
            //console.log(item.date,item.count)
            document.querySelector('.angle-wrapper').style.display = 'block'
            gitcalendar.span1 = item.date;
            gitcalendar.span2 = item.count;
            gitcalendar.x = event.clientX - 100;
            gitcalendar.y = event.clientY - 60
          }
        }
        //if(0< x - item.x <lineminwitdh&&0< y - item.y <lineminwitdh){
        //console.log(item.count,item.date);
        //}
      }
    }
  }
}
//数据统计算法
function addlastmonth() {
  if (gitcalendar.thisdayindex === 0) {
    thisweekcore(52);
    thisweekcore(51);
    thisweekcore(50);
    thisweekcore(49);
    thisweekcore(48);
    gitcalendar.thisweekdatacore += gitcalendar.firstdate[6].count;
    gitcalendar.amonthago = gitcalendar.firstdate[6].date
  } else {
    thisweekcore(52);
    thisweekcore(51);
    thisweekcore(50);
    thisweekcore(49);
    thisweek2core();
    gitcalendar.amonthago = gitcalendar.first2date[gitcalendar.thisdayindex - 1].date
  }
};

function thisweek2core() {
  for (let i = gitcalendar.thisdayindex - 1; i < gitcalendar.first2date.length; i++) {
    gitcalendar.thisweekdatacore += gitcalendar.first2date[i].count
  }
};

function thisweekcore(index) {
  for (let item of gitcalendar.data[index]) {
    gitcalendar.thisweekdatacore += item.count
  }
};

function addlastweek() {
  for (let item of gitcalendar.lastweek) {
    gitcalendar.weekdatacore += item.count
  }
};

function addbeforeweek() {
  for (let i = gitcalendar.thisdayindex; i < gitcalendar.beforeweek.length; i++) {
    gitcalendar.weekdatacore += gitcalendar.beforeweek[i].count
  }
};

function addweek(data) {
  if (gitcalendar.thisdayindex === 6) {
    gitcalendar.aweekago = gitcalendar.lastweek[0].date;
    addlastweek()
  } else {
    lastweek = data.contributions[51];
    gitcalendar.aweekago = lastweek[gitcalendar.thisdayindex + 1].date;
    addlastweek();
    addbeforeweek()
  }
}

fetch(githubapiurl)
  .then(data => data.json())
  .then(data => {
    gitcalendar.data = data.contributions;
    gitcalendar.total = data.total;
    gitcalendar.first2date = gitcalendar.data[48];
    gitcalendar.firstdate = gitcalendar.data[47];
    gitcalendar.firstweek = data.contributions[0];
    gitcalendar.lastweek = data.contributions[52];
    gitcalendar.beforeweek = data.contributions[51];
    gitcalendar.thisdayindex = gitcalendar.lastweek.length - 1;
    gitcalendar.thisday = gitcalendar.lastweek[gitcalendar.thisdayindex].date;
    gitcalendar.oneyearbeforeday = gitcalendar.firstweek[0].date;
    gitcalendar.monthindex = gitcalendar.thisday.substring(5, 7) * 1;
    gitcalendar.montharrbefore = gitcalendar.month.splice(gitcalendar.monthindex, 12 - gitcalendar.monthindex);
    gitcalendar.monthchange = gitcalendar.montharrbefore.concat(gitcalendar.month);
    addweek(data);
    addlastmonth();
    responsiveChart();
  })
  .catch(function(error) {
    console.log(error);
  });

//手机版更换为svg绘制
if (document.getElementById("gitcalendarcanvasbox") && (document.getElementById("gitcalendarcanvasbox").offsetWidth < 500)) {
  gitcalendar.simplemode = false
}
//当改变窗口大小时重新绘制canvas
window.onresize = function() {
  if (gitcalendar.simplemode) responsiveChart()
}

//解决滚动滑轮时出现的标签显示
window.onscroll = function() {
  if (document.querySelector('.angle-wrapper')) {
    document.querySelector('.angle-wrapper').style.display = 'none'
  }
};</script></div><script defer src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script defer src="https://cdn.jsdelivr.net/npm/hexo-theme-volantis@latest/source/js/issues.min.js"></script><script src="/js/moments.js"></script><canvas class="fireworks" mobile="false"></canvas><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/fireworks.min.js"></script><div class="js-pjax"><script async="async">var arr = document.getElementsByClassName('recent-post-item');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__zoomIn');
    arr[i].setAttribute('data-wow-duration', '1s');
    arr[i].setAttribute('data-wow-delay', '0');
    arr[i].setAttribute('data-wow-offset', '0');
    arr[i].setAttribute('data-wow-iteration', '1');
  }</script><script async="async">var arr = document.getElementsByClassName('card-widget');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__zoomIn');
    arr[i].setAttribute('data-wow-duration', '');
    arr[i].setAttribute('data-wow-delay', '');
    arr[i].setAttribute('data-wow-offset', '');
    arr[i].setAttribute('data-wow-iteration', '');
  }</script></div><script defer="defer" src="https://cdn.jsdelivr.net/gh/graingert/wow@1.3.0/dist/wow.min.js"></script><script defer="defer" src="/js/custom/wow_init.js"></script><div class="app-refresh" id="app-refresh" style="position: fixed;top: -2.2rem;left: 0;right: 0;z-index: 99999;padding: 0 1rem;font-size: 15px;height: 2.2rem;transition: all 0.3s ease;"><div class="app-refresh-wrap" style=" display: flex;color: #fff;height: 100%;align-items: center;justify-content: center;"><label>✨ 有文章更新啦！ 👉</label><a href="javascript:void(0)" onclick="location.reload()"><span style="color: #fff;text-decoration: underline;cursor: pointer;">🍭查看新品🍬</span></a></div></div><script>if ('serviceWorker' in navigator) {
if (navigator.serviceWorker.controller) {
navigator.serviceWorker.addEventListener('controllerchange', function() {
showNotification()
})
}
window.addEventListener('load', function() {
navigator.serviceWorker.register('/sw.js')
})
}
function showNotification() {
if (GLOBAL_CONFIG.Snackbar) {
var snackbarBg =
document.documentElement.getAttribute('data-theme') === 'light' ?
GLOBAL_CONFIG.Snackbar.bgLight :
GLOBAL_CONFIG.Snackbar.bgDark
var snackbarPos = GLOBAL_CONFIG.Snackbar.position
Snackbar.show({
text: '✨ 有文章更新啦！ 👉',
backgroundColor: snackbarBg,
duration: 500000,
pos: snackbarPos,
actionText: '🍭查看新品🍬',
actionTextColor: '#fff',
onActionClick: function(e) {
location.reload()
},
})
} else {
var showBg =
document.documentElement.getAttribute('data-theme') === 'light' ?
'#49b1f5' :
'#1f1f1f'
var cssText = `top: 0; background: ${showBg};`
document.getElementById('app-refresh').style.cssText = cssText
}
}</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>