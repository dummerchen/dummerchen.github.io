<!DOCTYPE html><html lang="zh-cn" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>经典网络实现 | Sakura        Momoko</title><meta name="keywords" content="机器学习"><meta name="author" content="dummerfu"><meta name="copyright" content="dummerfu"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Tensorflow写的，看看就好，别当真">
<meta property="og:type" content="article">
<meta property="og:title" content="经典网络实现">
<meta property="og:url" content="https://dummerfu.top/p/35344.html">
<meta property="og:site_name" content="Sakura        Momoko">
<meta property="og:description" content="Tensorflow写的，看看就好，别当真">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://dummerfu.top/img/lazyload.svg">
<meta property="article:published_time" content="2021-02-20T00:00:00.000Z">
<meta property="article:modified_time" content="2021-08-23T00:00:00.000Z">
<meta property="article:author" content="dummerfu">
<meta property="article:tag" content="机器学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://dummerfu.top/img/lazyload.svg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://dummerfu.top/p/35344"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//hm.baidu.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta name="google-site-verification" content="ul2nhVj6HNaI1d3xtFc7_eYD8Shq0bCu53fkA7a_7Bc"/><meta name="baidu-site-verification" content="code-584WEbZyly"/><link rel="manifest" href="/manifest.json"/><meta name="msapplication-TileColor" content="#212121"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?7cb70c60ee4da7f272c0d8059de063b7";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/4.1.1/animate.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Swiper/4.1.6/css/swiper.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"We didn't find any results for the search: ${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: {"limitDay":30,"position":"top","messagePrev":"It has been","messageNext":"days since the last update, the content of the article may be outdated."},
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":"70vh"},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: 'days',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"Traditional Chinese Activated Manually","cht_to_chs":"Simplified Chinese Activated Manually","day_to_night":"Dark Mode Activated Manually","night_to_day":"Light Mode Activated Manually","bgLight":"#49b1f5","bgDark":"#121212","position":"top-center"},
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: true,
  islazyload: true,
  isanchor: true
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2021-08-23 00:00:00'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    })(window)</script><meta http-equiv="content-type" content="text/html; charset=UTF-8" /><link rel="stylesheet" href="/css/mycss.css"><script src='https://cdn.jsdelivr.net/npm/butterfly-friend@1.0.4/dist/friend.min.js'></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/l-lin/font-awesome-animation/dist/font-awesome-animation.min.css"  media="defer" onload="this.media='all'"><link rel="stylesheet" href="https://at.alicdn.com/t/font_2134734_qu549vixs5f.css?spm=a313x.7781069.1998910419.60&file=font_2134734_qu549vixs5f.css" medis="defer" onload="this.media='all'"><script src="/js/lazyload.js"></script><meta name="generator" content="Hexo 5.4.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="wizard-scene"><div class="wizard-objects"><div class="wizard-square"></div><div class="wizard-circle"></div><div class="wizard-triangle"></div></div><div class="wizard"><div class="wizard-body"></div><div class="wizard-right-arm"><div class="wizard-right-hand"></div></div><div class="wizard-left-arm"><div class="wizard-left-hand"></div></div><div class="wizard-head"><div class="wizard-beard"></div><div class="wizard-face"><div class="wizard-adds"></div></div><div class="wizard-hat"><div class="wizard-hat-of-the-hat"></div><div class="wizard-four-point-star --first"></div><div class="wizard-four-point-star --second"></div><div class="wizard-four-point-star --third"></div></div></div></div></div></div><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" data-src="https://cdn.jsdelivr.net/gh/dummerchen/cdn@master/img/custom/avatar.jpg" src="/img/lazyload.svg" onerror="onerror=null;src='https://cdn.jsdelivr.net/gh/dummerchen/cdn/img/other/default_avatar.jpg'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">45</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">Tags</div><div class="length-num">18</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">Categories</div><div class="length-num">6</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/"><i class="fa-fw fas fa-home faa-tada"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/archives/"><i class="fa-fw fas fa-archive faa-tada"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/comment/"><i class="fa-fw fa fa-comments faa-tada"></i><span> 留言</span></a></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/links/"><i class="fa-fw fas fa-link faa-tada"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/circle/"><i class="fa-fw fas fa-user-friends faa-tada"></i><span> 朋友圈</span></a></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/about/"><i class="fa-fw fa-fw fas fa-heart faa-tada"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://cdn.jsdelivr.net/gh/dummerchen/My_Image_Bed02@image_bed_001/img/20210317004422.jpg')"><nav id="nav"><span id="blog_name"> <a id="site-name" onclick="btf.scrollToDest(0, 500)" data-title="Tensorflow写的，看看就好，别当真">经典网络实现</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/"><i class="fa-fw fas fa-home faa-tada"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/archives/"><i class="fa-fw fas fa-archive faa-tada"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/comment/"><i class="fa-fw fa fa-comments faa-tada"></i><span> 留言</span></a></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/links/"><i class="fa-fw fas fa-link faa-tada"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/circle/"><i class="fa-fw fas fa-user-friends faa-tada"></i><span> 朋友圈</span></a></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/about/"><i class="fa-fw fa-fw fas fa-heart faa-tada"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">经典网络实现</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2021-02-20T00:00:00.000Z" title="Created 2021-02-20 00:00:00">2021-02-20</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2021-08-23T00:00:00.000Z" title="Updated 2021-08-23 00:00:00">2021-08-23</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%8A%80%E6%9C%AF/">技术</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">Word count:</span><span class="word-count">5.5k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">Reading time:</span><span>27min</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="经典网络实现"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post View:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><div class="tip error">看不懂别人的代码,自己实现一遍经典网络,熟悉keras api</div>

 <div class="tip success"> 水篇博客 </div>

<div class="tip warning">没有训练测试过网络的效果,直接拿去用可能会出问题!!!</div>

<p>本意是了解如何自己构建网络,以防日后的模型迁移要再学一遍. <del>不要问为什么我知道要重学</del></p>
<p>可能网络会有错误,但是无伤大雅,知道如何构建就行 <del>反正以后经典网络可以直接导入</del></p>
<p>不过在之前要先了解一下模型保存不同格式的区别<del>以防模型实现了不会保存</del></p>
<h2 id="模型保存"><a href="#模型保存" class="headerlink" title="模型保存"></a>模型保存</h2><p><a target="_blank" rel="noopener" href="https://tensorflow.google.cn/guide/keras/save_and_serialize?hl=zh-cn">TF官网</a></p>
<h3 id="Save-model格式"><a href="#Save-model格式" class="headerlink" title="Save_model格式"></a>Save_model格式</h3><p>这个是最简单粗暴的模型保存方法了。</p>
<p>保存的模型将包括：</p>
<ul>
<li>模型的架构/配置</li>
<li>模型的权重值（在训练过程中学习）</li>
<li>模型的编译信息（如果调用了 <code>compile()</code>）</li>
<li>优化器及其状态（如果有的话，使您可以从上次中断的位置重新开始训练）</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 保存为dirname_path路径下文件名为dirname的文件夹</span></span><br><span class="line"></span><br><span class="line">model.save(dirname_path)</span><br></pre></td></tr></table></figure>
<h3 id="H5格式"><a href="#H5格式" class="headerlink" title="H5格式"></a>H5格式</h3><blockquote>
<p>Keras 还支持保存单个 HDF5 文件，其中包含模型的架构、权重值和 <code>compile()</code> 信息。它是 SavedModel 的轻量化替代选择。</p>
</blockquote>
<p>但是同时因为只有一个h5文件与 SavedModel 格式相比，H5 文件不包括以下两方面内容：</p>
<ul>
<li>通过 <code>model.add_loss()</code> 和 <code>model.add_metric()</code> 添加的<strong>外部损失和指标</strong>不会被保存（这与 SavedModel 不同）。如果您的模型有此类损失和指标且您想要恢复训练，则您需要在加载模型后自行重新添加这些损失。请注意，这不适用于通过 <code>self.add_loss()</code> 和 <code>self.add_metric()</code> 在层内创建的损失指标。只要该层被加载，这些损失和指标就会被保留，因为它们是该层 <code>call</code> 方法的一部分。</li>
<li>已保存的文件中<strong>不包含自定义对象（如自定义层）的计算图</strong>。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 只需要在文件名后加.h5后缀即可</span></span><br><span class="line">model.save(name.h5)</span><br></pre></td></tr></table></figure>
<h3 id="checkpoints"><a href="#checkpoints" class="headerlink" title="　checkpoints"></a>　checkpoints</h3><h3 id="保存时附带签名"><a href="#保存时附带签名" class="headerlink" title="保存时附带签名"></a>保存时附带签名</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Model</span>(<span class="params">tf.keras.Model</span>):</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @tf.function</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self, x</span>):</span></span><br><span class="line">      ...</span><br><span class="line"></span><br><span class="line">  m = Model()</span><br><span class="line">  tf.saved_model.save(</span><br><span class="line">      m, <span class="string">&#x27;/tmp/saved_model/&#x27;</span>,</span><br><span class="line">      signatures=m.call.get_concrete_function(</span><br><span class="line">          tf.TensorSpec(shape=[<span class="literal">None</span>, <span class="number">3</span>], dtype=tf.float32, name=<span class="string">&quot;inp&quot;</span>)))</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="ResNet"><a href="#ResNet" class="headerlink" title="ResNet"></a>ResNet</h2><h3 id="手写实现"><a href="#手写实现" class="headerlink" title="手写实现"></a>手写实现</h3><p>不同的ResNet只有结构不同,unit是相同的只需要改变layer_dims就可以实现了</p>
<p>这里使用重写类来构建网络,虽然要写前向传播比较麻烦,但是自由度更高</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.environ[<span class="string">&#x27;TF_CPP_MIN_LOG_LEVEL&#x27;</span>]=<span class="string">&#x27;2&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span>  tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">import</span> tensorboard</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> layers</span><br><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">BATCHSIZE=<span class="number">64</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BasicBlock</span>(<span class="params">layers.Layer</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,filter_num,stride=<span class="number">1</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(BasicBlock,self).__init__()</span><br><span class="line">        self.conv1=layers.Conv2D(kernel_size=(<span class="number">3</span>,<span class="number">3</span>) ,filters=filter_num,strides=stride,padding=<span class="string">&#x27;same&#x27;</span>)</span><br><span class="line">        self.bn1=layers.BatchNormalization()</span><br><span class="line">        self.relu=layers.Activation(<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        self.conv2=layers.Conv2D(kernel_size=(<span class="number">3</span>,<span class="number">3</span>) ,filters=filter_num,strides=<span class="number">1</span>,padding=<span class="string">&#x27;same&#x27;</span>)</span><br><span class="line">        self.bn2 = layers.BatchNormalization()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span>(stride!=<span class="number">1</span>):</span><br><span class="line">            self.downsample = keras.Sequential()</span><br><span class="line">            self.downsample.add(layers.Conv2D(filters=filter_num,kernel_size=(<span class="number">1</span>,<span class="number">1</span>),strides=stride))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.downsample=<span class="keyword">lambda</span> x:x</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self,inputs,training=<span class="literal">None</span></span>):</span></span><br><span class="line"></span><br><span class="line">        out=self.conv1(inputs)</span><br><span class="line">        out=self.bn1(out)</span><br><span class="line">        out=self.relu(out)</span><br><span class="line">        out=self.conv2(out)</span><br><span class="line">        out=self.bn2(out)</span><br><span class="line"></span><br><span class="line">        identity=self.downsample(inputs)</span><br><span class="line">        output=layers.add([out,identity])</span><br><span class="line">        output=self.relu(output)</span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ResNet</span>(<span class="params">keras.Model</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,layer_dims,num_classes=<span class="number">100</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(ResNet, self).__init__()</span><br><span class="line">        <span class="comment"># self.flatten=layers.Flatten(input_shape=(32,32,3))</span></span><br><span class="line">        self.stem=keras.Sequential([</span><br><span class="line">            layers.Conv2D(<span class="number">64</span>,(<span class="number">3</span>,<span class="number">3</span>),strides=(<span class="number">1</span>,<span class="number">1</span>)),</span><br><span class="line">            layers.BatchNormalization(),</span><br><span class="line">            layers.Activation(<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">            layers.MaxPool2D(pool_size=(<span class="number">2</span>,<span class="number">2</span>),strides=(<span class="number">1</span>,<span class="number">1</span>),padding=<span class="string">&#x27;same&#x27;</span>)</span><br><span class="line">        ])</span><br><span class="line">        self.layer1=self.build_resblock(filter_num=<span class="number">64</span>,blocks=layer_dims[<span class="number">0</span>])</span><br><span class="line">        self.layer2=self.build_resblock(filter_num=<span class="number">128</span>,blocks=layer_dims[<span class="number">1</span>],stride=<span class="number">2</span>)</span><br><span class="line">        self.layer3=self.build_resblock(filter_num=<span class="number">256</span>,blocks=layer_dims[<span class="number">2</span>],stride=<span class="number">2</span>)</span><br><span class="line">        self.layer4=self.build_resblock(filter_num=<span class="number">512</span>,blocks=layer_dims[<span class="number">3</span>],stride=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        self.avgpool=layers.GlobalAveragePooling2D()</span><br><span class="line">        self.fc=layers.Dense(num_classes)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self,inputs,training=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="comment"># x = tf.reshape(inputs, [-1, 32 * 32*3])</span></span><br><span class="line">        out=self.stem(inputs)</span><br><span class="line">        out=self.layer1(out)</span><br><span class="line">        out=self.layer2(out)</span><br><span class="line">        out=self.layer3(out)</span><br><span class="line">        out=self.layer4(out)</span><br><span class="line">        out=self.avgpool(out)</span><br><span class="line">        out=self.fc(out)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">build_resblock</span>(<span class="params">self,filter_num,blocks,stride=<span class="number">1</span></span>):</span></span><br><span class="line">        res_block=keras.Sequential()</span><br><span class="line">        res_block.add(BasicBlock(filter_num,stride))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,blocks):</span><br><span class="line">            res_block.add(BasicBlock(filter_num,stride=<span class="number">1</span>))</span><br><span class="line">        <span class="keyword">return</span>  res_block</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">resnet18</span>():</span></span><br><span class="line">    <span class="keyword">return</span> ResNet(layer_dims=[<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">preprocess</span>(<span class="params">x,y</span>):</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;pre:&#x27;</span>, x.shape, y.shape)</span><br><span class="line">    x=tf.cast(x,dtype=tf.float32)/<span class="number">255.0</span></span><br><span class="line">    y=tf.cast(y,dtype=tf.int32)</span><br><span class="line">    y = tf.squeeze(y)</span><br><span class="line">    y=tf.one_hot(y,depth=<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;after&#x27;</span>, x.shape, y.shape)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> x,y</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">data2tensor</span>(<span class="params">x,y</span>):</span></span><br><span class="line"></span><br><span class="line">    db=tf.data.Dataset.from_tensor_slices((x,y))</span><br><span class="line">    db=db.<span class="built_in">map</span>(preprocess)</span><br><span class="line">    db=db.shuffle(<span class="number">5000</span>).batch(BATCHSIZE)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> db</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_model</span>(<span class="params">train_db,val_db,is_train=<span class="literal">False</span></span>):</span></span><br><span class="line">    model = resnet18()</span><br><span class="line"></span><br><span class="line">    model.build(input_shape=(<span class="literal">None</span>, <span class="number">32</span>, <span class="number">32</span>, <span class="number">3</span>))</span><br><span class="line">    model.summary()</span><br><span class="line">    x=tf.random.normal([<span class="number">4</span>,<span class="number">32</span>,<span class="number">32</span>,<span class="number">3</span>])</span><br><span class="line">    out=model(x)</span><br><span class="line">    <span class="built_in">print</span>(out.shape)</span><br><span class="line"></span><br><span class="line">    model.<span class="built_in">compile</span>(</span><br><span class="line">        optimizer=tf.optimizers.Adam(),</span><br><span class="line">        loss=tf.losses.CategoricalCrossentropy(from_logits=<span class="literal">True</span>),</span><br><span class="line">        metrics=[<span class="string">&#x27;accuracy&#x27;</span>],</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    path=os.path.abspath(<span class="string">&#x27;./&#x27;</span>)</span><br><span class="line">    log_dir = path + <span class="string">&#x27;\\logs\\&#x27;</span> + datetime.datetime.now().strftime(<span class="string">&quot;%Y%m%d-%H%M&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(log_dir)</span><br><span class="line">    tensorboard=keras.callbacks.TensorBoard(log_dir=log_dir,histogram_freq=<span class="number">1</span>)</span><br><span class="line">    model.summary()</span><br><span class="line">    <span class="keyword">if</span> is_train:</span><br><span class="line"></span><br><span class="line">        model.fit(train_db,validation_data=val_db,validation_freq=<span class="number">1</span>,epochs=<span class="number">5</span>,callbacks=[tensorboard])</span><br><span class="line"></span><br><span class="line">        model.save_weights(<span class="string">&#x27;./resnet18.h5&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    (x,y),(x_test,y_test)=keras.datasets.cifar100.load_data()</span><br><span class="line"></span><br><span class="line">    l=<span class="built_in">int</span>(<span class="built_in">len</span>(x)*<span class="number">0.8</span>)</span><br><span class="line">    train_db=data2tensor(x[:l],y[:l])</span><br><span class="line">    val_db=data2tensor(x[l:],y[l:])</span><br><span class="line">    test_db=data2tensor(x_test,y_test)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># sample=next(iter(train_db))</span></span><br><span class="line">    <span class="comment"># print(sample[0].shape,sample[1].shape)</span></span><br><span class="line">    <span class="comment"># plt.imshow(sample[0])</span></span><br><span class="line">    <span class="comment"># plt.show()</span></span><br><span class="line">    train_model(train_db,val_db,is_train=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">main()</span><br></pre></td></tr></table></figure>
<h3 id="自带api实现"><a href="#自带api实现" class="headerlink" title="自带api实现"></a>自带api实现</h3><p>因为application里面都有，功能都类似故后面不再赘述</p>
<div class="tips warning"> tf.kears.application.resnet50.Resnet50与tf.kears.application.Resnet50的功能都一样</div>



<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.keras.applications <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line">model=ResNet50(weights=<span class="string">&#x27;./resnet50_weights_tf_dim_ordering_tf_kernels.h5&#x27;</span>)</span><br><span class="line">path=<span class="string">&#x27;./cat.jpg&#x27;</span></span><br><span class="line"><span class="comment"># 读入图片</span></span><br><span class="line">image=image_preprocess.img_decoder(path)</span><br><span class="line"></span><br><span class="line">pre1=model.predict(image)</span><br><span class="line"><span class="comment"># 这个能使标签对应起来</span></span><br><span class="line">pre=resnet50.decode_predictions(pre1)</span><br><span class="line"><span class="built_in">print</span>(pre)</span><br></pre></td></tr></table></figure>
<h2 id="VGG"><a href="#VGG" class="headerlink" title="VGG"></a>VGG</h2><p>​    这里使用keras的高级api来构建网络,当然使用Sequential也可以实现同样的效果.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Author : Dummerfu</span></span><br><span class="line"><span class="comment"># @Contact : https://github.com/dummerchen </span></span><br><span class="line"><span class="comment"># @Time : 2021/2/19 20:48</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.environ[<span class="string">&#x27;TF_CPP_MIN_LOG_LEVEL&#x27;</span>]=<span class="string">&#x27;2&#x27;</span></span><br><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span>  tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span>  tensorflow <span class="keyword">import</span>  keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">BATCHSIZE=<span class="number">32</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">preprocess</span>(<span class="params">x,y</span>):</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;pre&#x27;</span>,x.shape,y.shape)</span><br><span class="line"></span><br><span class="line">    x=<span class="number">2</span>*tf.cast(x,dtype=tf.float32)/<span class="number">255.0</span> -<span class="number">1</span></span><br><span class="line">    y = tf.squeeze(y)</span><br><span class="line">    y=tf.cast(y,dtype=tf.int32)</span><br><span class="line">    y=tf.one_hot(y,depth=<span class="number">100</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;after:&#x27;</span>,x.shape,y.shape)</span><br><span class="line">    <span class="keyword">return</span>  x,y</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">data2tensor</span>(<span class="params">x,y</span>):</span></span><br><span class="line"></span><br><span class="line">    db=tf.data.Dataset.from_tensor_slices((x,y))</span><br><span class="line">    db=db.<span class="built_in">map</span>(preprocess)</span><br><span class="line">    db=db.shuffle(<span class="number">5000</span>).batch(BATCHSIZE)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> db</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">VGG</span>(<span class="params">image_shape,n_class</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(image_shape[<span class="number">0</span>],image_shape[<span class="number">1</span>],image_shape[<span class="number">2</span>])</span><br><span class="line">    inputs = keras.Input(shape=[image_shape[<span class="number">0</span>],image_shape[<span class="number">1</span>],image_shape[<span class="number">2</span>]])</span><br><span class="line"></span><br><span class="line">    x=keras.layers.Conv2D(<span class="number">64</span>, kernel_size=[<span class="number">3</span>, <span class="number">3</span>], strides=[<span class="number">1</span>, <span class="number">1</span>], activation=keras.activations.relu,padding=<span class="string">&#x27;same&#x27;</span>)(inputs)</span><br><span class="line">    x=keras.layers.Conv2D(<span class="number">64</span>, kernel_size=[<span class="number">3</span>, <span class="number">3</span>], strides=[<span class="number">1</span>, <span class="number">1</span>], activation=keras.activations.relu,padding=<span class="string">&#x27;same&#x27;</span>)(x)</span><br><span class="line">    x=keras.layers.MaxPooling2D(pool_size=[<span class="number">2</span>, <span class="number">2</span>], strides=[<span class="number">2</span>, <span class="number">2</span>], padding=<span class="string">&#x27;same&#x27;</span>)(x)</span><br><span class="line"></span><br><span class="line">    x= keras.layers.Conv2D(<span class="number">128</span>, kernel_size=[<span class="number">3</span>, <span class="number">3</span>], strides=[<span class="number">1</span>, <span class="number">1</span>], activation=keras.activations.relu,padding=<span class="string">&#x27;same&#x27;</span>)(x)</span><br><span class="line">    x= keras.layers.Conv2D(<span class="number">128</span>, kernel_size=[<span class="number">3</span>, <span class="number">3</span>], strides=[<span class="number">1</span>, <span class="number">1</span>], activation=keras.activations.relu,padding=<span class="string">&#x27;same&#x27;</span>)(x)</span><br><span class="line">    x= keras.layers.MaxPooling2D(pool_size=[<span class="number">2</span>, <span class="number">2</span>], strides=[<span class="number">2</span>, <span class="number">2</span>], padding=<span class="string">&#x27;same&#x27;</span>)(x)</span><br><span class="line"></span><br><span class="line">    x= keras.layers.Conv2D(<span class="number">256</span>, kernel_size=[<span class="number">3</span>, <span class="number">3</span>], strides=[<span class="number">1</span>, <span class="number">1</span>], activation=keras.activations.relu,padding=<span class="string">&#x27;same&#x27;</span>)(x)</span><br><span class="line">    x= keras.layers.Conv2D(<span class="number">256</span>, kernel_size=[<span class="number">3</span>, <span class="number">3</span>], strides=[<span class="number">1</span>, <span class="number">1</span>], activation=keras.activations.relu,padding=<span class="string">&#x27;same&#x27;</span>)(x)</span><br><span class="line">    x= keras.layers.Conv2D(<span class="number">256</span>, kernel_size=[<span class="number">3</span>, <span class="number">3</span>], strides=[<span class="number">1</span>, <span class="number">1</span>], activation=keras.activations.relu,padding=<span class="string">&#x27;same&#x27;</span>)(x)</span><br><span class="line">    x= keras.layers.Conv2D(<span class="number">256</span>, kernel_size=[<span class="number">3</span>, <span class="number">3</span>], strides=[<span class="number">1</span>, <span class="number">1</span>], activation=keras.activations.relu,padding=<span class="string">&#x27;same&#x27;</span>)(x)</span><br><span class="line">    x= keras.layers.MaxPooling2D(pool_size=[<span class="number">2</span>, <span class="number">2</span>], strides=[<span class="number">2</span>, <span class="number">2</span>], padding=<span class="string">&#x27;same&#x27;</span>)(x)</span><br><span class="line"></span><br><span class="line">    x= keras.layers.Conv2D(<span class="number">512</span>, kernel_size=[<span class="number">3</span>, <span class="number">3</span>], strides=[<span class="number">1</span>, <span class="number">1</span>], activation=keras.activations.relu,padding=<span class="string">&#x27;same&#x27;</span>)(x)</span><br><span class="line">    x= keras.layers.Conv2D(<span class="number">512</span>, kernel_size=[<span class="number">3</span>, <span class="number">3</span>], strides=[<span class="number">1</span>, <span class="number">1</span>], activation=keras.activations.relu,padding=<span class="string">&#x27;same&#x27;</span>)(x)</span><br><span class="line">    x= keras.layers.Conv2D(<span class="number">512</span>, kernel_size=[<span class="number">3</span>, <span class="number">3</span>], strides=[<span class="number">1</span>, <span class="number">1</span>], activation=keras.activations.relu,padding=<span class="string">&#x27;same&#x27;</span>)(x)</span><br><span class="line">    x= keras.layers.Conv2D(<span class="number">512</span>, kernel_size=[<span class="number">3</span>, <span class="number">3</span>], strides=[<span class="number">1</span>, <span class="number">1</span>], activation=keras.activations.relu,padding=<span class="string">&#x27;same&#x27;</span>)(x)</span><br><span class="line">    x= keras.layers.MaxPooling2D(pool_size=[<span class="number">2</span>, <span class="number">2</span>], strides=[<span class="number">2</span>, <span class="number">2</span>], padding=<span class="string">&#x27;same&#x27;</span>)(x)</span><br><span class="line"></span><br><span class="line">    x= keras.layers.Conv2D(<span class="number">512</span>, kernel_size=[<span class="number">3</span>, <span class="number">3</span>], strides=[<span class="number">1</span>, <span class="number">1</span>], activation=keras.activations.relu,padding=<span class="string">&#x27;same&#x27;</span>)(x)</span><br><span class="line">    x= keras.layers.Conv2D(<span class="number">512</span>, kernel_size=[<span class="number">3</span>, <span class="number">3</span>], strides=[<span class="number">1</span>, <span class="number">1</span>], activation=keras.activations.relu,padding=<span class="string">&#x27;same&#x27;</span>)(x)</span><br><span class="line">    x= keras.layers.Conv2D(<span class="number">512</span>, kernel_size=[<span class="number">3</span>, <span class="number">3</span>], strides=[<span class="number">1</span>, <span class="number">1</span>], activation=keras.activations.relu,padding=<span class="string">&#x27;same&#x27;</span>)(x)</span><br><span class="line">    x= keras.layers.Conv2D(<span class="number">512</span>, kernel_size=[<span class="number">3</span>, <span class="number">3</span>], strides=[<span class="number">1</span>, <span class="number">1</span>], activation=keras.activations.relu,padding=<span class="string">&#x27;same&#x27;</span>)(x)</span><br><span class="line">    x= keras.layers.MaxPooling2D(pool_size=[<span class="number">2</span>, <span class="number">2</span>], strides=[<span class="number">2</span>, <span class="number">2</span>], padding=<span class="string">&#x27;same&#x27;</span>)(x)</span><br><span class="line"></span><br><span class="line">    x= keras.layers.Flatten()(x)</span><br><span class="line">    x= keras.layers.Dense(<span class="number">4096</span>, activation=keras.activations.relu, use_bias=<span class="literal">True</span>)(x)</span><br><span class="line">    x= keras.layers.Dense(<span class="number">4096</span>, activation=keras.activations.relu, use_bias=<span class="literal">True</span>)(x)</span><br><span class="line"></span><br><span class="line">    outputs= keras.layers.Dense(n_class, activation=keras.activations.softmax, use_bias=<span class="literal">True</span>)(x)</span><br><span class="line">    <span class="comment"># 基于Model方法构建模型</span></span><br><span class="line">    model = keras.Model(inputs=inputs, outputs=outputs)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span>(<span class="params">train_db,val_db,is_train=<span class="literal">False</span></span>):</span></span><br><span class="line">    model = VGG([<span class="number">32</span>,<span class="number">32</span>,<span class="number">3</span>],n_class=<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">    model.<span class="built_in">compile</span>(</span><br><span class="line">        optimizer=tf.optimizers.Adam(),</span><br><span class="line">        loss=tf.losses.CategoricalCrossentropy(),</span><br><span class="line">        metrics=[<span class="string">&#x27;accuracy&#x27;</span>],</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    path = os.path.abspath(<span class="string">&#x27;./&#x27;</span>)</span><br><span class="line">    log_dir = path + <span class="string">&#x27;\\logs\\&#x27;</span> + datetime.datetime.now().strftime(<span class="string">&quot;%Y%m%d-%H%M&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(log_dir)</span><br><span class="line">    tensorboard = keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=<span class="number">1</span>)</span><br><span class="line">    model.summary()</span><br><span class="line">    <span class="keyword">if</span> is_train:</span><br><span class="line"></span><br><span class="line">        model.fit(train_db, validation_data=val_db, validation_freq=<span class="number">1</span>, epochs=<span class="number">5</span>, callbacks=[tensorboard])</span><br><span class="line"></span><br><span class="line">        model.save_weights(<span class="string">&#x27;./vgg16.h5&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">(x,y),(x_test,y_test)=keras.datasets.cifar100.load_data()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;pre&#x27;</span>,x.shape,y.shape)</span><br><span class="line"></span><br><span class="line">train_db=data2tensor(x,y)</span><br><span class="line">test_db=data2tensor(x_test,y_test)</span><br><span class="line"></span><br><span class="line">train(train_db=train_db,val_db=test_db,is_train=<span class="literal">False</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h2><div class="tip warning">layers.lstmcell和layers.lstm传参是不一样的</div>

<p>前者需要手动更新state参数($h<em>{t-1}$,$c</em>{t-1}$)但是后者自动更新，如果需要多层叠加则需要设置return_sequence=True , unroll=True</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Author : Dummerfu</span></span><br><span class="line"><span class="comment"># @Contact : https://github.com/dummerchen </span></span><br><span class="line"><span class="comment"># @Time : 2021/2/21 17:46</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.environ[<span class="string">&#x27;TF_CPP_MIN_LOG_LEVEL&#x27;</span>]=<span class="string">&#x27;2&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib <span class="keyword">as</span> mpl</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">mpl.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = <span class="string">&#x27;SimHei&#x27;</span></span><br><span class="line">mpl.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"></span><br><span class="line"><span class="comment"># 最常见的前20000个单词</span></span><br><span class="line">max_features=<span class="number">20000</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 一句话的最大长度</span></span><br><span class="line">max_len=<span class="number">100</span></span><br><span class="line">batchsize=<span class="number">64</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Mylstm</span>(<span class="params">keras.Model</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,units</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Mylstm,self).__init__()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># [b,100] =&gt; [b,100,100]</span></span><br><span class="line"></span><br><span class="line">        self.embeding=keras.layers.Embedding(input_dim=max_features,input_length=max_len,output_dim=<span class="number">100</span>)</span><br><span class="line">        self.rnn=keras.Sequential([</span><br><span class="line">            keras.layers.LSTM(units=units,dropout=<span class="number">0.5</span>,return_sequences=<span class="literal">True</span>,unroll=<span class="literal">True</span>),</span><br><span class="line">            keras.layers.LSTM(units=units,dropout=<span class="number">0.5</span>,unroll=<span class="literal">True</span>)</span><br><span class="line">        ])</span><br><span class="line"></span><br><span class="line">        self.fc=keras.layers.Dense(<span class="number">1</span>,activation=keras.activations.sigmoid)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self,inputs,training=<span class="literal">None</span></span>):</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># [b,100] =&gt; [b,100,100]</span></span><br><span class="line">        x=self.embeding(inputs)</span><br><span class="line">        <span class="built_in">print</span>(x.shape)</span><br><span class="line">        <span class="comment"># [b,100,100] =&gt; [b,64]</span></span><br><span class="line">        x=self.rnn(x)</span><br><span class="line">        x=self.fc(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">data2tensor</span>(<span class="params">x,y</span>):</span></span><br><span class="line">    x=keras.preprocessing.sequence.pad_sequences(sequences=x,maxlen=max_len)</span><br><span class="line">    x=tf.cast(x,dtype=tf.int32)</span><br><span class="line">    y=tf.cast(y,dtype=tf.int32)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(x.shape,y.shape)</span><br><span class="line"></span><br><span class="line">    db=tf.data.Dataset.from_tensor_slices((x,y)).shuffle(<span class="number">10000</span>).batch(batchsize,drop_remainder=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> db</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span>(<span class="params">db_train,db_val,db_test</span>):</span></span><br><span class="line"></span><br><span class="line">    model=Mylstm(<span class="number">64</span>)</span><br><span class="line">    model.<span class="built_in">compile</span>(</span><br><span class="line">        optimizer=tf.optimizers.Adam(),</span><br><span class="line">        loss=tf.losses.BinaryCrossentropy(),</span><br><span class="line">        metrics=[<span class="string">&#x27;accuracy&#x27;</span>],</span><br><span class="line">    )</span><br><span class="line">    model.fit(db_train,epochs=<span class="number">5</span>,validation_data=db_val,validation_freq=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    model.evaluate(db_test)</span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    (x,y),(x_test,y_test)=keras.datasets.imdb.load_data(num_words=max_features)</span><br><span class="line"></span><br><span class="line">    l=<span class="built_in">int</span>(<span class="built_in">len</span>(x)*<span class="number">0.8</span>)</span><br><span class="line">    db_train=data2tensor(x[:l],y[:l])</span><br><span class="line">    db_val=data2tensor(x[l:],y[l:])</span><br><span class="line">    db_test=data2tensor(x_test,y_test)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    train(db_train,db_val,db_test)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    main()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="AutoEncoder-VAE"><a href="#AutoEncoder-VAE" class="headerlink" title="AutoEncoder|VAE"></a>AutoEncoder|VAE</h2><p><em>这里是自定义训练，当然相比之下更复杂但是自由度也更高。</em></p>
<p>autoencoder就是两个自定义网络，先降维得到特征向量h，再升到原本维度就行了<del>没什么技术含量，就不写了</del>，关键是它的思路非常具有启发性。</p>
<p>这里要注意的是mean,var Dense是两个Dense，即使计算方式一样但是要用两Dense,如果一个Dense算两次因为权重的原因结果是相同的，直接会导致图片越来越暗。</p>
<p>先附上<a target="_blank" rel="noopener" href="https://www.cnblogs.com/henuliulei/p/13742376.html">tf.nn的几种损失函数区别</a>再附代码</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Author : Dummerfu</span></span><br><span class="line"><span class="comment"># @Contact : https://github.com/dummerchen </span></span><br><span class="line"><span class="comment"># @Time : 2021/2/22 21:55</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.environ[<span class="string">&#x27;TF_CPP_MIN_LOG_LEVEL&#x27;</span>]=<span class="string">&#x27;2&#x27;</span></span><br><span class="line"><span class="keyword">import</span> matplotlib <span class="keyword">as</span> mpl</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> layers</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">mpl.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = <span class="string">&#x27;SimHei&#x27;</span></span><br><span class="line">mpl.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">tf.random.set_seed(<span class="number">2345</span>)</span><br><span class="line"><span class="comment"># autoencoder 计算量很小batch可以大一点</span></span><br><span class="line">batch_size=<span class="number">512</span></span><br><span class="line"><span class="comment"># 特征维数</span></span><br><span class="line">z_dims=<span class="number">20</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">VAE</span>(<span class="params">keras.Model</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(VAE,self).__init__()</span><br><span class="line"></span><br><span class="line">        <span class="comment">#encoder</span></span><br><span class="line">        self.encoder=keras.Sequential([</span><br><span class="line">            keras.layers.InputLayer(input_shape=(<span class="number">28</span>*<span class="number">28</span>)),</span><br><span class="line">            keras.layers.Dense(<span class="number">128</span>),</span><br><span class="line">        ])</span><br><span class="line"></span><br><span class="line">        self.meanfc=keras.layers.Dense(z_dims)</span><br><span class="line">        self.varfc=keras.layers.Dense(z_dims)</span><br><span class="line">        <span class="comment">#decoder</span></span><br><span class="line">        self.decoder=keras.Sequential([</span><br><span class="line">            keras.layers.Dense(<span class="number">128</span>, activation=tf.nn.relu),</span><br><span class="line">            keras.layers.Dense(<span class="number">784</span>),</span><br><span class="line">        ])</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">reparamize</span>(<span class="params">self,mean,log_var</span>):</span></span><br><span class="line"></span><br><span class="line">        eps=tf.random.normal(log_var.shape)</span><br><span class="line">        z=mean+eps*tf.exp(log_var*<span class="number">0.5</span>)</span><br><span class="line">        <span class="keyword">return</span> z</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self,inputs,training=<span class="literal">None</span></span>):</span></span><br><span class="line">        h=self.encoder(inputs)</span><br><span class="line">        </span><br><span class="line">        mean=self.meanfc(h)</span><br><span class="line">        log_var=self.varfc(h)</span><br><span class="line">        </span><br><span class="line">        z=self.reparamize(mean,log_var)</span><br><span class="line">        </span><br><span class="line">        outputs=self.decoder(z)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> outputs,mean,log_var</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">data2tensor</span>(<span class="params">x,y</span>):</span></span><br><span class="line"></span><br><span class="line">    x=tf.cast(x,dtype=tf.float32)/<span class="number">255.0</span></span><br><span class="line">    db=tf.data.Dataset.from_tensor_slices(x)</span><br><span class="line">    db=db.shuffle(batch_size*<span class="number">5</span>).batch(batch_size)</span><br><span class="line">    <span class="keyword">return</span> db</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save_images</span>(<span class="params">imgs,name</span>):</span></span><br><span class="line">    new_im = Image.new(<span class="string">&#x27;L&#x27;</span>, (<span class="number">280</span>, <span class="number">280</span>))</span><br><span class="line"></span><br><span class="line">    index = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">280</span>, <span class="number">28</span>):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">280</span>, <span class="number">28</span>):</span><br><span class="line">            im = imgs[index]</span><br><span class="line">            im = Image.fromarray(im, mode=<span class="string">&#x27;L&#x27;</span>)</span><br><span class="line">            new_im.paste(im, (i, j))</span><br><span class="line">            index += <span class="number">1</span></span><br><span class="line">    new_im.save(name)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_and_test</span>(<span class="params">db_train,db_test</span>):</span></span><br><span class="line"></span><br><span class="line">    model=VAE()</span><br><span class="line">    <span class="comment"># model.build(input_shape=(4,784))</span></span><br><span class="line">    optimizer=tf.optimizers.Adam()</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">        <span class="keyword">for</span> step,x <span class="keyword">in</span> <span class="built_in">enumerate</span>(db_train):</span><br><span class="line">            <span class="comment"># print(x.shape)</span></span><br><span class="line">            x=tf.reshape(x,[-<span class="number">1</span>,<span class="number">784</span>])</span><br><span class="line"></span><br><span class="line">            <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">                x_hat,mean,log_var=model(x)</span><br><span class="line">                <span class="comment"># 这里使用的这个loss是为了更好的收敛，使用其他的也行，但是要多训练</span></span><br><span class="line">                redu_loss=tf.nn.sigmoid_cross_entropy_with_logits(x,x_hat)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># 这里其实随便，reduce_mean(),reduce_sum()应该都行反正都是minimize loss</span></span><br><span class="line">                <span class="comment"># reduce_mean()和reduce_sum()|reduce_sum/x.shape[0]训练结果完全不同..</span></span><br><span class="line">                <span class="comment"># 但是后两者相似</span></span><br><span class="line">                redu_loss=tf.reduce_sum(redu_loss)/x.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">                kl=-<span class="number">0.5</span>*(log_var+<span class="number">1</span>-mean**<span class="number">2</span>-tf.exp(log_var))</span><br><span class="line">                <span class="comment"># prekl=tf.reduce_mean(kl)</span></span><br><span class="line">                kl=tf.reduce_sum(kl)/x.shape[<span class="number">0</span>]</span><br><span class="line">     </span><br><span class="line">                loss=redu_loss+kl*<span class="number">1.0</span></span><br><span class="line">            grads=tape.gradient(loss,model.trainable_variables)</span><br><span class="line"></span><br><span class="line">            optimizer.apply_gradients(<span class="built_in">zip</span>(grads,model.trainable_variables))</span><br><span class="line">            <span class="keyword">if</span> step%<span class="number">50</span>==<span class="number">0</span>:</span><br><span class="line"></span><br><span class="line">                <span class="built_in">print</span>(epoch,step,<span class="string">&quot;kl_loss:&quot;</span>,kl,<span class="string">&#x27;loss:&#x27;</span>,loss,<span class="string">&#x27;x_shape0&#x27;</span>,x.shape[<span class="number">0</span>])</span><br><span class="line">        <span class="comment"># evaluation</span></span><br><span class="line">        z=tf.random.normal((batch_size,z_dims))</span><br><span class="line">        sample_x=model.decoder(z)</span><br><span class="line">        sample_x=tf.nn.sigmoid(sample_x)</span><br><span class="line">        sample_x = tf.reshape(sample_x, [-<span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>]).numpy() * <span class="number">255.</span></span><br><span class="line">        sample_x= sample_x.astype(np.uint8)</span><br><span class="line"></span><br><span class="line">        save_images(sample_x, <span class="string">&#x27;vae_images/sample_epoch_%d.png&#x27;</span> % epoch)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        test_x = <span class="built_in">next</span>(<span class="built_in">iter</span>(db_test))</span><br><span class="line">        test_x,_,_= model(tf.reshape(test_x, [-<span class="number">1</span>, <span class="number">784</span>]))</span><br><span class="line">        <span class="comment"># [b, 784] =&gt; [b, 28, 28]</span></span><br><span class="line">        test_x=tf.nn.sigmoid(test_x)</span><br><span class="line">        test_x = tf.reshape(test_x, [-<span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># [b, 28, 28] =&gt; [2b, 28, 28]</span></span><br><span class="line">        test_x= test_x.numpy() * <span class="number">255.</span></span><br><span class="line">        test_x = test_x.astype(np.uint8)</span><br><span class="line">        save_images(test_x, <span class="string">&#x27;vae_images/test_epoch_%d.png&#x27;</span> % epoch)</span><br><span class="line"></span><br><span class="line">    model.save_weights(<span class="string">&#x27;./vae.h5&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    (x,y),(x_test,y_test)=keras.datasets.mnist.load_data()</span><br><span class="line"></span><br><span class="line">    l=<span class="built_in">int</span>(<span class="built_in">len</span>(x)*<span class="number">0.8</span>)</span><br><span class="line">    <span class="built_in">print</span>(x.shape, y.shape,l,<span class="number">28</span>*<span class="number">28</span>)</span><br><span class="line">    db_train=data2tensor(x[:l],y[:l])</span><br><span class="line">    db_val=data2tensor(x[l:],y[l:])</span><br><span class="line">    db_test=data2tensor(x_test,y_test)</span><br><span class="line"></span><br><span class="line">    train_and_test(db_train,db_val)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="Gan"><a href="#Gan" class="headerlink" title="Gan"></a>Gan</h2><h3 id="WGAN原理"><a href="#WGAN原理" class="headerlink" title="WGAN原理"></a>WGAN原理</h3><p>GAN一直面临着G,D训练困难、G,D的损失函数与训练好坏无关(由于js散度，loss 常常是log2)等问题，在此基础上便提出了WGAN，相对于传统的GAN,WGAN只做了几点改动确有很好的效果</p>
<ul>
<li>D的最后一层去掉sigmod</li>
<li>G,Dloss不取log</li>
<li>每次更新D的参数后做一个梯度惩罚（gradient penalty）</li>
</ul>
<p>GAN的原本损失函数为</p>
<script type="math/tex; mode=display">
E_{z \in p_z(z)}[log(1-D(G(z)))]</script><p>但是这样导致了如果D太好了G则训练不到有效的梯度，G太好了D又训练不到有效的梯度</p>
<p>所以WGAN的损失函数改为了，在improve WGAN中还加入了gradient penalty</p>
<script type="math/tex; mode=display">
E_{z\in p_z(z)}[-logD(G(z))] = KL(P_g||P_{data})-2JS(P_{data}||P_g)+\lambda gp</script><p>WGAN理论上给出了GAN训练不稳定的原因，即交叉熵（JS散度）不适合衡量具有不相交部分的分布之间的距离，转而使用wassertein距离去衡量生成数据分布和真实数据分布之间的距离，理论上解决了训练不稳定的问题。</p>
<p>​    WGAN相对于DCGAN，WGAN虽然收敛时间更长但是更稳定，所以对于更复杂网络来说更倾向于WGAN，比如使用resnet可以达到更好的结果。</p>
<h3 id="code"><a href="#code" class="headerlink" title="code"></a>code</h3><p><em>generator里的反卷积参数必须最后要计算结果能吻合Discriminator的input_shape</em></p>
<p>因为要在batchnorm后面做激活所以不能像之前一样在卷积层里面激活。</p>
<p>这是我自己的wgan跑3000个epoch后的结果，可以明显看出学习到了头发和眼睛(相比之下别人调的参太牛了)</p>
<p><img src= "/img/lazyload.svg" data-src="https://cdn.jsdelivr.net/gh/dummerchen/My_Image_Bed01@master/img/20210227002207.jpg" alt="wg_img_3400"></p>
<p>数据集kaggle上随便找<del>啊，kaggle真香，各方意义上</del>，</p>
<p>龙书里面的提到的数据集在这里<a target="_blank" rel="noopener" href="https://pan.baidu.com/s/1Yn53uxFLCbja13_6Ay44MA">https://pan.baidu.com/s/1Yn53uxFLCbja13_6Ay44MA</a> </p>
<p>数据集来源在<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/24767059">这里</a>,我开始没看issue没找到这个数据集，爬到一半才看到😓，</p>
<p>我爬的数据在<a target="_blank" rel="noopener" href="https://pan.baidu.com/s/1JsUHx_1blY6pGx0DQfE0nQ">https://pan.baidu.com/s/1JsUHx_1blY6pGx0DQfE0nQ</a> 提取码：3621 （只有三万张图片…</p>
<p>我写的gan参数太差了，看龙书说跑3万次似乎能得到比较好的效果？算了直接上别人已经调好参的WGAN代码吧，知乎那个调好参的DCGAN太猛了，300epoch居然就成型了orz（虽然我没跑</p>
<h3 id="train函数"><a href="#train函数" class="headerlink" title="train函数"></a>train函数</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.environ[<span class="string">&#x27;TF_CPP_MIN_LOG_LEVEL&#x27;</span>]=<span class="string">&#x27;2&#x27;</span></span><br><span class="line"><span class="keyword">import</span> glob</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib <span class="keyword">as</span> mpl</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">import</span> dataset</span><br><span class="line"><span class="keyword">import</span>  tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span>    tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span>    tensorflow.keras <span class="keyword">import</span> layers</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Generator</span>(<span class="params">keras.Model</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Generator, self).__init__()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># z: [b, 100] =&gt; [b, 3*3*512] =&gt; [b, 3, 3, 512] =&gt; [b, 64, 64, 3]</span></span><br><span class="line">        self.fc = layers.Dense(<span class="number">3</span>*<span class="number">3</span>*<span class="number">512</span>)</span><br><span class="line"></span><br><span class="line">        self.conv1 = layers.Conv2DTranspose(<span class="number">256</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="string">&#x27;valid&#x27;</span>)</span><br><span class="line">        self.bn1 = layers.BatchNormalization()</span><br><span class="line"></span><br><span class="line">        self.conv2 = layers.Conv2DTranspose(<span class="number">128</span>, <span class="number">5</span>, <span class="number">2</span>, <span class="string">&#x27;valid&#x27;</span>)</span><br><span class="line">        self.bn2 = layers.BatchNormalization()</span><br><span class="line"></span><br><span class="line">        self.conv3 = layers.Conv2DTranspose(<span class="number">3</span>, <span class="number">4</span>, <span class="number">3</span>, <span class="string">&#x27;valid&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self, inputs, training=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="comment"># [z, 100] =&gt; [z, 3*3*512]</span></span><br><span class="line">        x = self.fc(inputs)</span><br><span class="line">        x = tf.reshape(x, [-<span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">512</span>])</span><br><span class="line">        x = tf.nn.leaky_relu(x)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#</span></span><br><span class="line">        x = tf.nn.leaky_relu(self.bn1(self.conv1(x), training=training))</span><br><span class="line">        x = tf.nn.leaky_relu(self.bn2(self.conv2(x), training=training))</span><br><span class="line">        x = self.conv3(x)</span><br><span class="line">        x = tf.tanh(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Discriminator</span>(<span class="params">keras.Model</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Discriminator, self).__init__()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># [b, 64, 64, 3] =&gt; [b, 1]</span></span><br><span class="line">        self.conv1 = layers.Conv2D(<span class="number">64</span>, <span class="number">5</span>, <span class="number">3</span>, <span class="string">&#x27;valid&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        self.conv2 = layers.Conv2D(<span class="number">128</span>, <span class="number">5</span>, <span class="number">3</span>, <span class="string">&#x27;valid&#x27;</span>)</span><br><span class="line">        self.bn2 = layers.BatchNormalization()</span><br><span class="line"></span><br><span class="line">        self.conv3 = layers.Conv2D(<span class="number">256</span>, <span class="number">5</span>, <span class="number">3</span>, <span class="string">&#x27;valid&#x27;</span>)</span><br><span class="line">        self.bn3 = layers.BatchNormalization()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># [b, h, w ,c] =&gt; [b, -1]</span></span><br><span class="line">        self.flatten = layers.Flatten()</span><br><span class="line">        self.fc = layers.Dense(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self, inputs, training=<span class="literal">None</span></span>):</span></span><br><span class="line"></span><br><span class="line">        x = tf.nn.leaky_relu(self.conv1(inputs))</span><br><span class="line">        x = tf.nn.leaky_relu(self.bn2(self.conv2(x), training=training))</span><br><span class="line">        x = tf.nn.leaky_relu(self.bn3(self.conv3(x), training=training))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># [b, h, w, c] =&gt; [b, -1]</span></span><br><span class="line">        x = self.flatten(x)</span><br><span class="line">        <span class="comment"># [b, -1] =&gt; [b, 1]</span></span><br><span class="line">        logits = self.fc(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> logits</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save_result</span>(<span class="params">val_out, val_block_size, image_path, color_mode</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">preprocess</span>(<span class="params">img</span>):</span></span><br><span class="line">        img = ((img + <span class="number">1.0</span>) * <span class="number">127.5</span>).astype(np.uint8)</span><br><span class="line">        <span class="comment"># img = img.astype(np.uint8)</span></span><br><span class="line">        <span class="keyword">return</span> img</span><br><span class="line"></span><br><span class="line">    preprocesed = preprocess(val_out)</span><br><span class="line">    final_image = np.array([])</span><br><span class="line">    single_row = np.array([])</span><br><span class="line">    <span class="keyword">for</span> b <span class="keyword">in</span> <span class="built_in">range</span>(val_out.shape[<span class="number">0</span>]):</span><br><span class="line">        <span class="comment"># concat image into a row</span></span><br><span class="line">        <span class="keyword">if</span> single_row.size == <span class="number">0</span>:</span><br><span class="line">            single_row = preprocesed[b, :, :, :]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            single_row = np.concatenate((single_row, preprocesed[b, :, :, :]), axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># concat image row to final_image</span></span><br><span class="line">        <span class="keyword">if</span> (b+<span class="number">1</span>) % val_block_size == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">if</span> final_image.size == <span class="number">0</span>:</span><br><span class="line">                final_image = single_row</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                final_image = np.concatenate((final_image, single_row), axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># reset single row</span></span><br><span class="line">            single_row = np.array([])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> final_image.shape[<span class="number">2</span>] == <span class="number">1</span>:</span><br><span class="line">        final_image = np.squeeze(final_image, axis=<span class="number">2</span>) </span><br><span class="line">    Image.fromarray(final_image).save(image_path)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">celoss_ones</span>(<span class="params">logits</span>):</span></span><br><span class="line">   	<span class="keyword">return</span> - tf.reduce_mean(logits)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">celoss_zeros</span>(<span class="params">logits</span>):</span></span><br><span class="line">    <span class="keyword">return</span> tf.reduce_mean(logits)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gradient_penalty</span>(<span class="params">discriminator, batch_x, fake_image</span>):</span></span><br><span class="line"></span><br><span class="line">    batchsz = batch_x.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># [b, h, w, c]</span></span><br><span class="line">    t = tf.random.uniform([batchsz, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">    <span class="comment"># [b, 1, 1, 1] =&gt; [b, h, w, c]</span></span><br><span class="line">    t = tf.broadcast_to(t, batch_x.shape)</span><br><span class="line"></span><br><span class="line">    interplate = t * batch_x + (<span class="number">1</span> - t) * fake_image</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">        tape.watch([interplate])</span><br><span class="line">        d_interplote_logits = discriminator(interplate, training=<span class="literal">True</span>)</span><br><span class="line">    grads = tape.gradient(d_interplote_logits, interplate)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># grads:[b, h, w, c] =&gt; [b, -1]</span></span><br><span class="line">    grads = tf.reshape(grads, [grads.shape[<span class="number">0</span>], -<span class="number">1</span>])</span><br><span class="line">    gp = tf.norm(grads, axis=<span class="number">1</span>) <span class="comment">#[b]</span></span><br><span class="line">    gp = tf.reduce_mean( (gp-<span class="number">1</span>)**<span class="number">2</span> )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> gp</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">d_loss_fn</span>(<span class="params">generator, discriminator, batch_z, batch_x, is_training</span>):</span></span><br><span class="line">    <span class="comment"># 1. treat real image as real</span></span><br><span class="line">    <span class="comment"># 2. treat generated image as fake</span></span><br><span class="line">    fake_image = generator(batch_z, is_training)</span><br><span class="line">    d_fake_logits = discriminator(fake_image, is_training)</span><br><span class="line">    d_real_logits = discriminator(batch_x, is_training)</span><br><span class="line"></span><br><span class="line">    d_loss_real = celoss_ones(d_real_logits)</span><br><span class="line">    d_loss_fake = celoss_zeros(d_fake_logits)</span><br><span class="line">    gp = gradient_penalty(discriminator, batch_x, fake_image)</span><br><span class="line"></span><br><span class="line">    loss = d_loss_real + d_loss_fake + <span class="number">10.</span> * gp</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> loss, gp</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">g_loss_fn</span>(<span class="params">generator, discriminator, batch_z, is_training</span>):</span></span><br><span class="line"></span><br><span class="line">    fake_image = generator(batch_z, is_training)</span><br><span class="line">    d_fake_logits = discriminator(fake_image, is_training)</span><br><span class="line">    loss = celoss_ones(d_fake_logits)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> loss</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line"></span><br><span class="line">    tf.random.set_seed(<span class="number">233</span>)</span><br><span class="line">    np.random.seed(<span class="number">233</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># hyper parameters</span></span><br><span class="line">    z_dim = <span class="number">100</span></span><br><span class="line">    epochs = <span class="number">3000000</span></span><br><span class="line">    batch_size = <span class="number">512</span></span><br><span class="line">    learning_rate = <span class="number">0.0005</span></span><br><span class="line">    is_training = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    img_path = glob.glob(<span class="string">&#x27;.\animefacedataset\images\*.jpg&#x27;</span>)</span><br><span class="line">    <span class="keyword">assert</span> <span class="built_in">len</span>(img_path) &gt; <span class="number">0</span></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    dataset, img_shape, _ = make_anime_dataset(img_path, batch_size)</span><br><span class="line">    <span class="built_in">print</span>(dataset, img_shape)</span><br><span class="line">    sample = <span class="built_in">next</span>(<span class="built_in">iter</span>(dataset))</span><br><span class="line">    <span class="built_in">print</span>(sample.shape, tf.reduce_max(sample).numpy(),</span><br><span class="line">          tf.reduce_min(sample).numpy())</span><br><span class="line">    dataset = dataset.repeat()</span><br><span class="line">    db_iter = <span class="built_in">iter</span>(dataset)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    generator = Generator() </span><br><span class="line">    generator.build(input_shape = (<span class="literal">None</span>, z_dim))</span><br><span class="line">    discriminator = Discriminator()</span><br><span class="line">    discriminator.build(input_shape=(<span class="literal">None</span>, <span class="number">64</span>, <span class="number">64</span>, <span class="number">3</span>))</span><br><span class="line">    z_sample = tf.random.normal([<span class="number">100</span>, z_dim])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    g_optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, beta_1=<span class="number">0.5</span>)</span><br><span class="line">    d_optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, beta_1=<span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">		<span class="comment"># 训练5次discriminator 再训练一次generator！！！不然就会出现像我一样的图</span></span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">            batch_z = tf.random.normal([batch_size, z_dim])</span><br><span class="line">            batch_x = <span class="built_in">next</span>(db_iter)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># train D</span></span><br><span class="line">            <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">                d_loss, gp = d_loss_fn(generator, discriminator, batch_z, batch_x, is_training)</span><br><span class="line">            grads = tape.gradient(d_loss, discriminator.trainable_variables)</span><br><span class="line">            d_optimizer.apply_gradients(<span class="built_in">zip</span>(grads, discriminator.trainable_variables))</span><br><span class="line">        </span><br><span class="line">        batch_z = tf.random.normal([batch_size, z_dim])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">            g_loss = g_loss_fn(generator, discriminator, batch_z, is_training)</span><br><span class="line">        grads = tape.gradient(g_loss, generator.trainable_variables)</span><br><span class="line">        g_optimizer.apply_gradients(<span class="built_in">zip</span>(grads, generator.trainable_variables))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> epoch % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(epoch, <span class="string">&#x27;d-loss:&#x27;</span>,<span class="built_in">float</span>(d_loss), <span class="string">&#x27;g-loss:&#x27;</span>, <span class="built_in">float</span>(g_loss),</span><br><span class="line">                  <span class="string">&#x27;gp:&#x27;</span>, <span class="built_in">float</span>(gp))</span><br><span class="line"></span><br><span class="line">            z = tf.random.normal([<span class="number">100</span>, z_dim])</span><br><span class="line">            fake_image = generator(z, training=<span class="literal">False</span>)</span><br><span class="line">            img_path = os.path.join(<span class="string">&#x27;images&#x27;</span>, <span class="string">&#x27;wgan-%d.png&#x27;</span>%epoch)</span><br><span class="line">            save_result(fake_image.numpy(), <span class="number">10</span>, img_path, color_mode=<span class="string">&#x27;P&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>
<h3 id="datasetload-函数"><a href="#datasetload-函数" class="headerlink" title="datasetload 函数"></a>datasetload 函数</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> multiprocessing</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">make_anime_dataset</span>(<span class="params">img_paths, batch_size, resize=<span class="number">64</span>, drop_remainder=<span class="literal">True</span>, shuffle=<span class="literal">True</span>, repeat=<span class="number">1</span></span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># @tf.function</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_map_fn</span>(<span class="params">img</span>):</span></span><br><span class="line">        img = tf.image.resize(img, [resize, resize])</span><br><span class="line">        <span class="comment"># img = tf.image.random_crop(img,[resize, resize])</span></span><br><span class="line">        <span class="comment"># img = tf.image.random_flip_left_right(img)</span></span><br><span class="line">        <span class="comment"># img = tf.image.random_flip_up_down(img)</span></span><br><span class="line">        img = tf.clip_by_value(img, <span class="number">0</span>, <span class="number">255</span>)</span><br><span class="line">        img = img / <span class="number">127.5</span> - <span class="number">1</span> <span class="comment">#-1~1</span></span><br><span class="line">        <span class="keyword">return</span> img</span><br><span class="line"></span><br><span class="line">    dataset = disk_image_batch_dataset(img_paths,</span><br><span class="line">                                          batch_size,</span><br><span class="line">                                          drop_remainder=drop_remainder,</span><br><span class="line">                                          map_fn=_map_fn,</span><br><span class="line">                                          shuffle=shuffle,</span><br><span class="line">                                          repeat=repeat)</span><br><span class="line">    img_shape = (resize, resize, <span class="number">3</span>)</span><br><span class="line">    len_dataset = <span class="built_in">len</span>(img_paths) // batch_size</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> dataset, img_shape, len_dataset</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">batch_dataset</span>(<span class="params">dataset,</span></span></span><br><span class="line"><span class="params"><span class="function">                  batch_size,</span></span></span><br><span class="line"><span class="params"><span class="function">                  drop_remainder=<span class="literal">True</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                  n_prefetch_batch=<span class="number">1</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                  filter_fn=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                  map_fn=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                  n_map_threads=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                  filter_after_map=<span class="literal">False</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                  shuffle=<span class="literal">True</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                  shuffle_buffer_size=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                  repeat=<span class="literal">None</span></span>):</span></span><br><span class="line">    <span class="comment"># set defaults</span></span><br><span class="line">    <span class="keyword">if</span> n_map_threads <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        n_map_threads = multiprocessing.cpu_count()</span><br><span class="line">    <span class="keyword">if</span> shuffle <span class="keyword">and</span> shuffle_buffer_size <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        shuffle_buffer_size = <span class="built_in">max</span>(batch_size * <span class="number">128</span>, <span class="number">2048</span>)  <span class="comment"># set the minimum buffer size as 2048</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># [*] it is efficient to conduct `shuffle` before `map`/`filter` because `map`/`filter` is sometimes costly</span></span><br><span class="line">    <span class="keyword">if</span> shuffle:</span><br><span class="line">        dataset = dataset.shuffle(shuffle_buffer_size)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> filter_after_map:</span><br><span class="line">        <span class="keyword">if</span> filter_fn:</span><br><span class="line">            dataset = dataset.<span class="built_in">filter</span>(filter_fn)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> map_fn:</span><br><span class="line">            dataset = dataset.<span class="built_in">map</span>(map_fn, num_parallel_calls=n_map_threads)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">else</span>:  <span class="comment"># [*] this is slower</span></span><br><span class="line">        <span class="keyword">if</span> map_fn:</span><br><span class="line">            dataset = dataset.<span class="built_in">map</span>(map_fn, num_parallel_calls=n_map_threads)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> filter_fn:</span><br><span class="line">            dataset = dataset.<span class="built_in">filter</span>(filter_fn)</span><br><span class="line"></span><br><span class="line">    dataset = dataset.batch(batch_size, drop_remainder=drop_remainder)</span><br><span class="line"></span><br><span class="line">    dataset = dataset.repeat(repeat).prefetch(n_prefetch_batch)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> dataset</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">memory_data_batch_dataset</span>(<span class="params">memory_data,</span></span></span><br><span class="line"><span class="params"><span class="function">                              batch_size,</span></span></span><br><span class="line"><span class="params"><span class="function">                              drop_remainder=<span class="literal">True</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                              n_prefetch_batch=<span class="number">1</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                              filter_fn=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                              map_fn=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                              n_map_threads=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                              filter_after_map=<span class="literal">False</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                              shuffle=<span class="literal">True</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                              shuffle_buffer_size=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                              repeat=<span class="literal">None</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Batch dataset of memory data.</span></span><br><span class="line"><span class="string">    Parameters</span></span><br><span class="line"><span class="string">    ----------</span></span><br><span class="line"><span class="string">    memory_data : nested structure of tensors/ndarrays/lists</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    dataset = tf.data.Dataset.from_tensor_slices(memory_data)</span><br><span class="line">    dataset = batch_dataset(dataset,</span><br><span class="line">                            batch_size,</span><br><span class="line">                            drop_remainder=drop_remainder,</span><br><span class="line">                            n_prefetch_batch=n_prefetch_batch,</span><br><span class="line">                            filter_fn=filter_fn,</span><br><span class="line">                            map_fn=map_fn,</span><br><span class="line">                            n_map_threads=n_map_threads,</span><br><span class="line">                            filter_after_map=filter_after_map,</span><br><span class="line">                            shuffle=shuffle,</span><br><span class="line">                            shuffle_buffer_size=shuffle_buffer_size,</span><br><span class="line">                            repeat=repeat)</span><br><span class="line">    <span class="keyword">return</span> dataset</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">disk_image_batch_dataset</span>(<span class="params">img_paths,</span></span></span><br><span class="line"><span class="params"><span class="function">                             batch_size,</span></span></span><br><span class="line"><span class="params"><span class="function">                             labels=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                             drop_remainder=<span class="literal">True</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                             n_prefetch_batch=<span class="number">1</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                             filter_fn=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                             map_fn=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                             n_map_threads=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                             filter_after_map=<span class="literal">False</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                             shuffle=<span class="literal">True</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                             shuffle_buffer_size=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                             repeat=<span class="literal">None</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Batch dataset of disk image for PNG and JPEG.</span></span><br><span class="line"><span class="string">    Parameters</span></span><br><span class="line"><span class="string">    ----------</span></span><br><span class="line"><span class="string">        img_paths : 1d-tensor/ndarray/list of str</span></span><br><span class="line"><span class="string">        labels : nested structure of tensors/ndarrays/lists</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> labels <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        memory_data = img_paths</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        memory_data = (img_paths, labels)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_fn</span>(<span class="params">path, *label</span>):</span></span><br><span class="line">        img = tf.io.read_file(path)</span><br><span class="line">        img = tf.image.decode_jpeg(img, channels=<span class="number">3</span>)  <span class="comment"># fix channels to 3</span></span><br><span class="line">        <span class="keyword">return</span> (img,) + label</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> map_fn:  <span class="comment"># fuse `map_fn` and `parse_fn`</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">map_fn_</span>(<span class="params">*args</span>):</span></span><br><span class="line">            <span class="keyword">return</span> map_fn(*parse_fn(*args))</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        map_fn_ = parse_fn</span><br><span class="line"></span><br><span class="line">    dataset = memory_data_batch_dataset(memory_data,</span><br><span class="line">                                        batch_size,</span><br><span class="line">                                        drop_remainder=drop_remainder,</span><br><span class="line">                                        n_prefetch_batch=n_prefetch_batch,</span><br><span class="line">                                        filter_fn=filter_fn,</span><br><span class="line">                                        map_fn=map_fn_,</span><br><span class="line">                                        n_map_threads=n_map_threads,</span><br><span class="line">                                        filter_after_map=filter_after_map,</span><br><span class="line">                                        shuffle=shuffle,</span><br><span class="line">                                        shuffle_buffer_size=shuffle_buffer_size,</span><br><span class="line">                                        repeat=repeat)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> dataset</span><br></pre></td></tr></table></figure>
<p>1000epoch之后是这样</p>
<p><img src= "/img/lazyload.svg" data-src="https://cdn.jsdelivr.net/gh/dummerchen/My_Image_Bed01@master/img/20210227110619.png" alt="wgansample-1000"></p>
<h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>​    本来是想每一个经典网络都详细写的，但是感觉这样会导致太专业全是公式也不会有人去仔细看 <del>其实是我不会。</del>结果变成了现在这种类似板子的东西。<del>水博客才是原动力</del></p>
<p>​    终于体会到电脑的苦了，cpu占用率<em>99%</em> 还要开多线程同时爬图片…（虽然现在字都显示不出来了</p>
<p>这里就随便总结一下学习的经验：</p>
<h3 id="代码方面"><a href="#代码方面" class="headerlink" title="代码方面"></a>代码方面</h3><ul>
<li>keras.build(inputs_shape)：这里最好是使用tuple形式表示不然会报奇怪的错，tensorflow和pytorch不同这方面更加严格。</li>
<li>tf.losses： 这个模块里的函数大小写不同功能也是不同的，<del>具体可以看官网</del>，如果用complie建议用大写的函数，自定义loss使用小写的函数</li>
<li>sigmod和softmax： 当’分类’事物不完全相互独立可以使用sigmod否则softmax，softmax一定要onehot </li>
<li>model.save：这个因为保存了网络结构只能用在纯自定义网络里，继承类是不行的。</li>
<li>layers.BatchNormalization:：这个函数有一个trainable参数,train=True|None，test=False|0,具体可以看源码说明，但是千万要设置正确<a target="_blank" rel="noopener" href="http://www.cainiaoxueyuan.com/suanfa/11644.html">原因可参考这里</a></li>
<li>layers.Flatten与Dense：flatten只是单纯的reshape维度是固定的，Dense还作了一次全连接</li>
</ul>
<h3 id="网络等方面"><a href="#网络等方面" class="headerlink" title="网络等方面"></a>网络等方面</h3><p>​    可以从代码中看出现有的几种网络构建格式。当初我也纠结了许多，最后还是准备使用gan网络的格式，毕竟框架好用是好用，但这是牺牲‘自由’换来的，对后期自主构建网络可能会起到反效果。<del>每个人喜好不同，也不用太参考我的建议。</del></p>
<p>​    k折验证等trick是视频里没有讲的（视频参考下面的学习资源），可以自己去看看相关trick。</p>
<h3 id="学习资源"><a href="#学习资源" class="headerlink" title="学习资源"></a>学习资源</h3><p><del>我才不是看到Gan可以随机生成老婆才想学Gan的</del></p>
<p>日月光华的《tensorflow入门学习与实战的》资源弄不到，可惜了免费课程讲的确实好就是太贵了。</p>
<p>就跟着<a target="_blank" rel="noopener" href="https://github.com/dragen1860/Deep-Learning-with-TensorFlow-book">龙书</a>学Gan顺便复习了一遍经典网络，顺便附上<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1tE411Z78A?p=3">李宏毅讲解的Gan网络</a>（每次看完这种视频都感觉概率论白学了，建议李宏毅的可以先看一半再看龙书。</p>
<p>emmm，再附上别人整理的<a target="_blank" rel="noopener" href="https://leemeng.tw/deep-learning-resources.html">深度学习路线</a>吧 <del>应该不会有人看的完</del></p>
</article><div class="essaySuffix-box"> <div class="essaySuffix-box-left"> <img src="https://cdn.jsdelivr.net/gh/dummerchen/cdn@master/img/custom/avatar.jpg" onerror="onerror=null;src='https://cdn.jsdelivr.net/gh/dummerchen/cdn/img/other/default_avatar.jpg'" alt="avatar"></div><div class="essaySuffix-box-right"> <span class="essaySuffix-right-title">本文作者：</span><strong> <span><a href="https:dummerfu.top" target="_blank" one-link-mark="yes">dummerfu</a></span></strong><br><span class="essaySuffix-right-title">本文链接：</span><a href="https://dummerfu.top/p/35344.html">https://dummerfu.top/p/35344.html</a><br><span class="essaySuffix-right-title">版权声明: </span>
本博客所有文章除特别声明外，均采用<a rel="noopener" target="_blank" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0许可协议</a>
转载请注明出处！</div></div><div class="tag_share"><div class="post_share"></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/p/60871.html"><img class="prev-cover" data-src="https://cdn.jsdelivr.net/gh/dummerchen/cdn@master/img/cover/4.jpg" src="/img/lazyload.svg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">北斗文献综述</div></div></a></div><div class="next-post pull-right"><a href="/p/52642.html"><img class="next-cover" data-src="/img/lazyload.svg" src="/img/lazyload.svg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">线程与进程</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span> Related Articles</span></div><div class="relatedPosts-list"><div><a href="/p/40721.html" title="Logistic回归"><img class="cover" data-src="https://cdn.jsdelivr.net/gh/dummerchen/cdn@master/img/cover/5.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-07-27</div><div class="title">Logistic回归</div></div></a></div><div><a href="/p/3028.html" title="YoloV3 介绍"><img class="cover" data-src="https://cdn.jsdelivr.net/gh/dummerchen/cdn@master/img/cover/5.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-06-01</div><div class="title">YoloV3 介绍</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> Comment</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-info-avatar is-center"><img class="avatar-img" data-src="https://cdn.jsdelivr.net/gh/dummerchen/cdn@master/img/custom/avatar.jpg" src="/img/lazyload.svg" onerror="this.onerror=null;this.src='https://cdn.jsdelivr.net/gh/dummerchen/cdn/img/other/default_avatar.jpg'" alt="avatar"/><div class="author-info__name">dummerfu</div><div class="author-info__description"></div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">45</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">Tags</div><div class="length-num">18</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">Categories</div><div class="length-num">6</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/dummerchen"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon faa-parent animated-hover" href="https://github.com/dummerchen" target="_blank" title="Github"><svg class="icon faa-tada" aria-hidden="true"><use xlink:href="#icon-rat"></use></svg></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>Announcement</span></div><div class="announcement_content">本博客由博客园<a href="https://www.cnblogs.com/cherrypill/" target=" _blank">cherrypill</a>迁移</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Catalog</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%89%8D%E8%A8%80"><span class="toc-number">1.</span> <span class="toc-text">前言</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E4%BF%9D%E5%AD%98"><span class="toc-number">2.</span> <span class="toc-text">模型保存</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Save-model%E6%A0%BC%E5%BC%8F"><span class="toc-number">2.1.</span> <span class="toc-text">Save_model格式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#H5%E6%A0%BC%E5%BC%8F"><span class="toc-number">2.2.</span> <span class="toc-text">H5格式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#checkpoints"><span class="toc-number">2.3.</span> <span class="toc-text">　checkpoints</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BF%9D%E5%AD%98%E6%97%B6%E9%99%84%E5%B8%A6%E7%AD%BE%E5%90%8D"><span class="toc-number">2.4.</span> <span class="toc-text">保存时附带签名</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#ResNet"><span class="toc-number">3.</span> <span class="toc-text">ResNet</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%89%8B%E5%86%99%E5%AE%9E%E7%8E%B0"><span class="toc-number">3.1.</span> <span class="toc-text">手写实现</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%87%AA%E5%B8%A6api%E5%AE%9E%E7%8E%B0"><span class="toc-number">3.2.</span> <span class="toc-text">自带api实现</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#VGG"><span class="toc-number">4.</span> <span class="toc-text">VGG</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#LSTM"><span class="toc-number">5.</span> <span class="toc-text">LSTM</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#AutoEncoder-VAE"><span class="toc-number">6.</span> <span class="toc-text">AutoEncoder|VAE</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Gan"><span class="toc-number">7.</span> <span class="toc-text">Gan</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#WGAN%E5%8E%9F%E7%90%86"><span class="toc-number">7.1.</span> <span class="toc-text">WGAN原理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#code"><span class="toc-number">7.2.</span> <span class="toc-text">code</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#train%E5%87%BD%E6%95%B0"><span class="toc-number">7.3.</span> <span class="toc-text">train函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#datasetload-%E5%87%BD%E6%95%B0"><span class="toc-number">7.4.</span> <span class="toc-text">datasetload 函数</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%90%8E%E8%AE%B0"><span class="toc-number">8.</span> <span class="toc-text">后记</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E6%96%B9%E9%9D%A2"><span class="toc-number">8.1.</span> <span class="toc-text">代码方面</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BD%91%E7%BB%9C%E7%AD%89%E6%96%B9%E9%9D%A2"><span class="toc-number">8.2.</span> <span class="toc-text">网络等方面</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%BA%90"><span class="toc-number">8.3.</span> <span class="toc-text">学习资源</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/p/49081.html" title="【论文复现】Restormer"><img data-src="https://cdn.jsdelivr.net/gh/dummerchen/My_Image_Bed03@image_bed_001/img/20211212145136.jpg" src="/img/lazyload.svg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【论文复现】Restormer"/></a><div class="content"><a class="title" href="/p/49081.html" title="【论文复现】Restormer">【论文复现】Restormer</a><time datetime="2022-07-30T00:00:00.000Z" title="Created 2022-07-30 00:00:00">2022-07-30</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/p/3640.html" title="【论文复现】SwinIR"><img data-src="https://cdn.jsdelivr.net/gh/dummerchen/My_Image_Bed03@image_bed_001/img/20211212145155.jpg" src="/img/lazyload.svg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【论文复现】SwinIR"/></a><div class="content"><a class="title" href="/p/3640.html" title="【论文复现】SwinIR">【论文复现】SwinIR</a><time datetime="2022-07-30T00:00:00.000Z" title="Created 2022-07-30 00:00:00">2022-07-30</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/p/63048.html" title="图像理解与计算机视觉笔记"><img data-src="https://cdn.jsdelivr.net/gh/dummerchen/My_Image_Bed03@image_bed_001/img/20211212145212.jpg" src="/img/lazyload.svg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="图像理解与计算机视觉笔记"/></a><div class="content"><a class="title" href="/p/63048.html" title="图像理解与计算机视觉笔记">图像理解与计算机视觉笔记</a><time datetime="2022-06-18T00:00:00.000Z" title="Created 2022-06-18 00:00:00">2022-06-18</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/p/42559.html" title="代码审计工具"><img data-src="https://cdn.jsdelivr.net/gh/dummerchen/My_Image_Bed03@image_bed_001/img/20211212145136.jpg" src="/img/lazyload.svg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="代码审计工具"/></a><div class="content"><a class="title" href="/p/42559.html" title="代码审计工具">代码审计工具</a><time datetime="2022-05-20T00:00:00.000Z" title="Created 2022-05-20 00:00:00">2022-05-20</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/p/44311.html" title="【论文复现】卷积网络可视化Grad-cam和Guide backpropagation"><img data-src="https://cdn.jsdelivr.net/gh/dummerchen/My_Image_Bed03@image_bed_001/img/20211212120605.jpg" src="/img/lazyload.svg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【论文复现】卷积网络可视化Grad-cam和Guide backpropagation"/></a><div class="content"><a class="title" href="/p/44311.html" title="【论文复现】卷积网络可视化Grad-cam和Guide backpropagation">【论文复现】卷积网络可视化Grad-cam和Guide backpropagation</a><time datetime="2022-05-16T00:00:00.000Z" title="Created 2022-05-16 00:00:00">2022-05-16</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2022 By dummerfu</div><p id="ghbdages"><a class="github-badge" target="_blank" href="https://hexo.io/" style="margin-inline:5px"><img src="https://img.shields.io/badge/Frame-Hexo-blue?style=flat&amp;logo=hexo"/></a><a class="github-badge" target="_blank" href="https://butterfly.js.org/" style="margin-inline:5px"><img src="https://img.shields.io/badge/Theme-Butterfly-6513df?style=flat&amp;logo=bitdefender"/></a><a class="github-badge" target="_blank" href="https://www.jsdelivr.com/" style="margin-inline:5px"><img src="https://img.shields.io/badge/CDN-jsDelivr-orange?style=flat&amp;logo=jsDelivr"/></a><a class="github-badge" target="_blank" href="https://github.com/" style="margin-inline:5px"><img src="https://img.shields.io/badge/Source-Github-d021d6?style=flat&amp;logo=GitHub"/></a></p></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="Toggle Between Traditional Chinese And Simplified Chinese">简</button><button id="darkmode" type="button" title="Toggle Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="Scroll To Comments"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">Local search</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/vue@2.6.11"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script async="async">var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',preloader.endLoading())
setTimeout(function(){preloader.endLoading();}, 5000);</script></div><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    loader: {
      source: {
        '[tex]/amsCd': '[tex]/amscd'
      }
    },
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        addClass: [200,() => {
          document.querySelectorAll('mjx-container:not([display=\'true\']').forEach( node => {
            const target = node.parentNode
            if (!target.classList.contains('has-jax')) {
              target.classList.add('mathjax-overflow')
            }
          })
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/contrib/copy-tex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/contrib/copy-tex.css"><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', '', 'katex-wrap')
  })
})()</script><script>(()=>{
  const $countDom = document.getElementById('twikoo-count')
  const init = () => {
    twikoo.init(Object.assign({
      el: '#twikoo-wrap',
      envId: 'twikoo-8g53l3ue41b208dc',
      region: 'ap-shanghai'
    }, null))
  }

  const getCount = () => {
    twikoo.getCommentsCount({
      envId: 'twikoo-8g53l3ue41b208dc',
      region: 'ap-shanghai',
      urls: [window.location.pathname],
      includeReply: false
    }).then(function (res) {
      $countDom.innerText = res[0].count
    }).catch(function (err) {
      console.error(err);
    });
  }

  const loadTwikoo = (bool = false) => {
    if (typeof twikoo === 'object') {
      init()
      bool && $countDom && setTimeout(getCount,0)
    } else {
      getScript('https://cdn.jsdelivr.net/npm/twikoo@1.4.15/dist/twikoo.all.min.js').then(()=> {
        init()
        bool && $countDom && setTimeout(getCount,0)
      })
    }
  }

  if ('Twikoo' === 'Twikoo' || !true) {
    if (true) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo(true)
  } else {
    window.loadOtherComment = () => {
      loadTwikoo()
    }
  }
})()</script><script>var gitcalendar = new Vue({
  el: '#gitcalendar',
  data: {
    simplemode: false, 
    user: 'dummerchen',
    fixed: 'fixed',
    px: 'px',
    x: '',
    y: '',
    span1: '',
    span2: '',
    month: ['一月', '二月', '三月', '四月', '五月', '六月', '七月', '八月', '九月', '十月', '十一月', '十二月'],
    monthchange: [],
    oneyearbeforeday: '',
    thisday: '',
    amonthago: '',
    aweekago: '',
    weekdatacore: 0,
    datacore: 0,
    total: 0,
    datadate: '',
    data: [],
    positionplusdata: [],
    firstweek: [],
    lastweek: [],
    beforeweek: [],
    thisweekdatacore: 0,
    mounthbeforeday: 0,
    mounthfirstindex: 0,
    crispedges: 'crispedges',
    thisdayindex: 0,
    amonthagoindex: 0,
    amonthagoweek: [],
    firstdate: [],
    first2date: [],
    montharrbefore: [],
    monthindex: 0,
    color: ['#e4dfd7', '#f9f4dc', '#f7e8aa', '#f7e8aa', '#f8df72', '#fcd217', '#fcc515', '#f28e16', '#fb8b05', '#d85916', '#f43e06']
  },
  methods: {
    selectStyle(data, event) {
      document.querySelector('.angle-wrapper').style.display = 'block'
      this.span1 = data.date;
      this.span2 = data.count;
      this.x = event.clientX - 100;
      this.y = event.clientY - 60
    },
    outStyle() {
      document.querySelector('.angle-wrapper').style.display = 'none'
    },
    thiscolor(x) {
      if (x === 0) {
        let i = parseInt(x / 2);
        return this.color[0]
      } else if (x < 2) {
        return this.color[1]
      } else if (x < 20) {
        let i = parseInt(x / 2);
        return this.color[i]
      } else {
        return this.color[9]
      }
    },
  }
});
var apiurl = 'github-calendar-api.vercel.app' ? 'https://github-calendar-api.vercel.app/api?' : 'https://githubapi.ryanchristian.dev/user/'
var githubapiurl = apiurl + gitcalendar.user;
//canvas绘图
function responsiveChart() {
  let c = document.getElementById("gitcanvas");
  if (c) {
    let cmessage = document.getElementById("gitmessage");
    let ctx = c.getContext("2d");
    c.width = document.getElementById("gitcalendarcanvasbox").offsetWidth;
    let linemaxwitdh = 0.96 * c.width / gitcalendar.data.length;
    c.height = 9 * linemaxwitdh;
    let lineminwitdh = 0.8 * linemaxwitdh;
    let setposition = {
      x: 0.02 * c.width,
      y: 0.025 * c.width
    };
    for (let week in gitcalendar.data) {
      weekdata = gitcalendar.data[week];
      for (let day in weekdata) {
        let dataitem = {
          date: "",
          count: "",
          x: 0,
          y: 0
        };
        gitcalendar.positionplusdata.push(dataitem);
        ctx.fillStyle = gitcalendar.thiscolor(weekdata[day].count);
        setposition.y = Math.round(setposition.y * 100) / 100;
        dataitem.date = weekdata[day].date;
        dataitem.count = weekdata[day].count;
        dataitem.x = setposition.x;
        dataitem.y = setposition.y;
        ctx.fillRect(setposition.x, setposition.y, lineminwitdh, lineminwitdh);
        setposition.y = setposition.y + linemaxwitdh
      };
      setposition.y = 0.025 * c.width;
      setposition.x = setposition.x + linemaxwitdh
    };
    ctx.font = "600  Arial";
    ctx.fillStyle = '#aaa';
    ctx.fillText("日", 0, 1.9 * linemaxwitdh);
    ctx.fillText("二", 0, 3.9 * linemaxwitdh);
    ctx.fillText("四", 0, 5.9 * linemaxwitdh);
    ctx.fillText("六", 0, 7.9 * linemaxwitdh);
    let monthindexlist = c.width / 24;
    for (let index in gitcalendar.monthchange) {
      ctx.fillText(gitcalendar.monthchange[index], monthindexlist, 0.7 * linemaxwitdh);
      monthindexlist = monthindexlist + c.width / 12
    };
    cmessage.onmousemove = function(event) {
      document.querySelector('.angle-wrapper').style.display = 'none'
    };
    c.onmousemove = function(event) {
      document.querySelector('.angle-wrapper').style.display = 'none'
      getMousePos(c, event);
    };

    function getMousePos(canvas, event) {
      var rect = canvas.getBoundingClientRect();
      var x = event.clientX - rect.left * (canvas.width / rect.width);
      var y = event.clientY - rect.top * (canvas.height / rect.height);
      //console.log("x:"+x+",y:"+y);
      for (let item of gitcalendar.positionplusdata) {
        let lenthx = x - item.x;
        let lenthy = y - item.y;
        //console.log(lenthx,lenthy);
        if (0 < lenthx && lenthx < lineminwitdh) {
          if (0 < lenthy && lenthy < lineminwitdh) {
            //console.log(item.date,item.count)
            document.querySelector('.angle-wrapper').style.display = 'block'
            gitcalendar.span1 = item.date;
            gitcalendar.span2 = item.count;
            gitcalendar.x = event.clientX - 100;
            gitcalendar.y = event.clientY - 60
          }
        }
        //if(0< x - item.x <lineminwitdh&&0< y - item.y <lineminwitdh){
        //console.log(item.count,item.date);
        //}
      }
    }
  }
}
//数据统计算法
function addlastmonth() {
  if (gitcalendar.thisdayindex === 0) {
    thisweekcore(52);
    thisweekcore(51);
    thisweekcore(50);
    thisweekcore(49);
    thisweekcore(48);
    gitcalendar.thisweekdatacore += gitcalendar.firstdate[6].count;
    gitcalendar.amonthago = gitcalendar.firstdate[6].date
  } else {
    thisweekcore(52);
    thisweekcore(51);
    thisweekcore(50);
    thisweekcore(49);
    thisweek2core();
    gitcalendar.amonthago = gitcalendar.first2date[gitcalendar.thisdayindex - 1].date
  }
};

function thisweek2core() {
  for (let i = gitcalendar.thisdayindex - 1; i < gitcalendar.first2date.length; i++) {
    gitcalendar.thisweekdatacore += gitcalendar.first2date[i].count
  }
};

function thisweekcore(index) {
  for (let item of gitcalendar.data[index]) {
    gitcalendar.thisweekdatacore += item.count
  }
};

function addlastweek() {
  for (let item of gitcalendar.lastweek) {
    gitcalendar.weekdatacore += item.count
  }
};

function addbeforeweek() {
  for (let i = gitcalendar.thisdayindex; i < gitcalendar.beforeweek.length; i++) {
    gitcalendar.weekdatacore += gitcalendar.beforeweek[i].count
  }
};

function addweek(data) {
  if (gitcalendar.thisdayindex === 6) {
    gitcalendar.aweekago = gitcalendar.lastweek[0].date;
    addlastweek()
  } else {
    lastweek = data.contributions[51];
    gitcalendar.aweekago = lastweek[gitcalendar.thisdayindex + 1].date;
    addlastweek();
    addbeforeweek()
  }
}

fetch(githubapiurl)
  .then(data => data.json())
  .then(data => {
    gitcalendar.data = data.contributions;
    gitcalendar.total = data.total;
    gitcalendar.first2date = gitcalendar.data[48];
    gitcalendar.firstdate = gitcalendar.data[47];
    gitcalendar.firstweek = data.contributions[0];
    gitcalendar.lastweek = data.contributions[52];
    gitcalendar.beforeweek = data.contributions[51];
    gitcalendar.thisdayindex = gitcalendar.lastweek.length - 1;
    gitcalendar.thisday = gitcalendar.lastweek[gitcalendar.thisdayindex].date;
    gitcalendar.oneyearbeforeday = gitcalendar.firstweek[0].date;
    gitcalendar.monthindex = gitcalendar.thisday.substring(5, 7) * 1;
    gitcalendar.montharrbefore = gitcalendar.month.splice(gitcalendar.monthindex, 12 - gitcalendar.monthindex);
    gitcalendar.monthchange = gitcalendar.montharrbefore.concat(gitcalendar.month);
    addweek(data);
    addlastmonth();
    responsiveChart();
  })
  .catch(function(error) {
    console.log(error);
  });

//手机版更换为svg绘制
if (document.getElementById("gitcalendarcanvasbox") && (document.getElementById("gitcalendarcanvasbox").offsetWidth < 500)) {
  gitcalendar.simplemode = false
}
//当改变窗口大小时重新绘制canvas
window.onresize = function() {
  if (gitcalendar.simplemode) responsiveChart()
}

//解决滚动滑轮时出现的标签显示
window.onscroll = function() {
  if (document.querySelector('.angle-wrapper')) {
    document.querySelector('.angle-wrapper').style.display = 'none'
  }
};</script></div><script defer src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script defer src="https://cdn.jsdelivr.net/npm/hexo-theme-volantis@latest/source/js/issues.min.js"></script><script src="/js/moments.js"></script><canvas class="fireworks" mobile="false"></canvas><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/fireworks.min.js"></script><div class="js-pjax"><script async="async">var arr = document.getElementsByClassName('recent-post-item');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__zoomIn');
    arr[i].setAttribute('data-wow-duration', '1s');
    arr[i].setAttribute('data-wow-delay', '0');
    arr[i].setAttribute('data-wow-offset', '0');
    arr[i].setAttribute('data-wow-iteration', '1');
  }</script><script async="async">var arr = document.getElementsByClassName('card-widget');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__zoomIn');
    arr[i].setAttribute('data-wow-duration', '');
    arr[i].setAttribute('data-wow-delay', '');
    arr[i].setAttribute('data-wow-offset', '');
    arr[i].setAttribute('data-wow-iteration', '');
  }</script></div><script defer="defer" src="https://cdn.jsdelivr.net/gh/graingert/wow@1.3.0/dist/wow.min.js"></script><script defer="defer" src="/js/custom/wow_init.js"></script><div class="app-refresh" id="app-refresh" style="position: fixed;top: -2.2rem;left: 0;right: 0;z-index: 99999;padding: 0 1rem;font-size: 15px;height: 2.2rem;transition: all 0.3s ease;"><div class="app-refresh-wrap" style=" display: flex;color: #fff;height: 100%;align-items: center;justify-content: center;"><label>✨ 有文章更新啦！ 👉</label><a href="javascript:void(0)" onclick="location.reload()"><span style="color: #fff;text-decoration: underline;cursor: pointer;">🍭查看新品🍬</span></a></div></div><script>if ('serviceWorker' in navigator) {
if (navigator.serviceWorker.controller) {
navigator.serviceWorker.addEventListener('controllerchange', function() {
showNotification()
})
}
window.addEventListener('load', function() {
navigator.serviceWorker.register('/sw.js')
})
}
function showNotification() {
if (GLOBAL_CONFIG.Snackbar) {
var snackbarBg =
document.documentElement.getAttribute('data-theme') === 'light' ?
GLOBAL_CONFIG.Snackbar.bgLight :
GLOBAL_CONFIG.Snackbar.bgDark
var snackbarPos = GLOBAL_CONFIG.Snackbar.position
Snackbar.show({
text: '✨ 有文章更新啦！ 👉',
backgroundColor: snackbarBg,
duration: 500000,
pos: snackbarPos,
actionText: '🍭查看新品🍬',
actionTextColor: '#fff',
onActionClick: function(e) {
location.reload()
},
})
} else {
var showBg =
document.documentElement.getAttribute('data-theme') === 'light' ?
'#49b1f5' :
'#1f1f1f'
var cssText = `top: 0; background: ${showBg};`
document.getElementById('app-refresh').style.cssText = cssText
}
}</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>